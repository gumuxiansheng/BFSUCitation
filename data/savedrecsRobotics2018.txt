FN Clarivate Analytics Web of Science
VR 1.0
PT J
AU Kleawsirikul, N
   Mitake, H
   Hasegawa, S
AF Kleawsirikul, Nutnaree
   Mitake, Hironori
   Hasegawa, Shoichi
TI Unsupervised embrace pose recognition method for stuffed-toy robot
SO ADVANCED ROBOTICS
LA English
DT Article
DE Embrace recognition; embrace interaction; k-means; touch sensor;
   soft-stuffed robot
AB This paper presents a new approach to model and recognize embrace interaction based on an embrace-comfortable fabric-based touchpad attached to a stuffed-toy robot with k-mean clustering of location-based features. Evaluation of the method demonstrated its ability to recognize embrace poses in new users with a suitable number of clusters. Consequently, the proposed class assignment method, which assigned classes based on the most common patterns, was used to determine the number of clusters in the model selection experiment. The experimental results showed that the selected model could obtain sufficient recognition performance, which contributed to a guideline for model selection, based directly on variations of embraces without requiring ground truths. This guideline could potentially be applied to different target populations and definitions of the embrace pose.
C1 [Kleawsirikul, Nutnaree] Tokyo Inst Technol, Interdisciplinary Grad Sch Sci & Engn, Dept Computat Intelligence & Syst Sci, Yokohama, Kanagawa, Japan.
   [Mitake, Hironori; Hasegawa, Shoichi] Tokyo Inst Technol, Lab Future Interdisciplinary Res Sci & Technol, Yokohama, Kanagawa, Japan.
RP Kleawsirikul, N (reprint author), Tokyo Inst Technol, Hasegawa Shoichi Lab R2 20, Midor IWard, 4259 Nagatsuta, Yokohama, Kanagawa, Japan.
EM cnk@haselab.net
FU Japan Society for the Promotion of Science (JSPS) KAKENHI [JP24656164]
FX This research is partially supported by Japan Society for the Promotion
   of Science (JSPS) KAKENHI [grant number JP24656164].
CR Altun K, 2015, PATTERN RECOGN LETT, V66, P31, DOI 10.1016/j.patrec.2014.10.016
   Cohen S, 2015, PSYCHOL SCI, V26, P135, DOI 10.1177/0956797614559284
   Cooney MD, 2012, IEEE INT C INT ROBOT, P1420, DOI 10.1109/IROS.2012.6385956
   Cypress, 2017, AN75400 PSOC 3 PSOC
   dos Santos KB., 2012, THESIS MIT CAMBRIDGE
   Flagg A, 2013, P INT C TANG EMB EMB, P25
   Forsell LM, 2012, COMPR PSYCHOL, V1, P2
   Goutte C, 1999, NEUROIMAGE, V9, P298, DOI 10.1006/nimg.1998.0391
   Goutte C, 2001, HUM BRAIN MAPP, V13, P165, DOI 10.1002/hbm.1031
   HARLOW HF, 1958, AM PSYCHOL, V13, P673, DOI 10.1037/h0047884
   HUBERT L, 1985, J CLASSIF, V2, P193, DOI 10.1007/BF01908075
   Hughes Dana, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P2315, DOI 10.1109/ICRA.2017.7989267
   Hutson S, 2011, LECT NOTES COMPUT SC, V6974, P578, DOI 10.1007/978-3-642-24600-5_61
   Inaba M, 1996, IROS 96 - PROCEEDINGS OF THE 1996 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS - ROBOTIC INTELLIGENCE INTERACTING WITH DYNAMIC WORLDS, VOLS 1-3, P450, DOI 10.1109/IROS.1996.570816
   Jung M, 2017, J MULTIMODAL USER IN, V11, P81, DOI 10.1007/s12193-016-0232-9
   Kaboli M, 2015, ADV ROBOTICS, V29, P1411, DOI 10.1080/01691864.2015.1095652
   Kim YM, 2010, IEEE T CONSUM ELECTR, V56, P1979, DOI 10.1109/TCE.2010.5606355
   Kleawsirikul N, 2017, IEEE ROMAN, P883, DOI 10.1109/ROMAN.2017.8172407
   Light KC, 2005, BIOL PSYCHOL, V69, P5, DOI 10.1016/j.biopsycho.2004.11.002
   Mathews J., 2004, NUMERICAL METHODS US
   ROUSSEEUW PJ, 1987, J COMPUT APPL MATH, V20, P53, DOI 10.1016/0377-0427(87)90125-7
   Shibata T, 2001, IEEE ASME INT C ADV, P1053, DOI 10.1109/AIM.2001.936838
   Shiina M, 2008, JSME ANN C ROB MECH
   Souza C, 2014, ACCORD NET FRAMEWORK
   Sugiura Y, 2011, P 24 ANN ACM S US IN, P509
   Takase Y, 2013, PROC SICE ANN CONF, P213
   Wada K, 2005, IEEE INT CONF ROBOT, P2785
   Wada K, 2006, IEEE INT CONF ROBOT, P3966, DOI 10.1109/ROBOT.2006.1642310
   wikiHow, 2018, HOW TO HOLD A BAB
NR 29
TC 0
Z9 0
U1 3
U2 3
PU TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND
SN 0169-1864
EI 1568-5535
J9 ADV ROBOTICS
JI Adv. Robot.
PD DEC 17
PY 2018
VL 32
IS 24
BP 1285
EP 1301
DI 10.1080/01691864.2018.1553687
PG 17
WC Robotics
SC Robotics
GA HF8ZQ
UT WOS:000454531100002
DA 2019-02-18
ER

PT J
AU Beckerle, P
   Koiva, R
   Kirchner, EA
   Bekrater-Bodmann, R
   Dosen, S
   Christ, O
   Abbink, DA
   Castellini, C
   Lenggenhager, B
AF Beckerle, Philipp
   Koiva, Risto
   Kirchner, Elsa Andrea
   Bekrater-Bodmann, Robin
   Dosen, Strahinja
   Christ, Oliver
   Abbink, David A.
   Castellini, Claudio
   Lenggenhager, Bigna
TI Feel-Good Robotics: Requirements on Touch for Embodiment in Assistive
   Robotics
SO FRONTIERS IN NEUROROBOTICS
LA English
DT Article
DE embodiment; affective touch; social touch; self-touch; human-machine
   interfaces; tactile feedback; assistive robotics
ID NONINVASIVE SENSORY FEEDBACK; UPPER-EXTREMITY PROSTHESIS; RUBBER HAND;
   VIBROTACTILE; SENSATION; AMPUTEES; FORCE; EXOSKELETON; PROGRESS; SKIN
AB The feeling of embodiment, i.e., experiencing the body as belonging to oneself and being able to integrate objects into one's bodily self-representation, is a key aspect of human self-consciousness and has been shown to importantly shape human cognition. An extension of such feelings toward robots has been argued as being crucial for assistive technologies aiming at restoring, extending, or simulating sensorimotor functions. Empirical and theoretical work illustrates the importance of sensory feedback for the feeling of embodiment and also immersion; we focus on the the perceptual level of touch and the role of tactile feedback in various assistive robotic devices. We critically review how different facets of tactile perception in humans, i.e., affective, social, and self-touch, might influence embodiment. This is particularly important as current assistive robotic devices - such as prostheses, orthoses, exoskeletons, and devices for teleoperation-often limit touch low-density and spatially constrained haptic feedback, i.e., the mere touch sensation linked to an action. Here, we analyze, discuss, and propose how and to what degree tactile feedback might increase the embodiment of certain robotic devices, e.g., prostheses, and the feeling of immersion in human-robot interaction, e.g., in teleoperation. Based on recent findings from cognitive psychology on interactive processes between touch and embodiment, we discuss technical solutions for specific applications, which might be used to enhance embodiment, and facilitate the study of how embodiment might alter human-robot interactions. We postulate that high-density and large surface sensing and stimulation are required to foster embodiment of such assistive devices.
C1 [Beckerle, Philipp] Tech Univ Dortmund, Robot Res Inst, Dept Elect Engn & Informat Technol, Elast Lightweight Robot, Dortmund, Germany.
   [Beckerle, Philipp] Tech Univ Dortmund, Inst Mechatron Syst, Mech Engn, Darmstadt, Germany.
   [Koiva, Risto] Bielefeld Univ, Ctr Excellence Cognit Interact Technol, Neuroinformat Grp, Bielefeld, Germany.
   [Kirchner, Elsa Andrea] German Res Ctr Artificial Intelligence, Robot Innovat Ctr, Bremen, Germany.
   [Kirchner, Elsa Andrea] Univ Bremen, Robot Grp, Bremen, Germany.
   [Bekrater-Bodmann, Robin] Heidelberg Univ, Cent Inst Mental Hlth, Med Fac Mannheim, Dept Cognit & Clin Neurosci, Mannheim, Germany.
   [Dosen, Strahinja] Aalborg Univ, Fac Med, Ctr Sensory Motor Interact, Dept Hlth Sci & Technol, Aalborg, Denmark.
   [Christ, Oliver] Univ Appl Sci & Arts Northwestern Switzerland, Inst Humans Complex Syst, Sch Appl Psychol, Olten, Switzerland.
   [Abbink, David A.] Delft Univ Technol, Dept Cognit Robot, Fac 3mE, Delft Hapt Lab, Delft, Netherlands.
   [Castellini, Claudio] DLR German Aerosp Ctr, Inst Robot & Mechatron, Oberpfaffenhofen, Germany.
   [Lenggenhager, Bigna] Univ Zurich, Dept Psychol, Cognit Neuropsychol, Zurich, Switzerland.
RP Beckerle, P (reprint author), Tech Univ Dortmund, Robot Res Inst, Dept Elect Engn & Informat Technol, Elast Lightweight Robot, Dortmund, Germany.; Beckerle, P (reprint author), Tech Univ Dortmund, Inst Mechatron Syst, Mech Engn, Darmstadt, Germany.
EM philipp.beckerle@tu-dortmund.de
OI Koiva, Risto/0000-0002-7219-775X
FU German Research Foundation (DFG) [5729/311, CA 1389/1]; Independent
   Research Fund Denmark [8022-00243A]; Swiss National Science Foundation
   [170511]; German Research Foundation; Open Access Publishing Fund of
   Technische Universitat Darmstadt, Germany
FX This work received support from the German Research Foundation (DFG)
   through the projects "Users Body Experience and Human-Machine Interfaces
   in (Assistive) Robotics" (no. BE 5729/3& 11), "TACT-HAND: improving
   control of prosthetic hands using tactile sensors and realistic machine
   learning" (no. CA 1389/1), and the project ROBIN (no. 8022-00243A)
   funded by the Independent Research Fund Denmark as well as the Swiss
   National Science Foundation (no. 170511). The support by the German
   Research Foundation and the Open Access Publishing Fund of Technische
   Universitat Darmstadt, Germany is acknowledged.
CR Aggarwal A, 2015, J FIELD ROBOT, V32, P167, DOI 10.1002/rob.21538
   Antfolk C, 2013, IEEE T NEUR SYS REH, V21, P112, DOI 10.1109/TNSRE.2012.2217989
   Antfolk C, 2013, EXPERT REV MED DEVIC, V10, P45, DOI [10.1586/erd.12.68, 10.1586/ERD.12.68]
   Avizzano C. A., 1999, IEEE RSJ INT C INT R
   Bark K, 2015, IEEE T NEUR SYS REH, V23, P51, DOI 10.1109/TNSRE.2014.2327229
   Beckerle P, 2017, FRONT NEUROROBOTICS, V11, DOI 10.3389/fnbot.2017.00032
   Beckerle P, 2017, FRONT NEUROROBOTICS, V11, DOI 10.3389/fnbot.2017.00024
   Bekrater-Bodmann R, 2012, BRAIN RES, V1452, P130, DOI 10.1016/j.brainres.2012.03.001
   Ben-Tzvi P, 2015, IEEE T NEUR SYS REH, V23, P992, DOI 10.1109/TNSRE.2014.2378171
   Bensmaia SJ, 2014, NAT REV NEUROSCI, V15, P313, DOI 10.1038/nrn3724
   Bergamasco Massimo, 2009, Applied Bionics and Biomechanics, V6, P115, DOI 10.1080/11762320902959250
   Botvinick M, 1998, NATURE, V391, P756, DOI 10.1038/35784
   Bovet S, 2018, IEEE T VIS COMPUT GR, V24, P1428, DOI 10.1109/TVCG.2018.2794658
   Bremner A J, 2017, Adv Child Dev Behav, V52, P227, DOI 10.1016/bs.acdb.2016.12.002
   Buscher GH, 2015, ROBOT AUTON SYST, V63, P244, DOI 10.1016/j.robot.2014.09.007
   Castellini C, 2014, FRONT NEUROROBOTICS, V8, P1, DOI 10.3389/fnbot.2014.00022
   Choi W, 2016, BIOMED RES INT, DOI 10.1155/2016/8163098
   Cotton L. T, 2013, LIMB AMPUTATION AETI
   Crucianelli L, 2018, CORTEX, V104, P180, DOI 10.1016/j.cortex.2017.04.018
   Crucianelli Laura, 2013, Front Psychol, V4, P703, DOI 10.3389/fpsyg.2013.00703
   Culbertson H, 2018, IEEE HAPTICS SYM, P32, DOI 10.1109/HAPTICS.2018.8357149
   D'Alonzo M, 2015, IEEE T NEUR SYS REH, V23, P450, DOI 10.1109/TNSRE.2014.2337952
   D'Alonzo M, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0050756
   Dahiya RS, 2010, IEEE T ROBOT, V26, P1, DOI 10.1109/TRO.2009.2033627
   Dieguez S, 2009, CURR BIOL, V19, pR1108, DOI 10.1016/j.cub.2009.10.055
   Dollar AM, 2008, IEEE T ROBOT, V24, P144, DOI 10.1109/TRO.2008.915453
   Dosen S, 2017, IEEE T NEUR SYS REH, V25, P183, DOI 10.1109/TNSRE.2016.2550864
   Ehrsson HH, 2008, BRAIN, V131, P3443, DOI 10.1093/brain/awn297
   Fani S, 2018, IEEE ROBOT AUTOM MAG, V25, P77, DOI 10.1109/MRA.2017.2741579
   Folgheraiter M, 2012, INT J SOC ROBOT, V4, P285, DOI 10.1007/s12369-012-0147-x
   Franceschi M, 2017, IEEE T HAPTICS, V10, P162, DOI 10.1109/TOH.2016.2618377
   Gallo S., 2012, IEEE INT WORKSH ADV
   Gomez-Rodriguez M, 2011, J NEURAL ENG, V8, DOI 10.1088/1741-2560/8/3/036005
   Graczyk EL, 2018, SCI REP-UK, V8, DOI [10.1038/s41598-018-26959-x, 10.1038/s41598-018-26952-x]
   Haans A, 2009, IEEE T HAPTICS, V2, P136, DOI 10.1109/ToH.2009.20
   Hahne JM, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-04255-x
   Hara M, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.01509
   Hertenstein MJ, 2006, EMOTION, V6, P528, DOI 10.1037/1528-3542.6.3.528
   Hertenstein MJ, 2009, EMOTION, V9, P566, DOI 10.1037/a0016108
   Holden MK, 2005, CYBERPSYCHOL BEHAV, V8, P187, DOI 10.1089/cpb.2005.8.187
   Huisman G, 2017, IEEE T HAPTICS, V10, P391, DOI 10.1109/TOH.2017.2650221
   Huynh T. V., 2018, INT S ROB MUN
   Imaizumi S, 2016, CONSCIOUS COGN, V45, P75, DOI 10.1016/j.concog.2016.08.019
   Kern U, 2009, SCHMERZ, V23, P479, DOI 10.1007/s00482-009-0786-5
   Kim J, 2014, NAT COMMUN, V5, DOI 10.1038/ncomms6747
   Kim K, 2010, IEEE-ASME T MECH, V15, P27, DOI 10.1109/TMECH.2009.2013944
   Koiva R., 2013, IEEE ASME INT C ADV
   Li KR, 2017, IEEE SENS J, V17, P2625, DOI 10.1109/JSEN.2017.2674965
   Loken LS, 2009, NAT NEUROSCI, V12, P547, DOI 10.1038/nn.2312
   Lugo-Villeda L. I., 2009, IEEE INT S ROB HUM I
   Makin TR, 2017, NAT BIOMED ENG, V1, DOI 10.1038/s41551-016-0014
   Mallwitz M, 2015, P 13 S ADV SPAC TECH
   Marasco PD, 2011, BRAIN, V134, P747, DOI 10.1093/brain/awq361
   MEEK S G, 1989, Journal of Rehabilitation Research and Development, V26, P53
   Moseley GL, 2012, NEUROSCI BIOBEHAV R, V36, P34, DOI 10.1016/j.neubiorev.2011.03.013
   Niedernhuber M, 2018, NEUROSCI BIOBEHAV R, V92, P1, DOI 10.1016/j.neubiorev.2018.04.020
   O'Malley MK, 2008, MORG KAUF SER INTER, P25, DOI 10.1016/B978-0-12-374017-5.00002-X
   Pacchierotti C, 2017, IEEE T HAPTICS, V10, P580, DOI 10.1109/TOH.2017.2689006
   Pamungkas DS, 2014, I C CONT AUTOMAT ROB, P1706, DOI 10.1109/ICARCV.2014.7064573
   Pazzaglia M, 2016, PHYS LIFE REV, V16, P163, DOI 10.1016/j.plrev.2015.11.006
   Planthaber S., 2018, J SOFTW ENG APPL, V11, P341, DOI [10.4236/jsea.2018.117021, DOI 10.4236/JSEA.2018.117021]
   Prewett MS, 2012, IEEE T SYST MAN CY C, V42, P123, DOI 10.1109/TSMCC.2010.2103057
   Raspopovic S, 2014, SCI TRANSL MED, V6, DOI 10.1126/scitranslmed.3006820
   Rohde M, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0021659
   Roncone A, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0163713
   Rosen B, 2009, SCAND J PLAST RECONS, V43, P260, DOI 10.3109/02844310903113107
   Schofield JS, 2014, EXPERT REV MED DEVIC, V11, P499, DOI 10.1586/17434440.2014.929496
   Sengul A, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0049473
   Shokur S, 2016, SCI REP-UK, V6, DOI 10.1038/srep32293
   Sigrist R, 2015, EXP BRAIN RES, V233, P909, DOI 10.1007/s00221-014-4167-7
   Stephens-Fripp B, 2018, IEEE ACCESS, V6, P6878, DOI 10.1109/ACCESS.2018.2791583
   Strbac M, 2017, IEEE T NEUR SYS REH, V25, P2133, DOI 10.1109/TNSRE.2017.2712287
   Strbac M, 2016, J NEURAL ENG, V13, DOI 10.1088/1741-2560/13/4/046014
   Svensson P, 2017, EXPERT REV MED DEVIC, V14, P439, DOI 10.1080/17434440.2017.1332989
   Synofzik M, 2008, CONSCIOUS COGN, V17, P411, DOI 10.1016/j.concog.2008.03.008
   van Stralen HE, 2014, COGNITION, V131, P147, DOI 10.1016/j.cognition.2013.11.020
   Veneman JF, 2017, ADVANCES IN COOPERATIVE ROBOTICS, P840
   Weber B., 2015, INT C U ACC HUM COMP
   Weiss P, 2006, TXB NEURAL REPAIR RE, P182
   Witteveen HJB, 2015, PROSTHET ORTHOT INT, V39, P204, DOI 10.1177/0309364614522260
   Zou L, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17112653
NR 81
TC 0
Z9 0
U1 4
U2 4
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1662-5218
J9 FRONT NEUROROBOTICS
JI Front. Neurorobotics
PD DEC 11
PY 2018
VL 12
AR 84
DI 10.3389/fnbot.2018.00084
PG 7
WC Computer Science, Artificial Intelligence; Robotics; Neurosciences
SC Computer Science; Robotics; Neurosciences & Neurology
GA HD9HC
UT WOS:000452871400001
PM 30618706
OA DOAJ Gold, Green Published
DA 2019-02-18
ER

PT J
AU Singh, S
   Lacotte, J
   Majumdar, A
   Pavone, M
AF Singh, Sumeet
   Lacotte, Jonathan
   Majumdar, Anirudha
   Pavone, Marco
TI Risk-sensitive inverse reinforcement learning via semi- and
   non-parametric methods
SO INTERNATIONAL JOURNAL OF ROBOTICS RESEARCH
LA English
DT Article
DE risk-sensitive inverse reinforcement learning; coherent risk measures;
   non-parametric method; semi-parametric method
ID MARKOV DECISION-PROCESSES; VALUE-AT-RISK; EXPECTED-UTILITY;
   PROSPECT-THEORY; NONSMOOTH
AB The literature on inverse reinforcement learning (IRL) typically assumes that humans take actions to minimize the expected value of a cost function, i.e., that humans are risk neutral. Yet, in practice, humans are often far from being risk neutral. To fill this gap, the objective of this paper is to devise a framework for risk-sensitive (RS) IRL to explicitly account for a human's risk sensitivity. To this end, we propose a flexible class of models based on coherent risk measures, which allow us to capture an entire spectrum of risk preferences from risk neutral to worst case. We propose efficient non-parametric algorithms based on linear programming and semi-parametric algorithms based on maximum likelihood for inferring a human's underlying risk measure and cost function for a rich class of static and dynamic decision-making settings. The resulting approach is demonstrated on a simulated driving game with 10 human participants. Our method is able to infer and mimic a wide range of qualitatively different driving styles from highly risk averse to risk neutral in a data-efficient manner. Moreover, comparisons of the RS-IRL approach with a risk-neutral model show that the RS-IRL framework more accurately captures observed participant behavior both qualitatively and quantitatively, especially in scenarios where catastrophic outcomes such as collisions can occur.
C1 [Singh, Sumeet; Pavone, Marco] Stanford Univ, Dept Aeronaut & Astronaut, 496 Lomita Mall, Stanford, CA 94305 USA.
   [Lacotte, Jonathan] Stanford Univ, Dept Elect Engn, Stanford, CA 94305 USA.
   [Majumdar, Anirudha] Princeton Univ, Dept Mech & Aerosp Engn, Princeton, NJ 08544 USA.
RP Singh, S (reprint author), Stanford Univ, Dept Aeronaut & Astronaut, 496 Lomita Mall, Stanford, CA 94305 USA.
EM ssingh19@stanford.edu
FU Office of Naval Research (ONR), Science of Autonomy Program
   [N00014-15-1-2673]; Toyota Research Institute (TRI)
FX The author(s) disclosed receipt of the following financial support for
   the research, authorship, and/or publication of this article: The
   authors were partially supported by the Office of Naval Research (ONR),
   Science of Autonomy Program (contract number N00014-15-1-2673) and by
   the Toyota Research Institute (TRI). This article solely reflects the
   opinions and conclusions of its authors and not ONR, TRI, or any other
   Toyota entity.
CR Abbeel P, 2005, INT C MACH LEARN
   Abbeel P, 2004, INT C MACH LEARN
   Acerbi C, 2002, J BANK FINANC, V26, P1505, DOI 10.1016/S0378-4266(02)00281-9
   Acerbi C, 2002, J BANK FINANC, V26, P1487, DOI 10.1016/S0378-4266(02)00283-2
   Allais M, 1953, ECONOMETRICA, V21, P503, DOI 10.2307/1907921
   ApS M, 2017, MOSEK OPTIMIZATION S
   Artzner P, 1999, MATH FINANC, V9, P203, DOI 10.1111/1467-9965.00068
   Axelrod A, 2016, IEEE DECIS CONTR P, P5833, DOI 10.1109/CDC.2016.7799166
   Baeuerle N, 2011, MATH METHOD OPER RES, V74, P361, DOI 10.1007/s00186-011-0367-0
   Barberis NC, 2013, J ECON PERSPECT, V27, P173, DOI 10.1257/jep.27.1.173
   Burke JV, 2005, SIAM J OPTIMIZ, V15, P751, DOI 10.1137/030601296
   Carton D, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0167021
   Chen XJ, 2012, MATH PROGRAM, V134, P71, DOI 10.1007/s10107-012-0569-0
   Chow Y, 2015, ADV NEURAL INFORM PR
   Chow Y, 2014, AM CONTR C
   Eichhorn A, 2005, SIAM J OPTIMIZ, V16, P69, DOI 10.1137/040605217
   ELLSBERG D, 1961, Q J ECON, V75, P643, DOI 10.2307/1884324
   Englert P, 2015, INT S ROB RES
   FILAR JA, 1989, MATH OPER RES, V14, P147, DOI 10.1287/moor.14.1.147
   Finn C, 2016, INT C MACH LEARN
   Geibel P, 2005, J ARTIF INTELL RES, V24, P81, DOI 10.1613/jair.1666
   GILBOA I, 1989, J MATH ECON, V18, P141, DOI 10.1016/0304-4068(89)90018-9
   Gilboa I, 2016, READINGS FORMAL EPIS
   Glimcher P, 2014, NEUROECONOMICS
   Gul F, 2014, ECONOMETRICA, V82, P1, DOI 10.3982/ECTA9188
   Hey JD, 2010, J RISK UNCERTAINTY, V41, P81, DOI 10.1007/s11166-010-9102-0
   HOWARD RA, 1972, MANAGE SCI, V18, P356, DOI 10.1287/mnsc.18.7.356
   Hsu M, 2005, SCIENCE, V310, P1680, DOI 10.1126/science.1115327
   KAHNEMAN D, 1979, ECONOMETRICA, V47, P263, DOI 10.2307/1914185
   Kolter JZ, 2007, ADV NEURAL INFORM PR
   Kretzschmar H, 2016, INT J ROBOT RES, V35, P1352, DOI 10.1177/0278364915619772
   Kuderer M, 2015, P IEEE C ROB AUT
   Lanza A, 2017, NUMER MATH, V136, P343, DOI 10.1007/s00211-016-0842-x
   Levine S, 2012, INT C MACH LEARN
   Lofberg J, 2004, IEEE INT S COMP AID
   Majumdar A, 2017, INT S ROB RES
   Majumdar A, 2017, ROBOTICS SCI SYSTEMS
   Mihatsch O, 2002, MACH LEARN, V49, P267, DOI 10.1023/A:1017940631555
   Mombaur K, 2010, AUTON ROBOT, V28, P369, DOI 10.1007/s10514-009-9170-7
   Ng A, 2000, INT C MACH LEARN
   Nilim A, 2005, OPER RES, V53, P780, DOI 10.1287/opre.1050.0216
   Osogami T, 2012, ADV NEURAL INFORM PR
   Park T, 2013, ROB SCI SYST WORKSH
   Petrik M, 2012, P C UNC ART INT
   Prashanth LA, 2016, INT C MACH LEARN
   QUIGGIN J, 1982, J ECON BEHAV ORGAN, V3, P323, DOI 10.1016/0167-2681(82)90008-7
   Rabin M, 2000, ECONOMETRICA, V68, P1281, DOI 10.1111/1468-0262.00158
   Ramachandran D, 2007, INT JOINT C ART INT
   Ratliff LJ, 2017, RISK SENSITIVE INVER
   Rockafellar R, 2000, J RISK, V2, P21, DOI DOI 10.21314/JOR.2000.038
   Rockafellar RT, 2002, J BANK FINANC, V26, P1443, DOI 10.1016/S0378-4266(02)00271-6
   Rockafellar RT, 2007, OR TOOLS APPL GLIMPS
   Russell S, 1998, P COMP LEARN THEOR
   Ruszczynski A, 2010, MATH PROGRAM, V125, P235, DOI 10.1007/s10107-010-0393-3
   Sadigh D, 2016, IEEE RSJ INT C INT R
   Sadigh D., 2016, ROBOTICS SCI SYSTEMS
   Shapiro A, 2014, LECT STOCHASTIC PROG
   Shapiro A, 2009, OPER RES LETT, V37, P143, DOI 10.1016/j.orl.2009.02.005
   Shen Y, 2014, NEURAL COMPUT, V26, P1298, DOI 10.1162/NECO_a_00600
   Tamar A, 2012, INT C MACH LEARN
   Tamar A, 2017, IEEE T AUTOMAT CONTR, V62, P3323, DOI 10.1109/TAC.2016.2644871
   Torrance G W, 1989, Int J Technol Assess Health Care, V5, P559
   VIRES Simulationstechnologie GmbH, 2017, VTD VIRT TEST DRIV
   Waugh K, 2011, INT C MACH LEARN
   Wu CB, 1999, J MATH ANAL APPL, V231, P47, DOI 10.1006/jmaa.1998.6203
   Wulfmeier M, 2015, MAXIMUM ENTROPY DEEP
   Xu H, 2010, ADV NEURAL INFORM PR
   YAARI ME, 1987, ECONOMETRICA, V55, P95, DOI 10.2307/1911158
   Ziebart BD, 2009, IEEE RSJ INT C INT R
   Ziebart BD, 2008, P AAAI C ART INT
   Zucker M, 2010, P IEEE C ROB AUT
NR 71
TC 0
Z9 0
U1 0
U2 0
PU SAGE PUBLICATIONS LTD
PI LONDON
PA 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND
SN 0278-3649
EI 1741-3176
J9 INT J ROBOT RES
JI Int. J. Robot. Res.
PD DEC
PY 2018
VL 37
IS 13-14
SI SI
BP 1713
EP 1740
DI 10.1177/0278364918772017
PG 28
WC Robotics
SC Robotics
GA HI6AW
UT WOS:000456536600011
DA 2019-02-18
ER

PT J
AU Obaid, M
   Aylett, R
   Barendregt, W
   Basedow, C
   Corrigan, LJ
   Hall, L
   Jones, A
   Kappas, A
   Kuster, D
   Paiva, A
   Papadopoulos, F
   Serholt, S
   Castellano, G
AF Obaid, Mohammad
   Aylett, Ruth
   Barendregt, Wolmet
   Basedow, Christina
   Corrigan, Lee J.
   Hall, Lynne
   Jones, Aidan
   Kappas, Arvid
   Kuester, Dennis
   Paiva, Ana
   Papadopoulos, Fotios
   Serholt, Sofia
   Castellano, Ginevra
TI Endowing a Robotic Tutor with Empathic Qualities: Design and Pilot
   Evaluation
SO INTERNATIONAL JOURNAL OF HUMANOID ROBOTICS
LA English
DT Article
DE Robot; tutor; empathy; education; children
ID MULTI-TOUCH TABLES; PEDAGOGICAL AGENTS; AFFECT RECOGNITION; CLASSROOM;
   EMOTION; NEUROSCIENCE; CHALLENGES; CHILDREN; BEHAVIOR
AB As increasingly more research efforts are geared towards creating robots that can teach and interact with children in educational contexts, it has been speculated that endowing robots with artificial empathy may facilitate learning. In this paper, we provide a background to the concept of empathy, and how it factors into learning. We then present our approach to equipping a robotic tutor with several empathic qualities, describing the technical architecture and its components, a map-reading learning scenario developed for an interactive multitouch table, as well as the pedagogical and empathic strategies devised for the robot. We also describe the results of a pilot study comparing the robotic tutor with these empathic qualities against a version of the tutor without them. The pilot study was performed with 26 school children aged 10-11 at their school. Results revealed that children in the test condition indeed rated the robot as more empathic than children in the control condition. Moreover, we explored several related measures, such as relational status and learning effect, yet no other significant differences were found. We further discuss these results and provide insights into future directions.
C1 [Obaid, Mohammad; Castellano, Ginevra] Uppsala Univ, Dept Informat Technol, Uppsala, Sweden.
   [Aylett, Ruth] Heriot Watt Univ, Math & Comp Sci, Edinburgh, Midlothian, Scotland.
   [Barendregt, Wolmet] Univ Gothenburg, Dept Appl IT, Gothenburg, Sweden.
   [Basedow, Christina] Vancouver Isl Univ, Dept Psychol, Nanaimo, BC, Canada.
   [Corrigan, Lee J.; Jones, Aidan] Univ Birmingham, Dept Elect Elect & Syst Engn, Birmingham, W Midlands, England.
   [Hall, Lynne] Univ Sunderland, Fac Comp Sci, Sunderland, Durham, England.
   [Kappas, Arvid] Jacobs Univ Bremen, Dept Psychol & Methods, Bremen, Germany.
   [Kuester, Dennis] Univ Bremen, Dept Comp Sci, Bremen, Germany.
   [Paiva, Ana] Univ Lisbon, Inst Super Tecn, IINESC ID, Lisbon, Portugal.
   [Papadopoulos, Fotios] Plymouth Univ, Sch Comp Elect & Math, Plymouth, Devon, England.
   [Serholt, Sofia] Chalmers Univ Technol, Dept Comp Sci & Engn, Gothenburg, Sweden.
RP Obaid, M (reprint author), Uppsala Univ, Dept Informat Technol, Uppsala, Sweden.
EM mohammad.obaid@it.uu.se
OI Barendregt, Wolmet/0000-0003-0730-7286
FU European Commission (EC); EU FP7 [ICT-317923]; Swedish Research Council
   [2015-04378]; COIN project - Swedish Foundation for Strategic Research
   [RIT15-0133]
FX Thanks to the students and teachers, from Sutton Park Community Primary
   School, for their support and participation. Also, thanks to all of the
   EMOTE project's team. This work was supported by the European Commission
   (EC) and was funded by the EU FP7 ICT-317923 project EMOTE. The work was
   partly supported by the Swedish Research Council (Grant No. 2015-04378)
   and the COIN project (RIT15-0133) funded by the Swedish Foundation for
   Strategic Research. The authors are solely responsible for the content
   of this publication. It does not represent the opinion of the EC, and
   the EC is not responsible for any use that might be made of data
   appearing therein.
CR Alves-Oliveira P., 2016, 2016 AAAI FALL S SER
   Anghileri J, 2006, J MATH TEACH EDUC, V9, P33, DOI 10.1007/s10857-006-9005-9
   Bartneck C., 2003, P 2003 INT C DES PLE, P55, DOI [10.1145/782896.782911, DOI 10.1145/782896.782911]
   Batson C. Daniel, 2009, THESE THINGS CALLED
   Baxter P, 2012, ACMIEEE INT CONF HUM, P105
   Belpaeme T, 2013, LECT NOTES ARTIF INT, V8239, P452, DOI 10.1007/978-3-319-02675-6_45
   Boucsein W, 2012, ELECTRODERMAL ACTIVITY, SECOND EDITION, P1, DOI 10.1007/978-1-4614-1126-0
   Cacioppo JT, 2008, LONELINESS HUMAN NAT
   Castellano Ginevra, 2013, Artificial Intelligence in Education. Proceedings of 16th International Conference (AIED 2013): LNCS 7926, P733, DOI 10.1007/978-3-642-39112-5_100
   Castellano G., 2016, AUTON ROBOT, P1
   Castellano G, 2014, ACM T INTERACT INTEL, V4, DOI 10.1145/2622615
   Castellano G, 2013, INT J HUM ROBOT, V10, DOI 10.1142/S0219843613500102
   Castellano G, 2010, J MULTIMODAL USER IN, V3, P89, DOI 10.1007/s12193-009-0033-5
   Castellano G, 2010, INTERACT STUD, V11, P201, DOI 10.1075/is.11.2.04cas
   Clabaugh C, 2015, 5TH INTERNATIONAL CONFERENCE ON DEVELOPMENT AND LEARNING AND ON EPIGENETIC ROBOTICS (ICDL-EPIROB), P314, DOI 10.1109/DEVLRN.2015.7346164
   Coeckelbergh M., 2010, STUD ETHICS LAW TECH, V4
   Corrigan L. J., 2016, ENGAGEMENT PERCEPTIO, P29
   Costa S, 2018, INT J HUM ROBOT, V15, DOI 10.1142/S0219843618500068
   DAHLBACK N, 1993, KNOWL-BASED SYST, V6, P258, DOI 10.1016/0950-7051(93)90017-N
   Davis M. H, 1994, EMPATHY SOCIAL PSYCH
   DAVIS MH, 1983, J PERS SOC PSYCHOL, V44, P113, DOI 10.1037//0022-3514.44.1.113
   Decety J, 2008, DEV PSYCHOPATHOL, V20, P1053, DOI 10.1017/S0954579408000503
   DECI EL, 1991, EDUC PSYCHOL-US, V26, P325, DOI 10.1207/s15326985ep2603&4_6
   Faul F., G POWER 3 FLEXIBLE S, V39, P175
   Feshbach ND, 2009, SOCIAL NEUROSCIENCE OF EMPATHY, P85
   Fong T, 2003, ROBOT AUTON SYST, V42, P143, DOI 10.1016/S0921-8890(02)00372-X
   Fridin M, 2014, COMPUT EDUC, V70, P53, DOI 10.1016/j.compedu.2013.07.043
   Fuertes JN, 2006, PSYCHOTHERAPY, V43, P480, DOI 10.1037/0033-3204.43.4.480
   Gordon Goren, 2016, P 30 AAAI C ART INT, P3951
   Graesser A. C., 1999, Cognitive Systems Research, V1, P35, DOI 10.1016/S1389-0417(99)00005-4
   Greenberg LS, 2001, PSYCHOTHERAPY, V38, P380, DOI 10.1037//0033-3204.38.4.380
   Hall L, 2016, PROCEEDINGS OF THE 15TH INTERNATIONAL CONFERENCE ON INTERACTION DESIGN AND CHILDREN (IDC2016), P311, DOI 10.1145/2930674.2930719
   Hastie H, 2016, ICMI'16: PROCEEDINGS OF THE 18TH ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P256, DOI 10.1145/2993148.2993169
   Hatfield E., 1993, CURRENT DIRECTIONS P, V2, P96, DOI DOI 10.1111/1467-8721.EP10770953
   Hattie J, 2007, REV EDUC RES, V77, P81, DOI 10.3102/003465430298487
   Hess U, 2013, PERS SOC PSYCHOL REV, V17, P142, DOI 10.1177/1088868312472607
   Higgins S, 2012, BRIT J EDUC TECHNOL, V43, P1041, DOI 10.1111/j.1467-8535.2011.01259.x
   Higgins SE, 2011, INT J COMP-SUPP COLL, V6, P515, DOI 10.1007/s11412-011-9131-y
   Janarthanam S., 2015, P SEM DIAL 2015 SEM, P182
   Johnson W. Lewis, 2004, GENERATING SOCIALLY, P254
   Johnson WL, 2000, INT J ARTIFICIAL INT, V11, P47
   Jones A., 2015, EMPATHIC ROBOTIC TUT
   Jones A., 2015, P WONDER INT WORKSH
   Kappas A., 2015, 1 INT CONV PSYCH SCI
   Kappas A, 2013, HANDB COMMUN SCI, V2, P131
   Kdzierski J., 2015, INT J HUM ROBOT, V12
   Kennedy J, 2016, ELEVENTH ACM/IEEE INTERNATIONAL CONFERENCE ON HUMAN ROBOT INTERACTION (HRI'16), P231, DOI 10.1109/HRI.2016.7451757
   Kennedy J, 2015, ACMIEEE INT CONF HUM, P67, DOI 10.1145/2696454.2696457
   Kory Westlund Jacqueline M, 2017, Front Hum Neurosci, V11, P295, DOI 10.3389/fnhum.2017.00295
   Kuster D., 2017, CYBEREMOTIONS, P71
   Leite Iolanda, 2012, Social Robotics. 4th International Conference (ICSR 2012). Proceedings, P298, DOI 10.1007/978-3-642-34103-8_30
   Leite I, 2013, INT J SOC ROBOT, V5, P291, DOI 10.1007/s12369-013-0178-y
   Leite I, 2013, ACMIEEE INT CONF HUM, P41, DOI 10.1109/HRI.2013.6483500
   Leyzberg D, 2014, ACMIEEE INT CONF HUM, P423, DOI 10.1145/2559636.2559671
   Li J, 2015, INT J HUM-COMPUT ST, V77, P23, DOI 10.1016/j.ijhcs.2015.01.001
   Liu CC, 2008, IEEE T ROBOT, V24, P883, DOI 10.1109/TRO.2008.2001362
   Lusk MM, 2007, APPL COGNITIVE PSYCH, V21, P747, DOI 10.1002/acp.1347
   Mauss I, 2009, COGNITION EMOTION, V23, P209, DOI 10.1080/02699930802204677
   Meghdari A, 2018, INT J HUM ROBOT, V15, DOI 10.1142/S0219843618500196
   Moreno R, 2001, COGNITION INSTRUCT, V19, P177, DOI 10.1207/S1532690XCI1902_02
   Mubin O., 2013, TECHNOLOGY ED LEARNI, V1, P209, DOI DOI 10.2316/J0URNAL.209.2013.1.209-0015
   Papadopoulos F, 2016, INTERACT STUD, V17, P321, DOI 10.1075/is.17.3.01pap
   Parson M. L., 1998, STRATEGIES, V11, P30
   Pereira Andre, 2008, P 7 INT JOINT C AUT, V3, P1253
   Powers A., 2007, 2007 2nd Annual Conference on Human-Robot Interaction (HRI), P145
   Ramachandran Aditi, 2017, 2017 12th ACM/IEEE International Conference on Human-Robot Interaction (HRI), P146, DOI 10.1145/2909824.3020209
   Ribeiro T., 2014, P IVA 2014 WORKSH AR
   Rich C, 2010, ACMIEEE INT CONF HUM, P375, DOI 10.1109/HRI.2010.5453163
   Robison JL, 2009, FRONT ARTIF INTEL AP, V200, P25, DOI 10.3233/978-1-60750-028-5-25
   Russell JA, 2009, COGNITION EMOTION, V23, P1259, DOI 10.1080/02699930902809375
   Sabanovic S, 2014, J HUM-ROBOT INTERACT, V3, P70, DOI 10.5898/JHRI.3.1.Sabanovic
   Saerbeck M, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1613
   Serholt S, 2017, AI SOC, V32, P613, DOI 10.1007/s00146-016-0667-2
   Serholt S, 2014, IEEE-RAS INT C HUMAN, P1134, DOI 10.1109/HUMANOIDS.2014.7041511
   Sharkey AJC, 2016, ETHICS INF TECHNOL, V18, P283, DOI 10.1007/s10676-016-9387-z
   Sharkey N, 2010, INTERACT STUD, V11, P161, DOI 10.1075/is.11.2.o1sha
   Singer T, 2009, ANN NY ACAD SCI, V1156, P81, DOI 10.1111/j.1749-6632.2009.04418.x
   Stueber K., 2017, STANFORD ENCY PHILOS
   Tanaka F, 2012, J HUM-ROBOT INTERACT, V1, P78, DOI 10.5898/JHRI.1.1.Tanaka
   Traum DR, 2003, TEXT SPEECH LANG TEC, V22, P325
   Vanderborght B., 2012, PALADYN, V3, P209, DOI [10.2478/s13230-013-0107-7, DOI 10.2478/S13230-013-0107-7]
   Benitti FBV, 2012, COMPUT EDUC, V58, P978, DOI 10.1016/j.compedu.2011.10.006
   Verenikina I., 2008, LEARNING LEARNER EXP, P161
   Vollmer AL, 2018, SCI ROBOT, V3, DOI 10.1126/scirobotics.aat7111
   Warren C, 2012, THESIS
   Wood D, 1996, OXFORD REV EDUC, V22, P5, DOI 10.1080/0305498960220101
   Yik M, 2011, EMOTION, V11, P705, DOI 10.1037/a0023980
   Yilmaz R, 2012, COMPUT EDUC, V59, P828, DOI 10.1016/j.compedu.2012.03.020
   Zeng ZH, 2009, IEEE T PATTERN ANAL, V31, P39, DOI 10.1109/TPAMI.2008.52
NR 89
TC 0
Z9 0
U1 0
U2 0
PU WORLD SCIENTIFIC PUBL CO PTE LTD
PI SINGAPORE
PA 5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE
SN 0219-8436
EI 1793-6942
J9 INT J HUM ROBOT
JI Int. J. Humanoid Robot.
PD DEC
PY 2018
VL 15
IS 6
AR 1850025
DI 10.1142/S0219843618500251
PG 29
WC Robotics
SC Robotics
GA HH3AU
UT WOS:000455592000002
DA 2019-02-18
ER

PT J
AU Jang, I
   Shin, HS
   Tsourdos, A
AF Jang, Inmo
   Shin, Hyo-Sang
   Tsourdos, Antonios
TI Anonymous Hedonic Game for Task Allocation in a Large-Scale Multiple
   Agent System
SO IEEE TRANSACTIONS ON ROBOTICS
LA English
DT Article
DE Coalition formation; distributed robot systems; multi-robot systems;
   networked robots; task allocation
ID SWARM ROBOTIC SYSTEMS; COALITION-FORMATION; STABILITY; OPTIMIZATION;
   TAXONOMY; POLICIES; UAVS
AB This paper proposes a novel game-theoretical autonomous decision-making framework to address a task allocation problem for a swarm of multiple agents. We consider cooperation of self-interested agents, and show that our proposed decentralized algorithm guarantees convergence of agents with social inhibition to a Nash stable partition (i. e., social agreement) within polynomial time. The algorithm is simple and executable based on local interactions with neighbor agents under a strongly connected communication network and even in asynchronous environments. We analytically present a mathematical formulation for computing the lower bound of suboptimality of the outcome, and additionally show that at least 50% of suboptimality can be guaranteed if social utilities are nondecreasing functions with respect to the number of coworking agents. The results of numerical experiments confirm that the proposed framework is scalable, fast adaptable against dynamical environments, and robust even in a realistic situation.
C1 [Jang, Inmo; Shin, Hyo-Sang; Tsourdos, Antonios] Cranfield Univ, Ctr Autonomous & Cyber Phys Syst, Cranfield MK43 0AL, Beds, England.
RP Shin, HS (reprint author), Cranfield Univ, Ctr Autonomous & Cyber Phys Syst, Cranfield MK43 0AL, Beds, England.
EM inmo.jang@cranfield.ac.uk; h.shin@cranfield.ac.uk;
   a.tsourdos@cranfield.ac.uk
OI Jang, Inmo/0000-0002-7492-3938; Shin, Hyo-Sang/0000-0001-9938-0370;
   Tsourdos, Antonios/0000-0002-3966-7633
FU International Joint Research Programme with Chungnam National University
   [EFA3004Z]
FX This work was supported by International Joint Research Programme with
   Chungnam National University under Grant EFA3004Z.
CR Acikmese B, 2015, ASIAN J CONTROL, V17, P1105, DOI 10.1002/asjc.982
   Bandyopadhyay S, 2017, IEEE T ROBOT, V33, P1103, DOI 10.1109/TRO.2017.2705044
   Banerjee S, 2001, SOC CHOICE WELFARE, V18, P135, DOI 10.1007/s003550000067
   Bekmezci I, 2013, AD HOC NETW, V11, P1254, DOI 10.1016/j.adhoc.2012.12.004
   Berman S, 2009, IEEE T ROBOT, V25, P927, DOI 10.1109/TRO.2009.2024997
   Bogomolnaia A, 2002, GAME ECON BEHAV, V38, P201, DOI 10.1006/game.2001.0877
   Brambilla M, 2013, SWARM INTELL-US, V7, P1, DOI 10.1007/s11721-012-0075-2
   Brandl F., 2012, P 11 INT C AUT AG MU, P763
   Brutschy A, 2014, AUTON AGENT MULTI-AG, V28, P101, DOI 10.1007/s10458-012-9212-y
   Castello E, 2014, ADV ROBOTICS, V28, P1343, DOI 10.1080/01691864.2014.939104
   Chattopadhyay I, 2009, IEEE T SYST MAN CY B, V39, P1505, DOI 10.1109/TSMCB.2009.2020173
   Choi HL, 2009, IEEE T ROBOT, V25, P912, DOI 10.1109/TRO.2009.2022423
   Clark CM, 2009, DISTRIBUTED AUTONOMOUS ROBOTIC SYSTEMS 8, P261, DOI 10.1007/978-3-642-00644-9_23
   Correll N, 2006, DISTRIBUTED AUTONOMOUS ROBOTIC SYSTEMS 7, P31, DOI 10.1007/4-431-35881-1_4
   Darmann A., 2012, P 8 INT WORKSH INT N, P156
   Darmann A, 2015, LECT NOTES ARTIF INT, V9346, P35, DOI 10.1007/978-3-319-23114-3_3
   Demir N, 2015, P AMER CONTR CONF, P5238, DOI 10.1109/ACC.2015.7172157
   Dimitrov D, 2006, KYBERNETIKA, V42, P453
   Dorigo M., 2014, SCHOLARPEDIA, V9, P1463, DOI DOI 10.4249/SCH0LARPEDIA.1463
   DREZE JH, 1980, ECONOMETRICA, V48, P987, DOI 10.2307/1912943
   Erdelj M, 2017, IEEE PERVAS COMPUT, V16, P24, DOI 10.1109/MPRV.2017.11
   Gerkey BP, 2004, INT J ROBOT RES, V23, P939, DOI 10.1177/0278364904045564
   Guerrero J, 2012, ROBOT AUTON SYST, V60, P1295, DOI 10.1016/j.robot.2012.06.004
   Halasz Adam, 2007, 2007 IEEE/RSJ International Conference on Intelligent Robots and Systems, P2320, DOI 10.1109/IROS.2007.4399528
   Hsieh M. Ani, 2008, Swarm Intelligence, V2, P121, DOI 10.1007/s11721-008-0019-z
   Jang I, 2017, IFAC PAPERSONLINE, V50, P8011, DOI 10.1016/j.ifacol.2017.08.1225
   Jevtic A, 2012, IEEE SYST J, V6, P296, DOI 10.1109/JSYST.2011.2167820
   Johnson L., 2011, INFOTECH AEROSPACE
   Johnson LB, 2016, IEEE CONTR SYST MAG, V36, P45, DOI 10.1109/MCS.2016.2558419
   Kalra N, 2006, DISTRIBUTED AUTONOMOUS ROBOTIC SYSTEMS 7, P91, DOI 10.1007/4-431-35881-1_10
   KANAKIA A, 2016, DISTR AUT ROB SYST, V112, P193
   Karakaya M, 2011, MATH SOC SCI, V61, P157, DOI 10.1016/j.mathsocsci.2011.03.004
   Khamis A., 2015, COOPERATIVE ROBOTS S, P31, DOI DOI 10.1007/978-3-319-18299-5_2
   Korsah GA, 2013, INT J ROBOT RES, V32, P1495, DOI 10.1177/0278364913496484
   Kurdi H., 2016, P AIAA GUID NAV CONT, DOI [10.2514/6.2016-1377, DOI 10.2514/6.2016-1377]
   Labella TH, 2006, ACM T AUTON ADAP SYS, V1, P4, DOI 10.1145/1152934.1152936
   LERMAN K, 2005, SWARM ROB SAB 2004, V3342, P143
   Liu WG, 2007, ADAPT BEHAV, V15, P289, DOI 10.1177/1059712307082088
   Liu WG, 2010, INT J ROBOT RES, V29, P1743, DOI 10.1177/0278364910375139
   Martinoli A, 2004, INT J ROBOT RES, V23, P415, DOI 10.1177/0278364904042197
   Mather TW, 2011, INT J ROBOT RES, V30, P590, DOI 10.1177/0278364910401442
   Nam CJ, 2015, IEEE T AUTOM SCI ENG, V12, P889, DOI 10.1109/TASE.2015.2415514
   Prorok A, 2017, IEEE T ROBOT, V33, P346, DOI 10.1109/TRO.2016.2631593
   Prorok A, 2011, INT J ROBOT RES, V30, P574, DOI 10.1177/0278364910399521
   Rubenstein M, 2014, SCIENCE, V345, P795, DOI 10.1126/science.1254295
   Saad W, 2011, IEEE T MOBILE COMPUT, V10, P1327, DOI 10.1109/TMC.2010.242
   Saad W, 2009, IEEE T WIREL COMMUN, V8, P4580, DOI 10.1109/TWC.2009.080522
   Sahin E, 2005, LECT NOTES COMPUT SC, V3342, P10
   Saska M, 2016, J INTELL ROBOT SYST, V84, P469, DOI 10.1007/s10846-016-0338-z
   Segui-Gasco P, 2015, IEEE INT C INT ROBOT, P2829, DOI 10.1109/IROS.2015.7353766
   Shehory O, 1999, COMPUT INTELL-US, V15, P218, DOI 10.1111/0824-7935.00092
   Shin H.-S., 2014, ENCY AEROSPACE ENG, P1, DOI 10.1002/9780470686652.eae273
   Sung SC, 2007, THEOR DECIS, V62, P31, DOI 10.1007/s11238-006-9022-2
   Zhang Y, 2013, AUTON AGENT MULTI-AG, V26, P389, DOI 10.1007/s10458-012-9196-7
NR 54
TC 0
Z9 0
U1 2
U2 2
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1552-3098
EI 1941-0468
J9 IEEE T ROBOT
JI IEEE Trans. Robot.
PD DEC
PY 2018
VL 34
IS 6
BP 1534
EP 1548
DI 10.1109/TRO.2018.2858292
PG 15
WC Robotics
SC Robotics
GA HE6XO
UT WOS:000453564100009
DA 2019-02-18
ER

PT J
AU Haring, KS
   Watanabe, K
   Velonaki, M
   Tossell, CC
   Finomore, V
AF Haring, Kerstin S.
   Watanabe, Katsumi
   Velonaki, Mari
   Tossell, Chad C.
   Finomore, Victor
TI FFAB-The Form Function Attribution Bias in Human-Robot Interaction
SO IEEE TRANSACTIONS ON COGNITIVE AND DEVELOPMENTAL SYSTEMS
LA English
DT Article
DE Anthropomorphism; attribution bias; form function attribution bias
   (FFAB); human-robot interaction; visual perception
ID ANTHROPOMORPHISM INCREASES TRUST; MIND PERCEPTION; CULTURAL-DIFFERENCES;
   PHYSICALLY PRESENT; SOCIAL ROBOTS; APPEARANCE; CONTEXT
AB People seem to miscalibrate their expectations and interactions with a robot. When it comes to robot design, the anthropomorphism level of the robot form (appearance) has become an increasingly important variable to consider. It is argued here that people base their expectations and perceptions of a robot on its form and attribute functions which do not necessarily mirror the true functions of the robot. The term form function attribution bias (FFAB) refers to the cognitive bias which occurs when people are prone to perceptual errors, leading to a biased interpretation of a robot's functionality. We argue that rather than objectively perceiving the robot's functionalities, people take a cognitive shortcut using the information available to them through visual perception. FFAB intends to outline the implications the design of a robot has on the human predisposition to interact socially with robots. In this theoretical review, we examined the results of several studies suggesting an FFAB. We outline future directions of experimental paradigms and robot design implications.
C1 [Haring, Kerstin S.; Tossell, Chad C.; Finomore, Victor] US Air Force Acad, Dept Behav Sci & Leadership, Colorado Springs, CO 80840 USA.
   [Watanabe, Katsumi] Waseda Univ, Sch Fundamental Sci & Engn, Tokyo, Japan.
   [Velonaki, Mari] Univ New South Wales, Sydney, NSW, Australia.
RP Haring, KS (reprint author), US Air Force Acad, Dept Behav Sci & Leadership, Colorado Springs, CO 80840 USA.
EM kerstin.haring@usafa.edu; katz@waseda.jp; mari.velonaki@unsw.edu.au
OI Velonaki, Mari/0000-0002-7428-0303
FU Postgraduate Research Participation Program at the U.S. Air Force
   Research Laboratory; Air Force Office of Scientific Research Trust and
   Influence Program
FX This work was supported in part by the Postgraduate Research
   Participation Program at the U.S. Air Force Research Laboratory and in
   part by the Air Force Office of Scientific Research Trust and Influence
   Program. The work of K. S. Haring was supported by the 711th Human
   Performance Wing administered by the Oak Ridge Institute for Science and
   Education through an interagency agreement between the U.S. Department
   of Energy and USAFRL.
CR [Anonymous], 2015, ASS PRESS BERLI 0701
   Antos D., 2011, P 25 C ART INT APR, P772
   Bainbridge WA, 2011, INT J SOC ROBOT, V3, P41, DOI 10.1007/s12369-010-0082-7
   Baron-Cohen S., 2013, UNDERSTANDING OTHER
   Bartneck C, 2007, AI SOC, V21, P217, DOI 10.1007/s00146-006-0052-7
   Bartneck C, 2009, INT J SOC ROBOT, V1, P71, DOI 10.1007/s12369-008-0001-3
   Berger J., 1977, STATUS CHARACTERISTI
   Blow M., 2006, P 15 IEEE INT S ROB, P469
   Brohl C, 2016, COMM COM INF SC, V617, P97, DOI 10.1007/978-3-319-40548-3_16
   Brooks D, 2012, P IEEE RAS-EMBS INT, P1715, DOI 10.1109/BioRob.2012.6290714
   Chua HF, 2005, P NATL ACAD SCI USA, V102, P12629, DOI 10.1073/pnas.0506162102
   DAVIS FD, 1989, MIS QUART, V13, P319, DOI 10.2307/249008
   de Visser EJ, 2016, J EXP PSYCHOL-APPL, V22, P331, DOI 10.1037/xap0000092
   DiSalvo Carl F., 2002, P 4 C DES INT SYST P, P321, DOI [10.1145/778712.778756, DOI 10.1145/778712.778756]
   Duffy BR, 2003, ROBOT AUTON SYST, V42, P177, DOI 10.1016/S0921-8890(02)00374-3
   EKMAN P, 1987, J PERS SOC PSYCHOL, V53, P712, DOI 10.1037/0022-3514.53.4.712
   Eyssel F, 2012, BRIT J SOC PSYCHOL, V51, P724, DOI 10.1111/j.2044-8309.2011.02082.x
   Eyssel F, 2012, ACMIEEE INT CONF HUM, P125
   Ferrari F, 2016, INT J SOC ROBOT, V8, P287, DOI 10.1007/s12369-016-0338-y
   Fink Julia, 2012, Social Robotics. 4th International Conference (ICSR 2012). Proceedings, P199, DOI 10.1007/978-3-642-34103-8_20
   Fiske S. T., 2009, SOCIAL BEINGS CORE M
   Fogg B. J., 1997, Human Factors in Computing Systems. CHI 97 Extended Abstracts, P331
   Fussell S. R., 2008, 2008 3rd ACM/IEEE International Conference on Human-Robot Interaction (HRI 2008), P145
   Gray HM, 2007, SCIENCE, V315, P619, DOI 10.1126/science.1134475
   Gray K, 2012, COGNITION, V125, P125, DOI 10.1016/j.cognition.2012.06.007
   Gray K, 2012, PSYCHOL INQ, V23, P101, DOI 10.1080/1047840X.2012.651387
   Gray K, 2011, P NATL ACAD SCI USA, V108, P477, DOI 10.1073/pnas.1015493108
   Hancock PA, 2011, HUM FACTORS, V53, P517, DOI 10.1177/0018720811417254
   Haring K. S., 2013, P WORLD C ENG COMP S, V1, P425
   Haring KS, 2016, INT CONF KNOWL SMART, P265, DOI 10.1109/KST.2016.7440504
   Haring KS, 2016, LECT NOTES ARTIF INT, V9979, P392, DOI 10.1007/978-3-319-47437-3_38
   Haring KS, 2015, PROCEEDINGS OF THE 2015 6TH INTERNATIONAL CONFERENCE ON AUTOMATION, ROBOTICS AND APPLICATIONS (ICARA), P83, DOI 10.1109/ICARA.2015.7081129
   Haring KS, 2015, 2015 INTERNATIONAL CONFERENCE ON CONTROL, AUTOMATION AND ROBOTICS ICCAR 2015, P8, DOI 10.1109/ICCAR.2015.7165993
   Haring KS, 2013, ACMIEEE INT CONF HUM, P131, DOI 10.1109/HRI.2013.6483536
   Haring KS, 2014, INT J AFFECT ENG, V13, P149, DOI [10.5057/ijae.13.149, DOI 10.5057/IJAE.13.149]
   Harman Gilbert, 1999, P ARISTOTELIAN SOC, V99, P315, DOI DOI 10.1111/1467-9264.00062
   Heider F., 2013, PSYCHOL INTERPERSONA
   HOFSTEDE G, 1986, INT J INTERCULT REL, V10, P301, DOI 10.1016/0147-1767(86)90015-5
   Ji LJ, 2000, J PERS SOC PSYCHOL, V78, P943, DOI 10.1037//0022-3514.78.5.943
   Kahn PH, 2006, INTERACT STUD, V7, P405, DOI 10.1075/is.7.3.13kah
   Kahn PH, 2012, ACMIEEE INT CONF HUM, P33
   Kaplan F., 2004, INT J HUM ROBOT, V1, P465, DOI DOI 10.1142/S0219843604000289
   Kiesler S, 2008, SOC COGNITION, V26, P169, DOI 10.1521/soco.2008.26.2.169
   Kopka H., 1999, A GUIDE TO LATEX
   Kose-Bagci H, 2009, ADV ROBOTICS, V23, P1951, DOI 10.1163/016918609X12518783330360
   Lee MK, 2010, 2010 ACM CONFERENCE ON COMPUTER SUPPORTED COOPERATIVE WORK, P31
   Lemaignan S, 2014, ACMIEEE INT CONF HUM, P226, DOI 10.1145/2559636.2559814
   Lewis RS, 2008, PERS SOC PSYCHOL B, V34, P623, DOI 10.1177/0146167207313731
   Li DJ, 2010, INT J SOC ROBOT, V2, P175, DOI 10.1007/s12369-010-0056-9
   Li J, 2015, INT J HUM-COMPUT ST, V77, P23, DOI 10.1016/j.ijhcs.2015.01.001
   Litoiu A, 2015, ACMIEEE INT CONF HUM, P165, DOI 10.1145/2696454.2696456
   Liu P, 2013, ACMIEEE INT CONF HUM, P267, DOI 10.1109/HRI.2013.6483598
   MacDorman K. F., 2005, P 27 ANN M COGN SCI, P21
   Marin Mejia Angie L., 2015, Human Aspects of IT for the Aged Population. Design for Everyday Life. First International Conference, ITAP 2015, held as part of HCI International 2015. Proceedings: LNCS 9194, P300, DOI 10.1007/978-3-319-20913-5_28
   Masuda T, 2001, J PERS SOC PSYCHOL, V81, P922, DOI 10.1037//0022-3514.81.5.922
   Molloy M., 2017, ROGUE FACTORY ROBOT
   Moran R. T., 2014, MANAGING CULTURAL DI
   MORAVEC Hans, 1988, MIND CHILDREN FUTURE
   Mori M, 2012, IEEE ROBOT AUTOM MAG, V19, P98, DOI 10.1109/MRA.2012.2192811
   NASS C, 1994, HUMAN FACTORS IN COMPUTING SYSTEMS, CHI '94 CONFERENCE PROCEEDINGS - CELEBRATING INTERDEPENDENCE, P72
   Nomura T, 2009, 2009 IEEE/WIC/ACM INTERNATIONAL JOINT CONFERENCES ON WEB INTELLIGENCE (WI) AND INTELLIGENT AGENT TECHNOLOGIES (IAT), VOL 2, P108
   Norman DA, 2004, HUM-COMPUT INTERACT, V19, P311, DOI 10.1207/s15327051hci1904_1
   OLIVER RL, 1977, J APPL PSYCHOL, V62, P480, DOI 10.1037/0021-9010.62.4.480
   Pan Y, 2016, FRONT ROBOT AI, V3, DOI 10.3389/frobt.2016.00012
   Ross L., 1977, ADV EXPT SOCIAL PSYC, V10, P173, DOI [10.1177/0961463X11414296, DOI 10.1016/S0065-2601(08)60357-3]
   Ruijten P., 2017, P COMP ACM IEEE INT, P273
   Salem M, 2013, INT J SOC ROBOT, V5, P313, DOI 10.1007/s12369-013-0196-9
   Sandoval EB, 2016, INT J SOC ROBOT, V8, P303, DOI 10.1007/s12369-015-0323-x
   Segall M. H., 1966, INFLUENCE CULTURE VI, V184
   Short E, 2010, ACMIEEE INT CONF HUM, P219, DOI 10.1109/HRI.2010.5453193
   Siegel M, 2009, 2009 IEEE-RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, P2563, DOI 10.1109/IROS.2009.5354116
   Tanaka K., 2014, INT C COLL TECHN, P96
   Tay B, 2014, COMPUT HUM BEHAV, V38, P75, DOI 10.1016/j.chb.2014.05.014
   Vernon RJW, 2014, P NATL ACAD SCI USA, V111, pE3353, DOI 10.1073/pnas.1409860111
   Wagner AR, 2015, PROCEEDINGS OF THE 2015 INTERNATIONAL CONFERENCE ON COLLABORATION TECHNOLOGIES AND SYSTEMS, P485, DOI 10.1109/CTS.2015.7210395
   Wainer Joshua, 2007, 16th IEEE International Conference on Robot and Human Interactive Communication, P872
   Waytz A, 2014, J EXP SOC PSYCHOL, V52, P113, DOI 10.1016/j.jesp.2014.01.005
   Zakour A. B., 2004, P 7 ANN C SO ASS INF, P156
   Zanatto D, 2016, ELEVENTH ACM/IEEE INTERNATIONAL CONFERENCE ON HUMAN ROBOT INTERACTION (HRI'16), P543, DOI 10.1109/HRI.2016.7451847
NR 79
TC 0
Z9 0
U1 5
U2 5
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2379-8920
EI 2379-8939
J9 IEEE T COGN DEV SYST
JI IEEE Trans. Cogn. Dev. Syst.
PD DEC
PY 2018
VL 10
IS 4
BP 843
EP 851
DI 10.1109/TCDS.2018.2851569
PG 9
WC Computer Science, Artificial Intelligence; Robotics; Neurosciences
SC Computer Science; Robotics; Neurosciences & Neurology
GA HD6HK
UT WOS:000452636400002
DA 2019-02-18
ER

PT J
AU Hortensius, R
   Hekele, F
   Cross, ES
AF Hortensius, Ruud
   Hekele, Felix
   Cross, Emily S.
TI The Perception of Emotion in Artificial Agents
SO IEEE TRANSACTIONS ON COGNITIVE AND DEVELOPMENTAL SYSTEMS
LA English
DT Article
DE Artificial agent; emotion; human-robot interaction (HRI)
ID FACIAL EXPRESSIONS; AMYGDALA ACTIVATION; HUMANOID ROBOTS; SOCIAL ROBOTS;
   POINT-LIGHT; FACE; INTERFERENCE; RESPONSES; ANTHROPOMORPHISM; ENGAGEMENT
AB Given recent technological developments in robotics, artificial intelligence, and virtual reality, it is perhaps unsurprising that the arrival of emotionally expressive and reactive artificial agents is imminent. However, if such agents are to become integrated into our social milieu, it is imperative to establish an understanding of whether and how humans perceive emotion in artificial agents. In this review, we incorporate recent findings from social robotics, virtual reality, psychology, and neuroscience to examine how people recognize and respond to emotions displayed by artificial agents. First, we review how people perceive emotions expressed by an artificial agent, such as facial and bodily expressions. Second, we evaluate the similarities and differences in the consequences of perceived emotions in artificial compared to human agents. Besides accurately recognizing the emotional state of an artificial agent, it is critical to understand how humans respond to those emotions. Does interacting with an angry robot induce the same responses in people as interacting with an angry person? Similarly, does watching a robot rejoice when it wins a game elicit similar feelings of elation in the human observer? Here, we provide an overview of the current state of emotion expression and perception during interactions with artificial agents, as well as a clear articulation of the challenges and guiding principles to be addressed as we move ever closer to truly emotional artificial agents.
C1 [Hortensius, Ruud; Hekele, Felix; Cross, Emily S.] Bangor Univ, Sch Psychol, Wales Inst Cognit Neurosci, Bangor LL57 2AS, Gwynedd, Wales.
   [Hortensius, Ruud; Cross, Emily S.] Univ Glasgow, Sch Psychol, Inst Neurosci & Psychol, Glasgow G12 8QB, Lanark, Scotland.
RP Cross, ES (reprint author), Bangor Univ, Sch Psychol, Wales Inst Cognit Neurosci, Bangor LL57 2AS, Gwynedd, Wales.
EM ruud.hortensius@glasgow.ac.uk; f.hekele@bangor.ac.uk;
   emily.cross@glasgow.ac.uk
FU European Research Council [H2020-ERC-2015-StG-67720-SOCIAL ROBOTS]
FX This work was supported by the European Research Council under Grant
   H2020-ERC-2015-StG-67720-SOCIAL ROBOTS.
CR Allison T, 2000, TRENDS COGN SCI, V4, P267, DOI 10.1016/S1364-6613(00)01501-1
   Atkinson AP, 2004, PERCEPTION, V33, P717, DOI 10.1068/p5096
   Aviezer H, 2012, SCIENCE, V338, P1225, DOI 10.1126/science.1224313
   Bartneck C, 2001, USER MODEL USER-ADAP, V11, P279, DOI 10.1023/A:1011811315582
   BARTNECK C, 2004, P DES EM, P32
   Bartneck C, 2008, INTERACT STUD, V9, P415, DOI 10.1075/is.9.3.04bar
   Bazo D, 2010, IEEE INT C INT ROBOT, P5317, DOI 10.1109/IROS.2010.5651469
   Beauchamp MS, 2003, J COGNITIVE NEUROSCI, V15, P991, DOI 10.1162/089892903770007380
   Beck A., 2010, P 3 INT WORKSH AFF I, P37
   Beck A., 2012, ACM T INTERACTIVE IN, V2, P1
   Beck A, 2013, INT J SOC ROBOT, V5, P325, DOI 10.1007/s12369-013-0193-z
   Beck A, 2010, 2010 IEEE RO-MAN, P464, DOI 10.1109/ROMAN.2010.5598649
   Becker-Asano C., 2011, 2011 IEEE WORKSH AFF, P22, DOI DOI 10.1109/WACI.2011.5953147
   Beer J. M., 2010, P HUM FACT ERG SOC A, V54, P2388, DOI [10.1177/154193121005402806, DOI 10.1177/154193121005402806]
   Bernier Emily P, 2010, 2010 IEEE 9th International Conference on Development and Learning (ICDL 2010), P286, DOI 10.1109/DEVLRN.2010.5578828
   Blais C, 2008, PLOS ONE, V3, DOI 10.1371/journal.pone.0003022
   Breazeal C, 2003, INT J HUM-COMPUT ST, V59, P119, DOI 10.1016/S1071-5819(03)00018-1
   Broadbent E, 2017, ANNU REV PSYCHOL, V68, P627, DOI 10.1146/annurev-psych-010416-043958
   Broadbent E, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0072589
   Brscic D, 2015, ACMIEEE INT CONF HUM, P59, DOI 10.1145/2696454.2696468
   Burra N, 2013, J NEUROSCI, V33, P10483, DOI 10.1523/JNEUROSCI.3994-12.2013
   Chaminade T, 2005, INT C DEVEL LEARN, P96
   Chaminade T, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0011577
   Chammat M, 2010, BRAIN RES, V1348, P95, DOI 10.1016/j.brainres.2010.05.051
   Cook J, 2014, PSYCHOL MED, V44, P731, DOI 10.1017/S0033291713001335
   Cosker D, 2011, IEEE I CONF COMP VIS, P2296, DOI 10.1109/ICCV.2011.6126510
   Craig R, 2010, 2010 10th IEEE-RAS International Conference on Humanoid Robots (Humanoids 2010), P647, DOI 10.1109/ICHR.2010.5686272
   Cross ES, 2016, PHILOS T R SOC B, V371, DOI 10.1098/rstb.2015.0075
   Cross ES, 2012, HUM BRAIN MAPP, V33, P2238, DOI 10.1002/hbm.21361
   Darwin C., 2009, EXPRESSION EMOTION M
   Dautenhahn K, 2007, PHILOS T R SOC B, V362, P679, DOI 10.1098/rstb.2006.2004
   de Gelder B, 2006, NAT REV NEUROSCI, V7, P242, DOI 10.1038/nrn1872
   de Gelder B., 2014, NEW FRONT SOC NEUROS, P153, DOI DOI 10.1007/978-3-319-02904-7_9
   de Gelder B, 2010, NEUROSCI BIOBEHAV R, V34, P513, DOI 10.1016/j.neubiorev.2009.10.008
   de Gelder B, 2009, PHILOS T R SOC B, V364, P3475, DOI 10.1098/rstb.2009.0190
   Decety J, 2016, PHILOS T R SOC B, V371, DOI 10.1098/rstb.2015.0077
   Downing PE, 2011, COGN NEUROSCI-UK, V2, P186, DOI 10.1080/17588928.2011.582945
   Dubal S, 2011, SOC COGN AFFECT NEUR, V6, P90, DOI 10.1093/scan/nsq019
   Dyck M, 2008, PLOS ONE, V3, DOI 10.1371/journal.pone.0003628
   EKMAN P, 1971, J PERS SOC PSYCHOL, V17, P124, DOI 10.1037/h0030377
   Ekman P, 2011, EMOT REV, V3, P364, DOI 10.1177/1754073911410740
   Elfenbein HA, 2007, J NONVERBAL BEHAV, V31, P205, DOI 10.1007/s10919-007-0033-7
   Eyssel F. A., 2011, P 24 IEEE RSJ INT C
   Eyssel F, 2012, BRIT J SOC PSYCHOL, V51, P724, DOI 10.1111/j.2044-8309.2011.02082.x
   Eyssel F, 2012, ACMIEEE INT CONF HUM, P125
   Eyssel F, 2010, 2010 IEEE RO-MAN, P646, DOI 10.1109/ROMAN.2010.5598687
   Fabri M., 2002, P AUT AG MULT SYST E
   Ferrari F, 2016, INT J SOC ROBOT, V8, P287, DOI 10.1007/s12369-016-0338-y
   Gendron M, 2014, EMOTION, V14, P251, DOI 10.1037/a0036052
   Gobbini MI, 2011, J COGNITIVE NEUROSCI, V23, P1911, DOI 10.1162/jocn.2010.21574
   Goetz J, 2003, RO-MAN 2003: 12TH IEEE INTERNATIONAL WORKSHOP ON ROBOT AND HUMAN INTERACTIVE COMMUNICATION, PROCEEDINGS, P55
   Gutierrez-Maldonado J., 2013, VIRTUAL REALITY, V18, P61
   Hall J, 2014, ROBOT AUTON SYST, V62, P392, DOI 10.1016/j.robot.2013.09.012
   Hamacher A, 2016, IEEE ROMAN, P493, DOI 10.1109/ROMAN.2016.7745163
   Haring M., 2011, 2011 RO-MAN: The 20th IEEE International Symposium on Robot and Human Interactive Communication, P204, DOI 10.1109/ROMAN.2011.6005263
   Hess U, 2016, PERS SOC PSYCHOL B, V42, P1092, DOI 10.1177/0146167216651851
   Hofree G, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0099934
   Isik L, 2017, P NATL ACAD SCI USA, V114, pE9145, DOI 10.1073/pnas.1714471114
   Itier RJ, 2004, CEREB CORTEX, V14, P132, DOI 10.1093/cercor/bhg111
   Itoh K., 2004, 2004 First IEEE Technical Exhibition Based Conference on Robotics and Automation (IEEE Cat. No.04EX878), P35
   IZARD CE, 1994, PSYCHOL BULL, V115, P288, DOI 10.1037//0033-2909.115.2.288
   Jack RE, 2017, ANNU REV PSYCHOL, V68, P269, DOI 10.1146/annurev-psych-010416-044242
   Jack RE, 2012, P NATL ACAD SCI USA, V109, P7241, DOI 10.1073/pnas.1200155109
   Jack RE, 2012, J EXP PSYCHOL GEN, V141, P19, DOI 10.1037/a0023463
   Joyal CC, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00787
   Kahn PH, 2012, DEV PSYCHOL, V48, P303, DOI 10.1037/a0027033
   Kanwisher N, 1997, J NEUROSCI, V17, P4302
   Katsyri J., 2003, AVSP 2003 INT C AUD, P239
   Katsyri J, 2008, INT J HUM-COMPUT ST, V66, P233, DOI 10.1016/j.ijhcs.2007.10.001
   Kessens J. M., 2009, P INT C AFF COMP INT, P1, DOI DOI 10.1109/ACII.2009.5349582
   Kilner JM, 2003, CURR BIOL, V13, P522, DOI 10.1016/S0960-9822(03)00165-9
   Kim E. H., 2009, P 3 INT C UB INF MAN, P362
   Klapper A, 2014, J COGNITIVE NEUROSCI, V26, P2503, DOI 10.1162/jocn_a_00651
   Kleinsmith A, 2006, INTERACT COMPUT, V18, P1371, DOI 10.1016/j.intcom.2006.04.003
   Kuchenbrandt D., 2011, SOCIAL ROBOTICS
   Kuchenbrandt D, 2013, INT J SOC ROBOT, V5, P409, DOI 10.1007/s12369-013-0197-8
   Kupferberg A, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0039637
   Kupferberg A, 2011, AI SOC, V26, P339, DOI 10.1007/s00146-010-0314-2
   Kwak Sonya S., 2013, 2013 IEEE RO MAN, P180
   Lazzeri N., 2015, FRONT BIOENG BIOTECH, V3, P21
   Lewis M, 2013, INT CONF AFFECT, P97, DOI 10.1109/ACII.2013.23
   Li J, 2015, INT J HUM-COMPUT ST, V77, P23, DOI 10.1016/j.ijhcs.2015.01.001
   Mar RA, 2007, SOC COGN AFFECT NEUR, V2, P199, DOI 10.1093/scan/nsm011
   McDonnell R, 2008, APGV 2008: PROCEEDINGS OF THE SYMPOSIUM ON APPLIED PERCEPTION IN GRAPHICS AND VISUALIZATION, P67
   MILGRAM S, 1963, J ABNORM PSYCHOL, V67, P371, DOI 10.1037/h0040525
   Milgram S., 1964, YALE SCI MAGAZINE, V39, P9
   Miwa H, 2004, IEEE INT CONF ROBOT, P128, DOI 10.1109/ROBOT.2004.1307140
   Moser E, 2007, J NEUROSCI METH, V161, P126, DOI 10.1016/j.jneumeth.2006.10.016
   Muhlberger A, 2009, J NEURAL TRANSM, V116, P735, DOI 10.1007/s00702-008-0108-6
   Muir BM, 1996, ERGONOMICS, V39, P429, DOI 10.1080/00140139608964474
   N'Diaye K, 2009, EMOTION, V9, P798, DOI 10.1037/a0017845
   NADEL J, 2006, LUND U COGNITIVE STU, V128, P79
   Nass C, 1997, J APPL SOC PSYCHOL, V27, P864, DOI 10.1111/j.1559-1816.1997.tb00275.x
   Niedenthal PM, 2012, ANNU REV PSYCHOL, V63, P259, DOI 10.1146/annurev.psych.121208.131605
   Nomura T, 2008, IEEE T ROBOT, V24, P442, DOI 10.1109/TRO.2007.914004
   Nomura T, 2010, INT J SOC ROBOT, V2, P147, DOI 10.1007/s12369-010-0050-2
   Novikova J., 2014, 2 INT C HUM AG INT T, P353
   Pais AL, 2013, INT J SOC ROBOT, V5, P477, DOI 10.1007/s12369-013-0204-0
   Pfeiffer UJ, 2014, NEUROIMAGE, V101, P124, DOI 10.1016/j.neuroimage.2014.06.061
   Press C, 2011, NEUROSCI BIOBEHAV R, V35, P1410, DOI 10.1016/j.neubiorev.2011.03.004
   Preston SD, 2002, BEHAV BRAIN SCI, V25, P1
   Raffard S, 2016, SCHIZOPHR RES, V176, P506, DOI 10.1016/j.schres.2016.06.001
   Read R, 2016, INT J SOC ROBOT, V8, P31, DOI 10.1007/s12369-015-0304-0
   Rehm M, 2012, IEEE-RAS INT C HUMAN, P78, DOI 10.1109/HUMANOIDS.2012.6651502
   Riva G, 2007, CYBERPSYCHOL BEHAV, V10, P45, DOI 10.1089/cpb.2006.9993
   Rizzo AA, 2001, CYBERPSYCHOL BEHAV, V4, P471, DOI 10.1089/109493101750527033
   Roesch EB, 2011, J NONVERBAL BEHAV, V35, P1, DOI 10.1007/s10919-010-0095-9
   Rosenthal-von der Putten AM, 2014, COMPUT HUM BEHAV, V33, P201, DOI 10.1016/j.chb.2014.01.004
   Rosenthal-von der Putten AM, 2013, INT J SOC ROBOT, V5, P17, DOI 10.1007/s12369-012-0173-8
   Said CP, 2010, NEUROPSYCHOLOGIA, V48, P3596, DOI 10.1016/j.neuropsychologia.2010.08.009
   Salem M, 2013, INT J SOC ROBOT, V5, P313, DOI 10.1007/s12369-013-0196-9
   Salvini P, 2010, RO MAN, P1
   Scheeff M., 2002, SOCIALLY INTELLIGENT
   Schilbach L, 2013, BEHAV BRAIN SCI, V36, P393, DOI 10.1017/S0140525X12000660
   Schirmer A, 2017, TRENDS COGN SCI, V21, P216, DOI 10.1016/j.tics.2017.01.001
   Seo SH, 2015, ACMIEEE INT CONF HUM, P125, DOI 10.1145/2696454.2696471
   Shayganfar M, 2012, IEEE INT C INT ROBOT, P4577, DOI 10.1109/IROS.2012.6385901
   Sidner CL, 2005, ARTIF INTELL, V166, P140, DOI 10.1016/j.artint.2005.03.005
   Slater M, 2006, PLOS ONE, V1, DOI 10.1371/journal.pone.0000039
   Spencer-Smith J, 2001, BEHAV RES METH INS C, V33, P115, DOI 10.3758/BF03195356
   Tamagawa R, 2011, INT J SOC ROBOT, V3, P253, DOI 10.1007/s12369-011-0100-4
   Thierry G, 2007, NAT NEUROSCI, V10, P505, DOI 10.1038/nn1864
   Todorov A, 2008, SOC COGN AFFECT NEUR, V3, P119, DOI 10.1093/scan/nsn009
   Todorov A, 2015, ANNU REV PSYCHOL, V66, P519, DOI 10.1146/annurev-psych-113011-143831
   Van den Stock J, 2014, HUM BRAIN MAPP, V35, P492, DOI 10.1002/hbm.22195
   Wan-Ling Chang, 2012, 2012 RO-MAN: The 21st IEEE International Symposium on Robot and Human Interactive Communication, P845, DOI 10.1109/ROMAN.2012.6343857
   Wang Y, 2015, SOC COGN AFFECT NEUR, V10, P1515, DOI 10.1093/scan/nsv043
   Wehrle T, 2000, J PERS SOC PSYCHOL, V78, P105, DOI 10.1037//0022-3514.78.1.105
   Weiss A, 2015, 2015 24TH IEEE INTERNATIONAL SYMPOSIUM ON ROBOT AND HUMAN INTERACTIVE COMMUNICATION (RO-MAN), P381, DOI 10.1109/ROMAN.2015.7333568
   Weiss A, 2009, INT J SOC ROBOT, V1, P243, DOI 10.1007/s12369-009-0024-4
   Weyers P, 2006, PSYCHOPHYSIOLOGY, V43, P450, DOI 10.1111/j.1469-8986.2006.00451.x
   Weyers P, 2009, PSYCHOPHYSIOLOGY, V46, P328, DOI 10.1111/j.1469-8986.2008.00771.x
   Wieser MJ, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00471
   Yohanan S, 2012, INT J SOC ROBOT, V4, P163, DOI 10.1007/s12369-011-0126-7
   Yu H., 2013, P SPIE INT SOC OPT E
   Yuk N.-S., 2008, CONTR AUT SYST ICCAS, P2350
   Zaki J, 2008, PSYCHOL SCI, V19, P399, DOI 10.1111/j.1467-9280.2008.02099.x
   Zhan MY, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0139768
NR 138
TC 0
Z9 0
U1 5
U2 5
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2379-8920
EI 2379-8939
J9 IEEE T COGN DEV SYST
JI IEEE Trans. Cogn. Dev. Syst.
PD DEC
PY 2018
VL 10
IS 4
BP 852
EP 864
DI 10.1109/TCDS.2018.2826921
PG 13
WC Computer Science, Artificial Intelligence; Robotics; Neurosciences
SC Computer Science; Robotics; Neurosciences & Neurology
GA HD6HK
UT WOS:000452636400003
OA Bronze
DA 2019-02-18
ER

PT J
AU Boccignone, G
   Conte, D
   Cuculo, V
   D'Amelio, A
   Grossi, G
   Lanzarotti, R
AF Boccignone, Giuseppe
   Conte, Donatello
   Cuculo, Vittorio
   D'Amelio, Alessandro
   Grossi, Giuliano
   Lanzarotti, Raffaella
TI Deep Construction of an Affective Latent Space via Multimodal Enactment
SO IEEE TRANSACTIONS ON COGNITIVE AND DEVELOPMENTAL SYSTEMS
LA English
DT Article
DE Bayesian models; deep learning; emotion; human-agent interaction;
   simulation
ID MIRROR NEURON SYSTEM; EXPRESSION RECOGNITION; MOTOR CONTROL; EMOTION;
   MODELS; SIMULATION; MECHANISMS; FRAMEWORK; INFERENCE; COGNITION
AB We draw on a simulationist approach to the analysis of facially displayed emotions, e.g., in the course of a face-to-face interaction between an expresser and an observer. At the heart of such perspective lies the enactment of the perceived emotion in the observer. We propose a novel probabilistic framework based on a deep latent representation of a continuous affect space, which can be exploited for both the estimation and the enactment of affective states in a multimodal space (visible facial expressions and physiological signals). The rationale behind the approach lies in the large body of evidence from affective neuroscience showing that when we observe emotional facial expressions, we react with congruent facial mimicry. Further, in more complex situations, affect understanding is likely to rely on a comprehensive representation grounding the reconstruction of the state of the body associated with the displayed emotion. We show that our approach can address such problems in a unified and principled perspective, thus avoiding ad hoc heuristics while minimizing learning efforts.
C1 [Boccignone, Giuseppe; Cuculo, Vittorio; D'Amelio, Alessandro; Grossi, Giuliano; Lanzarotti, Raffaella] Univ Milan, Dept Comp Sci, PHuSeLab, I-20122 Milan, Italy.
   [Conte, Donatello] Univ Tours, Comp Sci Lab, F-37000 Tours, France.
RP Lanzarotti, R (reprint author), Univ Milan, Dept Comp Sci, PHuSeLab, I-20122 Milan, Italy.
EM donatello.conte@univ-tours.fr; lanzarotti@di.unimi.it
OI Cuculo, Vittorio/0000-0002-8479-9950; Boccignone,
   Giuseppe/0000-0002-5572-0924; D'Amelio, Alessandro/0000-0002-8210-4457;
   GROSSI, GIULIANO/0000-0001-9274-4047; Lanzarotti,
   Raffaella/0000-0002-8534-4413
FU Italian Government-MIUR, Future in Research Fund
FX This work was supported by the Italian Government-MIUR, Future in
   Research Fund through project "Interpreting emotions: A Computational
   Tool Integrating Facial Expressions and Biosignals Based Shape Analysis
   and Bayesian Networks."
CR Adolphs Ralph, 2002, Behav Cogn Neurosci Rev, V1, P21, DOI 10.1177/1534582302001001003
   Adolphs R, 2009, ANNU REV PSYCHOL, V60, P693, DOI 10.1146/annurev.psych.60.110707.163514
   Ahlberg J., 2010, LITHISYR2326 LINK U
   Ahmadi A., 2017, LNCS, V10636
   Ahmadi A, 2017, NEURAL NETWORKS, V92, P3, DOI 10.1016/j.neunet.2017.02.015
   Anderson DJ, 2014, CELL, V157, P187, DOI 10.1016/j.cell.2014.03.003
   Archambeau C., 2011, BAYESIAN TIME SERIES, P125
   Asada M, 2015, INT J SOC ROBOT, V7, P19, DOI 10.1007/s12369-014-0253-z
   Atkinson AP, 2011, PHILOS T R SOC B, V366, P1726, DOI 10.1098/rstb.2010.0349
   Baltrusaitis T, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P354, DOI 10.1109/ICCVW.2013.54
   Barrett LF, 2015, NAT REV NEUROSCI, V16, P419, DOI 10.1038/nrn3950
   Barros P, 2016, ADAPT BEHAV, V24, P373, DOI 10.1177/1059712316664017
   Beal MJ, 2005, BIOINFORMATICS, V21, P349, DOI 10.1093/bioinformatics/bti014
   Beal MJ, 2003, BAYESIAN STATISTICS 7, P453
   Becker-Asano Christian, 2010, IADIS Multi Conference on Computer Science and Information Systems (MCCSIS 2010). Proceedings of the IADIS International Conferences. Computer Graphics, Visualization, Computer Vision and Image Processing 2010. Visual Communication 2010: Creative Industries Photography and Culture. Web Virtual Reality and Three-Dimensional Worlds 2010. Part of the IADIS Multi Conference on Computer Science and Information Systems 2010, P121
   Bengio Yoshua, 2014, P 31 INT C MACH LEAR, P226
   Breazeal C., 1999, Proceedings 1999 IEEE/RSJ International Conference on Intelligent Robots and Systems. Human and Environment Friendly Robots with High Intelligence and Emotional Quotients (Cat. No.99CH36289), P858, DOI 10.1109/IROS.1999.812787
   Breazeal C, 2003, INT J HUM-COMPUT ST, V59, P119, DOI 10.1016/S1071-5819(03)00018-1
   Broekens J, 2008, COGN SYST RES, V9, P173, DOI 10.1016/j.cogsys.2007.06.007
   Calvo RA, 2010, IEEE T AFFECT COMPUT, V1, P18, DOI 10.1109/T-AFFC.2010.1
   Carr L, 2003, P NATL ACAD SCI USA, V100, P5497, DOI 10.1073/pnas.0935845100
   Ceruti C., 2017, LNCS, V10590
   Chakrabarti B, 2006, SOC NEUROSCI-UK, V1, P364, DOI 10.1080/17470910601041317
   Chater N, 2006, TRENDS COGN SCI, V10, P287, DOI 10.1016/j.tics.2006.05.007
   Churamani N, 2017, IEEE IJCNN, P627, DOI 10.1109/IJCNN.2017.7965911
   Conati C, 2002, APPL ARTIF INTELL, V16, P555, DOI 10.1080/08839510290030390
   Craig AD, 2003, CURR OPIN NEUROBIOL, V13, P500, DOI 10.1016/S0959-4388(03)00090-4
   D'Mello SK, 2015, ACM COMPUT SURV, V47, DOI 10.1145/2682899
   Dai Z., 2015, ARXIV E PRINTS
   Damianou A. C., 2013, P AISTATS, V31, P207
   Damianou AC, 2016, J MACH LEARN RES, V17
   Demiris Y, 2014, NEUROINFORMATICS, V12, P63, DOI 10.1007/s12021-013-9200-7
   Diano M, 2017, SCI REP-UK, V7, DOI 10.1038/srep45260
   Ekman P., 1997, WHAT FACE REVEALS BA
   Fanello SR, 2017, ROBOT AUTON SYST, V91, P151, DOI 10.1016/j.robot.2016.10.001
   Friston KJ, 2008, PLOS COMPUT BIOL, V4, DOI 10.1371/journal.pcbi.1000081
   Frith CD, 2012, ANNU REV PSYCHOL, V63, P287, DOI 10.1146/annurev-psych-120710-100449
   Gal Y., 2016, INT C MACH LEARN, P1050
   Gallese V, 2004, TRENDS COGN SCI, V8, P396, DOI 10.1016/j.tics.2004.07.002
   Gallese V, 2001, J CONSCIOUSNESS STUD, V8, P33
   Goldman AI, 2005, COGNITION, V94, P193, DOI 10.1016/j.cognition.2004.01.005
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Gothard KM, 2014, FRONT NEUROSCI-SWITZ, V8, DOI 10.3389/fnins.2014.00043
   Grimm M, 2005, 2005 IEEE Workshop on Automatic Speech Recognition and Understanding (ASRU), P381
   Grossi G, 2015, DIGIT SIGNAL PROCESS, V45, P96, DOI 10.1016/j.dsp.2015.06.006
   Gunes H, 2016, IMAGE VISION COMPUT, V55, P6, DOI 10.1016/j.imavis.2016.03.013
   Heskes T, 2001, IEEE T NEURAL NETWOR, V12, P1299, DOI 10.1109/72.963766
   Hoey J, 2013, INT CONF AFFECT, P166, DOI 10.1109/ACII.2013.34
   Horii T., 2016, PALADYN J BEHAV ROBO, V7, P2081
   Iacoboni M, 2009, CURR OPIN NEUROBIOL, V19, P661, DOI 10.1016/j.conb.2009.09.008
   Ipser A, 2016, J EXP PSYCHOL HUMAN, V42, P706, DOI 10.1037/xhp0000177
   Johnson Matthew, 2016, ADV NEURAL INFORM PR, P2946
   Kawato M, 1999, CURR OPIN NEUROBIOL, V9, P718, DOI 10.1016/S0959-4388(99)00028-8
   Kim Y, 2013, INT CONF ACOUST SPEE, P3687, DOI 10.1109/ICASSP.2013.6638346
   Koller D., 2009, PROBABILISTIC GRAPHI
   Kuppens P, 2010, J PERS SOC PSYCHOL, V99, P1042, DOI 10.1037/a0020962
   Lim A, 2015, INT J SOC ROBOT, V7, P35, DOI 10.1007/s12369-014-0262-y
   Marr D., 1982, VISION COMPUTATIONAL
   Molenberghs P, 2010, HUM BRAIN MAPP, V31, P1316, DOI 10.1002/hbm.20938
   Mollahosseini A., 2016, P IEEE C COMP VIS PA, P58
   Mukamel R, 2010, CURR BIOL, V20, P750, DOI 10.1016/j.cub.2010.02.045
   Murata S, 2017, IEEE T NEUR NET LEAR, V28, P830, DOI 10.1109/TNNLS.2015.2492140
   Ogata T, 1999, ICRA '99: IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS 1-4, PROCEEDINGS, P3177, DOI 10.1109/ROBOT.1999.774082
   Oh JH, 2006, 2006 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-12, P1428, DOI 10.1109/IROS.2006.281935
   Orozco J, 2013, IMAGE VISION COMPUT, V31, P322, DOI 10.1016/j.imavis.2013.02.001
   Pessoa L, 2010, NAT REV NEUROSCI, V11, P773, DOI 10.1038/nrn2920
   Pitcher D, 2011, EXP BRAIN RES, V209, P481, DOI 10.1007/s00221-011-2579-1
   Prochazkova E, 2017, NEUROSCI BIOBEHAV R, V80, P99, DOI 10.1016/j.neubiorev.2017.05.013
   Rasmussen CE, 2005, ADAPT COMPUT MACH LE, P1
   Reisenzein R, 2013, IEEE T AFFECT COMPUT, V4, P246, DOI 10.1109/T-AFFC.2013.14
   Ringeval F., 2013, AUT FAC GEST REC FG, P1, DOI DOI 10.1109/FG.2013.6553805
   Rizzolatti G, 2016, NAT REV NEUROSCI, V17, P757, DOI 10.1038/nrn.2016.135
   Rudrauf D, 2008, J NEUROSCI, V28, P2793, DOI 10.1523/JNEUROSCI.3476-07.2008
   RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714
   Russell JA, 2003, PSYCHOL REV, V110, P145, DOI 10.1037/0033-295X.110.1.145
   Salzman CD, 2010, ANNU REV NEUROSCI, V33, P173, DOI 10.1146/annurev.neuro.051508.135256
   Sanborn AN, 2016, TRENDS COGN SCI, V20, P883, DOI 10.1016/j.tics.2016.10.003
   Sariyanidi E, 2015, IEEE T PATTERN ANAL, V37, P1113, DOI 10.1109/TPAMI.2014.2366127
   Saxe R, 2005, TRENDS COGN SCI, V9, P174, DOI 10.1016/j.tics.2005.01.012
   Scassellati B, 2002, AUTON ROBOT, V12, P13, DOI 10.1023/A:1013298507114
   Seth AK, 2013, TRENDS COGN SCI, V17, P565, DOI 10.1016/j.tics.2013.09.007
   Sultana M, 2015, INT J PATTERN RECOGN, V29, DOI 10.1142/S0218001415560133
   Tipping ME, 1999, J ROY STAT SOC B, V61, P611, DOI 10.1111/1467-9868.00196
   Tramacere A, 2016, J ANTHROPOL SCI, V94, P113, DOI [10.4436/jass.94037, 10.4436/JASS.94037]
   Tran D., 2017, P IEEE 28 ANN INT S, P1
   Uhlenbeck GE, 1930, PHYS REV, V36, P0823, DOI 10.1103/PhysRev.36.823
   Vinciarelli A, 2012, IEEE T AFFECT COMPUT, V3, P69, DOI 10.1109/T-AFFC.2011.27
   Vitale J, 2014, BIOL INSPIR COGN ARC, V10, P30, DOI 10.1016/j.bica.2014.11.005
   Vogeley K, 2017, PHILOS T R SOC B, V372, DOI 10.1098/rstb.2016.0245
   Wiese E, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.01663
   Wolpert DM, 2003, PHILOS T R SOC B, V358, P593, DOI 10.1098/rstb.2002.1238
   Wood A, 2016, TRENDS COGN SCI, V20, P227, DOI 10.1016/j.tics.2015.12.010
   Ziemke T, 2009, COGN COMPUT, V1, P104, DOI 10.1007/s12559-009-9012-0
NR 93
TC 0
Z9 0
U1 1
U2 1
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2379-8920
EI 2379-8939
J9 IEEE T COGN DEV SYST
JI IEEE Trans. Cogn. Dev. Syst.
PD DEC
PY 2018
VL 10
IS 4
BP 865
EP 880
DI 10.1109/TCDS.2017.2788820
PG 16
WC Computer Science, Artificial Intelligence; Robotics; Neurosciences
SC Computer Science; Robotics; Neurosciences & Neurology
GA HD6HK
UT WOS:000452636400004
DA 2019-02-18
ER

PT J
AU Donnarumma, F
   Dindo, H
   Pezzulo, G
AF Donnarumma, Francesco
   Dindo, Hans
   Pezzulo, Giovanni
TI Sensorimotor Communication for Humans and Robots: Improving Interactive
   Skills by Sending Coordination Signals
SO IEEE TRANSACTIONS ON COGNITIVE AND DEVELOPMENTAL SYSTEMS
LA English
DT Article
DE Human-robot interaction; joint action; sensorimotor communication;
   signaling
ID ACTIVE INFERENCE; JOINT ACTION; TURN-TAKING; DYNAMICS; NETWORK;
   ARCHITECTURE; MOTIONESE; MOVEMENT; BRAIN; MOTOR
AB During joint actions, humans continuously exchange coordination signals and use nonverbal, sensorimotor forms of communication. Here we discuss a specific example of sensorimotor communication-"signaling"-which consists in the intentional modification of one's own action plan (e.g., a plan for reaching a glass of wine) to make it more predictable or discriminable from alternative action plans that are contextually plausible (e.g., a plan for reaching another glass on the same table). We first review the existing evidence on signaling in human-human interactions, discussing under which conditions humans use signaling. Successively, we distill these insights into a computational theory of signaling during online interactions. Central to our approach are the following ideas: 1) signaling endows pragmatic plans with communicative goals; 2) signaling can be understood within a cost-benefit scheme, balancing the costs for the signaling agent against its benefits for interaction success; and 3) signaling may be part of an interactive strategy that optimizes success when joint goals are uncertain. Finally, we exemplify the benefits of signaling in a series of simulations and discuss how endowing robots with signaling abilities can increase the quality of human-robot interactions by making their behavior more predictable and "legible" for humans.
C1 [Donnarumma, Francesco; Pezzulo, Giovanni] CNR, Inst Cognit Sci & Technol, I-00185 Rome, Italy.
   [Dindo, Hans] Univ Palermo, Dept Comp Sci Engn, I-90128 Palermo, Italy.
RP Pezzulo, G (reprint author), CNR, Inst Cognit Sci & Technol, I-00185 Rome, Italy.
EM giovanni.pezzulo@istc.cnr.it
OI Pezzulo, Giovanni/0000-0001-6813-8282; Donnarumma,
   Francesco/0000-0003-4248-5360
FU Human Frontier Science Program [RGY0088/2014]; EU's FP7
   [FP7-ICT-270108]; NVIDIA Corporation
FX This work was supported in part by the Human Frontier Science Program
   under Award RGY0088/2014, in part by EU's FP7 under Grant FP7-ICT-270108
   (Goal-Leaders), and in part by NVIDIA Corporation.
CR Ambrosini E, 2015, J NEUROPHYSIOL, V113, P2271, DOI 10.1152/jn.00464.2014
   Anderson ML, 2010, BEHAV BRAIN SCI, V33, P245, DOI 10.1017/S0140525X10000853
   Ansuini C, 2016, J EXP PSYCHOL HUMAN, V42, P918, DOI 10.1037/xhp0000169
   Ansuini C, 2015, NEUROSCIENTIST, V21, P126, DOI 10.1177/1073858414533827
   Arpaia P., 2010, ENV EN STRUCT MON SY, P70
   Badino L, 2014, NEUROPSYCHOLOGIA, V55, P98, DOI 10.1016/j.neuropsychologia.2013.11.012
   Becchio C, 2008, CONSCIOUS COGN, V17, P557, DOI 10.1016/j.concog.2007.03.003
   Becchio C, 2012, FRONT HUM NEUROSCI, V6, DOI 10.3389/fnhum.2012.00117
   Billings DR, 2012, ACMIEEE INT CONF HUM, P109
   Bohus D, 2011, P 13 INT C MULT INT, P153
   Brand RJ, 2008, DEVELOPMENTAL SCI, V11, P853, DOI 10.1111/j.1467-7687.2008.00734.x
   Brand RJ, 2002, DEVELOPMENTAL SCI, V5, P72, DOI 10.1111/1467-7687.00211
   Breazeal C. L., 2004, DESIGNING SOCIABLE R
   Candidi M, 2015, J R SOC INTERFACE, V12, DOI 10.1098/rsif.2015.0644
   Cavallo A, 2016, SCI REP-UK, V6, DOI 10.1038/srep37036
   Chao C, 2012, J HUM-ROBOT INTERACT, V1, P4, DOI 10.5898/JHRI.1.1.Chao
   Chatzis SP, 2011, IEEE T NEURAL NETWOR, V22, P1435, DOI 10.1109/TNN.2011.2162109
   Chinellato Eris, 2013, Biomimetic and Biohybrid Systems. Second International Conference, Living Machines 2013. Proceedings. LNCS 8064, P47, DOI 10.1007/978-3-642-39802-5_5
   Clark H. H, 1996, USING LANGUAGE
   Csibra G, 2009, TRENDS COGN SCI, V13, P148, DOI 10.1016/j.tics.2009.01.005
   D'Ausilio A, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0035757
   Dasgupta I, 2017, COGNITIVE PSYCHOL, V96, P1, DOI 10.1016/j.cogpsych.2017.05.001
   Dautenhahn K, 2007, PHILOS T R SOC B, V362, P679, DOI 10.1098/rstb.2006.2004
   Dehaene S, 2007, NEURON, V56, P384, DOI 10.1016/j.neuron.2007.10.004
   Demiris Y, 2006, ROBOT AUTON SYST, V54, P361, DOI 10.1016/j.robot.2006.02.003
   Dindo H., 2011, P IJCAI 2011, P2113
   Dindo H, 2015, BIOL CYBERN, V109, P453, DOI 10.1007/s00422-015-0654-6
   Donnarumma F., 2015, CONTROL CYBERN, V44, P99
   Donnarumma F, 2017, BIOL CYBERN, V111, P165, DOI 10.1007/s00422-017-0714-1
   Donnarumma F, 2017, FRONT PSYCHOL, V8, P1, DOI 10.3389/fpsyg.2017.00237
   Donnarumma F, 2017, CORTEX, V89, P45, DOI 10.1016/j.cortex.2017.01.016
   Donnarumma F, 2016, PLOS COMPUT BIOL, V12, DOI 10.1371/journal.pcbi.1004864
   Donnarumma F, 2016, ADAPT BEHAV, V24, P27, DOI 10.1177/1059712315609412
   Donnarumma F, 2015, INT J NEURAL SYST, V25, DOI 10.1142/S0129065715500173
   Donnarumma F, 2012, CONNECT SCI, V24, P71, DOI 10.1080/09540091.2012.684670
   Dragan AD, 2013, ACMIEEE INT CONF HUM, P301, DOI 10.1109/HRI.2013.6483603
   Fogassi L, 2005, SCIENCE, V308, P662, DOI 10.1126/science.1106138
   Friston K, 2015, CONSCIOUS COGN, V36, P390, DOI 10.1016/j.concog.2014.12.003
   Friston KJ, 2015, CORTEX, V68, P129, DOI 10.1016/j.cortex.2015.03.025
   Friston KJ, 2011, BIOL CYBERN, V104, P137, DOI 10.1007/s00422-011-0424-z
   Frith U, 2010, PHILOS T R SOC B, V365, P165, DOI 10.1098/rstb.2009.0160
   Garrod S, 2009, TOP COGN SCI, V1, P292, DOI 10.1111/j.1756-8765.2009.01020.x
   Hancock PA, 2011, HUM FACTORS, V53, P517, DOI 10.1177/0018720811417254
   Hastie T, 2003, ELEMENTS STAT LEARNI
   Iacoboni M, 2009, ANNU REV PSYCHOL, V60, P653, DOI 10.1146/annurev.psych.60.110707.163604
   Jeannerod M, 2001, NEUROIMAGE, V14, pS103, DOI 10.1006/nimg.2001.0832
   Jerde TE, 2003, J NEUROSCI, V23, P2383
   Kilner James M, 2007, Cogn Process, V8, P159, DOI 10.1007/s10339-007-0170-2
   Kilner JM, 2003, CURR BIOL, V13, P522, DOI 10.1016/S0960-9822(03)00165-9
   Konvalinka I, 2014, NEUROIMAGE, V94, P79, DOI 10.1016/j.neuroimage.2014.03.003
   Kuhl PK, 1997, SCIENCE, V277, P684, DOI 10.1126/science.277.5326.684
   Leibfried F, 2015, COGNITION, V141, P73, DOI 10.1016/j.cognition.2015.03.008
   Levinson SC, 2016, TRENDS COGN SCI, V20, P6, DOI 10.1016/j.tics.2015.10.010
   Lewkowicz D, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.01175
   Maisto D, 2016, ENTROPY-SWITZ, V18, DOI 10.3390/e18020061
   Manera V, 2011, EXP BRAIN RES, V211, P547, DOI 10.1007/s00221-011-2649-4
   MARTENIUK RG, 1987, CAN J PSYCHOL, V41, P365, DOI 10.1037/h0084157
   Mavridis N, 2015, ROBOT AUTON SYST, V63, P22, DOI 10.1016/j.robot.2014.09.031
   Maynard-Smith J, 2003, ANIMAL SIGNALS
   Montone G, 2011, LECT NOTES COMPUT SC, V6593, P250, DOI 10.1007/978-3-642-20282-7_26
   Murphy K. P., 2002, THESIS
   Nagai Y, 2009, IEEE T AUTON MENT DE, V1, P44, DOI 10.1109/TAMD.2009.2021090
   Naish KR, 2013, EXP BRAIN RES, V225, P261, DOI 10.1007/s00221-012-3367-2
   Neal A, 2010, EUR J NEUROSCI, V32, P1765, DOI 10.1111/j.1460-9568.2010.07435.x
   Noy L, 2011, P NATL ACAD SCI USA, V108, P20947, DOI 10.1073/pnas.1108155108
   Oullier O, 2008, SOC NEUROSCI, V3, P178, DOI 10.1080/17470910701563392
   Pecenka N, 2011, EXP BRAIN RES, V211, P505, DOI 10.1007/s00221-011-2616-0
   Pezzulo G, 2017, ENTROPY-SWITZ, V19, DOI 10.3390/e19060266
   Pezzulo G, 2017, ANN NY ACAD SCI, V1396, P144, DOI 10.1111/nyas.13329
   Pezzulo G, 2017, PSYCHOL SCI, V28, P338, DOI 10.1177/0956797616683015
   Pezzulo G, 2016, TRENDS COGN SCI, V20, P414, DOI 10.1016/j.tics.2016.03.013
   Pezzulo G, 2015, PROG NEUROBIOL, V134, P17, DOI 10.1016/j.pneurobio.2015.09.001
   Pezzulo G, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00800
   Pezzulo G, 2013, CORTEX, V49, P2968, DOI 10.1016/j.cortex.2013.06.008
   Pezzulo G, 2011, REV PHILOS PSYCHOL, V2, P303, DOI 10.1007/s13164-011-0060-5
   Pezzulo G, 2013, BEHAV BRAIN SCI, V36, P371, DOI 10.1017/S0140525X12002816
   Pezzulo G, 2012, IEEE T AUTON MENT DE, V4, P105, DOI 10.1109/TAMD.2011.2166261
   Pezzulo G, 2011, EXP BRAIN RES, V211, P613, DOI 10.1007/s00221-011-2712-1
   Pezzulo Giovanni, 2013, PLOS ONE, V8, P11
   Pickering MJ, 2004, BEHAV BRAIN SCI, V27, P212, DOI 10.1017/S0140525X04450055
   Pitsch K, 2014, INTERACT STUD, V15, P55, DOI 10.1075/is.15.1.03pit
   Pitsch K, 2013, INTERACT STUD, V14, P268, DOI 10.1075/is.14.2.06pit
   Quesque F, 2013, FRONT NEUROROBOTICS, V7, DOI 10.3389/fnbot.2013.00014
   Richardson MJ, 2007, HUM MOVEMENT SCI, V26, P867, DOI 10.1016/j.humov.2007.07.002
   Rizzolatti G, 2004, ANNU REV NEUROSCI, V27, P169, DOI 10.1146/annurev.neuro.27.070203.144230
   Sacheli LM, 2013, EXP BRAIN RES, V226, P473, DOI 10.1007/s00221-013-3459-7
   Sanborn AN, 2017, BRAIN COGNITION, V112, P98, DOI 10.1016/j.bandc.2015.06.008
   Sartori L, 2009, CONSCIOUS COGN, V18, P766, DOI 10.1016/j.concog.2009.06.004
   Schmidt RC, 1997, ECOL PSYCHOL, V9, P189, DOI 10.1207/s15326969eco0903_2
   Schutz-Bosbach S, 2007, TRENDS COGN SCI, V11, P349, DOI 10.1016/j.tics.2007.06.005
   Sebanz N, 2006, TRENDS COGN SCI, V10, P70, DOI 10.1016/j.tics.2005.12.009
   Sebanz N, 2009, TOP COGN SCI, V1, P353, DOI 10.1111/j.1756-8765.2009.01024.x
   Slepian ML, 2013, PSYCHOL SCI, V24, P2335, DOI 10.1177/0956797613487384
   Tessitore G, 2010, BIOL CYBERN, V103, P471, DOI 10.1007/s00422-010-0415-5
   van der Wel RPRD, 2011, J EXP PSYCHOL HUMAN, V37, P1420, DOI 10.1037/a0022337
   van Ulzen NR, 2008, NEUROSCI LETT, V432, P88, DOI 10.1016/j.neulet.2007.11.070
   Vesper C, 2014, EXP BRAIN RES, V232, P2945, DOI 10.1007/s00221-014-3982-1
   Vesper C, 2013, J EXP PSYCHOL HUMAN, V39, P48, DOI 10.1037/a0028066
   Vesper C, 2011, EXP BRAIN RES, V211, P517, DOI 10.1007/s00221-011-2706-z
   Vesper C, 2010, NEURAL NETWORKS, V23, P998, DOI 10.1016/j.neunet.2010.06.002
   Vollmer AL, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0091349
   Wolpert D., 2003, HDB BRAIN THEORY NEU, P1020
   Wolpert DM, 2003, PHILOS T R SOC B, V358, P593, DOI 10.1098/rstb.2002.1238
   Wright MJ, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0104290
NR 104
TC 0
Z9 0
U1 0
U2 0
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2379-8920
EI 2379-8939
J9 IEEE T COGN DEV SYST
JI IEEE Trans. Cogn. Dev. Syst.
PD DEC
PY 2018
VL 10
IS 4
BP 903
EP 917
DI 10.1109/TCDS.2017.2756107
PG 15
WC Computer Science, Artificial Intelligence; Robotics; Neurosciences
SC Computer Science; Robotics; Neurosciences & Neurology
GA HD6HK
UT WOS:000452636400007
DA 2019-02-18
ER

PT J
AU Cappagli, G
   Finocchieth, S
   Baud-Bovy, G
   Badino, L
   D'Ausilio, A
   Cocchi, E
   Gori, M
AF Cappagli, Giulia
   Finocchieth, Sara
   Baud-Bovy, Gabriel
   Badino, Leonardo
   D'Ausilio, Alessandro
   Cocchi, Elena
   Gori, Monica
TI Assessing Social Competence in Visually Impaired People and Proposing an
   Interventional Program in Visually Impaired Children
SO IEEE TRANSACTIONS ON COGNITIVE AND DEVELOPMENTAL SYSTEMS
LA English
DT Article
DE Blindness; Granger causality; social interaction
ID YOUNG-CHILDREN; PLAY; SKILLS
AB Visually impaired children and adults have difficulties in engaging in positive social interactions. This paper assesses social competence in sighted and visually impaired people and to propose a novel interventional strategy in visually impaired children. We designed a task that assesses the ability to initiate and sustain an interaction with the experimenter while performing free hand movements using a sonorous feedback on the experimenter's wrist. Both participant and experimenter kinematic data were recorded with a motion capture system. The level of social interaction between participant and experimenter has been computed through objective measurements based on Granger causality analysis applied to the participant arm kinematics. The interventional program followed by the visually impaired children lasted 12 weeks and consisted in a series of spatial and social games performed with the use of a sonorous bracelet which provides an auditory feedback of body actions in space. Visually impaired individuals present a poorer communication How with the experimenter than sighted people, which indicates a less efficient social interaction. The amount of communication between the two agents resulted in a significant improvement after the interventional program. Thus, a specific intervention, based on the substitution of visual with auditory feedback of body actions, can enhance social inclusion for the blind population.
C1 [Cappagli, Giulia; Finocchieth, Sara; Gori, Monica] Ist Italiano Tecnol, Unit Visually Impaired People, I-16100 Genoa, Italy.
   [Baud-Bovy, Gabriel] Ist Italiano Tecnol, Robot Brain & Cognit Sci, I-16163 Genoa, Italy.
   [Baud-Bovy, Gabriel] Univ Vita Salute San Raffaele, San Raffaele Sci Inst, Div Neurosci, Unit Expt Psychol, I-20132 Milan, Italy.
   [Badino, Leonardo; D'Ausilio, Alessandro] Ist Italiano Tecnol, Ctr Translat Neurophysiol Speech & Commun, I-44121 Ferrara, Italy.
   [D'Ausilio, Alessandro] Univ Ferrara, Dipartimento Sci Biomed & Chirurg Specialist, Sez Fisiol Umana, I-44121 Ferrara, Italy.
   [Cocchi, Elena] Ist David Chiossone Ciechi & Ipovedenti ONLUS, I-16100 Genoa, Italy.
RP Finocchieth, S (reprint author), Ist Italiano Tecnol, Unit Visually Impaired People, I-16100 Genoa, Italy.
EM monica.gori@iit.it
OI Gori, Monica/0000-0002-5616-865X; D'Ausilio,
   Alessandro/0000-0003-1472-6200
FU EU Strep Project ABBI [FP7-ICT 611452]; EU Irses Project CODEFROR
   [FP7-PIRSES-2013-612555]
FX This work was supported in part by the EU Strep Project ABBI under Grant
   FP7-ICT 611452, and in part by the EU Irses Project CODEFROR under Grant
   FP7-PIRSES-2013-612555.
CR ADELSON E, 1974, CHILD DEV, V45, P114, DOI 10.2307/1127757
   Anderson E. S., 1985, P 17 ANN CHILD LANG, P1
   [Anonymous], 2004, INT STAT CLASS DIS R
   Brownell CA, 2011, REV PHILOS PSYCHOL, V2, P193, DOI 10.1007/s13164-011-0056-1
   Celeste M, 2007, J VISUAL IMPAIR BLIN, V101, P521, DOI 10.1177/0145482X0710100902
   Finocchietti S., 2015, P INT C EN ACC PERS, P80
   Finocchietti S, 2015, IEEE ENG MED BIO, P7998, DOI 10.1109/EMBC.2015.7320248
   Gilbert C, 2003, BRIT MED J, V327, P760, DOI 10.1136/bmj.327.7418.760
   Gori M, 2016, NEUROSCI BIOBEHAV R, V69, P79, DOI 10.1016/j.neubiorev.2016.06.043
   GRANGER CWJ, 1969, ECONOMETRICA, V37, P424, DOI 10.2307/1912791
   Groenveld M., 1993, MANAGEMENT VISUAL IM, P64
   Guralnick M. J., 1992, ASSESSMENT PEER RELA
   Guralnick MJ, 1996, J APPL DEV PSYCHOL, V17, P625, DOI 10.1016/S0193-3973(96)90019-2
   Guralnick MJ, 1996, CHILD DEV, V67, P471
   Guralnick MJ, 1996, AM J MENT RETARD, V100, P359
   McConnell SR, 1999, TOP EARLY CHILD SPEC, V19, P67, DOI 10.1177/027112149901900201
   Meltzoff AN, 2003, PHILOS T R SOC B, V358, P491, DOI 10.1098/rstb.2002.1261
   PARSONS S, 1986, J VISUAL IMPAIR BLIN, V80, P777
   Porquis B. L., 2017, IEEE BIOM CIRC SYST, P35
   RETTIG M, 1994, J VISUAL IMPAIR BLIN, V88, P410
   Sacks S, 1992, DEV SOCIAL SKILLS BL
   Sacks S., 1992, DEV SOCIAL SKILLS
   Sattler JM, 2008, ASSESSMENT CHILDREN
   Seth AK, 2010, J NEUROSCI METH, V186, P262, DOI 10.1016/j.jneumeth.2009.11.020
   SIMON EP, 1979, EXCEPT CHILDREN, V45, P463, DOI 10.1177/001440297904500606
   SKELLENGER AC, 1994, J VISUAL IMPAIR BLIN, V88, P433
   Tait P. E., 1984, EARLY CHILD DEV CARE, V13, P155
   Tomasello M, 2005, BEHAV BRAIN SCI, V28, P675, DOI 10.1017/S0140525X05000129
   TROSTER H, 1994, EARLY CHILD DEV CARE, V104, P61
   Warren D. H., 1977, BLINDNESS EARLY CHIL
   Wechsler D., 1949, WECHSLER INTELLIGENC
   Weiss L. G., 2006, WISC 4 ADV CLIN INTE
NR 32
TC 0
Z9 0
U1 3
U2 3
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2379-8920
EI 2379-8939
J9 IEEE T COGN DEV SYST
JI IEEE Trans. Cogn. Dev. Syst.
PD DEC
PY 2018
VL 10
IS 4
BP 929
EP 935
DI 10.1109/TCDS.2018.2809487
PG 7
WC Computer Science, Artificial Intelligence; Robotics; Neurosciences
SC Computer Science; Robotics; Neurosciences & Neurology
GA HD6HK
UT WOS:000452636400009
DA 2019-02-18
ER

PT J
AU Honig, SS
   Oron-Gilad, T
   Zaichyk, H
   Sarne-Fleisehmann, V
   Olatunji, S
   Edan, Y
AF Honig, Shanee S.
   Oron-Gilad, Tal
   Zaichyk, Hanan
   Sarne-Fleisehmann, Vardit
   Olatunji, Samuel
   Edan, Yael
TI Toward Socially Aware Person-Following Robots
SO IEEE TRANSACTIONS ON COGNITIVE AND DEVELOPMENTAL SYSTEMS
LA English
DT Article
DE Accompanying robot; human-robot interaction (HRI); person-following;
   proxemics; social robotics; user needs
ID MOBILE ROBOT; INTERPERSONAL DISTANCE; HUMAN TRACKING; NAVIGATION;
   BEHAVIOR; VISION; SPACE; IDENTIFICATION; ORIENTATION; APPEARANCE
AB Significant research and development has been invested in technical issues related to person following. However, a systematic approach for designing robotic person-following behavior that maintains appropriate social conventions across contexts has not yet been developed. To understand why this may be the case, an in-depth literature review of 221 articles on person-following robots was performed, from which 107 are referenced. From these papers, six relevant topics were identified that shed light on the types of social interactions that have been studied in person-following scenarios: 1) applications; 2) robotic systems; 3) environments; 4) following strategies; 5) human-robot communication; and 6) evaluation methods. Gaps in the existing research on person-following robots were identified, mainly in addressing social interaction and user needs, noting that only 25 articles reported proper user studies. Human-related, robot-related, task-related, and environment-related factors that are likely to influence people's spatial preferences and expectations of a robot's person-following behavior are then discussed. To guide the design of socially aware person following robots, a user-needs layered design framework that combines the four factor categories is proposed. The framework provides a systematic way to incorporate social considerations in the design of person-following robots. Finally, framework limitations and future challenges in the field are presented and discussed.
C1 [Honig, Shanee S.; Oron-Gilad, Tal; Zaichyk, Hanan; Sarne-Fleisehmann, Vardit; Olatunji, Samuel; Edan, Yael] Ben Gurion Univ Negev, Dept Ind Engn & Management, IL-84105 Beer Sheva, Israel.
RP Honig, SS (reprint author), Ben Gurion Univ Negev, Dept Ind Engn & Management, IL-84105 Beer Sheva, Israel.
EM shaneeh@post.bgu.ac.il; orontal@bgu.ac.il; zaichyk@post.bgu.ac.il;
   sarne@post.bgu.ac.il; olatunji@post.bgu.ac.il; yael@bgu.ac.il
OI Olatunji, Samuel/0000-0002-0535-2780; Honig, Shanee/0000-0003-0674-6623;
   Oron-Gilad, Tal/0000-0002-9523-0161
FU Ministry of Science, Technology and Space, Israel [3-12060]; Helmsley
   Charitable Trust through the Agricultural, Biological, and Cognitive
   Robotics Center; Marcus Endowment fund through Ben-Gurion University of
   the Negev; EU [721619]; Rabbi W. Gunther Plaut Chair in Manufacturing
   Engineering through Ben-Gurion University of the Negev
FX This work was supported in part by the Ministry of Science, Technology
   and Space, Israel, (Follow me) under Grant 3-12060, in part by the
   Helmsley Charitable Trust through the Agricultural, Biological, and
   Cognitive Robotics Center, the Marcus Endowment fund through Ben-Gurion
   University of the Negev, and in part by the Rabbi W. Gunther Plaut Chair
   in Manufacturing Engineering through Ben-Gurion University of the Negev.
   The work of S. Olatunji was supported by the EU funded Innovative
   Training Network in the Marie Sklodowska-Curie People Programme
   (Horizon2020): Social Cognitive Robotics in a European Society Training
   Research Network under Grant 721619.
CR Ackerman E., IEEE SPECTR
   Adamides G, 2015, IEEE T HUM-MACH SYST, V45, P256, DOI 10.1109/THMS.2014.2371048
   ADAMS L, 1991, J GEN PSYCHOL, V118, P335, DOI 10.1080/00221309.1991.9917794
   ADLER LL, 1974, PERCEPT MOTOR SKILL, V39, P683, DOI 10.2466/pms.1974.39.2.683
   Agarwal P., 2017, INT RES J ENG TECHNO, V4, P1635
   AIELLO JR, 1977, ENVIRON PSYCH NONVER, V1, P122, DOI 10.1007/BF01145461
   Alvarez-Santos V, 2012, ROBOT AUTON SYST, V60, P1021, DOI 10.1016/j.robot.2012.05.014
   [Anonymous], 2011, 1021812011 ISO
   [Anonymous], 2016, 1864612016 ISO
   [Anonymous], 2014, 134822014 ISO
   [Anonymous], 186462 ISODIS
   [Anonymous], 2011, 1021822011 ISO
   Bakar M N A, 2011, 2011 IEEE Applied Power Electronics Colloquium (IAPEC 2011), P86, DOI 10.1109/IAPEC.2011.5779843
   Bassani C, 2016, IEEE ROMAN, P599, DOI 10.1109/ROMAN.2016.7745179
   BAXTER JC, 1970, SOCIOMETRY, V33, P444, DOI 10.2307/2786318
   Bohlmann K., 2013, J AUTOM MOBILE ROBOT, V7, P24
   Brandl C, 2016, HUM FACTOR ERGON MAN, V26, P713, DOI 10.1002/hfm.20675
   Brookshire J, 2010, INT J SOC ROBOT, V2, P137, DOI 10.1007/s12369-010-0046-y
   Butler JT, 2001, AUTON ROBOT, V10, P185, DOI 10.1023/A:1008986004181
   Calvo R., 2005, P INT C INF CONTR IC, P463
   Carton D, 2017, INT J SOC ROBOT, V9, P309, DOI 10.1007/s12369-016-0394-3
   CELSI RL, 1988, J CONSUM RES, V15, P210, DOI 10.1086/209158
   Chao HY, 2014, J INTELL ROBOT SYST, V73, P361, DOI 10.1007/s10846-013-9923-6
   Chen SY, 2012, IEEE T IND ELECTRON, V59, P4409, DOI 10.1109/TIE.2011.2162714
   Chi W., IEEE T SYST MAN CYBE
   Chik S., 2016, J TELECOMMUNICATION, V8, P41
   Chin-Shyurng Fahn, 2010, 2010 International Computer Symposium (ICS 2010), P234, DOI 10.1109/COMPSYM.2010.5685513
   Choi JS, 2014, ACTA BIOENG BIOMECH, V16, P3, DOI 10.5277/abb140101
   Cielniak G., 2005, P EUR C MOB ROB
   Clarkson E., 2007, FLAIRS C, P44
   COCHRAN CD, 1982, J PSYCHOL, V111, P137, DOI 10.1080/00223980.1982.9923525
   COCHRAN CD, 1984, J PSYCHOL, V117, P121, DOI 10.1080/00223980.1984.9923667
   Cosgun A, 2013, IEEE INT CONF ROBOT, P4335, DOI 10.1109/ICRA.2013.6631191
   Cristani M., 2011, Proceedings of the 2011 IEEE Third International Conference on Privacy, Security, Risk and Trust and IEEE Third International Conference on Social Computing (PASSAT/SocialCom 2011), P290, DOI 10.1109/PASSAT/SocialCom.2011.32
   Dautenhahn K., 2006, 1st Annual Conference on Human-Robot Interaction, P172
   de Winter JCF, 2014, COGN TECHNOL WORK, V16, P1, DOI 10.1007/s10111-011-0188-1
   DeSouza GN, 2002, IEEE T PATTERN ANAL, V24, P237, DOI 10.1109/34.982903
   Di Paola D, 2010, INT J ADV ROBOT SYST, V7, P19
   Diefenbach S, 2014, P 2014 C DES INT SYS, P305, DOI DOI 10.1145/2598510.2598549
   Doisy G., 2012, P IEEE RSJ INT C INT, P43
   Doisy G, 2013, ACMIEEE INT CONF HUM, P117, DOI 10.1109/HRI.2013.6483529
   Eresha Ghadeer, 2013, 2013 IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN), P430, DOI 10.1109/ROMAN.2013.6628517
   Ericson CA, 2005, HAZARD ANALYSIS TECHNIQUES FOR SYSTEM SAFETY, P183
   ErwinPrassler, 2002, International Journal of Control, Automation, and Systems, V4, P56
   Ferreira BQ, 2016, LECT NOTES ARTIF INT, V9979, P179, DOI 10.1007/978-3-319-47437-3_18
   Ferrer G, 2017, AUTON ROBOT, V41, P775, DOI 10.1007/s10514-016-9584-y
   Ferrer G, 2013, IEEE INT C INT ROBOT, P1688, DOI 10.1109/IROS.2013.6696576
   FISHER JD, 1975, J PERS SOC PSYCHOL, V32, P15, DOI 10.1037/h0076837
   Fleishman V., 2018, 312060 ISR MIN SCI T
   Fleishman V., 2018, 312060 ISR MIN SCI
   Fuentes-Pacheco J, 2015, ARTIF INTELL REV, V43, P55, DOI 10.1007/s10462-012-9365-8
   GELLER ES, 1994, PROF SAF, V39, P18
   Gockley R., 2007, 2007 2nd Annual Conference on Human-Robot Interaction (HRI), P17
   Granata C., 2011, 11 INT C CLIMB WALK, P11
   Granata C, 2012, IEEE INT C INT ROBOT, P4652, DOI 10.1109/IROS.2012.6385976
   Gross HM, 2014, IEEE SYS MAN CYBERN, P1880, DOI 10.1109/SMC.2014.6974195
   Gross HM, 2017, AUTON ROBOT, V41, P679, DOI 10.1007/s10514-016-9552-6
   Gupta M, 2017, IEEE T SYST MAN CY-S, V47, P1415, DOI 10.1109/TSMC.2016.2616343
   Hall E. T., 1966, HIDDEN DIMENSION
   Ham Jaap, 2012, Social Robotics. 4th International Conference (ICSR 2012). Proceedings, P15, DOI 10.1007/978-3-642-34103-8_2
   Hancock PA, 2005, ERGON DES, V13, P8, DOI 10.1177/106480460501300104
   Hancock PA, 2011, HUM FACTORS, V53, P517, DOI 10.1177/0018720811417254
   Harada AC, 2016, IEEE/SICE I S SYS IN, P717, DOI 10.1109/SII.2016.7844084
   Haring KS, 2013, LECT NOTES ENG COMP, VI, P425
   HASSAN MS, 2016, P 2016 2 INT C, P62
   Hassenzahl M, 2001, INT J HUM-COMPUT INT, V13, P481, DOI 10.1207/S15327590IJHC1304_07
   Henry P., 1998, USER CTR INFORM DESI
   Hiroi Y., 2012, J MAN MACHINE TECHNO, V1, P44
   Hoeller Frank, 2007, 2007 IEEE/RSJ International Conference on Intelligent Robots and Systems, P1260, DOI 10.1109/IROS.2007.4399194
   Holmquist LE, 2014, J HUM-ROBOT INTERACT, V3, P1, DOI 10.5898/JHRI.3.1.Holmquist
   Honig S. S., 2018, 312060 ISR MIN SCI
   Hoshino F., 2011, 2011 IEEE/SICE International Symposium on System Integration (SII 2011), P212, DOI 10.1109/SII.2011.6147448
   Hoy M, 2015, ROBOTICA, V33, P463, DOI 10.1017/S0263574714000289
   Hoyeon Kim, 2010, 2010 IEEE/ASME International Conference on Advanced Intelligent Mechatronics (AIM 2010), P812, DOI 10.1109/AIM.2010.5695844
   Hsieh YH, 2016, IEEE SYS MAN CYBERN, P550, DOI 10.1109/SMC.2016.7844297
   Hu JS, 2014, IEEE T IND ELECTRON, V61, P1916, DOI 10.1109/TIE.2013.2262758
   Huettenrauch H, 2006, 2006 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-12, P5052, DOI 10.1109/IROS.2006.282535
   Iagnemma S., 2004, MOBILE ROBOTS ROUGH, P1
   Ilias B., 2014, ARPN J ENG APPL SCI, V9, P2454
   Itadera S., 2016, P INT S MICR HUM SCI, P1
   Jae-Geun Lee, 2016, 2016 IEEE International Conference on Consumer Electronics (ICCE), P209, DOI 10.1109/ICCE.2016.7430583
   Jevtic A, 2015, IEEE T HUM-MACH SYST, V45, P653, DOI 10.1109/THMS.2015.2461683
   Jian J., 2000, INT J COGNITIVE ERGO, V4, P53, DOI DOI 10.1207/S15327566IJCE0401_04
   Joosse M. P., 2014, P 5 ACM INT C COLL B, P121, DOI DOI 10.1145/2631488.2631499
   Jung EJ, 2014, IEEE-ASME T MECH, V19, P1963, DOI 10.1109/TMECH.2013.2294180
   Jung EJ, 2012, IEEE INT C INT ROBOT, P2411, DOI 10.1109/IROS.2012.6386200
   Kanda T, 2013, J HUM-ROBOT INTERACT, V2, P1, DOI 10.5898/JHRI.2.1.Kanda
   Karunarathne D., 2017, INT J SOC ROBOT, P1
   Katz D., 2016, DEV ALGORITHMS HUMAN
   Kheng Lee Koay, 2007, 16th IEEE International Conference on Robot and Human Interactive Communication, P564
   Kim HR, 2013, INT CONF UBIQ ROBOT, P741, DOI 10.1109/URAI.2013.6677443
   Kirwan B., 1992, GUIDE TASK ANAL TASK
   Kletz TA, 1997, RELIAB ENG SYST SAFE, V55, P263, DOI 10.1016/S0951-8320(96)00100-7
   Knite W., THIS ROBOT WILL CARR
   Koay K. L., 2006, P 15 IEEE INT WORKSH, P66
   Kobayashi T, 2015, INT CONF COGN INFO, P165, DOI 10.1109/CogInfoCom.2015.7390584
   Kobayashi Y, 2009, 2009 IEEE-RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, P2013, DOI 10.1109/IROS.2009.5353933
   Kobilarov M, 2006, IEEE INT CONF ROBOT, P557, DOI 10.1109/ROBOT.2006.1641769
   Koide K, 2016, ROBOT AUTON SYST, V84, P76, DOI 10.1016/j.robot.2016.07.004
   Kosinski T, 2016, IEEE ROMAN, P335, DOI 10.1109/ROMAN.2016.7745152
   Kreitzberg C., 2008, LUCID FRAMEWORK INTR
   Kruse T, 2013, ROBOT AUTON SYST, V61, P1726, DOI 10.1016/j.robot.2013.05.007
   Kwon H, 2005, IEEE INT CONF ROBOT, P2877
   Lasota P, 2017, FDN TRENDS ROBOTICS, V5, P261, DOI DOI 10.1561/2300000052
   Lever JH, 2006, J TERRAMECHANICS, V43, P527, DOI 10.1016/j.jterra.2005.09.002
   Lindblom J., 2016, ADV ERGONOMICS MANUF, P267, DOI DOI 10.1007/978-3-319-41697-7_24
   Lun R, 2015, INT J PATTERN RECOGN, V29, DOI 10.1142/S0218001415550083
   Luo Ren C, 2009, IECON 2009 - 35th Annual Conference of IEEE Industrial Electronics (IECON 2009), P2235, DOI 10.1109/IECON.2009.5415185
   MacArthur KR, 2017, ADV INTELL SYST, V499, P365, DOI 10.1007/978-3-319-41959-6_30
   Maslow A. H, 1971, FARTHER REACHES HUMA
   Mayora-Ibarra O, 2003, RO-MAN 2003: 12TH IEEE INTERNATIONAL WORKSHOP ON ROBOT AND HUMAN INTERACTIVE COMMUNICATION, PROCEEDINGS, P37
   McKenna B., 2007, INCOSE INT S, V17, P1831
   Mead R, 2016, J HUM-ROBOT INTERACT, V5, P48, DOI 10.5898/JHRI.5.2.Mead
   Mi W., 2016, P INT C ART INT ROB, P4
   Milella A, 2007, PROCEEDINGS OF THE IASTED INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND APPLICATIONS, P151
   Moeslund TB, 2006, COMPUT VIS IMAGE UND, V104, P90, DOI 10.1016/j.cviu.2006.08.002
   Morales Y, 2014, J HUM-ROBOT INTERACT, V3, P50, DOI 10.5898/JHRI.3.2.Morales
   Morales Y, 2012, ACMIEEE INT CONF HUM, P301
   Morioka K, 2004, IEEE T IND ELECTRON, V51, P229, DOI 10.1109/TIE.2003.821894
   Morishita K., 2017, J ROBOT, V2017, P1
   Moussaid M, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0010047
   Muller J., 2008, 2008 INT C COGN SYST, P85
   Mumm J, 2011, ACMIEEE INT CONF HUM, P331, DOI 10.1145/1957656.1957786
   Murakami R, 2014, ACMIEEE INT CONF HUM, P471, DOI 10.1145/2559636.2559665
   Naseer T, 2013, IEEE INT C INT ROBOT, P624, DOI 10.1109/IROS.2013.6696416
   Nielsen J., 2012, USABILITY 101 INTRO
   Nielson J., 2000, WHY YOU ONLY NEED TE
   Ningshi Yao, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P3244, DOI 10.1109/ICRA.2017.7989369
   Obaid M, 2016, IEEE ROMAN, P354, DOI 10.1109/ROMAN.2016.7745155
   Oishi S, 2016, IEEE ROMAN, P1038, DOI 10.1109/ROMAN.2016.7745236
   Okita SY, 2012, ACMIEEE INT CONF HUM, P203
   Olmedo NA, 2014, 2014 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS IEEE-ROBIO 2014, P825, DOI 10.1109/ROBIO.2014.7090434
   Oron-Gilad T, 2017, EMOTIONS AND AFFECT IN HUMAN FACTORS AND HUMAN-COMPUTER INTERACTION, P185, DOI 10.1016/B978-0-12-801851-4.00007-0
   Ota M, 2013, IEEE IND ELEC, P4253, DOI 10.1109/IECON.2013.6699818
   Pacchierotti E., 2006, P 15 IEEE INT S ROB, P315
   Pandey A., 2017, INT J ROBOT AUTOM, V2, P1
   Parasuraman R, 1997, HUM FACTORS, V39, P230, DOI 10.1518/001872097778543886
   Peng W, 2017, ADV INTELL SYST, V531, P301, DOI 10.1007/978-3-319-48036-7_22
   Pol RS, 2015, 2015 INTERNATIONAL CONFERENCE ON INDUSTRIAL INSTRUMENTATION AND CONTROL (ICIC), P1339, DOI 10.1109/IIC.2015.7150956
   Prati A, 2006, INT C PATT RECOG, P920
   Raibert M., 2008, P 17 WORLD C INT FED, V41, P10822, DOI DOI 10.3182/20080706-5-KR-1001.01833
   REMLAND MS, 1995, J SOC PSYCHOL, V135, P281, DOI 10.1080/00224545.1995.9713958
   Ren QM, 2016, CHIN CONTR CONF, P6160, DOI 10.1109/ChiCC.2016.7554324
   Riek LD, 2012, J HUM-ROBOT INTERACT, V1, P119, DOI 10.5898/JHRI.1.1.Riek
   Rios-Martinez J, 2015, INT J SOC ROBOT, V7, P137, DOI 10.1007/s12369-014-0251-1
   Sabanovic S, 2014, J HUM-ROBOT INTERACT, V3, P70, DOI 10.5898/JHRI.3.1.Sabanovic
   Sarne-Fleischmann V, 2017, IEEE ROMAN, P1018, DOI 10.1109/ROMAN.2017.8172428
   Satake J, 2013, INT J AUTOM COMPUT, V10, P438, DOI 10.1007/s11633-013-0740-y
   Satake Junji, 2009, P IEEE INT C ROB AUT, P1
   Schaefer K., 2013, THESIS
   Schlingensief C, 1998, THEATER HEUTE, P1
   Shaker S., 2008, INT J SYSTEMS APPL E, V2, P29
   Shanee HS, 2016, IEEE ROMAN, P593, DOI 10.1109/ROMAN.2016.7745178
   Sharivas N. K., 2017, INT J SCI RES COMPUT, V2, P363
   Sidenbladh H., 1999, P IEEE, P670
   Sonoura T., 2008, PERSON FOLLOWING ROB, P538
   Stein P, 2016, ROBOT AUTON SYST, V75, P79, DOI 10.1016/j.robot.2014.09.028
   Sun Y, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS (ROBIO), P649, DOI 10.1109/ROBIO.2016.7866396
   Sung J, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P193
   Sung Y, 2016, IEEE T HUM-MACH SYST, V46, P340, DOI 10.1109/THMS.2015.2501282
   Syrdal Dag Sverre, 2007, 16th IEEE International Conference on Robot and Human Interactive Communication, P1143
   Syrdal D. S., 2008, P AAAI FALL S AI ELD, P116
   Syrdal D. S, 2006, 15 IEEE INT S ROB HU, P183, DOI DOI 10.1109/ROMAN.2006.314415
   Takayama L, 2009, 2009 IEEE-RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, P5495, DOI 10.1109/IROS.2009.5354145
   Takemura H, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS, VOLS 1-5, P1500, DOI 10.1109/ROBIO.2007.4522386
   Takemura H, 2009, 2009 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS (ROBIO 2009), VOLS 1-4, P1675, DOI 10.1109/ROBIO.2009.5420414
   Tani A., 2011, 2011 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2011), P2423, DOI 10.1109/IROS.2011.6048316
   Tarokh M., 2008, MECHATRONICS MACHINE, P99
   Tarokh M, 2008, PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE ON SENSING TECHNOLOGY, P147, DOI 10.1109/ICSENST.2008.4757090
   Tasaki R, 2017, 2017 IEEE CONFERENCE ON CONTROL TECHNOLOGY AND APPLICATIONS (CCTA 2017), P827, DOI 10.1109/CCTA.2017.8062562
   Teixeira T., 2010, ACM COMPUT SURV, V5, P1
   Mac TT, 2016, ROBOT AUTON SYST, V86, P13, DOI 10.1016/j.robot.2016.08.001
   Tominaga J., 2014, P 5 AUGM HUM INT C, P43
   Tomoya A, 2017, PROCEDIA COMPUT SCI, V112, P1994, DOI 10.1016/j.procs.2017.08.125
   Topp E. A., 2005, 2005 IEEE/RSJ International Conference on Intelligent Robots and Systems, P2321
   Tsui KM, 2010, ACMIEEE INT CONF HUM, P193, DOI 10.1109/HRI.2010.5453198
   Tsun M. T. K., 2016, P 5 INT C NETW COMM, P331
   Udsatid P., 2012, Proceedings of the 2012 IEEE International Conference on Robotics and Biomimetics (ROBIO), P1374, DOI 10.1109/ROBIO.2012.6491160
   Viola N., 2012, SYSTEMS ENG PRACTICE
   Walters M. L., 2011, 2011 RO-MAN: The 20th IEEE International Symposium on Robot and Human Interactive Communication, P137, DOI 10.1109/ROMAN.2011.6005274
   Walters ML, 2008, 2008 17TH IEEE INTERNATIONAL SYMPOSIUM ON ROBOT AND HUMAN INTERACTIVE COMMUNICATION, VOLS 1 AND 2, P707, DOI 10.1109/ROMAN.2008.4600750
   Walters ML, 2008, AUTON ROBOT, V24, P159, DOI 10.1007/s10514-007-9058-3
   Walters ML, 2005, 2005 IEEE International Workshop on Robot and Human Interactive Communication (RO-MAN), P347
   Walters ML, 2005, IEEE-RAS INT C HUMAN, P450
   Weiss A., 2009, P S NEW FRONT HUM RO, P150
   Wharton C., 1992, CHI '92 Conference Proceedings. ACM Conference on Human Factors in Computing Systems. Striking a Balance, P381
   WHITE MJ, 1975, J SOC PSYCHOL, V95, P241, DOI 10.1080/00224545.1975.9918710
   WILLIAMS JL, 1971, CAN J BEH SCI, V3, P156, DOI 10.1037/h0082257
   Yinka AO, 2014, 2014 INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND INTEGRATED NETWORKS (SPIN), P679, DOI 10.1109/SPIN.2014.6777041
   Yoshimi T, 2006, 2006 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-12, P5286, DOI 10.1109/IROS.2006.282029
   Young J. E., 2011, 2011 RO-MAN: The 20th IEEE International Symposium on Robot and Human Interactive Communication, P376, DOI 10.1109/ROMAN.2011.6005225
   Young JE, 2011, INT J SOC ROBOT, V3, P53, DOI 10.1007/s12369-010-0081-8
   Yuan F., 2008, P INT WORKSH COGN TE
   Zender Hendrik, 2007, 16th IEEE International Conference on Robot and Human Interactive Communication, P1131
   Zhang JF, 2014, 2014 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS IEEE-ROBIO 2014, P1927, DOI 10.1109/ROBIO.2014.7090618
   Zhichao Chen, 2007, 2007 IEEE/RSJ International Conference on Intelligent Robots and Systems, P815, DOI 10.1109/IROS.2007.4399459
   Zhou HY, 2008, BIOMED SIGNAL PROCES, V3, P1, DOI 10.1016/j.bspc.2007.09.001
NR 197
TC 0
Z9 0
U1 2
U2 2
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2379-8920
EI 2379-8939
J9 IEEE T COGN DEV SYST
JI IEEE Trans. Cogn. Dev. Syst.
PD DEC
PY 2018
VL 10
IS 4
BP 936
EP 954
DI 10.1109/TCDS.2018.2825641
PG 19
WC Computer Science, Artificial Intelligence; Robotics; Neurosciences
SC Computer Science; Robotics; Neurosciences & Neurology
GA HD6HK
UT WOS:000452636400010
DA 2019-02-18
ER

PT J
AU Noel, JP
   De Niear, MA
   Lazzara, NS
   Wallace, MT
AF Noel, Jean-Paul
   De Niear, Matthew A.
   Lazzara, Nicholas S.
   Wallace, Mark T.
TI Uncoupling Between Multisensory Temporal Function and Nonverbal
   Turn-Taking in Autism Spectrum Disorder
SO IEEE TRANSACTIONS ON COGNITIVE AND DEVELOPMENTAL SYSTEMS
LA English
DT Article
DE Autism; body; communication; interaction; multisensory; nonverbal
ID SOCIAL-INTERACTION; SPEECH-PERCEPTION; ASPERGER-SYNDROME; BODY MOVEMENT;
   COMMUNICATION; CHILDREN; ROBOTS; LANGUAGE; INDIVIDUALS; RELIABILITY
AB The integration of information across distinct modalities enhances perceptual abilities. An ecologically important role of multisensory integration is in scaffolding verbal communication, which relies upon the precise temporal integration of auditory and visual cues. However, the role of (multi)sensory function in supporting another important aspect of communication, namely, nonverbal communication, is unknown. Here, individuals with autism spectrum disorder (ASD) and a group of typically developing (TD) participants performed a simultaneity judgment task to index their audiovisual temporal acuity for speech stimuli. Further, under a naturalistic scenario, nonverbal synchrony between the participant and a naive experimenter was measured. Automated motion analysis was performed to quantify movements of different body-parts. Results demonstrate a wider window of audiovisual temporal integration for ASD participants in comparison to their TD counterparts. Moreover, ASD individuals performed less complex movements and demonstrated less nonverbal synchrony during the interactive exchange. Lastly, multisensory temporal acuity significantly predicted the synchrony in hand and head movements between TD participants and the experimenter, but not between the ASD participants and the experimenter. Taken together, the results suggest an important role for multisensory perceptual abilities in shaping nonverbal communication between dyads and highlight the important role of perceptual systems in supporting social interactive skills.
C1 [Noel, Jean-Paul; De Niear, Matthew A.; Lazzara, Nicholas S.; Wallace, Mark T.] Vanderbilt Univ, Vanderbilt Brain Inst, Nashville, TN 37232 USA.
RP Noel, JP (reprint author), Vanderbilt Univ, Vanderbilt Brain Inst, Nashville, TN 37232 USA.
EM jean-paul.noel@vanderbilt.edu
OI Noel, Jean-Paul/0000-0001-5297-3363; Wallace, Mark/0000-0002-0166-906X
FU NIH [HD083211, MH109225]
FX This work was supported by NIH under Grant HD083211 and Grant MH109225.
CR Alais D, 2004, CURR BIOL, V14, P257, DOI 10.1016/j.cub.2004.01.029
   American Psychiatric Association, 2013, DIAGN STAT MAN MENT
   Bailenson JN, 2004, PRESENCE-TELEOP VIRT, V13, P428, DOI 10.1162/1054746041944803
   Baron-Cohen S, 2004, J AUTISM DEV DISORD, V34, P163, DOI 10.1023/B:JADD.0000022607.19833.00
   Baud-Bovy G., 2014, BIOINSPIRED APPROACH, P241
   Baum SH, 2015, PROG NEUROBIOL, V134, P140, DOI 10.1016/j.pneurobio.2015.09.007
   Billard A, 1999, ADAPT BEHAV, V7, P415, DOI 10.1177/105971239900700311
   Bisio A, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0106172
   Breazeal C, 2002, DESIGNING SOCIABLE R
   Brown Linda, 2010, TEST NONVERBAL INTEL
   Castelli F, 2002, BRAIN, V125, P1839, DOI 10.1093/brain/awf189
   Celani G, 1999, J AUTISM DEV DISORD, V29, P57, DOI 10.1023/A:1025970600181
   Chamberlain B, 2007, J AUTISM DEV DISORD, V37, P230, DOI 10.1007/s10803-006-0164-4
   Coey C, 2011, EXP BRAIN RES, V211, P483, DOI 10.1007/s00221-011-2689-9
   Couzin ID, 2005, NATURE, V433, P513, DOI 10.1038/nature03236
   Dautenhahn K, 2007, PHILOS T R SOC B, V362, P679, DOI 10.1098/rstb.2006.2004
   Van de Cruys S, 2014, PSYCHOL REV, V121, P649, DOI 10.1037/a0037665
   De Niear MA, 2017, NEURAL PLAST, DOI 10.1155/2017/3478742
   de Vos C, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00268
   Diehl JJ, 2012, RES AUTISM SPECT DIS, V6, P249, DOI 10.1016/j.rasd.2011.05.006
   DIXON NF, 1980, PERCEPTION, V9, P719, DOI 10.1068/p090719
   Ernst MO, 2002, NATURE, V415, P429, DOI 10.1038/415429a
   Flack JC, 2013, CURR BIOL, V23, pR967, DOI 10.1016/j.cub.2013.10.001
   FONG T, 2001, P INT S ROB RES, P255, DOI DOI 10.1007/3-540-36460-9_17
   Foss-Feig JH, 2010, EXP BRAIN RES, V203, P381, DOI 10.1007/s00221-010-2240-4
   Frassinetti F, 2002, EXP BRAIN RES, V147, P332, DOI 10.1007/s00221-002-1262-y
   GARDNER MF, 1990, EXPRESSIVE ONE WORD
   GEPNER B, 1995, NEUROREPORT, V6, P1211, DOI 10.1097/00001756-199505300-00034
   Goodrich Michael A, 2007, Foundations and Trends in Human-Computer Interaction, V1, P203, DOI 10.1561/1100000005
   Grammer K, 1999, J PERS SOC PSYCHOL, V77, P487, DOI 10.1037//0022-3514.77.3.487
   Grice H. P., 1975, SYNTAX SEMANTICS, P41, DOI DOI 10.1017/S0022226700005296
   Hancock PA, 2011, HUM FACTORS, V53, P517, DOI 10.1177/0018720811417254
   Kanda T, 2007, IEEE T ROBOT, V23, P962, DOI 10.1109/TRO.2007.904904
   Kanner L, 1943, NERV CHILD, V2, P217
   Keetels M., 2012, NEURAL BASEMULTISE, P147
   Kidd CD, 2008, 2008 IEEE/RSJ INTERNATIONAL CONFERENCE ON ROBOTS AND INTELLIGENT SYSTEMS, VOLS 1-3, CONFERENCE PROCEEDINGS, P3230, DOI 10.1109/IROS.2008.4651113
   Klin A, 2000, J AUTISM DEV DISORD, V30, P163, DOI 10.1023/A:1005415823867
   Klin A, 2009, NATURE, V459, P257, DOI 10.1038/nature07868
   Kupper Z, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0145882
   Kupper Z, 2010, SCHIZOPHR RES, V121, P90, DOI 10.1016/j.schres.2010.03.032
   Kwakye LD, 2011, FRONT INTEGR NEUROSC, V4, DOI 10.3389/fnint.2010.00129
   LEMPEL A, 1976, IEEE T INFORM THEORY, V22, P75, DOI 10.1109/TIT.1976.1055501
   Levinson SC, 2016, TRENDS COGN SCI, V20, P6, DOI 10.1016/j.tics.2015.10.010
   Lohan KS, 2014, TOP COGN SCI, V6, P492, DOI 10.1111/tops.12098
   Lord C, 2000, J AUTISM DEV DISORD, V30, P205, DOI 10.1023/A:1005592401947
   LORD C, 1994, J AUTISM DEV DISORD, V24, P659, DOI 10.1007/BF02172145
   Magyari L, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00376
   Marco EJ, 2011, PEDIATR RES, V69, p48R, DOI [10.1203/PDR.0b013e3182130c54, 10.1109/SPL.2011.5782616]
   MEREDITH MA, 1987, J NEUROSCI, V7, P3215
   Molloy CA, 2003, J AUTISM DEV DISORD, V33, P643, DOI 10.1023/B:JADD.0000006001.00667.4c
   MORRISSUZUKI T, 1984, NEW LEFT REV, P109
   MUNDY P, 1987, J AUTISM DEV DISORD, V17, P349, DOI 10.1007/BF01487065
   MUNDY P, 1986, J CHILD PSYCHOL PSYC, V27, P657, DOI 10.1111/j.1469-7610.1986.tb00190.x
   Murray M. M., 2012, NEURAL BASEMULTISE
   Noel JP, 2017, EPILEPSY BEHAV, V70, P166, DOI 10.1016/j.yebeh.2017.02.018
   Noel JP, 2017, SCHIZOPHR RES, V179, P8, DOI 10.1016/j.schres.2016.09.021
   Noel JP, 2017, AUTISM RES, V10, P121, DOI 10.1002/aur.1633
   Noel JP, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0161698
   Noel JP, 2016, J VISION, V16, DOI 10.1167/16.3.21
   Noel JP, 2016, NEUROPSYCHOLOGIA, V82, P84, DOI 10.1016/j.neuropsychologia.2016.01.005
   Noel JP, 2015, SCI REP-UK, V5, DOI 10.1038/srep17467
   Ostrom E, 2000, J ECON PERSPECT, V14, P137, DOI 10.1257/jep.14.3.137
   OZONOFF S, 1995, NEUROPSYCHOLOGY, V9, P491, DOI 10.1037//0894-4105.9.4.491
   Pellicano E, 2007, CURR BIOL, V17, P1508, DOI 10.1016/j.cub.2007.07.065
   Pellicano E, 2012, TRENDS COGN SCI, V16, P504, DOI 10.1016/j.tics.2012.08.009
   PREISING B, 1991, IEEE ENG MED BIOL, V10, P13, DOI 10.1109/51.82001
   Ramseyer F., 2006, CONSTRUCTIVISM HUMAN, V11, P150
   Ramseyer F., 2008, SIMULTANEITY TEMPORA, P329, DOI [10.1142/9789812792426_0020, DOI 10.1142/9789812792426_0020]
   Ramseyer F, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00979
   Ramseyer F, 2011, J CONSULT CLIN PSYCH, V79, P284, DOI 10.1037/a0023419
   Redcay E, 2008, NEUROSCI BIOBEHAV R, V32, P123, DOI 10.1016/j.neubiorev.2007.06.004
   Robins B, 2006, INTERACT STUD, V7, P479
   Rogoff B, 2003, CULTURAL NATURE HUMA
   Schaal S, 1999, TRENDS COGN SCI, V3, P233, DOI 10.1016/S1364-6613(99)01327-3
   Sciutti A, 2012, INT J SOC ROBOT, V4, P223, DOI 10.1007/s12369-012-0143-1
   Semel E., 2003, CELF 4 CLIN EVALUATI
   Serino A, 2015, SCI REP-UK, V5, DOI 10.1038/srep18603
   Simon DM, 2017, FRONT INTEGR NEUROSC, V11, DOI 10.3389/fnint.2017.00008
   Stevenson RA, 2017, SCHIZOPHR RES, V179, P97, DOI 10.1016/j.schres.2016.09.035
   Stevenson RA, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00379
   Stevenson RA, 2014, J NEUROSCI, V34, P691, DOI 10.1523/JNEUROSCI.3615-13.2014
   Stivers T, 2009, P NATL ACAD SCI USA, V106, P10587, DOI 10.1073/pnas.0903616106
   Stone WL, 1997, J AUTISM DEV DISORD, V27, P677, DOI 10.1023/A:1025854816091
   Sugita Y, 2003, NATURE, V421, P911, DOI 10.1038/421911a
   Tomasello M., 2008, ORIGINS HUMAN COMMUN
   Torgesen JK, 1999, TEST WORD READING EF
   Turi M, 2016, SCI REP-UK, V6, DOI 10.1038/srep21756
   Wallace MT, 2014, NEUROPSYCHOLOGIA, V64, P105, DOI 10.1016/j.neuropsychologia.2014.08.005
   Woodcock R. W., 2001, WOODCOCK JOHNSON TES
   Woynaroski TG, 2013, J AUTISM DEV DISORD, V43, P2891, DOI 10.1007/s10803-013-1836-5
NR 90
TC 4
Z9 4
U1 4
U2 4
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2379-8920
EI 2379-8939
J9 IEEE T COGN DEV SYST
JI IEEE Trans. Cogn. Dev. Syst.
PD DEC
PY 2018
VL 10
IS 4
BP 973
EP 982
DI 10.1109/TCDS.2017.2778141
PG 10
WC Computer Science, Artificial Intelligence; Robotics; Neurosciences
SC Computer Science; Robotics; Neurosciences & Neurology
GA HD6HK
UT WOS:000452636400013
OA Bronze
DA 2019-02-18
ER

PT J
AU Lohan, KS
   Sheppard, E
   Little, G
   Rajendran, G
AF Lohan, Katrin Solveig
   Sheppard, Eli
   Little, Gillian
   Rajendran, Gnanathusharan
TI Toward Improved Child-Robot Interaction by Understanding Eye Movements
SO IEEE TRANSACTIONS ON COGNITIVE AND DEVELOPMENTAL SYSTEMS
LA English
DT Article
DE Autism spectrum disorder (ASD); child-robot interaction; cognitive load;
   eye movement
ID AUTISM SPECTRUM DISORDER; JOINT ATTENTION; VISUAL-ATTENTION; PUPILLARY
   RESPONSES; DISSOCIATION; COGNITION; PATTERNS; INFANTS; REVEAL; ADULTS
AB Globally, 1 in 160 children has an autism spectrum disorder (ASD). Problems with joint attention (JA) are core features of ASDs. Here, we investigate how typically developing (TD) children and children with ASD initiate JA with a gaze contingent avatar. Thirty-one participants with ASD and 33 TD matched controls directed an avatar's gaze to a series of referent images. Observing pupil diameter and gaze location data, we explore how distinguishing the two groups as well as their different eye-movement behaviors could be used to improve child-robot interaction. With a sequence to sequence neural network we distinguish if a child is TD or has an ASD, then using K-means clustering, we group pupil diameters and gaze locations independently to determine the child's attention level as well as to refine the classification process. Using these metrics, we could trigger appropriate responses from the robot to increase the level of attention from the child toward the robot. Results show significant differences between the eye behaviors of individuals with ASDs and those without. Further to this, we achieve a 79.76% classification accuracy when using pupil diameter data to distinguish the two groups.
C1 [Lohan, Katrin Solveig; Sheppard, Eli] Heriot Watt Univ, Dept Comp Sci, Sch Math & Comp Sci, Edinburgh EH14 4AS, Midlothian, Scotland.
   [Little, Gillian] Univ Strathclyde, Sch Psychol Sci & Hlth, Glasgow G1 1QE, Lanark, Scotland.
   [Rajendran, Gnanathusharan] Heriot Watt Univ, Sch Social Sci, Dept Psychol, Edinburgh EH14 4AS, Midlothian, Scotland.
RP Lohan, KS (reprint author), Heriot Watt Univ, Dept Comp Sci, Sch Math & Comp Sci, Edinburgh EH14 4AS, Midlothian, Scotland.
EM k.lohan@hw.ac.uk
OI Rajendran, Gnanathusharan/0000-0001-5370-3656
FU EPSRC; Edinburgh Centre for Robotics
FX This work was supported in part by EPSRC and in part by the Edinburgh
   Centre for Robotics.
CR Aldaqre I, 2016, EXP BRAIN RES, V234, P2515, DOI 10.1007/s00221-016-4656-y
   Anderson CJ, 2006, J CLIN EXP NEUROPSYC, V28, P1238, DOI 10.1080/13803390500376790
   Bhat AN, 2010, J CHILD PSYCHOL PSYC, V51, P989, DOI 10.1111/j.1469-7610.2010.02262.x
   Bottou L, 2010, COMPSTAT'2010: 19TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL STATISTICS, P177, DOI 10.1007/978-3-7908-2604-3_16
   Brugha T, 2012, ESTIMATING PREVALENC
   Charman T, 2003, PHILOS T ROY SOC B, V358, P315, DOI 10.1098/rstb.2002.1199
   Charman T, 2016, DEV MED CHILD NEUROL, V58, P369, DOI 10.1111/dmcn.12874
   Chen SY, 2014, HUM-COMPUT INTERACT, V29, P390, DOI 10.1080/07370024.2014.892428
   Chevallier C, 2012, TRENDS COGN SCI, V16, P231, DOI 10.1016/j.tics.2012.02.007
   Coeckelbergh M, 2016, SCI ENG ETHICS, V22, P47, DOI 10.1007/s11948-015-9649-x
   Cooper RA, 2017, COGNITION, V159, P127, DOI 10.1016/j.cognition.2016.11.013
   Dauphin Y, 2015, ADV NEURAL INFORM PR, P1504
   Dawson G, 2004, DEV PSYCHOL, V40, P271, DOI 10.1037/0012-1649.40.2.271
   Dreyfus S., 1962, J MATH ANAL APPL, V5, P30
   Ebner NC, 2008, BEHAV RES METHODS, V40, P130, DOI [10.3758/BRM.40.1.130, 10.3738/BRM.40.1.130]
   Falck-Ytter T, 2015, CHILD DEV, V86, P37, DOI 10.1111/cdev.12273
   Falck-Ytter T, 2013, J NEURODEV DISORD, V5, DOI 10.1186/1866-1955-5-28
   Falck-Ytter T, 2008, AUTISM RES, V1, P297, DOI 10.1002/aur.45
   Fan XF, 2009, J AUTISM DEV DISORD, V39, P1499, DOI 10.1007/s10803-009-0767-7
   Fletcher-Watson S, 2009, NEUROPSYCHOLOGIA, V47, P248, DOI 10.1016/j.neuropsychologia.2008.07.016
   Freeth M, 2010, J AUTISM DEV DISORD, V40, P534, DOI 10.1007/s10803-009-0893-2
   Gernsbacher MA, 2008, CHILD DEV PERSPECT, V2, P49, DOI 10.1111/j.1750-8606.2008.00041.x
   Gottesman II, 2003, AM J PSYCHIAT, V160, P636, DOI 10.1176/appi.ajp.160.4.636
   Graves A, 2013, INT CONF ACOUST SPEE, P6645, DOI 10.1109/ICASSP.2013.6638947
   Gredeback G, 2010, DEVELOPMENTAL SCI, V13, P839, DOI 10.1111/j.1467-7687.2009.00945.x
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI 10.1162/neco.1997.9.8.1735
   Iarocci G, 2007, BRAIN COGNITION, V65, P112, DOI 10.1016/j.bandc.2007.01.008
   Insel TR, 2014, AM J PSYCHIAT, V171, P395, DOI 10.1176/appi.ajp.2014.14020138
   Jack RE, 2017, ANNU REV PSYCHOL, V68, P269, DOI 10.1146/annurev-psych-010416-044242
   Jones W, 2013, NATURE, V504, P427, DOI 10.1038/nature12715
   Klin A, 2003, PHILOS T ROY SOC B, V358, P345, DOI 10.1098/rstb.2002.1202
   Le Q. V., 2014, ADV NEURAL INFORM PR, V27, P3104, DOI DOI 10.1007/S10107-014-0839-0
   Leekam S, 1997, BRIT J DEV PSYCHOL, V15, P77, DOI 10.1111/j.2044-835X.1997.tb00726.x
   Little GE, 2016, 2016 JOINT IEEE INTERNATIONAL CONFERENCE ON DEVELOPMENT AND LEARNING AND EPIGENETIC ROBOTICS (ICDL-EPIROB), P15, DOI 10.1109/DEVLRN.2016.7846780
   Lohan KS, 2012, INT J SOC ROBOT, V4, P131, DOI 10.1007/s12369-011-0125-8
   MacQueen J. B., 1967, P 5 BERK S MATH STAT, P281, DOI DOI 10.1234/12345678
   Mathot S, 2014, J VISION, V14, DOI 10.1167/14.14.7
   McPartland JC, 2011, J AUTISM DEV DISORD, V41, P148, DOI 10.1007/s10803-010-1033-8
   Mele ML, 2012, COGN PROCESS, V13, pS261, DOI 10.1007/s10339-012-0499-z
   Muller CL, 2016, NEUROSCIENCE, V321, P24, DOI 10.1016/j.neuroscience.2015.11.010
   Mundy P, 2009, AUTISM RES, V2, P2, DOI 10.1002/aur.61
   Nowak W, 2014, BIOMED ENG ONLINE, V13, DOI 10.1186/1475-925X-13-69
   Nystrom P, 2015, MOL AUTISM, V6, DOI 10.1186/s13229-015-0011-6
   OSTERLING J, 1994, J AUTISM DEV DISORD, V24, P247, DOI 10.1007/BF02172225
   Palinko O., 2014, P WORKSH 9 ACM IEEE, V3
   Palinko O., 2011, P 6 INT DRIV S HUM F, P329
   Pong M, 2000, J NEUROPHYSIOL, V84, P953
   Riby DM, 2013, J NEURODEV DISORD, V5, DOI 10.1186/1866-1955-5-13
   Robinson EB, 2016, NAT GENET, V48, P552, DOI 10.1038/ng.3529
   Rukmini AV, 2017, SCI REP-UK, V7, DOI 10.1038/srep43832
   Rutter M., 2012, AUTISM DIAGNOSTIC OB
   Sabyruly Y., 2015, AAAI FALL S SERIES
   Scassellati B, 2012, ANNU REV BIOMED ENG, V14, P275, DOI 10.1146/annurev-bioeng-071811-150036
   Senju A, 2009, SCIENCE, V325, P883, DOI 10.1126/science.1176170
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Strimbu K, 2010, CURR OPIN HIV AIDS, V5, P463, DOI 10.1097/COH.0b013e32833ed177
   Tomasello M., 1995, JOINT ATTENTION ITS, P103
   Tomasello M, 2008, TRENDS LINGUIST-STUD, V197, P375
   Uljarevic M, 2013, J AUTISM DEV DISORD, V43, P1517, DOI 10.1007/s10803-012-1695-5
   Waterhouse L, 2016, REV J AUTISM DEV DIS, V3, P302, DOI 10.1007/s40489-016-0085-x
   Waterhouse L, 2014, J AUTISM DEV DISORD, V44, P1788, DOI 10.1007/s10803-013-2030-5
NR 61
TC 0
Z9 0
U1 4
U2 4
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2379-8920
EI 2379-8939
J9 IEEE T COGN DEV SYST
JI IEEE Trans. Cogn. Dev. Syst.
PD DEC
PY 2018
VL 10
IS 4
BP 983
EP 992
DI 10.1109/TCDS.2018.2838342
PG 10
WC Computer Science, Artificial Intelligence; Robotics; Neurosciences
SC Computer Science; Robotics; Neurosciences & Neurology
GA HD6HK
UT WOS:000452636400014
DA 2019-02-18
ER

PT J
AU Del Coco, M
   Leo, M
   Carcagni, P
   Fama, F
   Spadaro, L
   Ruta, L
   Pioggia, G
   Distante, C
AF Del Coco, Marco
   Leo, Marco
   Carcagni, Pierluigi
   Fama, Francesca
   Spadaro, Letteria
   Ruta, Liliana
   Pioggia, Giovanni
   Distante, Cosimo
TI Study of Mechanisms of Social Interaction Stimulation in Autism Spectrum
   Disorder by Assisted Humanoid Robot
SO IEEE TRANSACTIONS ON COGNITIVE AND DEVELOPMENTAL SYSTEMS
LA English
DT Article
DE Autism spectrum disorders (ASDs) diagnostic; behavioral imaging;
   human-machine interaction; optical metrology of behavior
ID CHILDREN; CLASSIFICATION; RECOGNITION
AB Information and communication technologies (ICTs) have been proved to have a great impact in enhancing social, communicative, and language development in children with autism spectrum disorders (ASDs) as demonstrated by plenty of effective technological tools reported in the literature for diagnosis, assessment, and treatment of such neurological diseases. On the contrary, there arc very few works exploiting ICT to study the mechanisms that trigger the behavioral patterns during the specialized sessions of treatment focused on social interaction stimulation. From the study of the literature it emerges that the behavioral outcomes are qualitatively evaluated by the therapists making this way impossible to assess, in a consistent manner, the worth of the supplied ASD treatments that should be based on quantitative metric not available for this purpose yet. Moreover, the rare attempts to use a methodological approach are limited to the study of one (of at least a couple) of the several behavioral cues involved. In order to till this gap, in this paper a technological framework able to analyze and integrate multiple visual cues in order to capture the behavioral trend along an ASD treatment is introduced. It is based on an algorithmic pipeline involving face detection, landmark extraction, gaze estimation, head pose estimation and facial expression recognition and it has been used to detect behavioral features during the interaction among different children, affected by ASD, and a humanoid robot. Experimental results demonstrated the superiority of the proposed framework in the specific application context with respect to leading approaches in the literature, providing a reliable pathway to automatically build a quantitative report that could help therapists to better achieve either ASD diagnosis or assessment tasks.
C1 [Del Coco, Marco; Leo, Marco; Carcagni, Pierluigi; Distante, Cosimo] Natl Res Council Italy, Inst Appl Sci & Intelligent Syst, I-73100 Lecce, Italy.
   [Fama, Francesca; Spadaro, Letteria; Ruta, Liliana; Pioggia, Giovanni] Natl Res Council Italy, Inst Appl Sci & Intelligent Syst, I-98164 Messina, Italy.
RP Del Coco, M (reprint author), Natl Res Council Italy, Inst Appl Sci & Intelligent Syst, I-73100 Lecce, Italy.
EM marco.leo@cnr.it
OI Pioggia, Giovanni/0000-0002-8089-7449; Leo, Marco/0000-0001-5636-6130
FU "Fondazione Cassa di Risparmio di Puglia" through the Project "Studio
   dei Meccanismi di Stimolazione Dell'interazione Sociale nel Disordine
   Dello Spettro Autistico Tramite Robot Umanoide Assistito"
   [961_1102014054704]
FX This work was supported by the "Fondazione Cassa di Risparmio di Puglia"
   through the Project "Studio dei Meccanismi di Stimolazione
   Dell'interazione Sociale nel Disordine Dello Spettro Autistico Tramite
   Robot Umanoide Assistito" under Grant 961_1102014054704.
CR Anzalone SM, 2014, RES AUTISM SPECT DIS, V8, P814, DOI 10.1016/j.rasd.2014.03.002
   Baltrusaitis T., 2015, 2015 11 IEEE INT C W, V6, P1, DOI DOI 10.1109/FG.2015.7284869
   Baltrusaitis T., 2016, 2016 IEEE WINT C APP, P1, DOI DOI 10.1109/WACV.2016.7477553
   Baltrusaitis T, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P354, DOI 10.1109/ICCVW.2013.54
   Bartlett M., 2008, P IEEE INT C AUT FAC, P1
   Belhumeur PN, 2013, IEEE T PATTERN ANAL, V35, P2930, DOI 10.1109/TPAMI.2013.23
   Boucenna S, 2014, COGN COMPUT, V6, P722, DOI 10.1007/s12559-014-9276-x
   Carcagni P, 2015, SPRINGERPLUS, V4, DOI 10.1186/s40064-015-1427-3
   Cazzato D, 2014, SENSORS-BASEL, V14, P8363, DOI 10.3390/s140508363
   Cristinacce David, 2006, P BRIT MACH VIS C, P929, DOI DOI 10.5244/C.20.95
   Duan DR, 2017, J AMB INTEL SMART EN, V9, P225, DOI 10.3233/AIS-170424
   Ekman P., 2013, EMOTION HUMAN FACE G
   Essa IA, 1997, IEEE T PATTERN ANAL, V19, P757, DOI 10.1109/34.598232
   Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167
   Ghayoumi M., P INT C CIRC SYST SI, P259
   Griffith R., 2006, GRIFFITHS MENTAL DEV
   Gross R, 2010, IMAGE VISION COMPUT, V28, P807, DOI 10.1016/j.imavis.2009.08.002
   Gunes H, 2016, IMAGE VISION COMPUT, V55, P6, DOI 10.1016/j.imavis.2016.03.013
   Hardy C., 2016, AUTISM ICT GUIDE TEA
   Hashemi J., 2014, AUTISM RES TREAT, V2014
   Hirokawa M, 2016, IEEE ROMAN, P843, DOI 10.1109/ROMAN.2016.7745217
   King DE, 2009, J MACH LEARN RES, V10, P1755
   Kumari P, 2017, BIOSENS BIOELECTRON, V90, P298, DOI 10.1016/j.bios.2016.12.001
   Le V, 2012, LECT NOTES COMPUT SC, V7574, P679, DOI 10.1007/978-3-642-33712-3_49
   Leo M, 2017, COMPUT VIS IMAGE UND, V154, P1, DOI 10.1016/j.cviu.2016.09.001
   Leo M, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0102829
   Li YQ, 2013, IEEE T IMAGE PROCESS, V22, P2559, DOI 10.1109/TIP.2013.2253477
   Lord C, 2012, ADOS 2 AUTISM DIAGNO
   Lorenzo G, 2016, COMPUT EDUC, V98, P192, DOI 10.1016/j.compedu.2016.03.018
   Martinez B., 2016, ADV FACE DETECTION F, P63, DOI DOI 10.1007/978-3-319-25958-1_4
   Mavadati SM, 2013, IEEE T AFFECT COMPUT, V4, P151, DOI 10.1109/T-AFFC.2013.4
   McDuff D, 2016, P 2016 CHI C EXT HUM, P3723, DOI DOI 10.1145/2851581.2890247
   McKeown G, 2010, IEEE INT CON MULTI, P1079, DOI 10.1109/ICME.2010.5583006
   Palshikar G, 2009, P 1 INT C ADV DAT AN, P1
   Pan YD, 2015, 2015 24TH IEEE INTERNATIONAL SYMPOSIUM ON ROBOT AND HUMAN INTERACTIVE COMMUNICATION (RO-MAN), P48, DOI 10.1109/ROMAN.2015.7333683
   Pusiol Guido, 2016, Medical Image Computing and Computer-Assisted Intervention - MICCAI 2016. 19th International Conference. Proceedings: LNCS 9901, P317, DOI 10.1007/978-3-319-46723-8_37
   Rajagopalan ShyamSundar, 2015, AUT FAC GEST REC FG, V1, P1
   Regier DA, 2013, WORLD PSYCHIATRY, V12, P92, DOI 10.1002/wps.20050
   Rehg JM, 2014, IEEE PERVAS COMPUT, V13, P84, DOI 10.1109/MPRV.2014.23
   Ruvolo P, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0136492
   Samad MD, 2016, OPT LASER TECHNOL, V77, P221, DOI 10.1016/j.optlastec.2015.09.030
   Sariyanidi E, 2015, IEEE T PATTERN ANAL, V37, P1113, DOI 10.1109/TPAMI.2014.2366127
   Washington P, 2016, P 2016 CHI C HUM FAC, P2348, DOI DOI 10.1145/2851581.2892282
   Wood E, 2015, IEEE I CONF COMP VIS, P3756, DOI 10.1109/ICCV.2015.428
   Zhang X, 2014, IMAGE VISION COMPUT, V32, P692, DOI 10.1016/j.imavis.2014.06.002
   Zhong L, 2012, PROC CVPR IEEE, P2562, DOI 10.1109/CVPR.2012.6247974
NR 46
TC 0
Z9 0
U1 7
U2 7
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2379-8920
EI 2379-8939
J9 IEEE T COGN DEV SYST
JI IEEE Trans. Cogn. Dev. Syst.
PD DEC
PY 2018
VL 10
IS 4
BP 993
EP 1004
DI 10.1109/TCDS.2017.2783684
PG 12
WC Computer Science, Artificial Intelligence; Robotics; Neurosciences
SC Computer Science; Robotics; Neurosciences & Neurology
GA HD6HK
UT WOS:000452636400015
DA 2019-02-18
ER

PT J
AU Moulin-Frier, C
   Fischer, T
   Petit, M
   Pointeau, G
   Puigbo, JY
   Pattacini, U
   Low, SC
   Camilleri, D
   Nguyen, P
   Hoffmann, M
   Chang, HJ
   Zambelli, M
   Mealier, AL
   Damianou, A
   Metta, G
   Prescott, TJ
   Demiris, Y
   Dominey, PF
   Verschure, PFMJ
AF Moulin-Frier, Clement
   Fischer, Tobias
   Petit, Maxime
   Pointeau, Gregoire
   Puigbo, Jordi-Ysard
   Pattacini, Ugo
   Ching Low, Sock
   Camilleri, Daniel
   Nguyen, Phuong
   Hoffmann, Matej
   Chang, Hyung Jin
   Zambelli, Martina
   Mealier, Anne-Laure
   Damianou, Andreas
   Metta, Giorgio
   Prescott, Tony J.
   Demiris, Yiannis
   Dominey, Peter Ford
   Verschure, Paul F. M. J.
TI DAC-h3: A Proactive Robot Cognitive Architecture to Acquire and Express
   Knowledge About the World and the Self
SO IEEE TRANSACTIONS ON COGNITIVE AND DEVELOPMENTAL SYSTEMS
LA English
DT Article
DE Autobiographical memory (ABM); cognitive robotics; distributed adaptive
   control (DAC); human-robot interaction (HRI); symbol grounding
ID AUTOBIOGRAPHICAL MEMORY; LANGUAGE; MODEL; COMMUNICATION; INTEGRATION;
   ATTENTION; BEHAVIOR; SYSTEMS
AB This paper introduces a cognitive architecture for a humanoid robot to engage in a proactive, mixed-initiative exploration and manipulation of its environment, where the initiative can originate from both human and robot. The framework, based on a biologically grounded theory of the brain and mind, integrates a reactive interaction engine, a number of state-of-the-art perceptual and motor learning algorithms, as well as planning abilities and an autobiographical memory. The architecture as a whole drives the robot behavior to solve the symbol grounding problem, acquire language capabilities, execute goal-oriented behavior, and express a verbal narrative of its own experience in the world. We validate our approach in human-robot interaction experiments with the iCub humanoid robot, showing that the proposed cognitive architecture can be applied in real time within a realistic scenario and that it can be used with naive users.
C1 [Moulin-Frier, Clement; Puigbo, Jordi-Ysard; Ching Low, Sock; Verschure, Paul F. M. J.] Univ Pompeu Fabra, Lab Synthet Percept Emot & Cognit Syst, Barcelona 08002, Spain.
   [Fischer, Tobias; Petit, Maxime; Chang, Hyung Jin; Zambelli, Martina; Demiris, Yiannis] Imperial Coll London, Dept Elect & Elect Engn, Personal Robot Lab, London SW7 2AZ, England.
   [Pointeau, Gregoire; Mealier, Anne-Laure; Dominey, Peter Ford] INSERM U846 Stem Cell & Brain Res Inst, Robot Cognit Lab, F-69675 Bron, France.
   [Pattacini, Ugo; Nguyen, Phuong; Hoffmann, Matej; Metta, Giorgio] Italian Inst Technol, Dept iCub Facil, I-16163 Genoa, Italy.
   [Camilleri, Daniel; Damianou, Andreas; Prescott, Tony J.] Univ Sheffield, Dept Comp Sci, Sheffield S10 2TN, S Yorkshire, England.
   [Hoffmann, Matej] Czech Tech Univ, Fac Elect Engn, Dept Cybernet, Prague 16636, Czech Republic.
   [Damianou, Andreas] Amazon Com, Cambridge CB3 0RD, England.
   [Verschure, Paul F. M. J.] Inst Bioengn Catalonia IBEC, Barcelona 08028, Spain.
   [Verschure, Paul F. M. J.] BIST, Barcelona 08036, Spain.
   [Verschure, Paul F. M. J.] Inst Catalana Recerca & Estudis Avancats ICREA, Barcelona 08010, Spain.
RP Fischer, T (reprint author), Imperial Coll London, Dept Elect & Elect Engn, Personal Robot Lab, London SW7 2AZ, England.
EM t.fischer@imperial.ac.uk
OI Hoffmann, Matej/0000-0001-8137-3412; Chang, Hyung
   Jin/0000-0001-7495-9677; Pattacini, Ugo/0000-0001-8754-1632; Fischer,
   Tobias/0000-0003-2183-017X; Moulin-Frier, Clement/0000-0002-7258-7256
FU European Research Council through the European Union's Seventh Framework
   Programme (FP/2007-2013); ERC through the What You Say Is What You Did
   project [FP7-ICT-612139]; ERC's CDAC Project-Role of Consciousness in
   Adaptive Behavior [ERC-2013-ADG 341196]; EU Seventh Framework Programme
   as part of the Human Brain (HBP-SGA1) [720270]; ERC's H2020 [642667];
   Czech Science Foundation [GA17-15697Y]
FX This work was supported in part by the European Research Council through
   the European Union's Seventh Framework Programme (FP/2007-2013), in part
   by the ERC through the What You Say Is What You Did project under Grant
   FP7-ICT-612139, and in part by the ERC's CDAC Project-Role of
   Consciousness in Adaptive Behavior under Grant ERC-2013-ADG 341196. The
   work of D. Camilleri and T. Prescott was supported by the EU Seventh
   Framework Programme as part of the Human Brain (HBP-SGA1) under Project
   720270. The work of P. Nguyen was supported by the ERC's H2020 under
   Grant 642667 (SECURE). The work of M. Hoffmann was supported by the
   Czech Science Foundation under Project GA17-15697Y.
CR Adams B, 2000, IEEE INTELL SYST APP, V15, P25, DOI 10.1109/5254.867909
   Anderson J. R., 1983, ARCHITECTURE COGNITI
   Antunes A, 2016, IEEE INT CONF ROBOT, P5449, DOI 10.1109/ICRA.2016.7487757
   Berlyne DE, 1954, BRIT J PSYCHOL, V45, P180, DOI 10.1111/j.2044-8295.1954.tb01243.x
   Billard A, 1998, ROBOT AUTON SYST, V24, P71, DOI 10.1016/S0921-8890(98)00023-2
   Blouw P, 2016, COGNITIVE SCI, V40, P1128, DOI 10.1111/cogs.12265
   Breazeal C, 2000, ADAPT BEHAV, V8, P49, DOI 10.1177/105971230000800104
   BROOKS RA, 1991, ARTIF INTELL, V47, P139, DOI 10.1016/0004-3702(91)90053-M
   BROOKS RA, 1986, IEEE T ROBOTIC AUTOM, V2, P14, DOI 10.1109/JRA.1986.1087032
   Broz F, 2014, TOP COGN SCI, V6, P534, DOI 10.1111/tops.12099
   Calinon S, 2010, IEEE ROBOT AUTOM MAG, V17, P44, DOI 10.1109/MRA.2010.936947
   Camilleri D, 2016, LECT NOTES COMPUT SC, V9793, P48, DOI 10.1007/978-3-319-42417-0_5
   Cangelosi A., 2006, PRAGMAT COGN, V14, P275, DOI DOI 10.1075/PC.14.2.08CAN
   Cangelosi A, 2010, IEEE T AUTON MENT DE, V2, P167, DOI 10.1109/TAMD.2010.2053034
   Cangelosi A, 2006, IEEE IJCNN, P1576
   Carruthers P, 1996, THEORIES THEORIES MI
   Chang H. J., 2017, IEEE T PATTERN ANAL
   Chang HJ, 2016, PROC CVPR IEEE, P4216, DOI 10.1109/CVPR.2016.457
   Coradeschi S, 2003, ROBOT AUTON SYST, V43, P85, DOI 10.1016/S0921-8890(03)00021-6
   Damianou A. C., 2013, P AISTATS, V31, P207
   Damianou A, 2015, LECT NOTES ARTIF INT, V9222, P280, DOI 10.1007/978-3-319-22979-9_28
   Dautenhahn K., 1999, Proceedings of the Third International Conference on Autonomous Agents, P366, DOI 10.1145/301136.301237
   Dautenhahn K, 2007, PHILOS T R SOC B, V362, P679, DOI 10.1098/rstb.2006.2004
   Demiris Y, 2008, INFANT CHILD DEV, V17, P43, DOI 10.1002/icd.543
   Demiris Y, 2014, NEUROINFORMATICS, V12, P63, DOI 10.1007/s12021-013-9200-7
   Di Nuovo AG, 2013, NEURAL NETWORKS, V41, P147, DOI 10.1016/j.neunet.2012.09.019
   Di Paolo E, 2012, FRONT HUM NEUROSCI, V6, DOI 10.3389/fnhum.2012.00163
   Dias J, 2007, LECT NOTES COMPUT SC, V4738, P606
   Duff A, 2011, BRAIN RES BULL, V85, P289, DOI 10.1016/j.brainresbull.2010.11.008
   Eliasmith C, 2012, SCIENCE, V338, P1202, DOI 10.1126/science.1225266
   Ewerton M, 2015, IEEE INT C INT ROBOT, P456, DOI 10.1109/IROS.2015.7353412
   Fanello SR, 2014, IEEE-RAS INT C HUMAN, P1028, DOI 10.1109/HUMANOIDS.2014.7041491
   Fischer T, 2016, IEEE INT CONF ROBOT, P3309, DOI 10.1109/ICRA.2016.7487504
   Fitzpatrick P, 2008, ROBOT AUTON SYST, V56, P29, DOI 10.1016/j.robot.2007.09.014
   Fong T, 2003, ROBOT AUTON SYST, V42, P143, DOI 10.1016/S0921-8890(02)00372-X
   Gardenfors P., 2000, CONCEPTUAL SPACES GE
   HARNAD S, 1990, PHYSICA D, V42, P335, DOI 10.1016/0167-2789(90)90087-6
   Hinaut X, 2014, FRONT NEUROROBOTICS, V8, P1, DOI 10.3389/fnbot.2014.00016
   Hinaut X, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0052946
   Ivaldi S, 2014, IEEE T AUTON MENT DE, V6, P56, DOI 10.1109/TAMD.2013.2280614
   Jamone L., IEEE T COGN DEV SYST
   Jamone L, 2014, ROBOT AUTON SYST, V62, P556, DOI 10.1016/j.robot.2013.12.011
   Johnson M., 2005, International Journal of Advanced Robotic Systems, V2, P301
   KAPLAN F, 2000, COM ADAP SY, P372
   Kovacs D. L., 2012, P 3 WORKSH INT PLANN, P19
   Krause E. A., 2014, AAAI, P2796
   Kruger N, 2011, ROBOT AUTON SYST, V59, P740, DOI 10.1016/j.robot.2011.05.009
   LAIRD JE, 1987, ARTIF INTELL, V33, P1, DOI 10.1016/0004-3702(87)90050-6
   Lallee Stephane, 2015, Paladyn, Journal of Behavioral Robotics, V6, P136, DOI 10.1515/pjbr-2015-0010
   Lallee S, 2015, ROBOTICS, V4, P169, DOI 10.3390/robotics4020169
   Lallee S, 2013, IEEE INT C INT ROBOT, P129, DOI 10.1109/IROS.2013.6696343
   Lallee S, 2012, IEEE T AUTON MENT DE, V4, P239, DOI 10.1109/TAMD.2012.2199754
   Lee K, 2013, ROBOT AUTON SYST, V61, P1323, DOI 10.1016/j.robot.2013.08.003
   Levinson S. C., 2006, ROOTS HUMAN SOCIALIT, P39, DOI DOI 10.3389/FPSYG.2015.00731
   Lieto A, 2017, BIOL INSPIR COGN ARC, V19, P1, DOI 10.1016/j.bica.2016.10.005
   Liszkowski U, 2004, DEVELOPMENTAL SCI, V7, P297, DOI 10.1111/j.1467-7687.2004.00349.x
   Lutkebohle Ingo, 2009, 2009 IEEE International Conference on Robotics and Automation (ICRA), P4156, DOI 10.1109/ROBOT.2009.5152521
   Malfaz M, 2011, IEEE T AUTON MENT DE, V3, P232, DOI 10.1109/TAMD.2011.2112766
   Marocco D., 2010, FRONT NEUROROBOTICS, V4, P1
   Mathews Z, 2012, INFORM SCIENCES, V186, P1, DOI 10.1016/j.ins.2011.09.042
   Mealier AL, 2016, INTERACT STUD, V17, P48, DOI 10.1075/is.17.1.03mea
   Metta G, 2010, NEURAL NETWORKS, V23, P1125, DOI 10.1016/j.neunet.2010.08.010
   Miklosi A, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00075
   Moulin-Frier C, 2015, J PHONETICS, V53, P5, DOI 10.1016/j.wocn.2015.06.001
   Moulin-Frier C, 2014, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.01006
   Newell A., 1959, P INT C INF PROC, P256
   Newell Allen, 1990, UNIFIED THEORIES COG
   Nourbakhsh IR, 1999, ARTIF INTELL, V114, P95, DOI 10.1016/S0004-3702(99)00027-2
   Oudeyer PY, 2007, IEEE T EVOLUT COMPUT, V11, P265, DOI 10.1109/TEVC.2006.890271
   Parmiggiani A, 2012, INT J HUM ROBOT, V9, DOI 10.1142/S0219843612500272
   Pasquale G, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P4904, DOI 10.1109/IROS.2016.7759720
   Pattacini U, 2010, IEEE INT C INT ROBOT, P1668, DOI 10.1109/IROS.2010.5650851
   Petit M., 2016, P IEEE RSJ INT C INT
   Petit M, 2016, IEEE T COGN DEV SYST, V8, P201, DOI 10.1109/TAMD.2015.2507439
   Petit M, 2013, IEEE T AUTON MENT DE, V5, P3, DOI 10.1109/TAMD.2012.2209880
   Piaget J., 1954, CONSTRUCTION REALITY
   Pineau J, 2003, ROBOT AUTON SYST, V42, P271, DOI 10.1016/S0921-8890(02)00381-0
   Pointeau G, 2014, IEEE T AUTON MENT DE, V6, P200, DOI 10.1109/TAMD.2014.2307342
   Prescott T. J., 2014, P C BIOINS BIOM BIOR
   Puigbo JY, 2016, LECT NOTES COMPUT SC, V9793, P490, DOI 10.1007/978-3-319-42417-0_52
   Puigbo JY, 2015, IEEE-RAS INT C HUMAN, P447, DOI 10.1109/HUMANOIDS.2015.7363580
   Quine M. V., 1960, WORD OBJECT
   Roncone A, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0163713
   Fibla MS, 2010, IEEE INT C INT ROBOT, P1935, DOI 10.1109/IROS.2010.5652866
   Sanchez-Fibla M, 2010, ADV COMPLEX SYST, V13, P377, DOI 10.1142/S0219525910002621
   Scassellati B, 2003, IEEE IJCNN, P2704
   Schaal S, 1999, TRENDS COGN SCI, V3, P233, DOI 10.1016/S1364-6613(99)01327-3
   Scheutz M., 2013, P 2013 AAAI WORKSH I, P66
   Schrempf OC, 2005, 2005 IEEE International Workshop on Robot and Human Interactive Communication (RO-MAN), P555
   Sieber G, 2010, LECT NOTES ARTIF INT, V6356, P322, DOI 10.1007/978-3-642-15892-6_33
   STEELS L, 1997, EVOLUTION COMMUNICAT, V1, P1
   Stoytchev A, 2001, 2001 IEEE INTERNATIONAL SYMPOSIUM ON COMPUTATIONAL INTELLIGENCE IN ROBOTICS AND AUTOMATION, P290, DOI 10.1109/CIRA.2001.1013214
   Syrdal DS, 2014, COGN COMPUT, V6, P741, DOI 10.1007/s12559-014-9284-x
   Taniguchi T, 2016, IFAC PAPERSONLINE, V49, P144, DOI 10.1016/j.ifacol.2016.10.476
   Taniguchi T, 2016, ADV ROBOTICS, V30, P770, DOI 10.1080/01691864.2016.1159981
   Tomasello M, 2005, BEHAV BRAIN SCI, V28, P675, DOI 10.1017/S0140525X05000129
   Vernon D, 2015, FRONT ROBOT AI, V2, P19, DOI [10.3389/frobt.2015.00019, DOI 10.3389/FROBT.2015.00019]
   Vernon D, 2016, BIOL INSPIR COGN ARC, V18, P116, DOI 10.1016/j.bica.2016.10.004
   Verschure PFMJ, 2013, IEEE INTELL SYST, V28, P33
   Verschure PFMJ, 2003, NATURE, V425, P620, DOI 10.1038/nature02024
   Verschure PFMJ, 2014, BIOL SCI, V369, P1655, DOI DOI 10.1098/RSTB.2013.0483
   VOGT P, 2002, COGNITIVE SYSTEMS RE, V3, P429, DOI DOI 10.1016/S1389-0417(02)00051-7
   Vogt P, 2007, INTERACT STUD, V8, P31, DOI 10.1075/is.8.1.04vog
   Vouloutsi Vasiliki, 2014, Biomimetic and Biohybrid Systems. Third International Conference, Living Machines 2014. Proceedings. LNCS: 8608, P332
   Vouloutsi V, 2016, LECT NOTES COMPUT SC, V9793, P353, DOI 10.1007/978-3-319-42417-0_32
   Vygotsky L. S., 1978, MIND SOC DEV HIGHER
   Zambelli M., 2016, P IEEE RSJ INT C INT
   Zambelli M, 2017, IEEE T COGN DEV SYST, V9, P113, DOI 10.1109/TCDS.2016.2624705
NR 108
TC 3
Z9 3
U1 3
U2 3
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2379-8920
EI 2379-8939
J9 IEEE T COGN DEV SYST
JI IEEE Trans. Cogn. Dev. Syst.
PD DEC
PY 2018
VL 10
IS 4
BP 1005
EP 1022
DI 10.1109/TCDS.2017.2754143
PG 18
WC Computer Science, Artificial Intelligence; Robotics; Neurosciences
SC Computer Science; Robotics; Neurosciences & Neurology
GA HD6HK
UT WOS:000452636400016
OA Green Published
DA 2019-02-18
ER

PT J
AU Chen, YX
   Bordes, JB
   Filliat, D
AF Chen, Yuxin
   Bordes, Jean-Baptiste
   Filliat, David
TI Comparison Studies on Active Cross-Situational Object-Word Learning
   Using Non-Negative Matrix Factorization and Latent Dirichlet Allocation
SO IEEE TRANSACTIONS ON COGNITIVE AND DEVELOPMENTAL SYSTEMS
LA English
DT Article
DE Active learning; cross-situational learning; developmental robotics;
   latent Dirichlet association (LDA); non-negative matrix factorization
   (NMF); word-referent learning
ID SPATIAL LANGUAGE; ROBOT; BEHAVIOR
AB Future intelligent robots are expected to be able to adapt continuously to their environment. For this purpose, recognizing new objects and learning new words through interactive learning with humans is fundamental. Such setup results in ambiguous teaching data which humans have been shown to address using cross-situational learning, i.e., by analyzing common factors between multiple learning situations. Moreover, they have been shown to be more efficient when actively choosing the learning samples, e.g., which object they want to learn. Implementing such abilities on robots can be performed by latent-topic learning models such as non-negative matrix factorization or latent Dirichlet allocation. These cross-situational learning methods tackle referential and linguistic ambiguities, and can be associated with active learning strategies. We propose two such methods: 1) the maximum reconstruction error-based selection and 2) confidence base exploration. We present extensive experiments using these two learning algorithms through a systematic analysis on the effects of these active learning strategies in contrast with random choice. In addition, we study the factors underlying the active learning by focusing on the use of sample repetition, one of the learning behaviors that have been shown to be important for humans.
C1 [Chen, Yuxin; Filliat, David] ENSTA ParisTech, Unite Informat & Ingn Syst, F-91120 Palaiseau, France.
   [Chen, Yuxin; Filliat, David] INRIA, Flowing Epigenet Robots & Syst Team, F-78153 Rocquencourt, France.
   [Chen, Yuxin; Filliat, David] Univ Paris Saclay, F-91120 Palaiseau, France.
   [Bordes, Jean-Baptiste] Univ Paris Saclay, Ecole Polytech, F-91120 Palaiseau, France.
RP Chen, YX (reprint author), ENSTA ParisTech, Unite Informat & Ingn Syst, F-91120 Palaiseau, France.
EM yuxin.chen@ensta-paristech.fr; jean-baptiste.bordes@polytechnique.edu;
   david.filliat@ensta-paristech.fr
OI Filliat, David/0000-0002-5739-1618
FU China Scholarship Council
FX This work was supported by the China Scholarship Council.
CR Akhtar N., 1999, FIRST LANG, V19, P347, DOI DOI 10.1177/014272379901905703
   Altosaar T., 2010, P INT C LANG RES EV, P1062
   Araki T, 2011, IEEE INT C INT ROBOT, P1540, DOI 10.1109/IROS.2011.6048422
   BANDURA A, 1989, SOCIAL LEARNING THEO, V44, P1175, DOI DOI 10.111141460-2466.1978.TB01621.X
   Bandura A., 1963, SOCIAL LEARNING PERS
   Blei D. M., 2004, ADV NEURAL INFORM PR, P2003
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Calinon S, 2007, INTERACT STUD, V8, P441
   CALL J, 2002, COM ADAP SY, P211
   Cangelosi A., 2006, PRAGMAT COGN, V14, P275, DOI DOI 10.1075/PC.14.2.08CAN
   Chandrashekhariah Pramod, 2013, Proceedings of the 8th International Conference on Computer Vision Theory and Applications. VISAPP 2013, P169
   Chen YX, 2016, 2016 JOINT IEEE INTERNATIONAL CONFERENCE ON DEVELOPMENT AND LEARNING AND EPIGENETIC ROBOTICS (ICDL-EPIROB), P217, DOI 10.1109/DEVLRN.2016.7846822
   Chen YX, 2015, 5TH INTERNATIONAL CONFERENCE ON DEVELOPMENT AND LEARNING AND ON EPIGENETIC ROBOTICS (ICDL-EPIROB), P129, DOI 10.1109/DEVLRN.2015.7346129
   Coradeschi S, 2013, KUNSTL INTELL, V27, P129, DOI 10.1007/s13218-013-0247-2
   Coventry KR, 2004, ESSAYS COGN PSYCHOL, P1
   Cover T. M., 2012, ELEMENTS INFORM THEO
   Fontanari JF, 2011, INTERACT STUD, V12, P119, DOI 10.1075/is.12.1.05fon
   Gentner D, 1999, COGNITIVE DEV, V14, P487, DOI 10.1016/S0885-2014(99)00016-7
   Gold K., 2006, P 5 INT C DEV LEARN
   Gong YC, 2014, INT J COMPUT VISION, V106, P210, DOI 10.1007/s11263-013-0658-4
   Gorniak P. J., 2005, THESIS
   Grollman DH, 2008, IEEE INT CONF ROBOT, P3315, DOI 10.1109/ROBOT.2008.4543716
   HARNAD S, 1990, PHYSICA D, V42, P335, DOI 10.1016/0167-2789(90)90087-6
   Isbell C. L.  Jr., 2001, Proceedings of the Fifth International Conference on Autonomous Agents, P377, DOI 10.1145/375735.376334
   Joe Yue-Hei Ng, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P53, DOI 10.1109/CVPRW.2015.7301272
   Kachergis G., 2009, P 31 ANN M COGN SCI, P1704
   Kachergis G, 2017, COGNITIVE SCI, V41, P590, DOI 10.1111/cogs.12353
   Kachergis G, 2013, TOP COGN SCI, V5, P200, DOI 10.1111/tops.12008
   Kersting K, 2010, JMLR WORKSH CONF PRO, V13, P253
   Larson S. D., 2004, INTRINSIC REPRESENTA
   Lee DD, 1999, NATURE, V401, P788, DOI 10.1038/44565
   Maclin Richard, 2005, P 20 NAT C ART INT, P819
   Mangin O., 2014, THESIS
   Mavridis N., 2009, 2009 4th ACM/IEEE International Conference on Human-Robot Interaction (HRI)
   Mavridis N, 2006, 2006 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-12, P4690, DOI 10.1109/IROS.2006.282258
   Noda K, 2014, ROBOT AUTON SYST, V62, P721, DOI 10.1016/j.robot.2014.03.003
   Oudeyer PY, 2007, IEEE T EVOLUT COMPUT, V11, P265, DOI 10.1109/TEVC.2006.890271
   Piaget J., 1999, DEV PSYCHOL
   Pinker S., 1984, LANGUAGE LEARNABILIT, V193
   Quine W. V. O., 1960, LANGUAGE, P1
   Regier T, 2001, J EXP PSYCHOL GEN, V130, P273, DOI 10.1037//0096-3445.130.2.273
   Roy D. K., 2000, P INT C COGN MOD ICC
   Roy DK, 2002, COGNITIVE SCI, V26, P113, DOI 10.1016/S0364-0213(01)00061-1
   Roy DK, 2002, COMPUT SPEECH LANG, V16, P353, DOI 10.1016/S0885-2308(02)00024-4
   SALTON G, 1988, INFORM PROCESS MANAG, V24, P513, DOI 10.1016/0306-4573(88)90021-0
   Schueller W, 2015, 5TH INTERNATIONAL CONFERENCE ON DEVELOPMENT AND LEARNING AND ON EPIGENETIC ROBOTICS (ICDL-EPIROB), P220, DOI 10.1109/DEVLRN.2015.7346144
   Skubic M, 2004, IEEE T SYST MAN CY C, V34, P154, DOI 10.1109/TSMCC.2004.826273
   Spexard T, 2006, 2006 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-12, P934, DOI 10.1109/IROS.2006.281770
   Steels L, 2003, TRENDS COGN SCI, V7, P308, DOI 10.1016/S1364-6613(03)00129-3
   Tellex S, 2014, MACH LEARN, V94, P151, DOI 10.1007/s10994-013-5383-2
   Tellex S, 2011, AI MAG, V32, P64, DOI 10.1609/aimag.v32i4.2384
   Thomaz AL, 2008, ARTIF INTELL, V172, P716, DOI 10.1016/j.artint.2007.09.009
   Tomasello M., 1999, CULTURAL ORIGINS HUM, V114
   VOGT P, 2002, COGNITIVE SYSTEMS RE, V3, P429, DOI DOI 10.1016/S1389-0417(02)00051-7
   Yu C, 2004, PROCEEDING OF THE NINETEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE SIXTEENTH CONFERENCE ON INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE, P488
   Yu C., 2008, P 30 ANN C COGN SCI, P1017
   Zender H, 2008, ROBOT AUTON SYST, V56, P493, DOI 10.1016/j.robot.2008.03.007
NR 57
TC 0
Z9 0
U1 3
U2 3
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2379-8920
EI 2379-8939
J9 IEEE T COGN DEV SYST
JI IEEE Trans. Cogn. Dev. Syst.
PD DEC
PY 2018
VL 10
IS 4
BP 1023
EP 1034
DI 10.1109/TCDS.2017.2725304
PG 12
WC Computer Science, Artificial Intelligence; Robotics; Neurosciences
SC Computer Science; Robotics; Neurosciences & Neurology
GA HD6HK
UT WOS:000452636400017
DA 2019-02-18
ER

PT J
AU Sturdivant, RL
   Chong, EKP
AF Sturdivant, Rick L.
   Chong, Edwin K. P.
TI The Necessary and Sufficient Conditions for Emergence in Systems Applied
   to Symbol Emergence in Robots
SO IEEE TRANSACTIONS ON COGNITIVE AND DEVELOPMENTAL SYSTEMS
LA English
DT Article
DE Causation; complexity; emergence; robots; self-organization; symbol
   emergence; symbol emergence in robots; systems engineering
AB A conceptual model for emergence with downward causation is developed. In addition, the necessary and sufficient, conditions are identified for a phenomenon to be considered emergent in a complex system. It is then applied to symbol emergence in robots. This paper is motivated by the usefulness of emergence to explain a wide variety of phenomena in systems, and cognition in natural and artificial creatures. Downward causation is shown to be a critical requirement for potentially emergent phenomena to be considered actually emergent. Models of emergence with and without downward causation are described and how weak emergence can include downward causation. A process flow is developed for distinguishing emergence from nonemergence based upon the application of reduction ism and detection of downward causation. Examples are shown for applying the necessary and sufficient conditions to filter out actually emergent phenomena from nonemergent ones. Finally, this approach for detecting emergence is applied to complex projects and symbol emergence in robots.
C1 [Sturdivant, Rick L.] Azusa Pacific Univ, Engn & Comp Sci Dept, Azsua, CA 91702 USA.
   [Chong, Edwin K. P.] Colorado State Univ, Elect & Comp Engn Dept, Ft Collins, CO 80523 USA.
   [Chong, Edwin K. P.] Colorado State Univ, Math Dept, Ft Collins, CO 80523 USA.
RP Sturdivant, RL (reprint author), Azusa Pacific Univ, Engn & Comp Sci Dept, Azsua, CA 91702 USA.
EM ricksturdivant@apu.edu
CR Baraglia J, 2016, IEEE T COGN DEV SYST, V8, P141, DOI 10.1109/TCDS.2016.2562121
   Bedau M., 2002, PRINCIPIA, V6, P5
   Binder PM, 2009, NATURE, V459, P332, DOI 10.1038/459332a
   Blanchard B. S., 2011, SYSTEMS ENG ANAL, P15
   BUNGE M, 1963, PHILOS SCI, V30, P346, DOI 10.1086/287954
   Chalmers D., 2006, REEMERGENCE EMERGENC, P244, DOI DOI 10.1093/ACPROF:OSO/9780199544318.003.0011
   Chan WKV, 2011, WINT SIMUL C PROC, P357, DOI 10.1109/WSC.2011.6147763
   Chen C.-C., 2008, P 7 INT C COMPL SYST, P14
   Chen C.-C., 2007, P 2007 SUMM COMP SIM, P969
   Chen CY, 2007, PROC MONOGR ENG WATE, P35
   Cui T, 2007, Proceedings of 2007 International Conference on Management Science & Engineering (14th) Vols 1-3, P916
   Deguet Joris, 2006, ComPlexUs, V3, P24, DOI 10.1159/000094185
   Francis R, 2014, RELIAB ENG SYST SAFE, V121, P90, DOI 10.1016/j.ress.2013.07.004
   GARDNER M, 1970, SCI AM, V223, P120, DOI 10.1038/scientificamerican1070-120
   Gore Ross, 2007, 2007 Winter Simulation Conference, P1232, DOI 10.1109/WSC.2007.4419726
   Gu M, 2009, PHYSICA D, V238, P835, DOI 10.1016/j.physd.2008.12.016
   Harper DA, 2012, J ECON BEHAV ORGAN, V82, P329, DOI 10.1016/j.jebo.2012.02.004
   Harper DA, 2012, J ECON BEHAV ORGAN, V82, P352, DOI 10.1016/j.jebo.2011.03.013
   HEPPNER F, 1990, UBIQUITY OF CHAOS, P233
   Johnson CW, 2006, RELIAB ENG SYST SAFE, V91, P1475, DOI 10.1016/j.ress.2006.01.008
   Laplace P. S., 1951, PHILOS ESSAY PROBABI
   Ljung L, 2010, ANNU REV CONTROL, V34, P1, DOI 10.1016/j.arcontrol.2009.12.001
   Maier M., 1998, SYST ENG, V1, P267, DOI DOI 10.1002/(SICI)1520-6858(1998)1:4<267::AID-SYS3>3.0.C0;2-D
   Navarro Inaki, 2013, ISRN Robotics, DOI 10.5402/2013/608164
   Okubo A., 1986, Advances in Biophysics, V22, P1, DOI 10.1016/0065-227X(86)90003-1
   Piagent J., 1970, GENETIC EPISTEMOLOGY
   Reynolds C., 1987, COMPUT GRAPH, V21, P25, DOI DOI 10.1145/37402.37406
   Sawyer R. K., 2000, MULTIAGENT BASED SIM, P49
   Senanayake M, 2016, ROBOT AUTON SYST, V75, P422, DOI 10.1016/j.robot.2015.08.010
   Sjoberg J, 1995, AUTOMATICA, V31, P1691, DOI 10.1016/0005-1098(95)00120-8
   Szabo C., 2012, P 2012 IEEE C EV COM, P1
   Szabo C, 2014, WINT SIMUL C PROC, P207, DOI 10.1109/WSC.2014.7019889
   Tani J., 2016, EXPLORING ROBOTIC MI, P216
   Taniguchi T., 2016, P 13 IFAC S AN DES E
   Taniguchi T, 2016, ADV ROBOTICS, V30, P770, DOI 10.1080/01691864.2016.1159981
   Wagner RE, 2012, J ECON BEHAV ORGAN, V82, P433, DOI 10.1016/j.jebo.2011.07.019
   Wolpert DH, 2008, PHYSICA D, V237, P1257, DOI 10.1016/j.physd.2008.03.040
   Yamashita Y, 2008, PLOS COMPUT BIOL, V4, DOI 10.1371/journal.pcbi.1000220
   Zhu J, 2017, INT J PROJ MANAG, V35, P1, DOI 10.1016/j.ijproman.2016.10.004
NR 39
TC 0
Z9 0
U1 0
U2 0
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2379-8920
EI 2379-8939
J9 IEEE T COGN DEV SYST
JI IEEE Trans. Cogn. Dev. Syst.
PD DEC
PY 2018
VL 10
IS 4
BP 1035
EP 1042
DI 10.1109/TCDS.2017.2731361
PG 8
WC Computer Science, Artificial Intelligence; Robotics; Neurosciences
SC Computer Science; Robotics; Neurosciences & Neurology
GA HD6HK
UT WOS:000452636400018
DA 2019-02-18
ER

PT J
AU Nakamura, T
   Nagai, T
AF Nakamura, Tomoaki
   Nagai, Takayuki
TI Ensemble-of-Concept Models for Unsupervised Formation of Multiple
   Categories
SO IEEE TRANSACTIONS ON COGNITIVE AND DEVELOPMENTAL SYSTEMS
LA English
DT Article
DE Concept formation; language acquisition; multimodal object dataset
ID ROBOT; RECOGNITION; VISION
AB Recent studies have shown that robots can form concepts and understand the meanings of words through inference. The key idea underlying these studies is the "multimodal categorization" of a robot's experiences. Despite the success in the formation of concepts by robots, a major drawback of previous studies stems from the fact that they have been mainly focused on object concepts. Obviously, human concepts are limited not only to object concepts but also to other kinds such as those connected to the tactile sense and color. In this paper, we propose a novel model called the ensemble-of-concept models (EoCMs) to form various kinds of concepts. In EoCMs, we introduce weights that represent the strength connecting modalities and concepts. By changing these weights, many concepts that are connected to particular modalities can be formed; however, meaningless concepts for humans are included in these concepts. To communicate with humans, robots arc required to form meaningful concepts for us. Therefore, we utilize utterances taught by human users as the robot observes objects. The robot connects words included in the teaching utterances with formed concepts and selects meaningful concepts to communicate with users. The experimental results show that the robot can form not only object concepts but also others such as color-related concepts and haptic concepts. Furthermore, using word2vec, we compare the meanings of the words acquired by the robot in connecting them to the concepts formed.
C1 [Nakamura, Tomoaki; Nagai, Takayuki] Univ Electrocommun, Dept Mech Engn & Intelligent Syst, Chofu, Tokyo 1828585, Japan.
RP Nakamura, T (reprint author), Univ Electrocommun, Dept Mech Engn & Intelligent Syst, Chofu, Tokyo 1828585, Japan.
EM tnakamura@uec.ac.jp
FU JST CREST [JPMJCR15E3]; JSPS KAKENHI [JP17K12758]
FX This work was supported in part by JST CREST under Grant JPMJCR15E3, and
   in part by JSPS KAKENHI under Grant JP17K12758.
CR Aldous D. J., 1985, LECT NOTES MATH, P1, DOI DOI 10.1007/BFB0099421
   Ando Y, 2013, IEEE INT C INT ROBOT, P2272, DOI 10.1109/IROS.2013.6696674
   Araki T, 2013, IEEE INT C INT ROBOT, P2280, DOI 10.1109/IROS.2013.6696675
   Araki T, 2012, ADV ROBOTICS, V26, P1995, DOI 10.1080/01691864.2012.728693
   Barsalou LW, 1999, BEHAV BRAIN SCI, V22, P577
   Belpaeme T, 2005, ADAPT BEHAV, V13, P293, DOI 10.1177/105971230501300404
   Belpaeme T, 2012, ADV COMPLEX SYST, V15, DOI 10.1142/S0219525912500312
   Bergen BK, 2012, LOUDER WORDS NEW SCI
   Biswas J, 2013, INT J ROBOT RES, V32, P1679, DOI 10.1177/0278364913503892
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Chen YX, 2015, 5TH INTERNATIONAL CONFERENCE ON DEVELOPMENT AND LEARNING AND ON EPIGENETIC ROBOTICS (ICDL-EPIROB), P129, DOI 10.1109/DEVLRN.2015.7346129
   Chong W, 2009, PROC CVPR IEEE, P1903, DOI 10.1109/CVPRW.2009.5206800
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Eysenck M. W., 1985, BLACKWELL DICT COGNI
   Fei-Fei L, 2005, PROC CVPR IEEE, P524
   Fergus R, 2003, PROC CVPR IEEE, P264
   Geiger A, 2013, INT J ROBOT RES, V32, P1231, DOI 10.1177/0278364913491297
   HARNAD S, 1990, PHYSICA D, V42, P335, DOI 10.1016/0167-2789(90)90087-6
   HOLLINS M, 1993, PERCEPT PSYCHOPHYS, V54, P697, DOI 10.3758/BF03211795
   Jain A, 2015, IEEE I CONF COMP VIS, P3182, DOI 10.1109/ICCV.2015.364
   Jayagopi DB, 2013, ACMIEEE INT CONF HUM, P149, DOI 10.1109/HRI.2013.6483545
   Jia Deng, 2009, PROC CVPR IEEE, P248, DOI DOI 10.1109/CVPR.2009.5206848
   Kawanishi T, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P716, DOI 10.1109/ICIP.2001.958219
   Klingspor V., 2000, PRERATIONAL INTELLIG, V3, P962
   Krizhevsky A., 2012, ADV NEURAL INFORM PR, P1097, DOI DOI 10.1145/3065386
   Lallee S, 2013, ADAPT BEHAV, V21, P274, DOI 10.1177/1059712313488423
   LeCun Y, 2004, PROC CVPR IEEE, P97
   Maddern W, 2017, INT J ROBOT RES, V36, P3, DOI 10.1177/0278364916679498
   Mangin O., 2013, P 2013 IEEE 3 JOINT, P1
   Mangin O, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0140732
   Mikolov T., 2013, P INT C LEARN REPR
   Nakamura Tomoaki, 2011, IEEE International Conference on Robotics and Automation, P6233
   Nakamura Tomoaki, 2007, 2007 IEEE/RSJ International Conference on Intelligent Robots and Systems, P2415
   Nakamura T, 2012, IEEE INT C INT ROBOT, P3818, DOI 10.1109/IROS.2012.6385502
   Nakamura T, 2011, IEEE INT C INT ROBOT, P1520, DOI 10.1109/IROS.2011.6048371
   Nakamura T, 2011, ADV ROBOTICS, V25, P2189, DOI 10.1163/016918611X595035
   Natale L., 2004, P IEEE INT C INT MAN
   NENE S. A., 1996, CUCS00596
   Nishihara J, 2017, IEEE T COGN DEV SYST, V9, P255, DOI 10.1109/TCDS.2016.2552579
   Ogata T, 2010, PATTERN RECOGN LETT, V31, P1560, DOI 10.1016/j.patrec.2010.05.002
   Okada K., 2005, P IEEE INT C ROB AUT, V2, P2120
   Ridge B, 2010, IEEE INT CONF ROBOT, P5047, DOI 10.1109/ROBOT.2010.5509544
   Rosch E, 1999, CONCEPTS CORE READIN, P189, DOI DOI 10.1016/B978-1-4832-1446-7.50028-5
   Roy DK, 2002, COGNITIVE SCI, V26, P113, DOI 10.1016/S0364-0213(01)00061-1
   Ruiz-Sarmiento JR, 2017, INT J ROBOT RES, V36, P131, DOI 10.1177/0278364917695640
   Russell R., 2000, P AUST C ROB AUT
   Schneider A, 2009, 2009 IEEE-RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, P243, DOI 10.1109/IROS.2009.5354648
   Sinapov Jivko, 2011, IEEE International Conference on Robotics and Automation, P184
   Sinapov J, 2014, ROBOT AUTON SYST, V62, P632, DOI 10.1016/j.robot.2012.10.007
   Singh A, 2014, IEEE INT CONF ROBOT, P509, DOI 10.1109/ICRA.2014.6906903
   Sivic J., 2005, P IEEE C COMP VIS, P17
   Smith L, 2005, ARTIF LIFE, V11, P13, DOI 10.1162/1064546053278973
   Smith L, 2008, COGNITION, V106, P1558, DOI 10.1016/j.cognition.2007.06.010
   Smith M, 2009, INT J ROBOT RES, V28, P595, DOI 10.1177/0278364909103911
   Taguchi R., 2011, INTERSPEECH, P1325
   Taniguchi T, 2016, ADV ROBOTICS, V30, P770, DOI 10.1080/01691864.2016.1159981
   Teh YW, 2006, J AM STAT ASSOC, V101, P1566, DOI 10.1198/016214506000000302
   Vedaldi A., 2010, C P ACM INT C MULTIM, P1469, DOI DOI 10.1145/1873951.1874249
   Wermter S, 2004, ROBOT AUTON SYST, V47, P171, DOI 10.1016/j.robot.2004.03.011
   Xiao JX, 2010, PROC CVPR IEEE, P3485, DOI 10.1109/CVPR.2010.5539970
   Yuruten O, 2013, ADAPT BEHAV, V21, P437, DOI 10.1177/1059712313497976
NR 61
TC 0
Z9 0
U1 1
U2 1
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2379-8920
EI 2379-8939
J9 IEEE T COGN DEV SYST
JI IEEE Trans. Cogn. Dev. Syst.
PD DEC
PY 2018
VL 10
IS 4
BP 1043
EP 1057
DI 10.1109/TCDS.2017.2745502
PG 15
WC Computer Science, Artificial Intelligence; Robotics; Neurosciences
SC Computer Science; Robotics; Neurosciences & Neurology
GA HD6HK
UT WOS:000452636400019
DA 2019-02-18
ER

PT J
AU Wieser, E
   Cheng, G
AF Wieser, Erhard
   Cheng, Gordon
TI A Self-Verifying Cognitive Architecture for Robust Bootstrapping of
   Sensory-Motor Skills via Multipurpose Predictors
SO IEEE TRANSACTIONS ON COGNITIVE AND DEVELOPMENTAL SYSTEMS
LA English
DT Article
DE Bootstrapping; cognitive architecture; prediction; self-verification
ID DEVELOPMENTAL ROBOTICS; MODEL; INTELLIGENCE; ORGANIZATION; IMITATION;
   BEHAVIOR; SYSTEMS
AB The autonomous acquisition of sensory-motor skills along multiple developmental stages is one of the current challenges in robotics. To this end, we propose a new developmental cognitive architecture that combines multipurpose predictors and principles of self-verification for the robust bootstrapping of sensory-motor skills. Our architecture operates with loops formed by both mental simulation of sensory-motor sequences and their subsequent physical trial on a robot. During these loops, verification algorithms monitor the predicted and the physically observed sensory-motor data. Multiple types of predictors are acquired through several developmental stages. As a result, the architecture can select and plan actions, adapt to various robot platforms by adjusting proprioceptive feedback, predict the risk of self-collision, learn from a previous interaction stage by validating and extracting sensory-motor data for training the predictor of a subsequent stage, and finally acquire an internal representation for evaluating the performance of its predictors. These cognitive capabilities in turn realize the bootstrapping of early hand-eye coordination and its improvement. We validate the cognitive capabilities experimentally and, in particular, show an improvement of reaching as an example skill.
C1 [Wieser, Erhard; Cheng, Gordon] Tech Univ Munich, Inst Cognit Syst, D-80333 Munich, Germany.
RP Wieser, E (reprint author), Tech Univ Munich, Inst Cognit Syst, D-80333 Munich, Germany.
EM erhard.wieser@tum.de; gordon@tum.de
OI Cheng, Gordon/0000-0003-0770-8717
FU German Research Foundation DFG, as part of the Collaborative Research
   Center [(Sonderforschungsbereich) 1320]
FX This work was supported by the German Research Foundation DFG, as part
   of the Collaborative Research Center (Sonderforschungsbereich) 1320
   "EASE-Everyday Activity Science and Engineering," University of Bremen
   (http://www.ease-crc.org).
CR Arie H, 2012, ROBOT AUTON SYST, V60, P729, DOI 10.1016/j.robot.2011.11.005
   Asada M, 2001, ROBOT AUTON SYST, V37, P185, DOI 10.1016/S0921-8890(01)00157-9
   Asada M, 2009, IEEE T AUTON MENT DE, V1, P12, DOI 10.1109/TAMD.2009.2021702
   Ayer AJ, 1952, LANGUAGE TRUTH LOGIC
   Baars B. J., 1993, COGNITIVE THEORY CON
   Baars BJ, 2005, PROG BRAIN RES, V150, P45, DOI 10.1016/S0079-6123(05)50004-9
   Brooks R. A., 1990, Robotics and Autonomous Systems, V6, P3, DOI 10.1016/S0921-8890(05)80025-9
   BROOKS RA, 1991, ARTIF INTELL, V47, P139, DOI 10.1016/0004-3702(91)90053-M
   BROOKS RA, 1986, IEEE T ROBOTIC AUTOM, V2, P14, DOI 10.1109/JRA.1986.1087032
   Broz F., 2012, ARXIV12025600V1
   Burger Wolfgang, 2017, 2017 Joint IEEE International Conference on Development and Learning and Epigenetic Robotics (ICDL-EpiRob), P60, DOI 10.1109/DEVLRN.2017.8329788
   Caligiore D., 2010, P 10 INT C EP ROB LU, V149, P27
   Cheng G., 2000, Proceedings 2000 ICRA. Millennium Conference. IEEE International Conference on Robotics and Automation. Symposia Proceedings (Cat. No.00CH37065), P2235, DOI 10.1109/ROBOT.2000.846360
   Cheng GD, 2001, ROBOT AUTON SYST, V37, P161, DOI 10.1016/S0921-8890(01)00156-7
   Corbetta D., 2014, FRONT PSYCHOL, V5, P1, DOI 10.389/fpsyg.2014.00576
   Dean-Leon Emmanuel, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P2441, DOI 10.1109/ICRA.2017.7989284
   DeFelipe J, 2011, FRONT NEUROANAT, V5, DOI 10.3389/fnana.2011.00029
   Demiris Y., 2005, P 5 INT WORKSH EP RO, V123, P31
   Demiris Y, 2006, ROBOT AUTON SYST, V54, P361, DOI 10.1016/j.robot.2006.02.003
   Friston KJ, 2010, NAT REV NEUROSCI, V11, P127, DOI 10.1038/nrn2787
   Friston KJ, 2008, PLOS COMPUT BIOL, V4, DOI 10.1371/journal.pcbi.1000081
   Guerin F, 2013, IEEE T AUTON MENT DE, V5, P18, DOI 10.1109/TAMD.2012.2209879
   Haruno M, 2001, NEURAL COMPUT, V13, P2201, DOI 10.1162/089976601750541778
   Jamone L, 2012, INT J HUM ROBOT, V9, DOI 10.1142/S021984361250017X
   JOHNSON MH, 1997, DEV COGNITIVE NEUROS
   JORDAN MI, 1992, COGNITIVE SCI, V16, P307, DOI 10.1207/s15516709cog1603_1
   Kanai R, 2015, PHILOS T R SOC B, V370, P69, DOI 10.1098/rstb.2014.0169
   Karsoliya S., 2012, INT J ENG TRENDS TEC, V3, P714
   Kruger N., 2011, AISB CONV CIT, P23
   Kuniyoshi Y, 2003, IEEE INT CONF ROBOT, P3132
   Kuniyoshi Y, 2007, PROG BRAIN RES, V164, P425, DOI 10.1016/S0079-6123(07)64023-0
   Langley P, 2009, COGN SYST RES, V10, P141, DOI 10.1016/j.cogsys.2006.07.004
   Law J, 2014, FRONT NEUROROBOTICS, V8, DOI 10.3389/fnbot.2014.00001
   Law J, 2013, AUTON ROBOT, V35, P77, DOI 10.1007/s10514-013-9335-2
   Law J, 2011, ADAPT BEHAV, V19, P335, DOI 10.1177/1059712311419380
   Lee MH, 2007, ROBOT AUTON SYST, V55, P750, DOI 10.1016/j.robot.2007.05.002
   Lungarella M, 2003, CONNECT SCI, V15, P151, DOI 10.1080/09540090310001655110
   Luo DS, 2016, 2016 JOINT IEEE INTERNATIONAL CONFERENCE ON DEVELOPMENT AND LEARNING AND EPIGENETIC ROBOTICS (ICDL-EPIROB), P310, DOI 10.1109/DEVLRN.2016.7846840
   Mirza Naeem Assif, 2008, 2008 8th IEEE-RAS International Conference on Humanoid Robots (Humanoids 2008), P609, DOI 10.1109/ICHR.2008.4756013
   Mountcastle V. B., 1978, MINDFUL BRAIN
   Nassour J, 2013, IEEE T NEUR NET LEAR, V24, P81, DOI 10.1109/TNNLS.2012.2224370
   Nehaniv CL, 2013, IEEE SYMP ART LIFE, P148, DOI 10.1109/ALIFE.2013.6602445
   Nishimoto R, 2008, ADAPT BEHAV, V16, P166, DOI 10.1177/1059712308089185
   Noda K., 2011, IEEE INT C DEV LEARN, V2, P1
   Panchal F, 2014, INT J COMPUTER SCI M, V3, P455
   PFEIFER R, 1999, UNDERSTANDING INTELL
   Pfeifer R, 2007, SCIENCE, V318, P1088, DOI 10.1126/science.1145803
   Pfeifer Rolf, 2007, BODY SHAPES WAY WE T
   Pinto L, 2016, IEEE INT CONF ROBOT, P3406, DOI 10.1109/ICRA.2016.7487517
   PRINCE C, 2005, P 5 INT WORKSH EP RO, P63
   ROCKEL AJ, 1980, BRAIN, V103, P221, DOI 10.1093/brain/103.2.221
   Rumelhart DE, 2002, COGNITIVE MODELING, P213
   Saegusa R, 2014, IEEE T NEUR NET LEAR, V25, P183, DOI 10.1109/TNNLS.2013.2271793
   Saegusa R, 2009, 2008 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS, VOLS 1-4, P794, DOI 10.1109/ROBIO.2009.4913101
   Saunders J., 2012, P IEEE INT C DEV LEA, P1
   Schillaci G., 2014, THESIS
   Shanahan M, 2006, CONSCIOUS COGN, V15, P433, DOI 10.1016/j.concog.2005.11.005
   Shipp S, 2013, TRENDS NEUROSCI, V36, P706, DOI 10.1016/j.tins.2013.09.004
   Smitsman A. W., 2010, WILEY BLACKWELL HDB, V1, P167
   SoftBank Robotics, 2018, NAO ROB
   Stoytchev A, 2009, IEEE T AUTON MENT DE, V1, P122, DOI 10.1109/TAMD.2009.2029989
   Sutton R. S., 2001, VERIFICATION
   Sutton RS, 2001, VERIFICATION KEY AI
   Tani J, 1996, IEEE T SYST MAN CY B, V26, P421, DOI 10.1109/3477.499793
   Tani J, 2003, NEURAL NETWORKS, V16, P11, DOI 10.1016/S0893-6080(02)00214-9
   Tani J., 2016, EXPLORING ROBOTIC MI
   Ugur E, 2015, IEEE T AUTON MENT DE, V7, P119, DOI 10.1109/TAMD.2015.2426192
   Vernon D., 2014, ARTIFICIAL COGNITIVE
   Vernon D, 2007, IEEE T EVOLUT COMPUT, V11, P151, DOI 10.1109/TEVC.2006.890274
   Vernon D, 2010, COGN SYST MONOGR, V11, P1
   WENG J, 2004, INT J HUM ROBOT, V1, P199
   Weng JY, 2001, SCIENCE, V291, P599, DOI 10.1126/science.291.5504.599
   Wieser E, 2016, 2016 JOINT IEEE INTERNATIONAL CONFERENCE ON DEVELOPMENT AND LEARNING AND EPIGENETIC ROBOTICS (ICDL-EPIROB), P43, DOI 10.1109/DEVLRN.2016.7846788
   Wieser E, 2014, FOUTH JOINT IEEE INTERNATIONAL CONFERENCES ON DEVELOPMENT AND LEARNING AND EPIGENETIC ROBOTICS (IEEE ICDL-EPIROB 2014), P139, DOI 10.1109/DEVLRN.2014.6982969
   Worgotter F, 2015, IEEE T AUTON MENT DE, V7, P140, DOI 10.1109/TAMD.2015.2427233
   WOLPERT DM, 1995, SCIENCE, V269, P1880, DOI 10.1126/science.7569931
   Wolpert DM, 1998, NEURAL NETWORKS, V11, P1317, DOI 10.1016/S0893-6080(98)00066-5
   Yamashita Y, 2008, PLOS COMPUT BIOL, V4, DOI 10.1371/journal.pcbi.1000220
NR 78
TC 0
Z9 0
U1 2
U2 2
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2379-8920
EI 2379-8939
J9 IEEE T COGN DEV SYST
JI IEEE Trans. Cogn. Dev. Syst.
PD DEC
PY 2018
VL 10
IS 4
BP 1081
EP 1095
DI 10.1109/TCDS.2018.2871857
PG 15
WC Computer Science, Artificial Intelligence; Robotics; Neurosciences
SC Computer Science; Robotics; Neurosciences & Neurology
GA HD6HK
UT WOS:000452636400022
DA 2019-02-18
ER

PT J
AU Chukoskie, L
   Guo, SY
   Ho, E
   Zheng, YL
   Chen, QM
   Meng, V
   Cao, J
   Devgan, N
   Wu, S
   Cosman, PC
AF Chukoskie, Leanne
   Guo, Shengyao
   Ho, Eric
   Zheng, Yalun
   Chen, Qiming
   Meng, Vivian
   Cao, John
   Devgan, Nikhita
   Wu, Si
   Cosman, Pamela C.
TI Quantifying Gaze Behavior During Real-World Interactions Using Automated
   Object, Face, and Fixation Detection
SO IEEE TRANSACTIONS ON COGNITIVE AND DEVELOPMENTAL SYSTEMS
LA English
DT Article
DE Computer vision; eye-tracking; face detection; gaze behavior
ID SOCIAL SITUATIONS; ATTENTION; AUTISM; PATTERNS
AB As technologies develop for acquiring gaze behavior in real world social settings, robust methods are needed that minimize the time required for a trained observer to code behaviors. We record gaze behavior from a subject wearing eye-tracking glasses during a naturalistic interaction with three other people, with multiple objects that are referred to or manipulated during the interaction. The resulting gaze-hi-world video from each interaction can be manually coded for different behaviors, but this is extremely time-consuming and requires trained behavioral coders. Instead, we use a neural network to detect objects, and a Viola-Jones framework with feature tracking to detect faces. The time sequence of gazes landing within the object/face bounding boxes is processed for run lengths to determine "looks," and we discuss optimization of run length parameters. Algorithm performance is compared against an expert holistic ground truth.
C1 [Chukoskie, Leanne] Univ Calif San Diego, Inst Neural Computat, La Jolla, CA 92093 USA.
   [Guo, Shengyao; Ho, Eric; Zheng, Yalun; Chen, Qiming; Meng, Vivian; Cao, John; Devgan, Nikhita; Wu, Si; Cosman, Pamela C.] Univ Calif San Diego, Dept Elect & Comp Engn, La Jolla, CA 92093 USA.
RP Chukoskie, L (reprint author), Univ Calif San Diego, Inst Neural Computat, La Jolla, CA 92093 USA.
EM lchukoskie@ucsd.edu; pcosman@ucsd.edu
OI Cosman, Pamela/0000-0002-4012-0176
FU National Science Foundation [IIS-1522125, SBE-0542013]; National
   Institutes of Health [R21/R33 MH096967]
FX This work was supported in part by the National Science Foundation under
   Grant IIS-1522125 and Grant SBE-0542013, and in part by the National
   Institutes of Health under Grant R21/R33 MH096967. An early version of
   this work will appear at ISBI 2018.
CR Baldwin D. A., 1995, JOINT ATTENTION ITS, P131
   Buswell Guy T., 1935, PEOPLE LOOK PICTURES
   Chawarska K, 2009, J AUTISM DEV DISORD, V39, P1663, DOI 10.1007/s10803-009-0803-7
   Chita-Tegmark M, 2016, RES DEV DISABIL, V48, P79, DOI 10.1016/j.ridd.2015.10.011
   Chong E., 2017, P ACM INTERACT MOBIL, V1, P43
   Crooke PJ, 2016, TOP LANG DISORD, V36, P284, DOI 10.1097/TLD.0000000000000094
   Farfade SS, 2015, ICMR'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P643, DOI 10.1145/2671188.2749408
   Gidaris S, 2015, IEEE I CONF COMP VIS, P1134, DOI 10.1109/ICCV.2015.135
   Goldberg J.H., 2000, P 2000 S EYE TRACK R, P71, DOI DOI 10.1145/355017.355028
   Hirotani M, 2009, NEUROREPORT, V20, P600, DOI 10.1097/WNR.0b013e32832a0a7c
   Hosozawa M, 2012, PEDIATRICS, V129, pE1453, DOI 10.1542/peds.2011-2278
   Jiang HZ, 2017, IEEE INT CONF AUTOMA, P650, DOI [10.1109/MWSYM.2017.8058653, 10.1109/FG.2017.82]
   Klin A, 2002, ARCH GEN PSYCHIAT, V59, P809, DOI 10.1001/archpsyc.59.9.809
   Laugeson EA, 2009, J AUTISM DEV DISORD, V39, P596, DOI 10.1007/s10803-008-0664-5
   Lucas B., 1981, P INT JOINT C ART IN, P674, DOI DOI 10.1364/J0SAA.19.002142
   Magrelli S, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00840
   Mundy P, 2018, EUR J NEUROSCI, V47, P497, DOI 10.1111/ejn.13720
   Noris B, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0044144
   Noris B, 2007, ADV INTEL SOFT COMPU, V45, P663
   Pickard KE, 2015, J AUTISM DEV DISORD, V45, P262, DOI 10.1007/s10803-014-2193-8
   Pierce K, 2011, ARCH GEN PSYCHIAT, V68, P101, DOI 10.1001/archgenpsychiatry.2010.113
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Schreibman L, 2005, HDB AUTISM PERVASIVE, P882, DOI DOI 10.1002/9780470939352
   SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794
   Simonyan K., 2015, ARXIV14091556V6CSCV
   Townsend J, 1996, DEV PSYCHOPATHOL, V8, P563, DOI 10.1017/S0954579400007276
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Ye Zhefan, 2012, P 2012 ACM C UB COMP, P699, DOI DOI 10.1145/2370216.2370368
   Zablotsky Benjamin, 2015, Natl Health Stat Report, P1
   Zwaigenbaum L, 2005, INT J DEV NEUROSCI, V23, P143, DOI 10.1016/j.ijdevneu.2004.05.001
NR 30
TC 1
Z9 1
U1 5
U2 5
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2379-8920
EI 2379-8939
J9 IEEE T COGN DEV SYST
JI IEEE Trans. Cogn. Dev. Syst.
PD DEC
PY 2018
VL 10
IS 4
BP 1143
EP 1152
DI 10.1109/TCDS.2018.2821566
PG 10
WC Computer Science, Artificial Intelligence; Robotics; Neurosciences
SC Computer Science; Robotics; Neurosciences & Neurology
GA HD6HK
UT WOS:000452636400028
DA 2019-02-18
ER

PT J
AU Huang, X
   Wu, W
   Qiao, H
   Ji, YD
AF Huang, Xiao
   Wu, Wei
   Qiao, Hong
   Ji, Yidao
TI Brain-Inspired Motion Learning in Recurrent Neural Network With Emotion
   Modulation
SO IEEE TRANSACTIONS ON COGNITIVE AND DEVELOPMENTAL SYSTEMS
LA English
DT Article
DE Brain-inspired model; emotion; motion learning; recurrent neural network
   (RNN)
ID MODEL; GENERATION; COGNITION; MEMORY; REORGANIZATION; ACETYLCHOLINE;
   ALGORITHMS; PLASTICITY; NEURONS; SIGNALS
AB Based on basic emotion modulation theory and the neural mechanisms of generating complex motor patterns, we introduce a novel emotion-modulated learning rule to train a recurrent neural network, which enables a complex musculoskeletal arm and a robotic arm to perform goal-directed tasks with high accuracy and learning efficiency. Specifically, inspired by the fact that emotions can modulate the process of learning and decision making through neuromodulatory system, we present a model of emotion generation and modulation to adjust the parameters of learning adaptively, including the reward prediction error, the speed of learning, and the randomness in action selection. Additionally, we use Oja learning rule to adjust the recurrent weights in delayed-reinforcement tasks, which outperforms the Hebbian update rule in terms of stability and accuracy. In the experimental section, we use a musculoskeletal model of the human upper limb and a robotic arm to perform goal-directed tasks through trial-and-reward learning, respectively. The results show that emotion-based methods are able to control the arm with higher accuracy and a faster learning rate. Meanwhile, emotional Oja agent is superior to emotional Hebbian one in term of performance.
C1 [Huang, Xiao; Wu, Wei] Chinese Acad Sci, Inst Automat, State Key Lab Management & Control Complex Syst, Beijing 100190, Peoples R China.
   [Huang, Xiao; Wu, Wei; Qiao, Hong] Univ Chinese Acad Sci, Beijing 100049, Peoples R China.
   [Qiao, Hong] Chinese Acad Sci, Inst Automat, CAS Ctr Excellence Brain Sci & Intelligence Techn, State Key Lab Management & Control Complex Syst, Beijing 100190, Peoples R China.
   [Qiao, Hong] Chinese Acad Sci, Cloud Comp Ctr, Beijing 100190, Peoples R China.
   [Ji, Yidao] Univ Sci & Technol Beijing, Sch Automat & Elect Engn, Beijing 100083, Peoples R China.
RP Qiao, H (reprint author), Chinese Acad Sci, Inst Automat, CAS Ctr Excellence Brain Sci & Intelligence Techn, State Key Lab Management & Control Complex Syst, Beijing 100190, Peoples R China.; Qiao, H (reprint author), Chinese Acad Sci, Cloud Comp Ctr, Beijing 100190, Peoples R China.
EM hong.qiao@ia.ac.cn
FU Development of Science and Technology of Guangdong province Special Fund
   Project [2016B090910001]; Strategic Priority Research Program of CAS
   [XDB02080003]; Beijing Municipal Science and Technology
   [D16110400140000, D161100001416001]; National Natural Science Foundation
   of China [61210009, 61627808, 91648205, 51705515, U1713201, 61702516]
FX This work was supported in part by the Development of Science and
   Technology of Guangdong province Special Fund Project under Grant
   2016B090910001; in part by the Strategic Priority Research Program of
   CAS under Grant XDB02080003; in part by the Beijing Municipal Science
   and Technology under Grant D16110400140000 and Grant D161100001416001;
   and in part by the National Natural Science Foundation of China under
   Grant 61210009, Grant 61627808, Grant 91648205, Grant 51705515, Grant
   U1713201, and Grant 61702516.
CR Atiya AF, 2000, IEEE T NEURAL NETWOR, V11, P697, DOI 10.1109/72.846741
   BARBAS H, 1995, NEUROSCI BIOBEHAV R, V19, P499, DOI 10.1016/0149-7634(94)00053-4
   Bayer HM, 2005, NEURON, V47, P129, DOI 10.1016/j.neuron.2005.05.020
   Bemporad J. R., 1997, J AM ACAD PSYCHOAN, V25, P525
   Cohen JD, 2005, J ECON PERSPECT, V19, P3, DOI 10.1257/089533005775196750
   Damasio AR, 2001, ANN NY ACAD SCI, V935, P101
   Dolcos F, 2011, J COGN PSYCHOL, V23, P669, DOI 10.1080/20445911.2011.594433
   Doya K, 2002, NEURAL NETWORKS, V15, P495, DOI 10.1016/S0893-6080(02)00044-8
   Doya K., 2000, P C AFF MINDS, V46, P47
   Druckman JN, 2008, POLIT BEHAV, V30, P297, DOI 10.1007/s11109-008-9056-y
   Etkin A, 2015, NAT REV NEUROSCI, V16, P693, DOI 10.1038/nrn4044
   Fiete IR, 2007, J NEUROPHYSIOL, V98, P2038, DOI 10.1152/jn.01311.2006
   Fiete IR, 2006, PHYS REV LETT, V97, DOI 10.1103/PhysRevLett.97.048104
   Fremaux N, 2010, J NEUROSCI, V30, P13326, DOI 10.1523/JNEUROSCI.6249-09.2010
   GOLDMANRAKIC PS, 1989, P NATL ACAD SCI USA, V86, P9015, DOI 10.1073/pnas.86.22.9015
   Gross JJ, 2011, COGNITION EMOTION, V25, P765, DOI 10.1080/02699931.2011.555753
   Habib M, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00253
   Hasselmo ME, 1999, TRENDS COGN SCI, V3, P351, DOI 10.1016/S1364-6613(99)01365-0
   Hasselmo ME, 2006, CURR OPIN NEUROBIOL, V16, P710, DOI 10.1016/j.conb.2006.09.002
   Hebb Donald Olding, 2005, ORG BEHAV NEUROPSYCH
   Hoerzer GM, 2014, CEREB CORTEX, V24, P677, DOI 10.1093/cercor/bhs348
   Huang X, 2017, IEEE IJCNN, P873, DOI 10.1109/IJCNN.2017.7965944
   Izhikevich EM, 2007, CEREB CORTEX, V17, P2443, DOI 10.1093/cercor/bhl152
   Jaeger H, 2007, SCHOLARPEDIA, V2, P2330, DOI DOI 10.4249/SCH0LARPEDIA.2330
   Jarosiewicz B, 2008, P NATL ACAD SCI USA, V105, P19486, DOI 10.1073/pnas.0808113105
   Klingberg T, 2010, TRENDS COGN SCI, V14, P317, DOI 10.1016/j.tics.2010.05.002
   Lazarus R. S., 1991, EMOTION ADAPTATION
   LeDoux J. E, 2009, FOCUS, V7, P274, DOI DOI 10.1176/F0C.7.2.F0C274
   Ledoux JE, 2001, AM J PSYCHIAT, V158, P1953, DOI 10.1176/appi.ajp.158.12.1953
   Legenstein R, 2010, J NEUROSCI, V30, P8400, DOI 10.1523/JNEUROSCI.4284-09.2010
   Lovheim H, 2012, MED HYPOTHESES, V78, P341, DOI 10.1016/j.mehy.2011.11.016
   Marsella S., 2010, BLUEPRINT AFFECTIVE, P21
   Miconi T, 2017, ELIFE, V6, DOI 10.7554/eLife.20899
   Moerland TM, 2018, MACH LEARN, V107, P443, DOI 10.1007/s10994-017-5666-0
   Ochsner KN, 2009, PSYCHOL SCI, V20, P1322, DOI 10.1111/j.1467-9280.2009.02459.x
   Oja E., 1989, International Journal of Neural Systems, V1, P61, DOI 10.1142/S0129065789000475
   OJA E, 1982, J MATH BIOL, V15, P267, DOI 10.1007/BF00275687
   Phelps EA, 2005, NEURON, V48, P175, DOI 10.1016/j.neuron.2005.09.025
   Phelps EA, 2014, ANNU REV NEUROSCI, V37, P263, DOI 10.1146/annurev-neuro-071013-014119
   Qiao H, 2016, ASSEMBLY AUTOM, V36, P97, DOI 10.1108/AA-11-2015-099
   Rainer G, 2000, NEURON, V27, P179, DOI 10.1016/S0896-6273(00)00019-2
   Rajan K, 2016, NEURON, V90, P128, DOI 10.1016/j.neuron.2016.02.009
   Reynolds JNJ, 2002, NEURAL NETWORKS, V15, P507, DOI 10.1016/S0893-6080(02)00045-X
   Rolls ET, 2015, CORTEX, V62, P119, DOI 10.1016/j.cortex.2013.12.005
   Saul KR, 2015, COMPUT METHOD BIOMEC, V18, P1445, DOI 10.1080/10255842.2014.916698
   Schultz W, 2016, J NEURAL TRANSM, V123, P679, DOI 10.1007/s00702-016-1510-0
   Shidara M, 1998, J NEUROSCI, V18, P2613
   Shirafuji S, 2014, INT J ROBOT RES, V33, P677, DOI 10.1177/0278364913518357
   Shoushtari AL, 2016, ASSEMBLY AUTOM, V36, P200, DOI 10.1108/AA-11-2015-116
   Song HF, 2016, PLOS COMPUT BIOL, V12, DOI 10.1371/journal.pcbi.1004792
   Steil JJ, 2004, IEEE IJCNN, P843
   Sussillo D, 2009, NEURON, V63, P544, DOI 10.1016/j.neuron.2009.07.018
   SUTTON RS, 1981, PSYCHOL REV, V88, P135, DOI 10.1037//0033-295X.88.2.135
   Thelen DG, 2006, J BIOMECH, V39, P1107, DOI 10.1016/j.jbiomech.2005.02.010
   Thelen DG, 2003, J BIOMECH ENG-T ASME, V125, P70, DOI 10.1115/1.1531112
   Tricomi E, 2008, NEUROIMAGE, V41, P1154, DOI 10.1016/j.neuroimage.2008.02.066
   van Veen V, 2002, J COGNITIVE NEUROSCI, V14, P593, DOI 10.1162/08989290260045837
   WILLIAMS RJ, 1992, MACH LEARN, V8, P229, DOI 10.1007/BF00992696
   Zavala BA, 2014, J NEUROSCI, V34, P7322, DOI 10.1523/JNEUROSCI.1169-14.2014
NR 59
TC 0
Z9 0
U1 4
U2 4
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2379-8920
EI 2379-8939
J9 IEEE T COGN DEV SYST
JI IEEE Trans. Cogn. Dev. Syst.
PD DEC
PY 2018
VL 10
IS 4
BP 1153
EP 1164
DI 10.1109/TCDS.2018.2843563
PG 12
WC Computer Science, Artificial Intelligence; Robotics; Neurosciences
SC Computer Science; Robotics; Neurosciences & Neurology
GA HD6HK
UT WOS:000452636400029
DA 2019-02-18
ER

PT J
AU Liu, XX
   Duan, Y
   Hitzmann, A
   Xu, YT
   Chen, TY
   Ikemoto, S
   Hosoda, K
AF Liu, Xiangxiao
   Duan, Yu
   Hitzmann, Arne
   Xu, Yuntong
   Chen, Tsungyuan
   Ikemoto, Shuhei
   Hosoda, Koh
TI Using the foot windlass mechanism for jumping higher: A study on bipedal
   robot jumping
SO ROBOTICS AND AUTONOMOUS SYSTEMS
LA English
DT Article
DE Foot windlass mechanism; Musculoskeletal robot; Locomotion efficiency;
   Jumping height; Drop jumping/bouncing
ID ARTIFICIAL MUSCLE; EVOLUTION; COORDINATION; ARCHITECTURE; ANATOMY;
   WALKING; DESIGN; MOTION; MODEL; ARCH
AB Both scientists and roboticists widely agree that the musculoskeletal system of the human foot plays an important role in locomotion. Nevertheless, the contribution of the foot musculoskeletal system has not been fully uncovered because currently it is impossible to modify and evaluate musculoskeletons in living animals. Here, to understand the effects of foot windlass mechanism, we construct a bipedal robot, which has similar musculoskeleton and dynamics to those of human. By implementing experiments on this robot, we investigate the effects (e.g. jumping height) of foot windlass mechanism on drop jumping, a simple and representative bouncing gait comprising landing and push-off. Through a significant number of drop jumping trials, the results demonstrated that (1) the windlass mechanism is passively activated in the push-off phase and that (2) it contributes to the height of jumping. Our results suggest that the foot windlass mechanism contributes to the energy efficiency and performance in locomotion. (C) 2018 Published by Elsevier B.V.
C1 [Liu, Xiangxiao; Duan, Yu; Hitzmann, Arne; Xu, Yuntong; Chen, Tsungyuan; Ikemoto, Shuhei; Hosoda, Koh] 1-3 Machikaneyama, Toyonoka, Osaka 5608531, Japan.
   [Hosoda, Koh] Osaka Univ, Dept Engn Sci, Osaka, Japan.
RP Liu, XX (reprint author), 1-3 Machikaneyama, Toyonoka, Osaka 5608531, Japan.
EM liu.xiangxiao@arl.sys.es.osaka-u.ac.jp
FU JSPS KAKENHI, Japan [16J05748, 16KT0015, 23220004]
FX This work was supported by JSPS KAKENHI, Japan grant number 16J05748,
   16KT0015 and 23220004.
CR Auyang AG, 2009, EXP BRAIN RES, V192, P253, DOI 10.1007/s00221-008-1582-7
   Bates KT, 2013, P ROY SOC B-BIOL SCI, V280, DOI 10.1098/rspb.2013.1818
   BOBBERT MF, 1988, J BIOMECH, V21, P249, DOI 10.1016/0021-9290(88)90175-3
   Bramble DM, 2004, NATURE, V432, P345, DOI 10.1038/nature03052
   D'Aout K, 2009, FOOTWEAR SCI, V1, P81, DOI 10.1080/19424280903386411
   Farley CT, 1999, J BIOMECH, V32, P267, DOI 10.1016/S0021-9290(98)00170-5
   FRIEDERICH JA, 1990, J BIOMECH, V23, P91, DOI 10.1016/0021-9290(90)90373-B
   Funase K, 2001, EUR J APPL PHYSIOL, V84, P503, DOI 10.1007/s004210100414
   Gefen A, 2003, FOOT ANKLE INT, V24, P238, DOI 10.1177/107110070302400307
   Gibbons A., HUMAN EVOLUTION GAIN
   Griffin NL, 2015, AM J PHYS ANTHROPOL, V156, P1, DOI 10.1002/ajpa.22636
   Haeufle DFB, 2012, J R SOC INTERFACE, V9, P1458, DOI 10.1098/rsif.2011.0694
   Hamel AJ, 2001, CLIN ORTHOP RELAT R, P326
   Hashimoto K, 2011, IEEE INT CONF ROBOT, P2041
   Hay JG, 1988, ANATOMY MECH HUMAN M
   HICKS JH, 1954, J ANAT, V88, P25
   Holowka NB, 2017, J HUM EVOL, V104, P23, DOI 10.1016/j.jhevol.2016.12.002
   Hosoda K, 2010, AUTON ROBOT, V28, P307, DOI 10.1007/s10514-009-9171-6
   HOY MG, 1990, J BIOMECH, V23, P157, DOI 10.1016/0021-9290(90)90349-8
   Ijspeert AJ, 2014, SCIENCE, V346, P196, DOI 10.1126/science.1254486
   Jungers WL, 2009, NATURE, V459, P81, DOI 10.1038/nature07989
   Kelly LA, 2015, J R SOC INTERFACE, V12, DOI 10.1098/rsif.2014.1076
   Kelly LA, 2014, J R SOC INTERFACE, V11, DOI 10.1098/rsif.2013.1188
   KER RF, 1987, NATURE, V325, P147, DOI 10.1038/325147a0
   Kerscher T., 2006, P 1 IEEE RAS EMBS IN, P637
   Liu XX, 2014, IEEE-RAS INT C HUMAN, P658, DOI 10.1109/HUMANOIDS.2014.7041433
   Manoonpong P, 2016, SCI REP-UK, V6, DOI 10.1038/srep39455
   Niiyama R, 2010, IND ROBOT, V37, P250, DOI 10.1108/01439911011037640
   Nishiwaki K, 2002, 2002 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS I-IV, PROCEEDINGS, P3105, DOI 10.1109/ROBOT.2002.1013704
   OGURA Y, 2006, IEEE RSJ INT C INT R, P3976
   PANDY MG, 1991, J BIOMECH, V24, P1, DOI 10.1016/0021-9290(91)90321-D
   Paul C, 2005, BIOL CYBERN, V93, P153, DOI 10.1007/s00422-005-0559-x
   Roberts TJ, 2011, PHILOS T R SOC B, V366, P1488, DOI 10.1098/rstb.2010.0326
   SCHENAU GJV, 1994, HUM MOVEMENT SCI, V13, P495
   Shin H, 2016, ARTIF LIFE ROBOT, V21, P486, DOI 10.1007/s10015-016-0290-9
   Sprowitz A, 2013, INT J ROBOT RES, V32, P932, DOI 10.1177/0278364913489205
   Stainsby GD, 1997, ANN ROY COLL SURG, V79, P58
   Stearne SM, 2016, SCI REP-UK, V6, DOI 10.1038/srep19403
   Takahashi KZ, 2016, SCI REP-UK, V6, DOI 10.1038/srep29870
   Tondu B, 2012, J INTEL MAT SYST STR, V23, P225, DOI 10.1177/1045389X11435435
   Voigt M, 1998, ACTA PHYSIOL SCAND, V163, P181
   WICKIEWICZ TL, 1983, CLIN ORTHOP RELAT R, P275
   Yamane Katsu, 2009, 2009 9th IEEE-RAS International Conference on Humanoid Robots (Humanoids 2009), P230, DOI 10.1109/ICHR.2009.5379576
NR 43
TC 0
Z9 0
U1 0
U2 0
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0921-8890
EI 1872-793X
J9 ROBOT AUTON SYST
JI Robot. Auton. Syst.
PD DEC
PY 2018
VL 110
BP 85
EP 91
DI 10.1016/j.robot.2018.09.006
PG 7
WC Automation & Control Systems; Computer Science, Artificial Intelligence;
   Robotics
SC Automation & Control Systems; Computer Science; Robotics
GA HC4RJ
UT WOS:000451791600007
DA 2019-02-18
ER

PT J
AU Bennati, S
AF Bennati, Stefano
TI On the role of collective sensing and evolution in group formation
SO SWARM INTELLIGENCE
LA English
DT Article
DE Collective sensing; Natural selection; Foraging; Agent-based modeling;
   Multi-agent systems; Neural network
ID PUBLIC INFORMATION; COOPERATION; INDIVIDUALS; BIRDS
AB Collective sensing is an emergent phenomenon which enables individuals to estimate a hidden property of the environment through the observation of social interactions. Previous work on collective sensing shows that gregarious individuals obtain an evolutionary advantage by exploiting collective sensing when competing against solitary individuals. This work addresses the question of whether collective sensing allows for the emergence of groups from a population of individuals without predetermined behaviors. It is assumed that group membership does not lessen competition on the limited resources in the environment, e.g., groups do not improve foraging efficiency. Experiments are run in an agent-based evolutionary model of a foraging task, where the fitness of the agents depends on their foraging strategy. The foraging strategy of agents is determined by a neural network, which does not require explicit modeling of the environment and of the interactions between agents. Experiments demonstrate that gregarious behavior is not the evolutionary-fittest strategy if resources are abundant, thus invalidating previous findings in a specific region of the parameter space. In other words, resource scarcity makes gregarious behavior so valuable as to make up for the increased competition over the few available resources. Furthermore, it is shown that a population of solitary agents can evolve gregarious behavior in response to a sudden scarcity of resources, thus individuating a possible mechanism that leads to gregarious behavior in nature. The evolutionary process operates on the whole parameter space of the neural networks; hence, these behaviors are selected among an unconstrained set of behavioral models.
C1 [Bennati, Stefano] Swiss Fed Inst Technol, Computat Social Sci, CH-8092 Zurich, Switzerland.
RP Bennati, S (reprint author), Swiss Fed Inst Technol, Computat Social Sci, CH-8092 Zurich, Switzerland.
EM sbennati@ethz.ch
OI Bennati, Stefano/0000-0001-7603-8564
FU European Commission through the ERC Advanced Investigator Grant
   "Momentum" [324247]
FX The author acknowledges support by the European Commission through the
   ERC Advanced Investigator Grant "Momentum" (Grant No. 324247). The
   author thanks Leonard Wossnig and Johannes Thiele for their help with
   writing the simulation software, Andrew Berdahl and Dirk Helbing for
   many useful comments and several anonymous reviewer for their
   constructive criticism.
CR Axelrod R, 2002, PERS SOC PSYCHOL REV, V6, P341, DOI 10.1207/S15327957PSPR0604_08
   Batali J, 1996, EVOL COMPUT, V4, P235, DOI 10.1162/evco.1996.4.3.235
   Beauchamp G, 2000, J THEOR BIOL, V207, P21, DOI 10.1006/jtbi.2000.2153
   Bennati Stefano, 2016, ICAART 2016. 8th International Conference on Agents and Artificial Intelligence. Proceedings, P231
   Bennati S., 2017, AGENT BASED SIMULATI
   Berdahl A, 2013, SCIENCE, V339, P574, DOI 10.1126/science.1225883
   Bertram BC, 1978, BEHAV ECOLOGY
   Bhattacharya K, 2014, J R SOC INTERFACE, V11, DOI 10.1098/rsif.2014.0674
   Bowles S, 2004, THEOR POPUL BIOL, V65, P17, DOI 10.1016/j.tpb.2003.07.001
   Burtsev M, 2006, NATURE, V440, P1041, DOI 10.1038/nature04470
   Cote J., 1997, BEHAV RES ACCOUNTING, V9, P20
   Couzin ID, 2002, J THEOR BIOL, V218, P1, DOI 10.1006/yjtbi.3065
   Danchin E, 2004, SCIENCE, V305, P487, DOI 10.1126/science.1098254
   Dawkins R, 1976, SELFISH GENE ESSAYS
   Devenow A, 1996, EUR ECON REV, V40, P603, DOI 10.1016/0014-2921(95)00073-9
   Duan WQ, 2010, PHYS REV E, V81, DOI 10.1103/PhysRevE.81.026104
   ELGAR MA, 1989, BIOL REV, V64, P13, DOI 10.1111/j.1469-185X.1989.tb00636.x
   Epstein J. M., 1999, Complexity, V4, P41, DOI 10.1002/(SICI)1099-0526(199905/06)4:5<41::AID-CPLX9>3.0.CO;2-F
   Foerster J. N., 2016, ARXIV160202672
   Forsyth D. R., 2009, GROUP DYNAMICS
   Garnier Simon, 2007, Swarm Intelligence, V1, P3, DOI 10.1007/s11721-007-0004-y
   Giraldeau L.-A., 2000, SOCIAL FORAGING THEO
   Gruau F, 1993, EVOL COMPUT, V1, P213, DOI 10.1162/evco.1993.1.3.213
   Grund T, 2013, SCI REP-UK, V3, DOI 10.1038/srep01480
   Hales D, 2000, COOPERATION MEMORY S, P157
   Hamblin S, 2009, ANIM BEHAV, V78, P1343, DOI 10.1016/j.anbehav.2009.09.001
   Hamilton MJ, 2007, P R SOC B, V274, P2195, DOI 10.1098/rspb.2007.0564
   HAMILTON WD, 1964, J THEOR BIOL, V7, P1, DOI 10.1016/0022-5193(64)90038-4
   Hammond RA, 2006, THEOR POPUL BIOL, V69, P333, DOI 10.1016/j.tpb.2005.12.002
   HEALY MJR, 1967, MAN, V2, P639, DOI 10.2307/2799365
   Hein AM, 2015, ELIFE, V4, DOI 10.7554/eLife.10955
   Helbing D, 2008, ADV COMPLEX SYST, V11, P641, DOI 10.1142/S0219525908001866
   Helbing D, 2009, P NATL ACAD SCI USA, V106, P3680, DOI 10.1073/pnas.0811503106
   Hinton G. E., 1987, Complex Systems, V1, P495
   Huang JH, 2006, PSYCHOL MARKET, V23, P413, DOI 10.1002/mar.20119
   KLEIN LL, 1973, AM J PHYS ANTHROPOL, V38, P649, DOI 10.1002/ajpa.1330380282
   Krause J, 2002, LIVING GROUPS
   KREBS JR, 1973, CAN J ZOOL, V51, P1275, DOI 10.1139/z73-181
   KURLAND J A, 1973, Primates, V14, P245, DOI 10.1007/BF01730823
   KURLAND JA, 1985, AM ANTHROPOL, V87, P73, DOI 10.1525/aa.1985.87.1.02a00070
   Lazaridou A., 2016, ARXIV161207182
   Lewin K, 1947, HUM RELAT, V1, P5, DOI 10.1177/001872674700100103
   Mas M, 2010, PLOS COMPUT BIOL, V6, DOI 10.1371/journal.pcbi.1000959
   Montanier J.-M., 2013, ADV ARTIFICIAL LIFE, V2013, P260
   Nemeth A, 2007, JASSS-J ARTIF SOC S, V10
   NOWAK MA, 1992, NATURE, V359, P826, DOI 10.1038/359826a0
   Nowak MA, 2010, PHILOS T R SOC B, V365, P19, DOI 10.1098/rstb.2009.0215
   Perc M, 2013, J R SOC INTERFACE, V10, DOI 10.1098/rsif.2012.0997
   Puurtinen M, 2009, P ROY SOC B-BIOL SCI, V276, P355, DOI 10.1098/rspb.2008.1060
   Red'ko VG, 2010, STUD COMPUT INTELL, V262, P491
   Salva OR, 2014, FRONT NEURAL CIRCUIT, V8, DOI 10.3389/fncir.2014.00119
   Santos FC, 2006, PLOS COMPUT BIOL, V2, P1284, DOI 10.1371/journal.pcbi.0020140
   SCHNITZER MJ, 1993, PHYS REV E, V48, P2553, DOI 10.1103/PhysRevE.48.2553
   Schoener T. W., 1971, A Rev Ecol Syst, V2, P369, DOI 10.1146/annurev.es.02.110171.002101
   Seeley T. D., 2009, WISDOM HIVE SOCIAL P
   Simon Herbert. A, 1982, MODELS BOUNDED RATIO
   Skyrms B, 2010, SIGNALS EVOLUTION LE
   SMITH JM, 1964, NATURE, V201, P1145, DOI 10.1038/2011145a0
   Strandburg-Peshkin A, 2013, CURR BIOL, V23, pR709, DOI 10.1016/j.cub.2013.07.059
   Sukhbaatar S, 2016, ADV NEURAL INFORM PR, P2244
   SZATHMARY E, 1995, NATURE, V374, P227, DOI 10.1038/374227a0
   Tampuu A, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0172395
   Torney CJ, 2011, PLOS COMPUT BIOL, V7, DOI 10.1371/journal.pcbi.1002194
   VALONE TJ, 1989, OIKOS, V56, P357, DOI 10.2307/3565621
   Vergassola M, 2007, NATURE, V445, P406, DOI 10.1038/nature05464
   WARD P, 1973, IBIS, V115, P517, DOI 10.1111/j.1474-919X.1973.tb01990.x
NR 66
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI NEW YORK
PA 233 SPRING ST, NEW YORK, NY 10013 USA
SN 1935-3812
EI 1935-3820
J9 SWARM INTELL-US
JI Swarm Intell.
PD DEC
PY 2018
VL 12
IS 4
BP 267
EP 282
DI 10.1007/s11721-018-0156-y
PG 16
WC Computer Science, Artificial Intelligence; Mathematics, Applied;
   Robotics
SC Computer Science; Mathematics; Robotics
GA HB4YR
UT WOS:000451064300001
OA Other Gold
DA 2019-02-18
ER

PT J
AU Arvin, F
   Watson, S
   Turgut, AE
   Espinosa, J
   Krajnik, T
   Lennox, B
AF Arvin, Farshad
   Watson, Simon
   Turgut, Ali Emre
   Espinosa, Jose
   Krajnik, Tomas
   Lennox, Barry
TI Perpetual Robot Swarm: Long-Term Autonomy of Mobile Robots Using
   On-the-fly Inductive Charging
SO JOURNAL OF INTELLIGENT & ROBOTIC SYSTEMS
LA English
DT Article
DE Swarm robotics; Wireless charging; Long-term autonomy; Perpetual swarm
ID SELF-ORGANIZED AGGREGATION; WIRELESS POWER TRANSFER; CUE-BASED
   AGGREGATION; HONEYBEE AGGREGATION; COLLECTIVE DECISION; MACROSCOPIC
   MODEL; ION BATTERIES; RECEIVERS; BEHAVIOR; DOCKING
AB Swarm robotics studies the intelligent collective behaviour emerging from long-term interactions of large number of simple robots. However, maintaining a large number of robots operational for long time periods requires significant battery capacity, which is an issue for small robots. Therefore, re-charging systems such as automated battery-swapping stations have been implemented. These systems require that the robots interrupt, albeit shortly, their activity, which influences the swarm behaviour. In this paper, a low-cost on-the-fly wireless charging system, composed of several charging cells, is proposed for use in swarm robotic research studies. To determine the system's ability to support perpetual swarm operation, a probabilistic model that takes into account the swarm size, robot behaviour and charging area configuration, is outlined. Based on the model, a prototype system with 12 charging cells and a small mobile robot, Mona, was developed. A series of long-term experiments with different arenas and behavioural configurations indicated the model's accuracy and demonstrated the system's ability to support perpetual operation of multi-robotic system.
C1 [Arvin, Farshad; Watson, Simon; Espinosa, Jose; Lennox, Barry] Univ Manchester, Sch Elect & Elect Engn, Manchester M13 9PL, Lancs, England.
   [Turgut, Ali Emre] Middle East Tech Univ, Dept Mech Engn, TR-06800 Ankara, Turkey.
   [Krajnik, Tomas] Czech Tech Univ, Ctr Artificial Intelligence, Fac Elect Engn, Prague, Czech Republic.
RP Arvin, F (reprint author), Univ Manchester, Sch Elect & Elect Engn, Manchester M13 9PL, Lancs, England.
EM farshad.arvin@manchester.ac.uk
OI Watson, Simon/0000-0001-9783-0147
FU Innovate UK [KTP009811]; UK EPSRC [EP/P01366X/1]; Czech Science
   Foundation [17-27006Y]
FX This work was supported by Innovate UK (Project No. KTP009811), UK EPSRC
   (Reference: EP/P01366X/1) and Czech Science Foundation project
   17-27006Y.
CR Ahmad FA, 2014, SCI WORLD J, DOI 10.1155/2014/153162
   Arvin Farshad, 2015, Advances in Swarm and Computational Intelligence - 6th International Conference, ICSI 2015, held in conjunction with the Second BRICS Congress, CCI 2015. Proceedings: LNCS 9140, P551, DOI 10.1007/978-3-319-20466-6_58
   Arvin F., 2015, IROS
   Arvin F, 2016, ADAPT BEHAV, V24, P102, DOI 10.1177/1059712316632851
   Arvin F, 2014, LECT NOTES COMPUT SC, V8794, P1, DOI 10.1007/978-3-319-11857-4_1
   Arvin F, 2014, 2014 IEEE INTERNATIONAL CONFERENCE ON MECHATRONICS AND AUTOMATION (IEEE ICMA 2014), P635, DOI 10.1109/ICMA.2014.6885771
   Arvin F, 2014, ADAPT BEHAV, V22, P189, DOI 10.1177/1059712314528009
   Arvin F, 2014, INT J ADV ROBOT SYST, V11, DOI 10.5772/58730
   Arvin F, 2013, TURK J ELECTR ENG CO, V21, P1631, DOI 10.3906/elk-1109-65
   Arvin F, 2012, LECT NOTES COMPUT SC, V7461, P346, DOI 10.1007/978-3-642-32650-9_39
   Arvin F, 2011, INT J COMPUT INT SYS, V4, P739
   Arvin F, 2010, ADV ELECTR COMPUT EN, V10, P61, DOI 10.4316/AECE.2010.04010
   Arvin F, 2009, INTERNATIONAL CONFERENCE ON FUTURE COMPUTER AND COMMUNICATIONS, PROCEEDINGS, P127, DOI 10.1109/ICFCC.2009.48
   Arvin K. S. Farshad, 2009, INT J COMPUTER ELECT, V1, P436, DOI [10.7763/IJCEE.2009.V1.67, DOI 10.7763/IJCEE.2009.V1.67]
   Attarzadeh A., 2006, THESIS
   Bayindir L, 2016, NEUROCOMPUTING, V172, P292, DOI 10.1016/j.neucom.2015.05.116
   Bayindir L, 2009, 2009 IEEE SWARM INTELLIGENCE SYMPOSIUM, P88, DOI 10.1109/SIS.2009.4937849
   Bonani M., 2010, IROS
   Cannon BL, 2009, IEEE T POWER ELECTR, V24, P1819, DOI 10.1109/TPEL.2009.2017195
   Caprari G., 2002, Journal of Micromechatronics, V1, P177
   Caprari G., 2005, 2005 IEEE/RSJ International Conference on Intelligent Robots and Systems, P3295, DOI 10.1109/IROS.2005.1545568
   Chen CJ, 2010, IEEE T CIRCUITS-II, V57, P536, DOI 10.1109/TCSII.2010.2048403
   Correll N., 2007, IEEE INT C ROB AUT W
   Deyle T., 2008, ICRA
   Dorigo Marco, 2013, IEEE Robotics & Automation Magazine, V20, P60, DOI 10.1109/MRA.2013.2252996
   Ferrante E, 2015, PLOS COMPUT BIOL, V11, DOI 10.1371/journal.pcbi.1004273
   Floreano D., 1994, 3 INT C SIM AD BEH A
   Garnier S, 2009, ADAPT BEHAV, V17, P109, DOI 10.1177/1059712309103430
   Gerling K, 2016, Z GERONTOL GERIATR, V49, P288, DOI 10.1007/s00391-016-1065-6
   Hamann H., 2008, THESIS
   Hebesberger D., 2016, 11 ACM IEEE INT C HU
   Hu C, 2017, IEEE T COGN DEV SYST, V9, P241, DOI 10.1109/TCDS.2016.2574624
   Jeanson R, 2005, ANIM BEHAV, V69, P169, DOI 10.1016/j.anbehav.204.02.009
   Karpelson M., 2014, ICRA
   Kernbach S, 2009, ADAPT BEHAV, V17, P237, DOI 10.1177/1059712309104966
   Klingner J., 2014, IROS
   Krajnik T., 2013, P 16 INT C ADV ROB I, P1
   Krajnik T, 2014, J INTELL ROBOT SYST, V76, P539, DOI 10.1007/s10846-014-0041-x
   Krieger MJB, 2000, NATURE, V406, P992
   Liwanag HEM, 2014, J ZOOL, V293, P152, DOI 10.1111/jzo.12130
   Lu X, 2016, IEEE COMMUN SURV TUT, V18, P1413, DOI 10.1109/COMST.2015.2499783
   Lu X, 2015, IEEE COMMUN SURV TUT, V17, P757, DOI 10.1109/COMST.2014.2368999
   Martinoli A, 1999, ROBOT AUTON SYST, V29, P51, DOI 10.1016/S0921-8890(99)00038-X
   Martinoli A., 1998, EXPT ROBOTICS, VV, P595
   McLurkin J., 2006, AAAI SPRING S
   Minten BW, 2001, IEEE T ROBOTIC AUTOM, V17, P922, DOI 10.1109/70.976026
   Mondada F, 2004, AUTON ROBOT, V17, P193, DOI 10.1023/B:AURO.0000033972.50769.1c
   Mondada F., 2009, 9 C AUT ROB SYST COM
   Mondada F., 1994, EXPT ROBOTICS, VIII
   Neter John, 1996, APPL LINEAR STAT MOD, V4
   Roufas K, 2001, LECT NOTES CONTR INF, V271, P91
   Rubenstein M, 2014, ROBOT AUTON SYST, V62, P966, DOI 10.1016/j.robot.2013.08.006
   Sahin E, 2005, LECT NOTES COMPUT SC, V3342, P10
   Santos JM, 2016, IEEE ROBOT AUTOM LET, V1, P684, DOI 10.1109/LRA.2016.2516594
   Schmickl T, 2009, ROBOT AUTON SYST, V57, P913, DOI 10.1016/j.robot.2009.06.002
   Schmickl T, 2009, AUTON AGENT MULTI-AG, V18, P133, DOI 10.1007/s10458-008-9058-5
   Senyshyn A, 2015, SCI REP-UK, V5, DOI 10.1038/srep18380
   Soysal O, 2007, LECT NOTES COMPUT SC, V4433, P27
   Taheri P, 2013, J ELECTROCHEM SOC, V160, pA1731, DOI 10.1149/2.041310jes
   Takaya Y. U., 2003, INT S ART LIF ROB
   Turgut Ali E., 2008, Swarm Intelligence, V2, P97, DOI 10.1007/s11721-008-0016-2
   Valentini G, 2016, AUTON AGENT MULTI-AG, V30, P553, DOI 10.1007/s10458-015-9323-3
   WALTER WG, 1953, LIVING BRAIN
   Watson R. A., 1999, C EV COMP
   Wei XZ, 2014, ENERGIES, V7, P4316, DOI 10.3390/en7074316
   Winfield AFT, 2012, UNDERST COMPLEX SYST, P239, DOI 10.1007/978-3-642-33902-8_10
   Yuta S, 1998, 1998 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS - PROCEEDINGS, VOLS 1-3, P1871, DOI 10.1109/IROS.1998.724869
   Zhang Z., 2015, MAGN C INTERMAG
   Zhong WX, 2012, IEEE T POWER ELECTR, V27, P4750, DOI 10.1109/TPEL.2011.2174655
NR 69
TC 0
Z9 0
U1 12
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 0921-0296
EI 1573-0409
J9 J INTELL ROBOT SYST
JI J. Intell. Robot. Syst.
PD DEC
PY 2018
VL 92
IS 3-4
BP 395
EP 412
DI 10.1007/s10846-017-0673-8
PG 18
WC Computer Science, Artificial Intelligence; Robotics
SC Computer Science; Robotics
GA GX4XH
UT WOS:000447741700002
DA 2019-02-18
ER

PT J
AU Alonso, V
   de la Puente, P
AF Alonso, Victoria
   de la Puente, Paloma
TI System Transparency in Shared Autonomy: A Mini Review
SO FRONTIERS IN NEUROROBOTICS
LA English
DT Review
DE transparency; shared autonomy; human-robot interaction; communication;
   observability; predictability; interface; user-centered design
ID HUMAN-ROBOT INTERACTION; BILATERAL TELEOPERATION; SITUATION AWARENESS;
   AUTOMATION; IMPROVE; PERFORMANCE; STABILITY; MOTION; COMMUNICATION;
   OPTIMIZATION
AB What does transparency mean in a shared autonomy framework? Different ways of understanding system transparency in human-robot interaction can be found in the state of the art. In one of the most common interpretations of the term, transparency is the observability and predictability of the system behavior, the understanding of what the system is doing, why, and what it will do next. Since the main methods to improve this kind of transparency are based on interface design and training, transparency is usually considered a property of such interfaces, while natural language explanations are a popular way to achieve transparent interfaces. Mechanical transparency is the robot capacity to follow human movements without human-perceptible resistive forces. Transparency improves system performance, helping reduce human errors, and builds trust in the system. One of the principles of user-centered design is to keep the user aware of the state of the system: a transparent design is a user-centered design. This article presents a review of the definitions and methods to improve transparency for applications with different interaction requirements and autonomy degrees, in order to clarify the role of transparency in shared autonomy, as well as to identify research gaps and potential future developments.
C1 [Alonso, Victoria] Univ Politecn Madrid, ETSI Aeronaut & Espacio, Madrid, Spain.
   [de la Puente, Paloma] Univ Politecn Madrid, ETSI Ind, Madrid, Spain.
   [de la Puente, Paloma] Univ Politecn Madrid, CSIC, Ctr Automat & Robot, Madrid, Spain.
RP Alonso, V (reprint author), Univ Politecn Madrid, ETSI Aeronaut & Espacio, Madrid, Spain.
EM mariavictoria.alonso@upm.es
OI de la Puente, Paloma/0000-0002-8652-0300
FU Spanish Ministry of Economics
FX This work is partially funded by the Spanish Ministry of Economics and
   Competitivity-DPI2017-86915-C3-3-R COGDRIVE.
CR Anaya F, 2018, INT J INTELL ROBOT, V2, P1, DOI 10.1007/s41315-017-0042-6
   Aracil R, 2013, ROBOT AUTON SYST, V61, P86, DOI 10.1016/j.robot.2012.11.006
   Arrichiello Filippo, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P6032, DOI 10.1109/ICRA.2017.7989714
   Awad LN, 2017, SCI TRANSL MED, V9, DOI 10.1126/scitranslmed.aai9084
   Bai HY, 2015, IEEE INT CONF ROBOT, P454, DOI 10.1109/ICRA.2015.7139219
   Bai S, 2018, CONTROL ROBOTICS SEN, DOI [10.1049/PBCE108E, DOI 10.1049/PBCE108E]
   Baier H, 2004, J INTELL ROBOT SYST, V40, P1, DOI 10.1023/B:JINT.0000034338.53641.d0
   Baraka K, 2016, IEEE ROMAN, P652, DOI 10.1109/ROMAN.2016.7745187
   Barakova E., 2013, REV HUMAN FACTORS ER, V9, P175, DOI DOI 10.1177/1557234X13502463
   Baser O, 2013, MECHATRONICS, V23, P121, DOI 10.1016/j.mechatronics.2012.11.006
   Baser O, 2012, MECH MACH THEORY, V52, P78, DOI 10.1016/j.mechmachtheory.2012.01.012
   Beckerle P, 2017, FRONT NEUROROBOTICS, V11, DOI 10.3389/fnbot.2017.00024
   Beer JM, 2014, J HUM-ROBOT INTERACT, V3, P74, DOI 10.5898/JHRI.3.2.Beer
   Bensch S, 2018, PALADYN J BEHAV ROBO, V9, P110, DOI [10.1515/pjbr-2018-0009, DOI 10.1515/PJBR-2018-0009]
   Bethel CL, 2008, IEEE T SYST MAN CY C, V38, P83, DOI 10.1109/TSMCC.2007.905845
   Bi LZ, 2013, IEEE T HUM-MACH SYST, V43, P161, DOI 10.1109/TSMCC.2012.2219046
   Boaventura T, 2017, BIOSYST BIOROBOT, V15, P489, DOI 10.1007/978-3-319-46669-9_81
   Boaventura T, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P5683, DOI 10.1109/IROS.2016.7759836
   Boden M, 2017, CONNECT SCI, V29, P124, DOI 10.1080/09540091.2016.1271400
   Borenstein J, 2018, IEEE ROBOT AUTOM MAG, V25, P46, DOI 10.1109/MRA.2017.2778743
   Bradshaw JM, 2013, IEEE INTELL SYST, V28, P54, DOI 10.1109/MIS.2013.70
   Breazeal C, 2005, 2005 IEEE/RSJ International Conference on Intelligent Robots and Systems, Vols 1-4, P383, DOI 10.1109/IROS.2005.1545011
   Bryson J, 2017, COMPUTER, V50, P116, DOI 10.1109/MC.2017.154
   Buehler Moritz C., 2018, 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), P409, DOI 10.1109/IROS.2018.8594076
   Burget F, 2017, 2017 EUR C MOB ROB E, P1, DOI [10.1109/ECMR.2017.8098658, DOI 10.1109/ECMR.2017.8098658]
   Busch B, 2017, INT J SOC ROBOT, V9, P765, DOI 10.1007/s12369-017-0400-4
   Caminada M. W, 2014, P AAMAS 14 INT FDN A, P1625
   Casalino A, 2018, IEEE ROBOT AUTOM LET, V3, P4289, DOI 10.1109/LRA.2018.2865034
   Cha Elizabeth, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P1654, DOI 10.1109/ICRA.2017.7989195
   Cha Elizabeth, 2018, FDN TRENDS ROBOT, V6, P211, DOI [10.1561/2300000057, DOI 10.1561/2300000057]
   Chen J, 2014, ARLTR6905 ARM
   Chen M, 2018, P 2018 ACM IEEE INT, P307
   Chen X, 2017, IEEE T NEUR SYS REH, V25, P577, DOI 10.1109/TNSRE.2016.2582321
   Daniele Andrea F., 2017, 2017 12th ACM/IEEE International Conference on Human-Robot Interaction (HRI), P109, DOI 10.1145/2909824.3020241
   DARPA [Defense Advanced Research Projects Agency], 2016, DARPABAA1653
   Desai Munjal, 2012, THESIS
   DoD, 2012, TECHNICAL REPORT
   Doellinger Johannes, 2018, IEEE Robotics and Automation Letters, V3, P1522, DOI 10.1109/LRA.2018.2800780
   Dragan A. D., 2017, 2018 IEEE RSJ INT C
   Dragan AD, 2015, ACMIEEE INT CONF HUM, P51, DOI 10.1145/2696454.2696473
   Dragan AD, 2015, IEEE INT CONF ROBOT, P2339, DOI 10.1109/ICRA.2015.7139510
   Dragan AD, 2013, ACMIEEE INT CONF HUM, P301, DOI 10.1109/HRI.2013.6483603
   Duvallet F, 2016, INFERRING MAPS BEHAV
   Duvallet F, 2013, IEEE INT CONF ROBOT, P1047, DOI 10.1109/ICRA.2013.6630702
   Endsley M., 2012, DESIGNING SITUATION
   Endsley MR, 2018, J COGN ENG DECIS MAK, V12, P29, DOI 10.1177/1555343417723432
   Endsley MR, 2017, HUM FACTORS, V59, P5, DOI 10.1177/0018720816681350
   Endsley MR, 1999, ERGONOMICS, V42, P462, DOI 10.1080/001401399185595
   ENDSLEY MR, 1995, HUM FACTORS, V37, P32, DOI 10.1518/001872095779049543
   European Parlament, 2017, 20152103INL EUR PARL
   Ezeh C, 2017, INT C REHAB ROBOT, P835, DOI 10.1109/ICORR.2017.8009352
   Fani S, 2018, IEEE ROBOT AUTOM MAG, V25, P77, DOI 10.1109/MRA.2017.2741579
   Farooq U, 2016, P IEEE INT C EM TECH, P1, DOI 10.1109/ICET.2016.7813242
   Fathaliyan AH, 2018, FRONT ROBOT AI, V5, DOI 10.3389/frobt.2018.00025
   Ferre M., 2007, ADV TELEROBOTICS
   Fischer K, 2018, PALADYN, V9, P95, DOI [10.1515/pjbr-2018-0007, DOI 10.1515/PJBR-2018-0007]
   Fong J, 2017, INT C REHAB ROBOT, P771, DOI 10.1109/ICORR.2017.8009341
   Fong T, 2017, P COMP 2017 ACM IEEE, P163
   Franken M, 2012, MECHATRONICS, V22, P45, DOI 10.1016/j.mechatronics.2011.11.004
   Ganesan RK, 2018, IEEE ROBOT AUTOM MAG, V25, P59, DOI 10.1109/MRA.2018.2815655
   Gielniak M. J., 2011, 2011 RO-MAN: The 20th IEEE International Symposium on Robot and Human Interactive Communication, P449, DOI 10.1109/ROMAN.2011.6005255
   Gildert N, 2018, FRONT ROBOT AI, V5, DOI 10.3389/frobt.2018.00065
   Goethals P, 2007, WORLD HAPTICS 2007: SECOND JOINT EUROHAPTICS CONFERENCE AND SYMPOSIUM ON HAPTIC INTERFACES FOR VIRTUAL ENVIRONMENT AND TELEOPERATOR SYSTEMS, PROCEEDINGS, P458
   Goldhoorn A, 2018, AUTON ROBOT, V42, P739, DOI 10.1007/s10514-017-9681-6
   Goodman B., 2016, AI MAG, V38, P50
   Goodrich Michael A, 2007, Foundations and Trends in Human-Computer Interaction, V1, P203, DOI 10.1561/1100000005
   Gopinath D, 2017, IEEE ROBOT AUTOM LET, V2, P247, DOI 10.1109/LRA.2016.2593928
   Gransche B, 2014, WANDE AUTONOMIE KONT
   Grinbaum A, 2017, IEEE ROBOT AUTOM MAG, V24, P139, DOI 10.1109/MRA.2016.2611586
   Hancock PA, 2017, HUM FACTORS, V59, P35, DOI 10.1177/0018720816655240
   Havig P. R, 2014, TRANSPARENCY HUMAN M, P181
   Hayes Bradley, 2017, 2017 12th ACM/IEEE International Conference on Human-Robot Interaction (HRI), P303, DOI 10.1145/2909824.3020233
   Hemachandra S, 2015, IEEE INT CONF ROBOT, P5608, DOI 10.1109/ICRA.2015.7139984
   Hertkorn K, 2015, THESIS
   Hirche S, 2007, ADV TELEROBOTICS, P191, DOI [10.1007/978-3-540-71364-7_13, DOI 10.1007/978-3-540-71364-7_13]
   Hokayem PF, 2006, AUTOMATICA, V42, P2035, DOI 10.1016/j.automatica.2006.06.027
   Iden J., 2017, ROBOTICS SCI SYSTEMS
   Jarrasse N, 2008, IEEE INT CONF ROBOT, P2134, DOI 10.1109/ROBOT.2008.4543522
   Jarrasse N, 2009, SPR TRA ADV ROBOT, V54, P557
   Javdani S, 2018, INT J ROBOT RES, V37, P717, DOI 10.1177/0278364918776060
   Jones DG, 1996, AVIAT SPACE ENVIR MD, V67, P507
   Kaber DB, 2018, J COGN ENG DECIS MAK, V12, P7, DOI 10.1177/1555343417737203
   Kim H, 2015, J INTELL ROBOT SYST, V80, pS99, DOI 10.1007/s10846-015-0212-4
   Kim J, 2013, IEEE T CONTR SYST T, V21, P40, DOI 10.1109/TCST.2011.2172945
   Kim J, 2010, J INTELL ROBOT SYST, V58, P309, DOI 10.1007/s10846-009-9376-0
   Kim Taemie, 2006, 15 IEEE INT S ROB HU, P80, DOI [10.1109/ROMAN.2006.314398, DOI 10.1109/ROMAN.2006.314398]
   Kollar T, 2010, ACMIEEE INT CONF HUM, P259, DOI 10.1109/HRI.2010.5453186
   Kruijff G. J. M, 2014, EXPERIENCE SYSTEM DE
   Kuhner D., 2018, 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), P876, DOI 10.1109/IROS.2018.8593371
   Kuipers B, 2018, COMMUN ACM, V61, P86, DOI 10.1145/3173087
   Lakhmani S, 2016, PROPOSED APPROACH DE
   Lakomkin E, 2018, 2018 IEEE INT C ROB, P1, DOI [10.1109/ICRA.2018.8461058, DOI 10.1109/ICRA.2018.8461058]
   LAWRENCE DA, 1993, IEEE T ROBOTIC AUTOM, V9, P624, DOI 10.1109/70.258054
   Lee D, 2005, IEEE T ROBOT, V21, P936, DOI 10.1109/TRO.2005.852259
   Lee JD, 2004, HUM FACTORS, V46, P50, DOI 10.1518/hfes.46.1.50.30392
   Lewis M, 2018, ROLE TRUST HUMAN ROB, DOI [10.1007/978-3-319-64816-3_8, DOI 10.1007/978-3-319-64816-3_8]
   Li SP, 2017, IEEE T BIO-MED ENG, V64, P2824, DOI 10.1109/TBME.2017.2677902
   Li SP, 2017, IEEE T HUM-MACH SYST, V47, P437, DOI 10.1109/THMS.2017.2647882
   Liang-Yan Gui, 2018, 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), P562, DOI 10.1109/IROS.2018.8594452
   Lorenz T., 2015, THESIS
   Lorenz T, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00461
   Lu ZY, 2017, INT J CONTROL AUTOM, V15, P2301, DOI 10.1007/s12555-016-0467-y
   Lyons J.B, 2013, 2013 ASS ADV ART INT, P48
   MacMahon Matthew, 2006, P NAT C ART INT AAAI, V2, P1475
   Mai Lee Chang, 2018, 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), P3381, DOI 10.1109/IROS.2018.8593359
   Matthews M, 2017, P ROB SCI SYST RSS 2
   Matuszek C, 2010, ACMIEEE INT CONF HUM, P251, DOI 10.1109/HRI.2010.5453189
   Meli L, 2014, IEEE T BIO-MED ENG, V61, P1318, DOI 10.1109/TBME.2014.2303052
   Miller C. A, 2014, DELEGATION TRANSPARE, P191
   Miller CA, 2018, J COGN ENG DECIS MAK, V12, P74, DOI 10.1177/1555343417726254
   Milliotte C, 2018, GEOL SOC SPEC PUBL, V459, P191, DOI 10.1144/SP459.7
   Minsky M., 2006, EMOTION MACHINE COMM
   Monfaredi R, 2006, 2006 IEEE/RSJ International Conference on Intelligent Robots and Systems, Vols 1-12, P1686, DOI 10.1109/IROS.2006.282125
   Mueller E, 2016, TRANSPARENT COMPUTER
   Muelling K, 2017, AUTON ROBOT, V41, P1401, DOI 10.1007/s10514-017-9622-4
   Murphy RR, 2014, INTELL ROBOT AUTON, P1
   Nikolaidis Stefanos, 2017, 2017 12th ACM/IEEE International Conference on Human-Robot Interaction (HRI), P294, DOI 10.1145/2909824.3020252
   Nikolaidis S, 2018, ACM T HUMAN ROBOT IN, V7, P22
   Nikolaidis S, 2016, ELEVENTH ACM/IEEE INTERNATIONAL CONFERENCE ON HUMAN ROBOT INTERACTION (HRI'16), P271, DOI 10.1109/HRI.2016.7451762
   Nikolaidis S, 2015, INT J ROBOT RES, V34, P1711, DOI 10.1177/0278364915609673
   Okamura A. M, 2018, ACM T HUM ROBOT INTE, V7
   Onnasch L, 2014, HUM FACTORS, V56, P476, DOI 10.1177/0018720813501549
   Ososky S, 2014, PROC SPIE, V9084, DOI 10.1117/12.2050622
   Osswald S, 2014, IEEE INT CONF ROBOT, P3303, DOI 10.1109/ICRA.2014.6907334
   Oviatt S, 2017, HDB MULTIMODAL MULTI, V1
   Pacchierotti C, 2014, ACM T APPL PERCEPT, V11, DOI 10.1145/2604969
   Parasuraman R, 1997, HUM FACTORS, V39, P230, DOI 10.1518/001872097778543886
   Parasuraman R, 2000, IEEE T SYST MAN CY A, V30, P286, DOI 10.1109/3468.844354
   Parasuraman R, 1993, INT J AVIAT PSYCHOL, V3, P1, DOI DOI 10.1207/S15327108IJAP0301_
   Park S, 2016, INT J CONTROL AUTOM, V14, P835, DOI [10.1007/s12555-014-0109-9, 10.1007/s12555-014-0109-1]
   Perera V, 2016, IEEE ROMAN, P212, DOI 10.1109/ROMAN.2016.7745133
   Perzanowski D, 2001, IEEE INTELL SYST APP, V16, P16, DOI 10.1109/MIS.2001.1183338
   Polushin IG, 2007, IEEE-ASME T MECH, V12, P361, DOI 10.1109/TMECH.2007.897285
   RAJU GJ, 1989, PROCEEDINGS - 1989 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOL 1-3, P1316, DOI 10.1109/ROBOT.1989.100162
   Robertson J., 2007, LETT MED PHYS READAP, V23, P139
   Roncone Alessandro, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P1014, DOI 10.1109/ICRA.2017.7989122
   Rosenthal S, 2016, P 25 INT JOINT C ART, P862
   Rupp R, 2014, BRAIN COMPUTER INTER
   Sanders TL, 2014, 2014 IEEE INTERNATIONAL INTER-DISCIPLINARY CONFERENCE ON COGNITIVE METHODS IN SITUATION AWARENESS AND DECISION SUPPORT (COGSIMA), P156, DOI 10.1109/CogSIMA.2014.6816556
   Sarkar M., 2018, APPL COMPUTER VISION
   Schilling M, 2016, P AAAI FALL S SER 20, V2016
   Sciutti A, 2018, IEEE TECHNOL SOC MAG, V37, P22, DOI 10.1109/MTS.2018.2795095
   Sheh R. K., 2017, AAAI 17 WHORKSH HUM, P628
   Slawinski E, 2012, IEEE T SYST MAN CY A, V42, P430, DOI 10.1109/TSMCA.2011.2159588
   Suddrey G, 2017, IEEE ROBOT AUTOM LET, V2, P201, DOI 10.1109/LRA.2016.2588584
   Sun D, 2016, CONTROL ENG PRACT, V47, P15, DOI 10.1016/j.conengprac.2015.11.003
   Takayama L, 2011, ACMIEEE INT CONF HUM, P69, DOI 10.1145/1957656.1957674
   Theodorou A, 2016, AISB WORKSH PRINC RO
   Theodorou A, 2017, CONNECT SCI, V29, P230, DOI 10.1080/09540091.2017.1310182
   Tsiourti C., 2014, C HUM ROB INT HRI201
   Uhn Joo Na, 2012, 2012 IEEE International Workshop on Haptic Audio Visual Environments and Games (HAVE 2012), P38, DOI 10.1109/HAVE.2012.6374442
   van der Aalst WMP, 2013, FED CONF COMPUT SCI, P1
   Verplank W, 1978, TECHNICAL REPORT
   Villani V, 2018, IEEE ROBOT AUTOM MAG, V25, P37, DOI 10.1109/MRA.2017.2781308
   Walker M, 2018, P 2018 ACM IEEE INT, P316
   Wang ZK, 2017, ARTIF INTELL, V247, P399, DOI 10.1016/j.artint.2014.11.007
   Westlund JMK, 2016, ELEVENTH ACM/IEEE INTERNATIONAL CONFERENCE ON HUMAN ROBOT INTERACTION (HRI'16), P625, DOI 10.1109/HRI.2016.7451888
   Winfield AFT, 2017, LECT NOTES COMPUT SC, V10454, P262, DOI 10.1007/978-3-319-64107-2_21
   Wortham R. H, 2017, 26 IEEE INT S ROB HU
   Wortham R. H, 2016, P IJCAI WORKSH ETH A
   Wortham RH, 2017, LECT NOTES COMPUT SC, V10454, P274, DOI 10.1007/978-3-319-64107-2_22
   Wright J. L, 2017, ARLTR8044 ARM
   Xu X, 2016, IEEE ACCESS, V4, P425, DOI 10.1109/ACCESS.2016.2517926
   Yalcin B, 2010, IEEE T IND ELECTRON, V57, P3228, DOI 10.1109/TIE.2009.2038330
   Yang X. Jessie, 2017, 2017 12th ACM/IEEE International Conference on Human-Robot Interaction (HRI), P408, DOI 10.1145/2909824.3020230
   YOKOKOHJI Y, 1994, IEEE T ROBOTIC AUTOM, V10, P605, DOI 10.1109/70.326566
   Zhang WJ, 2016, IEEE SYS MAN CYBERN, P2335, DOI 10.1109/SMC.2016.7844587
   Zhao Z, 2017, ROBOT AUTON SYST, V96, P93, DOI 10.1016/j.robot.2017.05.017
   Zhu QXY, 2017, 2017 IEEE-RAS 17TH INTERNATIONAL CONFERENCE ON HUMANOID ROBOTICS (HUMANOIDS), P390, DOI 10.1109/HUMANOIDS.2017.8246903
NR 169
TC 0
Z9 0
U1 3
U2 3
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1662-5218
J9 FRONT NEUROROBOTICS
JI Front. Neurorobotics
PD NOV 30
PY 2018
VL 12
AR 83
DI 10.3389/fnbot.2018.00083
PG 11
WC Computer Science, Artificial Intelligence; Robotics; Neurosciences
SC Computer Science; Robotics; Neurosciences & Neurology
GA HC6OY
UT WOS:000451922400001
PM 30555317
OA DOAJ Gold
DA 2019-02-18
ER

PT J
AU Parisi, GI
   Tani, J
   Weber, C
   Wermter, S
AF Parisi, German, I
   Tani, Jun
   Weber, Cornelius
   Wermter, Stefan
TI Lifelong Learning of Spatiotemporal Representations With Dual-Memory
   Recurrent Self-Organization
SO FRONTIERS IN NEUROROBOTICS
LA English
DT Article
DE lifelong learning; complementary learning systems; self-organizing
   networks; continuous object recognition; catastrophic forgetting
ID ADULT NEUROGENESIS; HIPPOCAMPAL; SYSTEMS; CONSOLIDATION; REACTIVATION;
   EXPERIENCE; NETWORK; NEURONS; REPLAY; MODEL
AB Artificial autonomous agents and robots interacting in complex environments are required to continually acquire and fine-tune knowledge over sustained periods of time. The ability to learn from continuous streams of information is referred to as lifelong learning and represents a long-standing challenge for neural network models due to catastrophic forgetting in which novel sensory experience interferes with existing representations and leads to abrupt decreases in the performance on previously acquired knowledge. Computational models of lifelong learning typically alleviate catastrophic forgetting in experimental scenarios with given datasets of static images and limited complexity, thereby differing significantly from the conditions artificial agents are exposed to. In more natural settings, sequential information may become progressively available over time and access to previous experience may be restricted. Therefore, specialized neural network mechanisms are required that adapt to novel sequential experience while preventing disruptive interference with existing representations. In this paper, we propose a dual-memory self-organizing architecture for lifelong learning scenarios. The architecture comprises two growing recurrent networks with the complementary tasks of learning object instances (episodic memory) and categories (semantic memory). Both growing networks can expand in response to novel sensory experience: the episodic memory learns fine-grained spatiotemporal representations of object instances in an unsupervised fashion while the semantic memory uses task-relevant signals to regulate structural plasticity levels and develop more compact representations from episodic experience. For the consolidation of knowledge in the absence of external sensory input, the episodic memory periodically replays trajectories of neural reactivations. We evaluate the proposed model on the CORe50 benchmark dataset for continuous object recognition, showing that we significantly outperform current methods of lifelong learning in three different incremental learning scenarios.
C1 [Parisi, German, I; Weber, Cornelius; Wermter, Stefan] Univ Hamburg, Dept Informat, Knowledge Technol, Hamburg, Germany.
   [Tani, Jun] Okinawa Inst Sci & Technol, Cognit Neurorobot Res Unit, Onna, Okinawa, Japan.
RP Parisi, GI (reprint author), Univ Hamburg, Dept Informat, Knowledge Technol, Hamburg, Germany.
EM parisi@informatik.uni-hamburg.de
FU German Research Foundation (DFG) under project Transregio Crossmodal
   Learning [TRR 169]
FX This research was partially supported by the German Research Foundation
   (DFG) under project Transregio Crossmodal Learning (TRR 169). The
   authors would like to thank Pablo Barros and Vadym Gryshchuk for
   technical support.
CR Aimone JB, 2006, NAT NEUROSCI, V9, P723, DOI 10.1038/nn1707
   Aimone JB, 2009, NEURON, V61, P187, DOI 10.1016/j.neuron.2008.11.026
   Benna MK, 2016, NAT NEUROSCI, V19, P1697, DOI 10.1038/nn.4401
   Berkes P, 2005, J VISION, V5, P579, DOI 10.1167/5.6.9
   Boldrini M, 2018, CELL STEM CELL, V22, P589, DOI 10.1016/j.stem.2018.03.015
   Booth MCA, 1998, CEREB CORTEX, V8, P510, DOI 10.1093/cercor/8.6.510
   Cangelosi A., 2015, DEV ROBOTICS BABIES
   Carr MF, 2011, NAT NEUROSCI, V14, P147, DOI 10.1038/nn.2732
   Clarke A, 2014, J NEUROSCI, V34, P4766, DOI 10.1523/JNEUROSCI.2828-13.2014
   Ditzler G, 2015, IEEE COMPUT INTELL M, V10, P12, DOI 10.1109/MCI.2015.2471196
   Draelos TJ, 2017, IEEE IJCNN, P526, DOI 10.1109/IJCNN.2017.7965898
   Einhauser W, 2005, BIOL CYBERN, V93, P79, DOI 10.1007/s00422-005-0585-8
   Eriksson PS, 1998, NAT MED, V4, P1313, DOI 10.1038/3305
   Estevez P. A, 2012, WSOM, P205
   French R. M., 1997, Connection Science, V9, P353, DOI 10.1080/095400997116595
   Fritzke B., 1995, Advances in Neural Information Processing Systems 7, P625
   Gelbard-Sagiv H, 2008, SCIENCE, V322, P96, DOI 10.1126/science.1164685
   Gepperth A, 2016, COGN COMPUT, V8, P924, DOI 10.1007/s12559-016-9389-5
   GROSSBERG S, 1980, PSYCHOL REV, V87, P1, DOI 10.1037/0033-295X.87.1.1
   Grossberg S, 2007, NEURAL NETWORKS, V20, P1040, DOI 10.1016/j.neunet.2007.09.014
   Grossberg S, 2012, NEURAL NETWORKS, V27, P1, DOI [10.1016/j.neunet.2011.10.011, 10.1016/j.neunet.2012.09.017]
   He K., 2015, ARXIV151203385
   Kamra N, 2018, 171010368 ARXIV
   Karimi-Rouzbahani H, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-13756-8
   Karlsson MP, 2009, NAT NEUROSCI, V12, P913, DOI 10.1038/nn.2344
   Kemker R, 2018, AAAI 18
   Kemker R, 2018, ICLR 18
   Kirkpatricka J, 2017, P NATL ACAD SCI USA, V114, P3521, DOI 10.1073/pnas.1611835114
   Kitamura T, 2017, SCIENCE, V356, P73, DOI 10.1126/science.aam6808
   Knoblauch A, 2017, REWIRING BRAIN: A COMPUTATIONAL APPROACH TO STRUCTURAL PLASTICITY IN THE ADULT BRAIN, P361, DOI 10.1016/B978-0-12-803784-3.00017-2
   Knoblauch A, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0096485
   KOHONEN Teuvo, 1995, SELF ORGANIZING MAPS
   Krizhevsky A., 2009, THESIS
   Kudrimoti HS, 1999, J NEUROSCI, V19, P4090
   Kumaran D, 2016, TRENDS COGN SCI, V20, P512, DOI 10.1016/j.tics.2016.05.004
   Kumaran D, 2012, PSYCHOL REV, V119, P573, DOI 10.1037/a0028681
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Lewkowicz DJ, 2014, DEV PSYCHOBIOL, V56, P292, DOI 10.1002/dev.21197
   LI ZZ, 2016, EUR C COMP VIS, V9908, P614, DOI DOI 10.1007/978-3-319-46493-0_37
   Lomonaco V, 2017, CORL 17
   Lomonaco V, 2018, 180608568 ARXIV
   Marsland S, 2002, NEURAL NETWORKS, V15, P1041, DOI 10.1016/S0893-6080(02)00078-3
   MCCLELLAND JL, 1995, PSYCHOL REV, V102, P419, DOI 10.1037/0033-295X.102.3.419
   McCloskey M., 1989, PSYCHOL LEARN MOTIV, V24, P109, DOI DOI 10.1016/S0079-7421(08)60536-8
   Mermillod M, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00504
   Mineiro P, 1998, NEURAL COMPUT, V10, P353, DOI 10.1162/089976698300017791
   Ming GL, 2011, NEURON, V70, P687, DOI 10.1016/j.neuron.2011.05.001
   Neunuebel JP, 2014, NEURON, V81, P416, DOI 10.1016/j.neuron.2013.11.017
   O'Reilly RC, 2002, TRENDS COGN SCI, V6, P505, DOI 10.1016/S1364-6613(02)02005-3
   Parisi G. I, 2018, 180210408 ARXIV
   Parisi G. I, 2018, 180207569 ARXIV
   Parisi GI, 2017, NEURAL NETWORKS, V96, P137, DOI 10.1016/j.neunet.2017.09.001
   Parisi GI, 2017, COGN SYST RES, V43, P208, DOI 10.1016/j.cogsys.2016.08.002
   Parisi GI, 2015, FRONT NEUROROBOTICS, V9, P1, DOI 10.3389/fnbot.2015.00003
   Power JD, 2017, WIRES DEV BIOL, V6, DOI 10.1002/wdev.216
   PRINCIPE JC, 1994, IEEE T NEURAL NETWOR, V5, P331, DOI 10.1109/72.279195
   Rebuffi S. - A, 2017, ARXIV161107725
   Robins A., 1995, Connection Science, V7, P123, DOI 10.1080/09540099550039318
   Rougier N, 2011, NEUROCOMPUTING, V74, P1840, DOI 10.1016/j.neucom.2010.06.034
   Russakovsky O, 2014, 14090575 ARXIV
   Rusu A. A, 2016, 160604671 ARXIV
   Simonyan K., 2014, 14091556 ARXIV, DOI DOI 10.1109/TNN.2010.2066286
   Sorrells SF, 2018, NATURE, V555, P377, DOI 10.1038/nature25975
   STANLEY JC, 1976, NATURE, V261, P146, DOI 10.1038/261146a0
   Strickert M, 2005, NEUROCOMPUTING, V64, P39, DOI 10.1016/j.neucom.2004.11.014
   Tani J., 2016, EXPLORING ROBOTIC MI
   THRUN S, 1995, ROBOT AUTON SYST, V15, P25, DOI 10.1016/0921-8890(95)00004-Y
   Yamins DLK, 2014, P NATL ACAD SCI USA, V111, P8619, DOI 10.1073/pnas.1403112111
   Yassa MA, 2011, TRENDS NEUROSCI, V34, P515, DOI 10.1016/j.tins.2011.06.006
   Zenke F, 2017, P 34 INT C MACH LEAR, V70, P3987
   Zenke F, 2017, CURR OPIN NEUROBIOL, V43, P166, DOI 10.1016/j.conb.2017.03.015
NR 72
TC 0
Z9 0
U1 0
U2 0
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1662-5218
J9 FRONT NEUROROBOTICS
JI Front. Neurorobotics
PD NOV 28
PY 2018
VL 12
AR 78
DI 10.3389/fnbot.2018.00078
PG 15
WC Computer Science, Artificial Intelligence; Robotics; Neurosciences
SC Computer Science; Robotics; Neurosciences & Neurology
GA HC2ZK
UT WOS:000451670200001
PM 30546302
OA DOAJ Gold
DA 2019-02-18
ER

PT J
AU Huyck, C
   Mitchell, I
AF Huyck, Christian
   Mitchell, Ian
TI CABots and Other Neural Agents
SO FRONTIERS IN NEUROROBOTICS
LA English
DT Article
DE cell assembly; embodied cognition; neurocognitive model; turing test;
   closed-loop agents
ID MODEL; SIMULATION; NETWORKS; NEURONS
AB The best way to develop a Turing test passing Al is to follow the human model: an embodied agent that functions over a wide range of domains, is a human cognitive model, follows human neural functioning and learns. These properties will endow the agent with the deep semantics required to pass the test. An embodied agent functioning over a wide range of domains is needed to be exposed to and learn the semantics of those domains. Following human cognitive and neural functioning simplifies the search for sufficiently sophisticated mechanisms by reusing mechanisms that are already known to be sufficient. This is a difficult task, but initial steps have been taken, including the development of CABots, neural agents embodied in virtual environments. Several different CABots run in response to natural language commands, performing a cognitive mapping task. These initial agents are quite some distance from passing the test, and to develop an agent that passes will require broad collaboration. Several next steps are proposed, and these could be integrated using, for instance, the Platforms from the Human Brain Project as a foundation for this collaboration.
C1 [Huyck, Christian; Mitchell, Ian] Middlesex Univ, Dept Comp Sci, London, England.
RP Huyck, C (reprint author), Middlesex Univ, Dept Comp Sci, London, England.
EM c.huyck@mdx.ac.uk
FU Human Brain Project; UK EPSRC
FX This work was partially funded as part of the Human Brain Project. It
   has also been partially funded by the UK EPSRC.
CR Barandiaran XE, 2009, ADAPT BEHAV, V17, P367, DOI 10.1177/1059712309343819
   Barsalou LW, 1999, BEHAV BRAIN SCI, V22, P577
   Belavkin RV, 2011, COGN SYST RES, V12, P93, DOI 10.1016/j.cogsys.2010.08.003
   Bi GQ, 1998, J NEUROSCI, V18, P10464
   Braitenberg V, 1984, VEHICLES EXPT SYNTHE
   Brette R, 2005, J NEUROPHYSIOL, V94, P3637, DOI 10.1152/jn.00686.2005
   Brette R, 2007, J COMPUT NEUROSCI, V23, P349, DOI 10.1007/s10827-007-0038-6
   BROOKS RA, 1991, ARTIF INTELL, V47, P139, DOI 10.1016/0004-3702(91)90053-M
   Buzsaki G, 2010, NEURON, V68, P362, DOI 10.1016/j.neuron.2010.09.023
   Carrillo RR, 2008, BIOSYSTEMS, V94, P18, DOI 10.1016/j.biosystems.2008.05.008
   Davison Andrew P, 2008, Front Neuroinform, V2, P11, DOI 10.3389/neuro.11.011.2008
   Dean P, 2010, NAT REV NEUROSCI, V11, P30, DOI 10.1038/nrn2756
   Dennett D, 1984, MINDS MACHINES EVOLU, P129
   Diaper D, 2006, INTERACT COMPUT, V18, P117, DOI 10.1016/j.intcom.2005.06.004
   Eliasmith C, 2012, SCIENCE, V338, P1202, DOI 10.1126/science.1225266
   Fay R, 2005, LECT NOTES ARTIF INT, V3575, P118
   Ferrucci D, 2013, ARTIF INTELL, V199, P93, DOI 10.1016/j.artint.2012.06.009
   Floreano D., 2001, LNCS, P38
   Furber SB, 2013, IEEE T COMPUT, V62, P2454, DOI 10.1109/TC.2012.142
   Gewaltig MO, 2007, SCHOLARPEDIA, V2, P1430, DOI DOI 10.4249/SCH0LARPEDIA.1430
   Ghosh-Dastidar S, 2009, INT J NEURAL SYST, V19, P295, DOI 10.1142/S0129065709002002
   Gibson J. J., 1986, ECOLOGICAL APPROACH
   Gomila A, 2012, J COGN SCI, V13, P453
   Granger R, 2006, AI MAG, V27, P15
   HARNAD S, 1990, PHYSICA D, V42, P335, DOI 10.1016/0167-2789(90)90087-6
   Harnad S., 1992, SIGART B, V3, P9
   Hassabis D, 2017, NEURON, V95, P245, DOI 10.1016/j.neuron.2017.06.011
   Hebb D. O, 1949, ORG BEHAV NEUROPSYCH
   Holroyd CB, 2002, PSYCHOL REV, V109, P679, DOI 10.1037/0033-295X.109.4.679
   Hopcroft J., 2006, AUTOMATA THEORY LANG
   HUBEL DH, 1962, J PHYSIOL-LONDON, V160, P106, DOI 10.1113/jphysiol.1962.sp006837
   Huyck C., 2011, 7 INT WORKSH NEUR SY
   Huyck C, 2012, J SYST CYBERN INF, V10, P80
   Huyck CR, 2009, COGN NEURODYNAMICS, V3, P317, DOI 10.1007/s11571-009-9080-6
   Ikegaya Y, 2004, SCIENCE, V304, P559, DOI 10.1126/science.1093173
   Jackendoff R, 2002, FDN LANGUAGE BRAIN M
   James W., 1892, PSYCHOL BRIEFER COUR
   Kahneman D., 2011, THINKING FAST SLOW
   Levesque HJ, 2014, ARTIF INTELL, V212, P27, DOI 10.1016/j.artint.2014.03.007
   Maes P., 1989, Connection Science, V1, P291, DOI 10.1080/09540098908915643
   MORRIS RGM, 1982, NATURE, V297, P681, DOI 10.1038/297681a0
   Neftci E, 2013, P NATL ACAD SCI USA, V110, pE3468, DOI 10.1073/pnas.1212083110
   Potjans W, 2009, NEURAL COMPUT, V21, P301, DOI 10.1162/neco.2008.08-07-593
   QUILLIAN MR, 1967, BEHAV SCI, V12, P410, DOI 10.1002/bs.3830120511
   REBER AS, 1989, J EXP PSYCHOL GEN, V118, P219, DOI 10.1037/0096-3445.118.3.219
   Roehrbein F., 2016, ISR 2016 47 INT S RO, P1
   RUMELHART DE, 1982, PSYCHOL REV, V89, P60, DOI 10.1037/0033-295X.89.1.60
   Schemmel J, 2010, IEEE INT SYMP CIRC S, P1947, DOI 10.1109/ISCAS.2010.5536970
   Schwalger T, 2017, PLOS COMPUT BIOL, V13, DOI 10.1371/journal.pcbi.1005507
   Stroop JR, 1935, J EXP PSYCHOL, V18, P643, DOI 10.1037/h0054651
   Taddeo M, 2005, J EXP THEOR ARTIF IN, V17, P419, DOI 10.1080/09528130500284053
   Tinker J, 2014, FRONT SYST NEUROSCI, V8, DOI 10.3389/fnsys.2014.00073
   TULVING E, 1984, BEHAV BRAIN SCI, V7, P223, DOI 10.1017/S0140525X0004440X
   Turing A., 1950, MIND, V59, P433, DOI DOI 10.1093/MIND/LIX.236.433
   vanVreeswijk C, 1996, SCIENCE, V274, P1724
   Wilson M, 2002, PSYCHON B REV, V9, P625, DOI 10.3758/BF03196322
NR 56
TC 0
Z9 0
U1 0
U2 0
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1662-5218
J9 FRONT NEUROROBOTICS
JI Front. Neurorobotics
PD NOV 26
PY 2018
VL 12
AR 79
DI 10.3389/fnbot.2018.00079
PG 12
WC Computer Science, Artificial Intelligence; Robotics; Neurosciences
SC Computer Science; Robotics; Neurosciences & Neurology
GA HB8NA
UT WOS:000451345800001
PM 30534068
OA DOAJ Gold, Green Published
DA 2019-02-18
ER

PT J
AU Xu, GZ
   Gao, X
   Pan, LZ
   Chen, S
   Wang, Q
   Zhu, B
   Li, JF
AF Xu, Guozheng
   Gao, Xiang
   Pan, Lizheng
   Chen, Sheng
   Wang, Qiang
   Zhu, Bo
   Li, Jinfei
TI Anxiety detection and training task adaptation in robot-assisted active
   stroke rehabilitation
SO INTERNATIONAL JOURNAL OF ADVANCED ROBOTIC SYSTEMS
LA English
DT Article
DE Rehabilitation robot; stroke patients; anxiety detection; human-robot
   interaction; training task adaptation; engagements investigation
ID UPPER-LIMB REHABILITATION; EMOTION; RECOGNITION; DIFFICULTY; MOTIONS;
   SYSTEM; AUTISM
AB In the therapist-centered rehabilitation program, the experienced therapists can observe emotional changes of stroke patients and make corresponding decisions on their intervention strategies. Likewise, robotic-assisted stroke rehabilitation systems will be more appreciated if they can also perceive emotional states of the stroke patients and enhance their engagements by exploring emotion-based dynamic difficulty adjustments. Nevertheless, few research have addressed this issue. A two-phase pilot study with anxiety as the target emotion state was conducted in this article. In phase I, the motor performances and the physiological responses to the stroke subject's anxiety with high, medium, and low intensities were statistically analyzed, and anxiety models with three intensities were offline developed using support vector machine-based classifiers. In phase II, anxiety-based closed-loop robot-aided training task adaptation and its impacts on patient-robot interaction engagements were explored. As a comparison, a performance-based robotic behavior adaptation was also implemented. Experimental results with 12 recruited stroke patients conducted on the Barrett WAM(TM) manipulator verified that the rehabilitation robot can implicitly recognize the anxiety intensities of the stroke survivors and the anxiety-based real-time robotic behavior adaptation shows more engagements in the human-robot interactions.
C1 [Xu, Guozheng; Gao, Xiang; Chen, Sheng; Wang, Qiang; Zhu, Bo] Nanjing Univ Posts & Telecommun, Robot Informat Sensing & Control Res Inst, Nanjing, Jiangsu, Peoples R China.
   [Pan, Lizheng] Changzhou Univ, Sch Mech Engn, Changzhou, Peoples R China.
   [Li, Jinfei] Nanjing Tongren Hosp, Dept Rehabil Med, Nanjing, Jiangsu, Peoples R China.
RP Xu, GZ (reprint author), Nanjing Univ Posts & Telecommun, Coll Automat, Robot Informat Sensing & Control Res Inst, 9 Wenyuan Rd, Nanjing 210023, Jiangsu, Peoples R China.
EM xu_gz@hotmail.com
FU National Natural Science Foundation of China [61305095, 61673114,
   61603195, 61773078]; Key Research and Development Program of Jiangsu
   Province [BE2015701]; Natural Science Foundation of Jiangsu Province of
   China [BK20141426, BK20140878, BK20170898]; Qing Lan Project of Jiangsu
   Province of China [QL00516014]; Informatization Project of Jiangsu
   Provincial Commission of Health and Family Planning [X201603]; Jiangsu
   Overseas Research and Training Program for University Prominent Young
   and Middle-aged Teachers and Presidents
FX The author(s) disclosed receipt of the following financial support for
   the research, authorship, and/or publication of this article: This work
   was jointly supported by the National Natural Science Foundation of
   China (61305095, 61673114, 61603195, and 61773078), the Key Research and
   Development Program of Jiangsu Province (BE2015701), the Natural Science
   Foundation of Jiangsu Province of China (BK20141426, BK20140878, and
   BK20170898), the Qing Lan Project of Jiangsu Province of China
   (QL00516014), the Informatization Project of Jiangsu Provincial
   Commission of Health and Family Planning (X201603) and the Jiangsu
   Overseas Research and Training Program for University Prominent Young
   and Middle-aged Teachers and Presidents.
CR Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555
   Cai H, 2011, INT J HUM-COMPUT ST, V69, P571, DOI 10.1016/j.ijhcs.2011.05.003
   Chanel G, 2011, IEEE T SYST MAN CY A, V41, P1052, DOI 10.1109/TSMCA.2011.2116000
   Chang JJ, 2007, ARCH PHYS MED REHAB, V88, P1332, DOI 10.1016/j.apmi-.2007.07.016
   Cui CK, 2017, IEEE T BIOMED CIRC S, V11, P889, DOI 10.1109/TBCAS.2017.2699189
   Duschau-Wicke A, 2010, IEEE T NEUR SYS REH, V18, P38, DOI 10.1109/TNSRE.2009.2033061
   El Ayadi M, 2011, PATTERN RECOGN, V44, P572, DOI 10.1016/j.patcog.2010.09.020
   Hughes AM, 2010, J ELECTROMYOGR KINES, V20, P465, DOI 10.1016/j.jelekin.2009.08.001
   Hussain S, 2017, IEEE T IND ELECTRON, V64, P1675, DOI 10.1109/TIE.2016.2580123
   Khosrowabadi R, 2014, IEEE T NEUR NET LEAR, V25, P609, DOI 10.1109/TNNLS.2013.2280271
   Kim J, 2008, IEEE T PATTERN ANAL, V30, P2067, DOI 10.1109/TPAMI.2008.26
   Kleinsmith A, 2013, IEEE T AFFECT COMPUT, V4, P15, DOI 10.1109/T-AFFC.2012.16
   Koelstra S, 2012, IEEE T AFFECT COMPUT, V3, P18, DOI 10.1109/T-AFFC.2011.15
   Kreibig SD, 2010, BIOL PSYCHOL, V84, P394, DOI 10.1016/j.biopsycho.2010.03.010
   Kuriakose S, 2015, IEEE T NEUR SYS REH, V23, P665, DOI 10.1109/TNSRE.2015.2393891
   Lenzi T, 2012, IEEE T BIO-MED ENG, V59, P2180, DOI 10.1109/TBME.2012.2198821
   Liu CC, 2008, IEEE T ROBOT, V24, P883, DOI 10.1109/TRO.2008.2001362
   Liu CC, 2009, INT J HUM-COMPUT INT, V25, P506, DOI 10.1080/10447310902963944
   Lohmann S, 2011, DISABIL REHABIL, V33, P2311, DOI 10.3109/09638288.2011.570410
   Mazzoleni S, 2014, COMPUT METH PROG BIO, V116, P116, DOI 10.1016/j.cmpb.2013.12.017
   Shirzad N, 2016, J MOTOR BEHAV, V48, P31, DOI 10.1080/00222895.2015.1035430
   Soleymani M, 2016, IEEE T AFFECT COMPUT, V7, P17, DOI 10.1109/TAFFC.2015.2436926
   Vapnik V., 1998, STAT LEARNING THEORY
   Wakita K, 2013, IEEE-ASME T MECH, V18, P285, DOI 10.1109/TMECH.2011.2169980
   Xu GZ, 2017, INT J ADV ROBOT SYST, V14, DOI 10.1177/1729881417736670
   Xu GZ, 2014, ROBOTICA, V32, P1081, DOI 10.1017/S0263574713001264
   Xu GZ, 2011, ADV ROBOTICS, V25, P229, DOI 10.1163/016918610X538561
NR 27
TC 0
Z9 0
U1 3
U2 3
PU SAGE PUBLICATIONS INC
PI THOUSAND OAKS
PA 2455 TELLER RD, THOUSAND OAKS, CA 91320 USA
SN 1729-8814
J9 INT J ADV ROBOT SYST
JI Int. J. Adv. Robot. Syst.
PD NOV 5
PY 2018
VL 15
IS 6
AR 1729881418806433
DI 10.1177/1729881418806433
PG 18
WC Robotics
SC Robotics
GA HA2RH
UT WOS:000450087900001
OA DOAJ Gold
DA 2019-02-18
ER

PT J
AU Gonzalez, E
   Cheein, FAA
AF Gonzalez, Eduardo
   Auat Cheein, Fernando A.
TI Preliminary Results on Reducing the Workload of Assistive Vehicle Users:
   A Collaborative Driving Approach
SO INTERNATIONAL JOURNAL OF SOCIAL ROBOTICS
LA English
DT Article
DE Rehabilitation robotics; Human-robot interaction; Workload assessment
ID MENTAL WORKLOAD; WHEELCHAIR
AB Nowadays, physically impaired people still struggle with daily tasks when using mobility aid devices, whether for crossing doors, parking or manoeuvring in their homes. In this context, assistive robotics can offer solutions to those problems, thus increasing the users' quality of life. However, studies must be performed to determine the best architecture for human-robot interaction. In this work, we propose a collaborative navigation strategy for improving users' skills for driving assistive vehicles. We present four navigation modes: manual, assisted manual, autonomous and assisted autonomous. In particular in the two assisted modes, the system is able to predict the user's motion intentions, reducing his/her workload. The system was validated in a real world environment with a population of twenty volunteers. Objective and subjective metrics were used to asses the system's performance and usability, with special consideration to human factors. Results show that the system aids users to perform navigation tasks in a clear and compliant manner using a robotic assistive vehicle, while decreasing their perceived workload by 15% for the assisted manual, 41% for the autonomous and 40% for the assisted autonomous, when compared to the manual mode. Additionally, it is shown that if autonomous navigation sets a lower bound for user workload, the system approximates this bound while improving performance.
C1 [Gonzalez, Eduardo; Auat Cheein, Fernando A.] Univ Tecn Federico Santa Maria, Dept Elect Engn, Valparaiso, Chile.
RP Cheein, FAA (reprint author), Univ Tecn Federico Santa Maria, Dept Elect Engn, Valparaiso, Chile.
EM fernando.auat@usm.cl
RI publicaciones, AC3E/S-4625-2017; Auat Cheein, Fernando/H-7817-2012
OI Auat Cheein, Fernando/0000-0002-6347-7696
CR Akce A, 2013, IEEE T NEUR SYS REH, V21, P306, DOI 10.1109/TNSRE.2012.2233757
   Cheein FA, 2014, J FIELD ROBOT, V31, P861, DOI 10.1002/rob.21492
   Bastos TF, 2014, IEEE T NEUR SYS REH, V22, P567, DOI 10.1109/TNSRE.2013.2265237
   Bruemmer DJ, 2005, IEEE T SYST MAN CY A, V35, P494, DOI 10.1109/TSMCA.2005.850599
   Burke JL, 2004, IEEE T SYST MAN CY C, V34, P103, DOI 10.1109/TSMCC.2004.826287
   Carlson T, 2012, IEEE T SYST MAN CY B, V42, P876, DOI 10.1109/TSMCB.2011.2181833
   Census Bureau U S, 2014, AM DISABILITIES 2010
   Choset H., 2005, PRINCIPLES ROBOT MOT
   Cooper RA, 2006, IEEE T NEUR SYS REH, V14, P438, DOI 10.1109/TNSRE.2006.888382
   Evans S, 2007, DISABIL REHABIL, V29, P1281, DOI 10.1080/09638280600964406
   Fox D, 1997, IEEE ROBOT AUTOM MAG, V4, P23, DOI 10.1109/100.580977
   Galindo C, 2006, IEEE T SYST MAN CY B, V36, P1053, DOI 10.1109/TSMCB.2006.874131
   Hwang JY, 2003, IEEE T SYST MAN CY A, V33, P121, DOI 10.1109/TSMCA.2003.812599
   Katsura S, 2004, IEEE T IND ELECTRON, V51, P221, DOI 10.1109/TIE.2003.821890
   Kaupp T, 2010, ROBOT AUTON SYST, V58, P444, DOI 10.1016/j.robot.2010.02.003
   Leishman F, 2014, IEEE T HUM-MACH SYST, V44, P66, DOI 10.1109/TSMC.2013.2287792
   Luximon A, 2001, ERGONOMICS, V44, P229, DOI 10.1080/00140130010000901
   MacKenzie I. Scott, 2013, HUMAN COMPUTER INTER, P233
   Mars F, 2014, IEEE T HAPTICS, V7, P324, DOI 10.1109/TOH.2013.2295095
   Meshkati N, 1989, EVALUATION HUMAN WOR, P606
   Murphy RR, 2013, ACMIEEE INT CONF HUM, P197, DOI 10.1109/HRI.2013.6483569
   Nieto J, 2006, SPRINGER TRAC ADV RO, V25, P167
   Parikh SP, 2007, IEEE INTELL SYST, V22, P33, DOI 10.1109/MIS.2007.36
   Pauzie A, 2008, IET INTELL TRANSP SY, V2, P315, DOI 10.1049/iet-its:20080023
   Perrin X, 2010, ROBOT AUTON SYST, V58, P1246, DOI 10.1016/j.robot.2010.05.010
   Quinlan S., 1993, Proceedings IEEE International Conference on Robotics and Automation (Cat. No.93CH3247-4), P802, DOI 10.1109/ROBOT.1993.291936
   Ray DN, 2009, 14 NAT C MACH MECH, P173
   Reid GB, 1988, ADV PSYCHOL, V52, P185, DOI DOI 10.1016/S0166-4115(08)62387-0
   Rubio S, 2004, APPL PSYCHOL-INT REV, V53, P61, DOI 10.1111/j.1464-0597.2004.00161.x
   Simpson RC, 2005, J REHABIL RES DEV, V42, P423, DOI 10.1682/JRRD.2004.08.0101
   Steinfeld A., 2006, 1st Annual Conference on Human-Robot Interaction, P33
   Tahboub KA, 2006, J INTELL ROBOT SYST, V45, P31, DOI 10.1007/s10846-005-9018-0
   Tahboub KA, 2001, J INTELL ROBOT SYST, V32, P445, DOI 10.1023/A:1014295529170
   Tsui KM, 2009, PERFORMANCE EVALUATION AND BENCHMARKING OF INTELLIGENT SYSTEMS, P41, DOI 10.1007/978-1-4419-0492-8_3
   Ulrich I, 1998, IEEE INT CONF ROBOT, P1572, DOI 10.1109/ROBOT.1998.677362
   Urbano M, 2011, INTERNAL REPORT, P1
   Yanco HA, 2004, HUM-COMPUT INTERACT, V19, P117, DOI 10.1207/s15327051hci1901&2_6
   Zeng Q, 2008, IEEE T NEUR SYS REH, V16, P161, DOI 10.1109/TNSRE.2008.917288
NR 38
TC 1
Z9 1
U1 3
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1875-4791
EI 1875-4805
J9 INT J SOC ROBOT
JI Int. J. Soc. Robot.
PD NOV
PY 2018
VL 10
IS 5
BP 555
EP 568
DI 10.1007/s12369-018-0465-8
PG 14
WC Robotics
SC Robotics
GA HC3AM
UT WOS:000451673100002
DA 2019-02-18
ER

PT J
AU Rosenthal-von der Putten, AM
   Kramer, NC
   Herrmann, J
AF Puetten, Astrid M. Rosenthal-von der
   Kraemer, Nicole C.
   Herrmann, Jonathan
TI The Effects of Humanlike and Robot-Specific Affective Nonverbal Behavior
   on Perception, Emotion, and Behavior
SO INTERNATIONAL JOURNAL OF SOCIAL ROBOTICS
LA English
DT Article
DE Humanoid robot; Human-robot interaction; Experimental study; Affective
   nonverbal behavior; Self-disclosure; Emotional state
ID FACIAL EXPRESSION; AGENTS; COLOR; EMPATHY
AB Research demonstrated that humans are able to interpret humanlike (affective) nonverbal behavior (HNB) in artificial entities (e.g. Beck et al., in: Proceedings of the 19th IEEE international symposium on robot and human interactive communication, IEEE Press, Piscataway, 2010. 10.1109/ROMAN.2010.5598649; Bente et al. in J Nonverbal Behav 25: 151-166, 2001; Mumm and Mutlu, in: Proceedings of the 6th international conference on human-robot interaction, HRI. ACM Press, New York, 2011. 10.1145/1957656.1957786). However, some robots lack the possibility to produce HNB. Using robot-specific nonverbal behavior (RNB) such as different eye colors to convey emotional meaning might be a fruitful mechanism to enhance HRI experiences, but it is unclear whether RNB is as effective as HNB. We present a review on affective nonverbal behaviors in robots and an experimental study. We experimentally tested the influence of HNB and RNB (colored LEDs) on users' perception of the robot (e.g. likeability, animacy), their emotional experience, and self-disclosure. In a between-subjects design, users interacted with either (a) a robot displaying no nonverbal behavior, (b) a robot displaying affective RNB, (c) a robot displaying affective HNB or (d) a robot displaying affective HNB and RNB. Results show that HNB, but not RNB, has a significant effect on the perceived animacy of the robot, participants' emotional state, and self-disclosure. However, RNB still slightly influenced participants' perception, emotion, and behavior: Planned contrasts revealed having any type of nonverbal behavior significantly increased perceived animacy, positive affect, and self-disclosure. Moreover, observed linear trends indicate that the effects increased with the addition of nonverbal behaviors (control< RNB< HNB). In combination, our results suggest that HNB is more effective in transporting the robot's communicative message than RNB.
C1 [Puetten, Astrid M. Rosenthal-von der] Rhein Westfal TH Aachen, Individual & Technol, Theaterpl 14, D-52062 Aachen, Germany.
   [Puetten, Astrid M. Rosenthal-von der; Herrmann, Jonathan] Univ Duisburg Essen, Forsthausweg 2, D-47048 Duisburg, Germany.
   [Kraemer, Nicole C.] Univ Duisburg Essen, Social Psychol Media & Commun, Duisburg, Germany.
RP Rosenthal-von der Putten, AM (reprint author), Rhein Westfal TH Aachen, Individual & Technol, Theaterpl 14, D-52062 Aachen, Germany.; Rosenthal-von der Putten, AM (reprint author), Univ Duisburg Essen, Forsthausweg 2, D-47048 Duisburg, Germany.
EM a.rosenthalvdpuetten@uni-due.de; nicole.kraemer@uni-due.de;
   jonathan.herrmann@stud.uni-due.de
CR Banse R, 1996, J PERS SOC PSYCHOL, V70, P614, DOI 10.1037/0022-3514.70.3.614
   Bartneck C, 2009, INT J SOC ROBOT, V1, P71, DOI 10.1007/s12369-008-0001-3
   Beck A, 2013, INT J SOC ROBOT, V5, P325, DOI 10.1007/s12369-013-0193-z
   Beck A, 2010, 2010 IEEE RO-MAN, P464, DOI 10.1109/ROMAN.2010.5598649
   Becker-Asano C., 2011, 2011 IEEE WORKSH AFF, P22, DOI DOI 10.1109/WACI.2011.5953147
   Bente G, 2001, J NONVERBAL BEHAV, V25, P151, DOI 10.1023/A:1010690525717
   Bente G., 2003, SPRACHPRODUKTION ENZ, P219
   Breazeal C, 2005, 2005 IEEE/RSJ International Conference on Intelligent Robots and Systems, Vols 1-4, P383, DOI 10.1109/IROS.2005.1545011
   Burgoon J., 2011, SAGE HDB INTERPERSON, P239
   Burgoon JK, 2003, LEA COMMUN SER, P179
   Cicchetti D., 1994, PSYCHOL ASSESSMENTS, V6, P284, DOI [10.1037/1040-3590.6.4.284, DOI 10.1037/1040-3590.6.4.284]
   Collins EC, 2015, LECT NOTES ARTIF INT, V9222, P243, DOI 10.1007/978-3-319-22979-9_25
   Dael N, 2012, EMOTION, V12, P1085, DOI 10.1037/a0025737
   EKMAN P, 1993, AM PSYCHOL, V48, P384, DOI 10.1037/0003-066X.48.4.384
   Embgen S., 2012, 2012 RO-MAN: The 21st IEEE International Symposium on Robot and Human Interactive Communication, P1019, DOI 10.1109/ROMAN.2012.6343883
   Haring M., 2011, 2011 RO-MAN: The 20th IEEE International Symposium on Robot and Human Interactive Communication, P204, DOI 10.1109/ROMAN.2011.6005263
   Hurlbert AC, 2007, CURR BIOL, V17, pR623, DOI 10.1016/j.cub.2007.06.022
   Johnson DO, 2013, INT J SOC ROBOT, V5, P503, DOI 10.1007/s12369-013-0211-1
   Kang SH, 2010, COMPUT ANIMAT VIRT W, V21, P473, DOI 10.1002/cav.345
   Kishi T, 2010, P IEEE INT C ROB AUT, P1965
   Kramer N, 2013, INT J HUM-COMPUT ST, V71, P335, DOI 10.1016/j.ijhcs.2012.09.006
   Leite I, 2008, P 7 INT JOINT C AUT, P1229
   Leite I, 2010, LECT NOTES COMPUTER, P215
   Li J, 2011, INT J SOC ROBOT, V3, P125, DOI 10.1007/s12369-010-0071-x
   Manav B, 2007, COLOR RES APPL, V32, P144, DOI 10.1002/col.20294
   Manstead ASR, 1999, SOCIAL CONTEXT NONVE, P287
   McGraw KO, 1996, PSYCHOL METHODS, V1, P30, DOI 10.1037/1082-989X.1.1.30
   Mumm J, 2011, ACMIEEE INT CONF HUM, P331, DOI 10.1145/1957656.1957786
   Mutlu B, 2009, P 4 ACM IEEE INT C H, P61, DOI [10. 1145/1514095. 1514109, DOI 10.1145/1514095.1514109]
   Mutlu B, 2009, P 4 ACM IEEE INT C H, DOI [10. 1145/1514095. 1514110, DOI 10.1145/1514095.1514110]
   Nass C, 2000, J SOC ISSUES, V56, P81, DOI 10.1111/0022-4537.00153
   Nomura T, 2007, P 16 IEEE INT C ROB, P372, DOI DOI 10.1109/R0MAN.2006.314462
   Nomura T, 2006, INTERACT STUD, V7, P437, DOI 10.1075/is.7.3.14nom
   Pereira A, 2011, L N INST COMP SCI SO, V59, P130
   Press C, 2011, NEUROSCI BIOBEHAV R, V35, P1410, DOI 10.1016/j.neubiorev.2011.03.004
   Rosenthal-von der Putten AM, 2014, COMPUT HUM BEHAV, V33, P201, DOI 10.1016/j.chb.2014.01.004
   Rosenthal-von der Putten AM, 2013, INT J SOC ROBOT, V5, P17, DOI 10.1007/s12369-012-0173-8
   Salem Maha, 2011, Social Robotics. Proceedings Third International Conference (ICSR 2011), P31, DOI 10.1007/978-3-642-25504-5_4
   Scheutz M., 2006, P 1 ACM INT C HUM RO, P226, DOI [DOI 10.1145/1121241.1121281, 10.1145/1121241.1121281]
   Suzuki Y, 2015, SCI REP-UK, V5, DOI 10.1038/srep15924
   Terada K., 2012, 2012 RO-MAN: The 21st IEEE International Symposium on Robot and Human Interactive Communication, P314, DOI 10.1109/ROMAN.2012.6343772
   Tsai Jason, 2012, Intelligent Virtual Agents. Proceedings 12th International Conference, IVA 2012, P81, DOI 10.1007/978-3-642-33197-8_8
   VALDEZ P, 1994, J EXP PSYCHOL GEN, V123, P394, DOI 10.1037/0096-3445.123.4.394
   von der Piitten Astrid M., 2011, Intelligent Virtual Agents. Proceedings 11th International Conference, IVA 2011, P183, DOI 10.1007/978-3-642-23974-8_20
   von der Putten AM, 2010, COMPUT HUM BEHAV, V26, P1641, DOI 10.1016/j.chb.2010.06.012
   WALLBOTT HG, 1988, BRIT J SOC PSYCHOL, V27, P357, DOI 10.1111/j.2044-8309.1988.tb00837.x
   WATSON D, 1988, J PERS SOC PSYCHOL, V54, P1063, DOI 10.1037//0022-3514.54.6.1063
   Wu YX, 2014, IEEE T VIS COMPUT GR, V20, P626, DOI 10.1109/TVCG.2014.19
   Xu J, 2014, P 2014 INT C AUT AG, P973
   Zatsiorsky VM, 2012, BIOMECHANICS SKELETA
   Zecca Massimiliano, 2008, 2008 8th IEEE-RAS International Conference on Humanoid Robots (Humanoids 2008), P487, DOI 10.1109/ICHR.2008.4755969
NR 51
TC 1
Z9 1
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1875-4791
EI 1875-4805
J9 INT J SOC ROBOT
JI Int. J. Soc. Robot.
PD NOV
PY 2018
VL 10
IS 5
BP 569
EP 582
DI 10.1007/s12369-018-0466-7
PG 14
WC Robotics
SC Robotics
GA HC3AM
UT WOS:000451673100003
DA 2019-02-18
ER

PT J
AU David, DO
   Costescu, CA
   Matu, S
   Szentagotai, A
   Dobrean, A
AF David, Daniel O.
   Costescu, Cristina A.
   Matu, Silviu
   Szentagotai, Aurora
   Dobrean, Anca
TI Developing Joint Attention for Children with Autism in Robot-Enhanced
   Therapy
SO INTERNATIONAL JOURNAL OF SOCIAL ROBOTICS
LA English
DT Article
DE Joint-attention; Robot-enhanced therapy; Autism spectrum disorder;
   Cognitive-behavioral therapy
ID SPECTRUM; IMITATION; BEHAVIOR
AB Social difficulties is a core symptom of autism spectrum disorder (ASD). One of the main psychological factors supposed to underlie these difficulties is the lack or low levels of joint attention (JA) with the interaction partners. The use of a social robot in ASD interventions has received a lot of attention in the last years. The main objective of this research is to investigate if the JA performance of ASD children is dependent on the social cues that the robot uses in the therapy sessions. Three different types of social cues are adopted: gaze orientation, pointing and vocal instruction. Furthermore, our study aims also to investigate if the robot-enhanced treatment produces similar patterns in comparison with a standard human treatment. For testing our hypothesis, we have used a single case design involving five children with ASD who received 20 intervention sessions. The results pointed to a very consistent pattern across all types of sessions: using more cues for prompting JA increases the performance of the children. These findings emphasize the importance of using more cues, such as pointing, for increasing engagement and performance engagement in a child-robot interaction session.
C1 [David, Daniel O.; Costescu, Cristina A.; Matu, Silviu; Szentagotai, Aurora; Dobrean, Anca] Babes Bolyai Univ, Dept Clin Psychol & Psychotherapy, 37 Republ St,AVALON Bldg, Cluj Napoca 400015, Romania.
   [David, Daniel O.] Icahn Sch Med Mt Sinai, Dept Oncol Sci, New York, NY 10029 USA.
RP Costescu, CA (reprint author), Babes Bolyai Univ, Dept Clin Psychol & Psychotherapy, 37 Republ St,AVALON Bldg, Cluj Napoca 400015, Romania.
EM danieldavid@psychology.ro; christina.costescu@gmail.com;
   silviu.matu@ubbcluj.ro; auraszentagotai@psychology.ro;
   ancadobrean@psychology.ro
FU European Commission through the 7th Framework Programme Project
   "Development of Robot-Enhanced therapy for children with AutisM spectrum
   disorders" (DREAM) [611391]
FX This study was funded by European Commission through the 7th Framework
   Programme Project "Development of Robot-Enhanced therapy for children
   with AutisM spectrum disorders" (DREAM; http://www.dream2020.eu), Grant
   Agreement No. 611391.
CR American Psychiatric Association, 2013, DIAGN STAT MAN MENT
   Anzalone SM, 2015, INT J SOC ROBOT, V7, P465, DOI 10.1007/s12369-015-0298-7
   Anzalone SM, 2014, RES AUTISM SPECT DIS, V8, P814, DOI 10.1016/j.rasd.2014.03.002
   BARLOW DH, 1979, J APPL BEHAV ANAL, V12, P199, DOI 10.1901/jaba.1979.12-199
   Bekele E, 2014, AUTISM, V18, P598, DOI 10.1177/1362361313479454
   Boucenna S, 2014, COGN COMPUT, V6, P722, DOI 10.1007/s12559-014-9276-x
   Boucenna S, 2014, IEEE T AUTON MENT DE, V6, P213, DOI 10.1109/TAMD.2014.2319861
   Centers for Disease Control and Prevention, AUTISM SPECTRUM DISO
   Cooper J. O., 2007, APPL BEHAV ANAL
   Damm Oliver, 2013, 2013 IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN), P368, DOI 10.1109/ROMAN.2013.6628501
   David D, 2010, ADAPTATION AUTISM DI
   Dawson G, 2010, PEDIATRICS, V125, pE17, DOI 10.1542/peds.2009-0958
   Gotham K, 2009, J AUTISM DEV DISORD, V39, P693, DOI 10.1007/s10803-008-0674-3
   Gouaillier D., 2009, 2009 IEEE INT C ROB, P769, DOI DOI 10.1109/ROBOT.2009.5152516
   Ingersoll B, 2008, INFANT YOUNG CHILD, V21, P107, DOI 10.1097/01.IYC.0000314482.24087.14
   Jones W, 2008, ARCH GEN PSYCHIAT, V65, P946, DOI 10.1001/archpsyc.65.8.946
   Kasari C, 2010, J AUTISM DEV DISORD, V40, P1045, DOI 10.1007/s10803-010-0955-5
   Kazdin AE, 1982, NEW DIRECTIONS METHO
   Klin A, 2009, NATURE, V459, P257, DOI 10.1038/nature07868
   Kozima H, 2007, PROG BRAIN RES, V164, P385, DOI 10.1016/S0079-6123(07)64021-7
   Lausberg H, 2009, BEHAV RES METHODS, V41, P841, DOI 10.3758/BRM.41.3.841
   Lord C, 2000, J AUTISM DEV DISORD, V30, P205, DOI 10.1023/A:1005592401947
   LOVAAS OI, 1967, BEHAV RES THER, V5, P171, DOI 10.1016/0005-7967(67)90032-0
   Pennisi P, 2016, AUTISM RES, V9, P165, DOI 10.1002/aur.1527
   Robins B, 2004, DESIGNING A MORE INCLUSIVE WORLD, P225
   Robins B., 2009, 2 INT C ADV COMP HUM, P205, DOI DOI 10.1109/ACHI.2009.32
   Robins B, 2004, INTERACT STUD, V5, P161, DOI 10.1075/is.5.2.02rob
   Rogers SJ, 2009, PLAY ENGAGEMENT EARL
   Scassellati B, 2012, ANNU REV BIOMED ENG, V14, P275, DOI 10.1146/annurev-bioeng-071811-150036
   Tellegen PJ, 1998, SNIJDERS OOMEN NIET
   Warren ZE, 2015, J AUTISM DEV DISORD, V45, P3726, DOI 10.1007/s10803-013-1918-4
NR 31
TC 1
Z9 1
U1 6
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1875-4791
EI 1875-4805
J9 INT J SOC ROBOT
JI Int. J. Soc. Robot.
PD NOV
PY 2018
VL 10
IS 5
BP 595
EP 605
DI 10.1007/s12369-017-0457-0
PG 11
WC Robotics
SC Robotics
GA HC3AM
UT WOS:000451673100005
DA 2019-02-18
ER

PT J
AU Wilson, JR
   Lee, NY
   Saechao, A
   Tickle-Degnen, L
   Scheutz, M
AF Wilson, Jason R.
   Lee, Nah Young
   Saechao, Annie
   Tickle-Degnen, Linda
   Scheutz, Matthias
TI Supporting Human Autonomy in a Robot-Assisted Medication Sorting Task
SO INTERNATIONAL JOURNAL OF SOCIAL ROBOTICS
LA English
DT Article
DE Socially assistive robot; Medication sorting; Medication adherence;
   Autonomy; Occupational therapy
ID PHYSICALLY PRESENT; ADHERENCE; CARE; THERAPY; PERSISTENCE; MANAGEMENT;
   BENEFITS; IMPACT
AB Medication management is a significant challenge for older adults, and the resultant drug-related problems are linked with hospitalizations and increased need for nursing homes. In this work, we explored the role of a socially assistive robot for one aspect of medication management: sorting. Specifically, we proposed a human-centric approach towards the design of a robot assisting in a medication sorting task. The approach is based on the analyses of occupational therapists who are trained in evaluating and assisting older adults in important self-care skills and emphasizes the role of autonomy on the part of the person performing a medication sorting task. We developed and evaluated two robot prototypes that assist a person in a medication sorting task. In both prototypes, evaluated by students at an American university, we found that subjects voluntarily greeting the robot experienced the emotion of the interaction differently from non-greeters. Greeters of the physical robot gave a lower emotional rating of the interaction, whereas greeters of the virtual robot found the emotion of the experience to be better than the non-greeters.
C1 [Wilson, Jason R.; Lee, Nah Young] Tufts Univ, Medford, MA 02155 USA.
   [Saechao, Annie; Tickle-Degnen, Linda] Tufts Univ, Dept Occupat Therapy, Medford, MA 02155 USA.
   [Scheutz, Matthias] Tufts Univ, Cognit & Comp Sci, Dept Comp Sci, Medford, MA 02155 USA.
   [Wilson, Jason R.] Northwestern Univ, Dept Elect Engn & Comp Sci, Evanston, IL 60208 USA.
RP Wilson, JR (reprint author), Tufts Univ, Medford, MA 02155 USA.; Wilson, JR (reprint author), Northwestern Univ, Dept Elect Engn & Comp Sci, Evanston, IL 60208 USA.
EM wilson@cs.tufts.edu
FU NSF [IIS-1316809]
FX This work was funded by NSF (Grant No. IIS-1316809).
CR [Anonymous], 2014, AM J OCCUPATIONAL TH
   Association AOT, 2015, AM J OCCUP THER, V69, pS17
   Bainbridge JL, 2009, DRUG AGING, V26, P145, DOI 10.2165/0002512-200926020-00006
   Bainbridge WA, 2011, INT J SOC ROBOT, V3, P41, DOI 10.1007/s12369-010-0082-7
   Banks MR, 2008, J AM MED DIR ASSOC, V9, P173, DOI 10.1016/j.jamda.2007.11.007
   Baum E, 2006, US patent, Patent No. [7,100,793, 7100793]
   Briggs P, 2015, ACMIEEE INT CONF HUM, P327, DOI 10.1145/2696454.2696476
   Broekens Joost, 2009, Gerontechnology, V8, P94
   Burnier M, 2006, AM J HYPERTENS, V19, P1190, DOI 10.1016/j.amjhyper.2006.04.006
   Carlson MC, 2005, J GERONTOL A-BIOL, V60, P217, DOI 10.1093/gerona/60.2.217
   Chan M, 2001, INTERN MED J, V31, P199, DOI 10.1046/j.1445-5994.2001.00044.x
   Datta C, 2011, END USER PROGRAMMING
   Dayer L, 2013, J AM PHARM ASSOC, V53, P172, DOI 10.1331/JAPhA.2013.12202
   Doggrell SA, 2010, DRUG AGING, V27, P239, DOI 10.2165/11532870-000000000-00000
   Ernst F R, 2001, J Am Pharm Assoc (Wash), V41, P192
   Feil-Seifer D, 2005, INT C REHAB ROBOT, P465
   Feil-Seifer D, 2011, IEEE ROBOT AUTOM MAG, V18, P24, DOI [10.1109/MRA.2010.940149, 10.1109/MRA.2010.940150]
   Graf B, 2004, AUTON ROBOT, V16, P193, DOI 10.1023/B:AURO.0000016865.35796.e9
   Hayes TL, 2009, J AGING HEALTH, V21, P567, DOI 10.1177/0898264309332836
   Haynes RB, 2008, COCHRANE DB SYST REV, DOI 10.1002/14651858.CD000011.pub3
   HEBESBERGER D, 2016, ACMIEEE INT CONF HUM, P27
   Heerink M, 2006, ASSIST TECHNOL RES S, V19, P31
   Hemmesch AR, 2011, STIGMATIZING EFFECTS
   JOHNSON JA, 1995, ARCH INTERN MED, V155, P1949, DOI 10.1001/archinte.155.18.1949
   Kanamori M, 2002, JAPANESE J GERIASTRI, V39, P214, DOI DOI 10.3143/geriatrics.39.214
   Kidd C. D., 2004, 2004 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) (IEEE Cat. No.04CH37566), P3559
   Lamere P., 2003, IEEE INT C AC SPEECH, V1, P2
   Lewis A, 1997, REMINGTON REPORT, V5, P14
   Li J, 2015, INT J HUM-COMPUT ST, V77, P23, DOI 10.1016/j.ijhcs.2015.01.001
   MacLaughlin EJ, 2005, DRUG AGING, V22, P231, DOI 10.2165/00002512-200522030-00005
   Manning KJ, 2012, CLIN NEUROPSYCHOL, V26, P45, DOI 10.1080/13854046.2011.639312
   Marcum ZA, 2013, JAMA-J AM MED ASSOC, V309, P2105, DOI 10.1001/jama.2013.4638
   Mataric MJ, 2007, J NEUROENG REHABIL, V4, DOI 10.1186/1743-0003-4-5
   Muir BM, 1996, ERGONOMICS, V39, P429, DOI 10.1080/00140139608964474
   Osterberg L, 2005, NEW ENGL J MED, V353, P487, DOI 10.1056/NEJMra050100
   Pollack M. E., 2002, AAAI WORKSH AUT ELD, V2002, P85
   Prakash A, 2013, ACMIEEE INT CONF HUM, P283, DOI 10.1109/HRI.2013.6483600
   Rogers J, 1994, PERFORMANCE ASSESSME
   Sahai A, 1999, US patent, Patent No. [5,971,594, 5971594]
   Schell BA, 2013, WILLARD SPACKMANS OC
   Scheutz M, 2007, AUTON ROBOT, V22, P411, DOI 10.1007/s10514-006-9018-3
   Smarr Cory-Ann, 2012, Proc Hum Factors Ergon Soc Annu Meet, V56, P153
   SMITH CA, 1985, J PERS SOC PSYCHOL, V48, P813, DOI 10.1037/0022-3514.48.4.813
   Sokol MC, 2005, MED CARE, V43, P521, DOI 10.1097/01.mlr.0000163641.86870.af
   Stilley CS, 2010, HEALTH PSYCHOL, V29, P50, DOI 10.1037/a0016940
   Tamura T, 2004, J GERONTOL A-BIOL, V59, P83
   Tapus A, 2009, VIRT REH INT C 2009
   Wada K, 2002, 2002 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS I-IV, PROCEEDINGS, P1416, DOI 10.1109/ROBOT.2002.1014742
   Wada K, 2006, IEEE INT CONF ROBOT, P3966, DOI 10.1109/ROBOT.2006.1642310
   Wada K, 2007, IEEE T ROBOT, V23, P972, DOI 10.1109/TRO.2007.906261
   Wade RL, 2016, VALUE HEALTH, V19, pA306, DOI 10.1016/j.jval.2016.03.658
   Wainer J., 2006, IEEE P INT WORKSH RO, P117, DOI DOI 10.1109/ROMAN.2006.314404
   Warner I, 1998, HOME HLTH CARE MANAG, V10, P62, DOI [10.1177/108482239801000213, DOI 10.1177/108482239801000213]
   Wilcock W, 2014, WILLARD SPACKMANS OC, P541
NR 54
TC 0
Z9 0
U1 6
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1875-4791
EI 1875-4805
J9 INT J SOC ROBOT
JI Int. J. Soc. Robot.
PD NOV
PY 2018
VL 10
IS 5
BP 621
EP 641
DI 10.1007/s12369-017-0456-1
PG 21
WC Robotics
SC Robotics
GA HC3AM
UT WOS:000451673100007
DA 2019-02-18
ER

PT J
AU Whelan, S
   Murphy, K
   Barrett, E
   Krusche, C
   Santorelli, A
   Casey, D
AF Whelan, Sally
   Murphy, Kathy
   Barrett, Eva
   Krusche, Cheryl
   Santorelli, Adam
   Casey, Dympna
TI Factors Affecting the Acceptability of Social Robots by Older Adults
   Including People with Dementia or Cognitive Impairment: A Literature
   Review
SO INTERNATIONAL JOURNAL OF SOCIAL ROBOTICS
LA English
DT Review
DE Technology acceptability; Acceptance theories; Social robots; Dementia;
   Older adults
ID HEALTH-CARE ROBOTS; ELDERLY-PEOPLE; SEAL ROBOT; TECHNOLOGY; ENGAGEMENT;
   ATTITUDES; THERAPY
AB Social robots are being developed to support care given to older adults (OA), people with dementia (PWD) and OA with mild cognitive impairment (MCI) by facilitating their independence and well-being. The successful deployment of robots should be guided by knowledge of factors which affect acceptability. This paper critically reviews empirical studies which have explored how acceptability issues impact OA, PWD and OA with MCI. The aim is to identify the factors governing acceptability, to ascertain what is likely to improve acceptability and make recommendations for future research. A search of the literature published between 2005 and 2015 revealed a relatively small body of relevant work has been conducted focusing on the acceptability of robots by PWD or OA with MCI (n23). The findings are presented using constructs from the Almere robot acceptance model. They reveal acceptance of robots is affected by multiple interacting factors, pertaining to the individual, significant others and the wider society. Acceptability can be improved through robots using humanlike communication, being personalised in response to individual users' needs and including issues of trust and control of the robot which relates to degrees of robot adaptivity. However, most studies are of short duration, have small sample sizes and some do not involve actual robot usage or are conducted in laboratories rather than in real world contexts. Larger randomised controlled studies, conducted in the context where robots will be deployed, are needed to investigate how acceptance factors are affected when humans use robots for longer periods of time and become habituated to them.
C1 [Whelan, Sally; Murphy, Kathy; Barrett, Eva; Santorelli, Adam; Casey, Dympna] Natl Univ Ireland, Sch Nursing & Midwifery, Galway, Ireland.
   [Krusche, Cheryl] Regis Univ, Loretto Hts Sch Nursing, Denver, CO USA.
RP Whelan, S (reprint author), Natl Univ Ireland, Sch Nursing & Midwifery, Galway, Ireland.
EM s.whelan7@nuigalway.ie
OI Santorelli, Adam/0000-0002-8951-4619
FU European Union Horizons 2020-the Framework Programme for Research and
   Innovation [643808]
FX The research leading to these results has received funding from the
   European Union Horizons 2020-the Framework Programme for Research and
   Innovation (2014-2020) under Grant Agreement 643808 Project MARIO
   'Managing active and healthy aging with use of caring service robots".
CR Alaiad A, 2014, INT J MED INFORM, V83, P825, DOI [10.1016/j.ijmedinf.201.4.07.003, 10.1016/j.ijmedinf.2014.07.003]
   Alzheimers Society, 2015, WHAT IS MILD COGN IM
   Amirabdollahian F., 2013, J BEHAV ROBOTICS PAL, V4, P94
   Amirabdollahian F, 2013, C HUM SYST INTERACT, P570, DOI 10.1109/HSI.2013.6577882
   Arras K, 2005, 0605001 EPFL AUT SYS
   Bamford C, 2000, AGEING SOC, V20, P543, DOI 10.1017/S0144686X99007898
   Bartlett R, 2012, QUAL HEALTH RES, V22, P1717, DOI 10.1177/1049732312462240
   Begum M, 2013, IEEE INT C REH ROB S
   Brandon M, 2012, EFFECT ROBOT USER PE
   Broadbent E, 2009, 18 IEEE INT S ROB HU
   Campbell A., 2011, NURS RESIDENTIAL CAR, V13, P602, DOI DOI 10.12968/NREC.2011.13.12.602
   Chang W-L, 2013, IEEE ROBOTICS AUTOMA
   Cohen-Mansfield J, 2010, J NERV MENT DIS, V198, P586, DOI 10.1097/NMD.0b013e3181e9dc76
   Cohen-Mansfield J, 2009, AM J GERIAT PSYCHIAT, V17, P299, DOI 10.1097/JGP.0b013e31818f3a52
   Cowdell F, 2008, INT J OLDER PEOPLE N, V3, P29, DOI 10.1111/j.1748-3743.2007.00096.x
   Dautenhahn K, 2007, PHILOS T R SOC B, V362, P679, DOI 10.1098/rstb.2006.2004
   DAVIS FD, 1989, MANAGE SCI, V35, P982, DOI 10.1287/mnsc.35.8.982
   de Graaf MMA, 2015, COMPUT HUM BEHAV, V43, P1, DOI 10.1016/j.chb.2014.10.030
   DiSalvo C, 2002, ALL ROBOTS ARE NOT C
   Flandorfer P., 2012, INT J POPUL RES, DOI [10.1155/2012/829835, DOI 10.1155/2012/829835]
   Frennert S, 2013, LECT NOTES ARTIF INT, V8239, P8, DOI 10.1007/978-3-319-02675-6_2
   Granata C, 2013, TECHNOL HEALTH CARE, V21, P217, DOI 10.3233/THC-130718
   Gross H, 2012, IEEE INT C SYST MAN
   Heerink M., 2006, P 15 IEEE INT S ROB, P521, DOI DOI 10.1109/ROMAN.2006.314442
   Heerink M, 2008, HRI 08 AMST NETH MAR
   Heerink M, 2011, HRI 11 LAUS SWITZ MA
   Heerink M, 2013, LECT NOTES ARTIF INT, V8239, P104, DOI 10.1007/978-3-319-02675-6_11
   Heerink M, 2010, INT J SOC ROBOT, V2, P361, DOI 10.1007/s12369-010-0068-5
   Hubbard G, 2003, AGING MENT HEALTH, V7, P351, DOI 10.1080/1360786031000150685
   Kerssens C, 2015, AM J ALZHEIMERS DIS, V30, P85, DOI 10.1177/1533317514568338
   Khosla R., 2012, P 20 ACM INT C MULT, P1173
   Khosla R, 2014, IEEE INT CONF SERV, P73, DOI 10.1109/SOCA.2014.53
   Klein Barbara, 2012, Social Robotics. 4th International Conference (ICSR 2012). Proceedings, P108, DOI 10.1007/978-3-642-34103-8_11
   Lloyd V, 2006, QUAL HEALTH RES, V16, P1386, DOI 10.1177/1049732306293846
   Louie WYG, 2014, ASSIST TECHNOL, V26, P140, DOI 10.1080/10400435.2013.869703
   McColl D, 2013, IEEE ROBOT AUTOM MAG, V20, P74, DOI 10.1109/MRA.2012.2229939
   McKillop J, 2004, DEMENTIA, V3, P117, DOI DOI 10.1177/1471301204042332
   Mitzner TL, 2014, INT J SOC ROBOT, V6, P213, DOI 10.1007/s12369-013-0218-7
   Mordoch E, 2013, MATURITAS, V74, P14, DOI 10.1016/j.maturitas.2012.10.015
   Mori M, 2012, IEEE ROBOT AUTOM MAG, V19, P98, DOI 10.1109/MRA.2012.2192811
   Morris J, 1991, MDS RESIDENT ASSESSM
   Moyle W, 2013, INT PSYCHOGERIATR, V25, pS21
   Murphy K, 2015, DEMENTIA-LONDON, V14, P800, DOI 10.1177/1471301213512489
   Neven L, 2010, SOCIOL HEALTH ILL, V32, P335, DOI 10.1111/j.1467-9566.2009.01218.x
   Nomura T, 2012, 12 IEEE RAS INT C HU
   Pfadenhauer M, 2015, INT J SOC ROBOT, V7, P393, DOI 10.1007/s12369-015-0284-0
   Pino M, 2015, FRONT AGING NEUROSCI, V7, DOI 10.3389/fnagi.2015.00141
   Prince M., 2013, POLICY BRIEF HEADS G
   Robinson H, 2013, J AM MED DIR ASSOC, V14, P34, DOI 10.1016/j.jamda.2012.09.006
   Saaskilahti K, 2012, IEEE RO MAN
   Saaskilahti K, 2012, IEEE INT
   Sabanovic S, 2013, IEEE INT C REH ROB S
   Sakai Y, 2012, HRI 12 BOST MASS US
   Sakai Y, 2012, ACMIEEE INT CONF HUM, P199
   Scopelliti M., 2005, Universal Access in the Information Society, V4, P146, DOI 10.1007/s10209-005-0118-1
   Shibata T, 2012, P IEEE, V100, P2527, DOI 10.1109/JPROC.2012.2200559
   Spiekman Marleen E., 2011, Social Robotics. Proceedings Third International Conference (ICSR 2011), P226, DOI 10.1007/978-3-642-25504-5_23
   Stafford R, 2012, 4 INT C SOC ROB ICSR
   Stafford R, 2010, RO MAN INT S ROB HUM
   Stafford R, 2013, CONTRIBUTION PEOPLES
   Stafford RQ, 2014, INT J SOC ROBOT, V6, P281, DOI 10.1007/s12369-013-0224-9
   Stafford RQ, 2014, INT J SOC ROBOT, V6, P17, DOI 10.1007/s12369-013-0186-y
   Steinke Frederick, 2014, Gerontechnology, V12, P81, DOI 10.4017/gt.2013.12.2.002.00
   Sung HC, 2015, ASIA-PAC PSYCHIAT, V7, P1, DOI 10.1111/appy.12131
   Takayama L, 2011, HUMAN COMPUTER INTER, P195
   Takayanagi K, 2014, FRONT AGING NEUROSCI, V6, DOI 10.3389/fnagi.2014.00257
   Tapus A, 2009, 18 IEEE INT S ROB HU
   Torta E, 2014, J INTELL ROBOT SYST, V76, P57, DOI 10.1007/s10846-013-0019-0
   Walters ML, 2006, CONNECT SCI, V18, P429, DOI 10.1080/09540090600879513
   Wimo A, 2010, WORLD ALZHEIMER REPO
   Wu YH, 2014, CLIN INTERV AGING, V9, P801, DOI 10.2147/CIA.S56435
   Wu YH, 2011, HEALTH INFORM J, V17, P33, DOI 10.1177/1460458210380517
   Yamazaki R, 2014, INT J SOC ROBOT, V6, P429, DOI 10.1007/s12369-014-0247-x
   Young JE, 2009, INT J SOC ROBOT, V1, P95, DOI 10.1007/s12369-008-0006-y
NR 74
TC 0
Z9 0
U1 6
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1875-4791
EI 1875-4805
J9 INT J SOC ROBOT
JI Int. J. Soc. Robot.
PD NOV
PY 2018
VL 10
IS 5
BP 643
EP 668
DI 10.1007/s12369-018-0471-x
PG 26
WC Robotics
SC Robotics
GA HC3AM
UT WOS:000451673100008
DA 2019-02-18
ER

PT J
AU Castro, E
   Cecchi, F
   Salvini, P
   Valente, M
   Buselli, E
   Menichetti, L
   Calvani, A
   Dario, P
AF Castro, Emanuela
   Cecchi, Francesca
   Salvini, Pericle
   Valente, Massimiliano
   Buselli, Elisa
   Menichetti, Laura
   Calvani, Antonio
   Dario, Paolo
TI Design and Impact of a Teacher Training Course, and Attitude Change
   Concerning Educational Robotics
SO INTERNATIONAL JOURNAL OF SOCIAL ROBOTICS
LA English
DT Article
DE Educational Robotics; Training course; Pedagogy; STEM; Teacher attitude
ID ENGAGEMENT; ACHIEVEMENT; CLASSROOM
AB Current initiatives and laboratories concerning Educational Robotics (ER) are often not based on strong pedagogical backgrounds. Additionally, they are carried out by inadequately trained teachers, and are not evaluated properly in terms of effectiveness. Moreover, according to teachers, ER usability is often neglected. The main goal of the present article is to present a training course on ER (Edu.Ro.Co.), grounded in pedagogical insights, and to discuss the results of the course and teacher's opinion about ER in terms of: (i) teachers' attitudes and perceptions of using ER; (ii) the potential impact of ER on students' key competences for lifelong learning; and (iii) strengths and weaknesses of ER. These aspects were analysed by means of questionnaires specifically designed by the authors, and administered before and after the training course. A total of 339 teachers attended the training course and 254 completed the questionnaires. The article describes the methodology utilised in the realisation of the course and analyses the questionnaire's results. In particular, the number of teachers that considered themselves prepared to apply ER significantly improved after the training course. ER is considered by teachers an important tool for the improvement of students' motivation, planning skills, team working, problem solving and creativity development. Finally, the results from questionnaires indicate that teachers consider ER, a method that improves team-working abilities and motivation in the students. In contrast, the main disadvantage is the cost of the robotic kits. Based on these results, new directions for future research in ER are discussed.
C1 [Castro, Emanuela; Cecchi, Francesca; Salvini, Pericle; Valente, Massimiliano; Buselli, Elisa; Dario, Paolo] Scuola Super Sant Anna, BioRobot Inst, Viale Rinaldo Piaggio 34, I-56025 Pisa, Italy.
   [Menichetti, Laura; Calvani, Antonio] Univ Florence, Dept Educ Sci & Psychol, Via Laura 48, I-50121 Florence, Italy.
RP Cecchi, F (reprint author), Scuola Super Sant Anna, BioRobot Inst, Viale Rinaldo Piaggio 34, I-56025 Pisa, Italy.
EM francesca.cecchi@santannapisa.it
FU Tuscany Region
FX This study was partially funded by the Tuscany Region.
CR Adams A. E., 2014, ELECT J SCI ED, V18, P1
   Albirini A, 2006, COMPUT EDUC, V47, P373, DOI 10.1016/j.compedu.2004.10.013
   Alimisis D., 2013, THEMES SCI TECHNOLOG, V6, P63
   Alimisis D, 2010, P CONSTR 2010, P1
   Allen WC, 2006, ADV DEV HUM RESOUR, V8, P430, DOI 10.1177/1523422306292942
   Anderson ML, 2003, ARTIF INTELL, V149, P91, DOI 10.1016/S0004-3702(03)00054-7
   Archer L, 2013, PEDAGOG CULT SOC, V21, P171, DOI 10.1080/14681366.2012.748676
   BANDURA A, 1977, PSYCHOL REV, V84, P191, DOI 10.1037//0033-295X.84.2.191
   Barker BS, 2007, J RES TECHNOL EDUC, V39, P229, DOI 10.1080/15391523.2007.10782481
   Bogue R, 2014, IND ROBOT, V41, P487, DOI 10.1108/IR-07-2014-0364
   Bredenfeld A, 2010, P INT C SIM MOD PROG, P568
   Bruner J, 1989, NARRATIVES CRIB, P73
   Calvani A, 2015, CAROCCI FABER
   Capuzza V, 2016, G GIAPPICHELLI EDITO
   Castellano Ginevra, 2013, Artificial Intelligence in Education. Proceedings of 16th International Conference (AIED 2013): LNCS 7926, P733, DOI 10.1007/978-3-642-39112-5_100
   Chevalier M, 2016, IEEE ROBOT AUTOM MAG, V23, P16, DOI 10.1109/MRA.2016.2535080
   Datteri E, 2016, IEEE ROBOT AUTOM MAG, V23, P24, DOI 10.1109/MRA.2016.2533038
   Elkin M, 2014, J INF TECHNOL EDUC-I, V13, P153
   Fridin M, 2014, COMPUT HUM BEHAV, V33, P23, DOI 10.1016/j.chb.2013.12.016
   Gascoine L, 2017, REV EDUC-US, V5, P3, DOI 10.1002/rev3.3077
   Greenberg J, 2013, TEACHER PREP REV REV
   Greene BA, 2004, CONTEMP EDUC PSYCHOL, V29, P462, DOI 10.1016/j.cedpsych.2004.01.006
   Hattie J., 2012, VISIBLE LEARNING TEA
   Hattie JAC, 2009, VISIBLE LEARNING: A SYNTHESIS OF OVER 800 META-ANALYSES RELATING TO ACHIEVEMENT, P1
   Karahoca D, 2011, PROCEDIA COMPUT SCI, V3, DOI 10.1016/j.procs.2011.01.025
   Kay J. S., 2014, P 45 ACM TECHN S COM, P499
   Kearney C, 2011, NATL MEASURES TAKEN
   Kennedy J, 2017, INT J SOC ROBOT, V9, P109, DOI 10.1007/s12369-016-0378-3
   Kim CM, 2015, COMPUT EDUC, V91, P14, DOI 10.1016/j.compedu.2015.08.005
   Kim K.-h., 2014, ADV SCI TECHNOL LETT, V59, P105
   Kradolfer S, 2014, LECT NOTES ARTIF INT, V8755, P217, DOI 10.1007/978-3-319-11973-1_22
   Maltese AV, 2010, INT J SCI EDUC, V32, P669, DOI 10.1080/09500690902792385
   Mataric M, 2007, AAAI SPRING S SEM SC, P99
   Merrill MD, 2002, ETR&D-EDUC TECH RES, V50, P43, DOI 10.1007/BF02505024
   Mishra P, 2006, TEACH COLL REC, V108, P1017, DOI 10.1111/j.1467-9620.2006.00684.x
   Osborne J., 2008, SCI ED EUROPE CRITIC, V13
   Palogiannidi E, 2016, 10 ED LANG RES EV C
   Papert S, 1980, MINDSTORMS CHILDREN
   Papert Seymour, 1991, CONSTRUCTIONISM, P1
   Piaget J, 1973, UNDERSTAND IS INVENT
   PRAWAT RS, 1992, AM J EDUC, V100, P354, DOI 10.1086/444021
   RIEDO F, 2012, ADV ROBOTICS ITS SOC, P19
   Rusk N, 2008, J SCI EDUC TECHNOL, V17, P59, DOI 10.1007/s10956-007-9082-2
   SKINNER EA, 1993, J EDUC PSYCHOL, V85, P571, DOI 10.1037//0022-0663.85.4.571
   Tobias S., 2009, CONSTRUCTIVIST INSTR
   Benitti FBV, 2012, COMPUT EDUC, V58, P978, DOI 10.1016/j.compedu.2011.10.006
NR 46
TC 0
Z9 0
U1 4
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1875-4791
EI 1875-4805
J9 INT J SOC ROBOT
JI Int. J. Soc. Robot.
PD NOV
PY 2018
VL 10
IS 5
BP 669
EP 685
DI 10.1007/s12369-018-0475-6
PG 17
WC Robotics
SC Robotics
GA HC3AM
UT WOS:000451673100009
DA 2019-02-18
ER

PT J
AU Sandygulova, A
   O'Hare, GMP
AF Sandygulova, Anara
   O'Hare, Gregory M. P.
TI Age- and Gender-Based Differences in Children's Interactions with a
   Gender-Matching Robot
SO INTERNATIONAL JOURNAL OF SOCIAL ROBOTICS
LA English
DT Article
DE Child-robot interaction; Human-robot interaction; Social robotics;
   Adaptive strategies; Gender; Age
ID IMPACT; SIMILARITY
AB Social robots are increasingly being used to encourage social, emotional and cognitive growth in children. However, in order to establish social and bonding interactions, social robots need to be able to exhibit adaptive strategies to keep children engaged and interested. Adaptive strategies of a social robot based on children's age and gender are motivated by the comprehensive theory on gender development. Given the strong influence of gender in children's cognitive development, the experiment first examined the responses of 107 children, ages 5-12, whether synthesized voice evokes gender associations in children. The results suggest that young children (ages 5-8) are not able to successfully attribute gender to the robot in correspondence with the synthesized voice. In addition, we explicitly investigated children's preferences for the robot's gender, and the results were contrary to our expectations: young children indicated their preference for a robot with a matching gender while there was no difference in preferences for a robot's gender by older children (ages 9-12).
C1 [Sandygulova, Anara] Nazarbayev Univ, Sch Sci & Technol, 53 Kabanbay Batyr Ave, Astana, Kazakhstan.
   [O'Hare, Gregory M. P.] Univ Coll Dublin, Dept Comp Sci, Dublin 4, Ireland.
   [O'Hare, Gregory M. P.] Univ Coll Dublin, Sch Comp Sci & Informat, Dublin 4, Ireland.
RP Sandygulova, A (reprint author), Nazarbayev Univ, Sch Sci & Technol, 53 Kabanbay Batyr Ave, Astana, Kazakhstan.
EM anara.sandygulova@nu.edu.kz; gregory.ohare@ucd.ie
OI TAMBURINI, ALBERTO/0000-0002-3371-6254
FU Irish Research Council; Science Foundation Ireland [07/CE/l1147]
FX This study was funded by Irish Research Council and Science Foundation
   Ireland (07/CE/l1147).
CR Alonso-Martin F, 2013, SENSORS-BASEL, V13, P15549, DOI 10.3390/s131115549
   Auster CJ, 2012, SEX ROLES, V67, P375, DOI 10.1007/s11199-012-0177-8
   Bell A, 2007, J RES NURS, V12, P461, DOI 10.1177/17449871079616
   Belpaeme T, 2015, P ICSR 2015 WONDER W
   Belpaeme T, 2012, J HUM-ROBOT INTERACT, V1, P33, DOI 10.5898/JHRI.1.2.Belpaeme
   Belpaeme T, 2013, LECT NOTES ARTIF INT, V8239, P452, DOI 10.1007/978-3-319-02675-6_45
   Chiasson S, 2005, P ACM C HUM FACT COM, P829
   Clark C, 2010, YOUNGER VOICE DOING
   Cook J., 2003, CHILD DEV PRINCIPLES
   Crowell CR, 2009, 2009 IEEE-RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, P3735, DOI 10.1109/IROS.2009.5354204
   Egan SK, 2001, DEV PSYCHOL, V37, P451, DOI 10.1037/0012-1649.37.4.451
   Ernst A., 2009, WORKSH PERV ADV INF, P75
   Espinoza R. R., 2011, P 13 INT C MULT INT, P335
   Eyssel F, 2012, ACMIEEE INT CONF HUM, P125
   Fine C., 2010, DELUSIONS GENDER OUR
   Fink J, 2014, ACMIEEE INT CONF HUM, P439, DOI 10.1145/2559636.2559659
   Foley S, 2006, GROUP ORGAN MANAGE, V31, P420, DOI 10.1177/1059601106286884
   Fussell S. R., 2008, 2008 3rd ACM/IEEE International Conference on Human-Robot Interaction (HRI 2008), P145
   Heyman GD, 2001, SOC DEV, V10, P230, DOI 10.1111/1467-9507.00161
   Hood D, 2015, P 10 ANN ACM IEEE IN, P269
   Huston A. C., 1983, HDB CHILD PSYCHOL, V4, P387
   Johnson J., 2003, Artificial Life and Robotics, V7, P16, DOI 10.1007/s10015-003-0265-5
   Kanda T, 2004, HUM-COMPUT INTERACT, V19, P61, DOI 10.1207/s15327051hci1901&2_4
   Katibeh Z, 2013, THESIS
   Kaufman SB, 2012, PSYCHOL TODAY
   Kennedy J, 2015, ACMIEEE INT CONF HUM, P67, DOI 10.1145/2696454.2696457
   Kose-Bagci H, 2009, ADV ROBOTICS, V23, P1951, DOI 10.1163/016918609X12518783330360
   Kriz S., 2009, 2009 4th ACM/IEEE International Conference on Human-Robot Interaction (HRI), P271
   Lee KM, 2007, HUM COMMUN RES, V33, P310, DOI 10.1111/j.1468-2958.2007.00301.x
   Leite Iolanda, 2012, Social Robotics. 4th International Conference (ICSR 2012). Proceedings, P298, DOI 10.1007/978-3-642-34103-8_30
   MACCOBY EE, 1988, DEV PSYCHOL, V24, P755, DOI 10.1037//0012-1649.24.6.755
   Martin CL, 2010, ANNU REV PSYCHOL, V61, P353, DOI 10.1146/annurev.psych.093008.100511
   Mehta CM, 2009, DEV REV, V29, P201, DOI 10.1016/j.dr.2009.06.001
   Meiirbekov Serik, 2016, 2016 11th ACM/IEEE International Conference on Human-Robot Interaction (HRI), P475, DOI 10.1109/HRI.2016.7451813
   Nass C., 2005, WIRED SPEECH VOICE A
   Ozogul G, 2013, COMPUT EDUC, V67, P36, DOI 10.1016/j.compedu.2013.02.006
   Powers A, 2005, 2005 IEEE International Workshop on Robot and Human Interactive Communication (RO-MAN), P158
   POWLISHTA KK, 1994, DEV PSYCHOL, V30, P526, DOI 10.1037/0012-1649.30.4.526
   Rao A. S., 1995, ICMAS-95 Proceedings. First International Conference on Multi-Agent Systems, P312
   Reeves B., 1996, MEDIA EQUATION PEOPL
   Ruble DN, 2007, GENDER DEV
   SANDYGULOVA A, 2016, ACMIEEE INT CONF HUM, P399
   Sandygulova A, 2014, P 3 INT S NEW FRONT
   Sandygulova A, 2015, LECT NOTES ARTIF INT, V9388, P594, DOI 10.1007/978-3-319-25554-5_59
   Scheeff M, 2002, MU S ART SOC SIM ORG, V3, P173
   Schermerhorn P., 2008, 2008 3rd ACM/IEEE International Conference on Human-Robot Interaction (HRI 2008), P263
   Serbin L A, 1994, New Dir Child Dev, P7
   Siegel M, 2009, 2009 IEEE-RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, P2563, DOI 10.1109/IROS.2009.5354116
   Tamagawa R, 2011, INT J SOC ROBOT, V3, P253, DOI 10.1007/s12369-011-0100-4
   Tung FW, 2011, LECT NOTES COMPUT SC, V6764, P637, DOI 10.1007/978-3-642-21619-0_76
   Verkuyten M, 2001, INFANT CHILD DEV, V10, P203, DOI 10.1002/icd.279
   Wang Y, 2014, P GEND IT APPR SCI P
   Woods S, 2006, INTERACT COMPUT, V18, P1390, DOI 10.1016/j.intcom.2006.05.001
   YEE M, 1994, BRIT J SOC PSYCHOL, V33, P183, DOI 10.1111/j.2044-8309.1994.tb01017.x
   Zosuls KM, 2011, SEX ROLES, V64, P826, DOI 10.1007/s11199-010-9902-3
NR 55
TC 1
Z9 1
U1 4
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1875-4791
EI 1875-4805
J9 INT J SOC ROBOT
JI Int. J. Soc. Robot.
PD NOV
PY 2018
VL 10
IS 5
BP 687
EP 700
DI 10.1007/s12369-018-0472-9
PG 14
WC Robotics
SC Robotics
GA HC3AM
UT WOS:000451673100010
DA 2019-02-18
ER

PT J
AU Zlotowski, J
   Sumioka, H
   Eyssel, F
   Nishio, S
   Bartneck, C
   Ishiguro, H
AF Zlotowski, Jakub
   Sumioka, Hidenobu
   Eyssel, Friederike
   Nishio, Shuichi
   Bartneck, Christoph
   Ishiguro, Hiroshi
TI Model of Dual Anthropomorphism: The Relationship Between the Media
   Equation Effect and Implicit Anthropomorphism
SO INTERNATIONAL JOURNAL OF SOCIAL ROBOTICS
LA English
DT Article
DE Anthropomorphism; Human-robot interaction; Dual-process model;
   Humanlikeness; Media equation
ID INDIVIDUAL-DIFFERENCES; SELF-ESTEEM; COGNITION
AB Anthropomorphism, the attribution of humanlike characteristics to nonhuman entities, may be resulting from a dual process: first, a fast and intuitive (Type 1) process permits to quickly classify an object as humanlike and results in implicit anthropomorphism. Second, a reflective (Type 2) process may moderate the initial judgment based on conscious effort and result in explicit anthropomorphism. In this study, we manipulated both participants' motivation for Type 2 processing and a robot's emotionality to investigate the role of Type 1 versus Type 2 processing in forming judgments about the robot Robovie R2. We did so by having participants play the Jeopardy! game with the robot. Subsequently, we directly and indirectly measured anthropomorphism by administering self-report measures and a priming task, respectively. Furthermore, we measured treatment of the robot as a social actor to establish its relation with implicit and explicit anthropomorphism. The results suggested that the model of dual anthropomorphism can explain when responses are likely to reflect judgments based on Type 1 and Type 2 processes. Moreover, we showed that the social treatment of a robot, as described by the Media Equation theory, is related with implicit, but not explicit anthropomorphism.
C1 [Zlotowski, Jakub] Univ Canterbury, HIT Lab NZ, Christchurch, New Zealand.
   [Bartneck, Christoph] Univ Canterbury, HIT Lab NZ, Postgrad Studies, Christchurch, New Zealand.
   [Zlotowski, Jakub; Sumioka, Hidenobu; Nishio, Shuichi; Ishiguro, Hiroshi] Adv Telecommun Res Inst Int, Hiroshi Ishiguro Lab, Kyoto, Japan.
   [Eyssel, Friederike] Bielefeld Univ, CITEC, Bielefeld, Germany.
   [Ishiguro, Hiroshi] Osaka Univ, Grad Sch Engn Sci, Dept Syst Innovat, Osaka, Japan.
RP Zlotowski, J (reprint author), Univ Canterbury, HIT Lab NZ, Christchurch, New Zealand.; Zlotowski, J (reprint author), Adv Telecommun Res Inst Int, Hiroshi Ishiguro Lab, Kyoto, Japan.
EM jaz18@uclive.ac.nz
FU JST CREST (Core Research for Evolutional Science and Technology)
   research promotion program "Creation of Human-Harmonized Information
   Technology for Convivial Society" Research Area, ERATO; European Project
   CODE-FROR [FP7-PIRSES-2013-612555]; ISHIGURO symbiotic Human-Robot
   Interaction Project
FX The authors would like to thank Kaiko Kuwamura, Daisuke Nakamichi, Junya
   Nakanishi, Masataka Okubo and Kurima Sakai for their help with data
   collection. The authors are very grateful for the helpful comments from
   the anonymous reviewers. This work was partially supported by JST CREST
   (Core Research for Evolutional Science and Technology) research
   promotion program "Creation of Human-Harmonized Information Technology
   for Convivial Society" Research Area, ERATO, ISHIGURO symbiotic
   Human-Robot Interaction Project and the European Project CODE-FROR
   (FP7-PIRSES-2013-612555).
CR Aaker JL, 1997, J MARKETING RES, V34, P347, DOI 10.2307/3151897
   Aggarwal P, 2007, J CONSUM RES, V34, P468, DOI 10.1086/518544
   Airenti G, 2015, INT J SOC ROBOT, V7, P117, DOI 10.1007/s12369-014-0263-x
   Aviezer H, 2012, SCIENCE, V338, P1225, DOI 10.1126/science.1224313
   Barrett J., 2004, WHY WOULD ANYONE BEL
   Bartneck C., 2007, 2007 2nd Annual Conference on Human-Robot Interaction (HRI), P81
   Bartneck C, 2009, INT J SOC ROBOT, V1, P71, DOI 10.1007/s12369-008-0001-3
   Beck A, 2010, 2010 IEEE RO-MAN, P464, DOI 10.1109/ROMAN.2010.5598649
   Bosson JK, 2000, J PERS SOC PSYCHOL, V79, P631, DOI 10.1037//0022-3514.79.4.631
   Damiano L, 2015, INT J SOC ROBOT, V7, P7, DOI 10.1007/s12369-014-0258-7
   Darlow AL, 2010, WIRES COGN SCI, V1, P382, DOI 10.1002/wcs.34
   Darwin C., 1872, EXPRESSION EMOTIONS
   De Houwer J., 2006, HDB IMPLICIT COGNITI, P11, DOI DOI 10.4135/9781412976237.N2
   Epley N, 2007, PSYCHOL REV, V114, P864, DOI 10.1037/0033-295X.114.4.864
   Epstein S, 1996, J PERS SOC PSYCHOL, V71, P390, DOI 10.1037/0022-3514.71.2.390
   Evans JSBT, 2008, ANNU REV PSYCHOL, V59, P255, DOI 10.1146/annurev.psych.59.103006.093629
   Evans JST, 2013, PERSPECT PSYCHOL SCI, V8, P223, DOI 10.1177/1745691612460685
   Eyssel FA, 2016, P 25 IEEE INT S ROB, P916
   Eyssel F, 2010, 2010 IEEE RO-MAN, P646, DOI 10.1109/ROMAN.2010.5598687
   Fischer K, 2012, ACMIEEE INT CONF HUM, P463
   Fischer K, 2011, ACMIEEE INT CONF HUM, P53, DOI 10.1145/1957656.1957672
   Friedman B., 2003, P SIGCHI C HUM FACT, P273, DOI DOI 10.1145/642611.642660
   Fussell S. R., 2008, 2008 3rd ACM/IEEE International Conference on Human-Robot Interaction (HRI 2008), P145
   Gawronski B, 2006, PSYCHOL BULL, V132, P692, DOI 10.1037/0033-2909.132.5.692
   Gergely G, 2003, TRENDS COGN SCI, V7, P287, DOI 10.1016/S1364-6613(03)00128-1
   GERGELY G, 1995, COGNITION, V56, P165, DOI 10.1016/0010-0277(95)00661-H
   GREENWALD AG, 1995, PSYCHOL REV, V102, P4, DOI 10.1037//0033-295X.102.1.4
   Hard R., 2004, ROUTLEDGE HDB GREEK
   Haslam N, 2006, PERS SOC PSYCHOL REV, V10, P252, DOI 10.1207/s15327957pspr1003_4
   Heider F, 1944, AM J PSYCHOL, V57, P243, DOI 10.2307/1416950
   Ho CC, 2010, COMPUT HUM BEHAV, V26, P1508, DOI 10.1016/j.chb.2010.05.015
   Johnson DO, 2016, INT J SOC ROBOT, V8, P247, DOI 10.1007/s12369-015-0331-x
   Kamide H, 2013, LECT NOTES ARTIF INT, V8239, P199, DOI 10.1007/978-3-319-02675-6_20
   Kuchenbrandt D, 2014, ACMIEEE INT CONF HUM, P218, DOI 10.1145/2559636.2563710
   Lemaignan S, 2014, 2014 HUM ROB INT C W
   Nass C, 2000, J SOC ISSUES, V56, P81, DOI 10.1111/0022-4537.00153
   NASS C, 1994, HUMAN FACTORS IN COMPUTING SYSTEMS, CHI '94 CONFERENCE PROCEEDINGS - CELEBRATING INTERDEPENDENCE, P72
   Nosek BA, 2005, PERS SOC PSYCHOL B, V31, P166, DOI 10.1177/0146167204271418
   Payne BK, 2001, J PERS SOC PSYCHOL, V81, P181, DOI 10.1037//0022-3514.81.2.181
   Reeves B., 1996, PEOPLE TREAT COMPUTE
   Salem Maha, 2011, Social Robotics. Proceedings Third International Conference (ICSR 2011), P31, DOI 10.1007/978-3-642-25504-5_4
   Sims VK, 2009, P HUMAN FACTORS ERGO, V3, P1418
   Smith ER, 2000, PERS SOC PSYCHOL REV, V4, P108, DOI 10.1207/S15327957PSPR0402_01
   Strack F, 2004, PERS SOC PSYCHOL REV, V8, P220, DOI 10.1207/s15327957pspr0803_1
   von Zitzewitz J, 2013, INT J SOC ROBOT, V5, P263, DOI 10.1007/s12369-012-0177-4
   Walters ML, 2008, 2008 17TH IEEE INTERNATIONAL SYMPOSIUM ON ROBOT AND HUMAN INTERACTIVE COMMUNICATION, VOLS 1 AND 2, P707, DOI 10.1109/ROMAN.2008.4600750
   Wang E, 2006, HRI 2006, V2006, P180
   Waytz A., 2013, OXFORD HDB DEV IMAGI, P272, DOI DOI 10.1093/OXFORDHB/9780195395761.013
   Waytz A, 2010, PERSPECT PSYCHOL SCI, V5, P219, DOI 10.1177/1745691610369336
   WEIZENBAUM J, 1966, COMMUN ACM, V9, P36, DOI 10.1145/365153.365168
   Wesson CJ, 2009, PSYCHOL REP, V105, P151, DOI 10.2466/PR0.105.1.151-160
   Wilson TD, 2000, PSYCHOL REV, V107, P101, DOI 10.1037/0033-295X.107.1.101
   Yoshikawa Y, 2006, P ROB SCI SYST
   Zlotowski J, 2014, ACMIEEE INT CONF HUM, P66, DOI 10.1145/2559636.2559679
   Zlotowski J, 2015, INT J SOC ROBOT, V7, P347, DOI 10.1007/s12369-014-0267-6
   Zlotowski J, 2013, ACMIEEE INT CONF HUM, P365, DOI 10.1109/HRI.2013.6483611
NR 56
TC 0
Z9 0
U1 6
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1875-4791
EI 1875-4805
J9 INT J SOC ROBOT
JI Int. J. Soc. Robot.
PD NOV
PY 2018
VL 10
IS 5
BP 701
EP 714
DI 10.1007/s12369-018-0476-5
PG 14
WC Robotics
SC Robotics
GA HC3AM
UT WOS:000451673100011
DA 2019-02-18
ER

PT J
AU Duysens, J
   Forner-Cordero, A
AF Duysens, Jacques
   Forner-Cordero, Arturo
TI Walking with perturbations: a guide for biped humans and robots
SO BIOINSPIRATION & BIOMIMETICS
LA English
DT Review
DE biped gait; central pattern generator (CPG); stability; perturbed gait;
   walking robots
ID CENTRAL PATTERN GENERATORS; PHASE-DEPENDENT MODULATION; SPLIT-BELT
   WALKING; CAPTURABILITY-BASED ANALYSIS; MUSCULO-SKELETAL SYSTEM; ANKLE
   EXTENSOR MUSCLES; SPINAL-CORD INSIGHTS; CENTER-OF-MASS; FICTIVE
   LOCOMOTION; INTERLIMB COORDINATION
AB This paper provides an update on the neural control of bipedal walking in relation to bioinspired models and robots. It is argued that most current models or robots are based on the construct of a symmetrical central pattern generator (CPG). However, new evidence suggests that CPG functioning is basically asymmetrical with its flexor half linked more tightly to the rhythm generator. The stability of bipedal gait, which is an important problem for robots and biological systems, is also addressed. While it is not possible to determine how biological biped systems guarantee stability, robot solutions can be useful to propose new hypotheses for biology. In the second part of this review, the focus is on gait perturbations, which is an important topic in robotics in view of the frequent falls of robots when faced with perturbations. From the human physiology it is known that the initial reaction often consists of a brief interruption followed by an adequate response. For instance, the successful recovery from a trip is achieved using some basic reactions (termed elevating and lowering strategies), that depend on the phase of the step cycle of the trip occurrence. Reactions to stepping unexpectedly in a hole depend on comparing expected and real feedback. Implementation of these ideas in models and robotics starts to emerge, with the most advanced robots being able to learn how to fall safely and how to deal with complicated disturbances such as provided by walking on a split-belt.
C1 [Duysens, Jacques; Forner-Cordero, Arturo] Univ Sao Paulo, Escola Politecn, Mechatron Dept, Biomechatron Lab, Av Prof Mello Moraes 2231,Cidade Univ, BR-05508030 Sao Paulo, SP, Brazil.
   [Duysens, Jacques] Katholieke Univ Leuven, FaBeR, Dept Kinesiol, Leuven, Belgium.
RP Duysens, J (reprint author), Univ Sao Paulo, Escola Politecn, Mechatron Dept, Biomechatron Lab, Av Prof Mello Moraes 2231,Cidade Univ, BR-05508030 Sao Paulo, SP, Brazil.; Duysens, J (reprint author), Katholieke Univ Leuven, FaBeR, Dept Kinesiol, Leuven, Belgium.
EM Jacques.Duysens@kuleuven.be; aforner@usp.br
RI Forner-Cordero, Arturo/G-5054-2013
OI Forner-Cordero, Arturo/0000-0002-0352-1640
FU National Research Council of Brazil (CNPq) [400819/2013-9]; CNPq
   [311055/2016-8]
FX JD was supported by a visiting professorship from the National Research
   Council of Brazil (CNPq, grant number: 400819/2013-9). AFC acknowledges
   a CNPq research grant (grant number: 311055/2016-8). We acknowledge
   Clara Ploretti Cappatto for the help with the figures.
CR Abbas JJ, 2000, BIOMECHANICS AND NEURAL CONTROL OF POSTURE AND MOVEMENT, P177
   Af Klint R, 2010, J NEUROPHYSIOL, V103, P2747, DOI 10.1152/jn.00547.2009
   Akay T, 2014, P NATL ACAD SCI USA, V111, P16877, DOI 10.1073/pnas.1419045111
   ANDERSSON O, 1983, ACTA PHYSIOL SCAND, V118, P229, DOI 10.1111/j.1748-1716.1983.tb07267.x
   ANDERSSON O, 1981, ACTA PHYSIOL SCAND, V113, P89, DOI 10.1111/j.1748-1716.1981.tb06867.x
   Aoi S, 2005, AUTON ROBOT, V19, P219, DOI 10.1007/s10514-005-4051-1
   Aoi SY, 2016, SCI REP-UK, V6, DOI 10.1038/srep30199
   Aoi S, 2016, NEUROSCI RES, V104, P88, DOI 10.1016/j.neures.2015.11.005
   Aoi S, 2012, ROBOT AUTON SYST, V60, P685, DOI 10.1016/j.robot.2011.12.005
   Aoi S, 2010, BIOL CYBERN, V102, P373, DOI 10.1007/s00422-010-0373-y
   Ausborn J, 2018, J NEUROPHYSIOL, V119, P96, DOI 10.1152/jn.00550.2017
   Baken BCM, 2005, BRAIN RES, V1031, P268, DOI 10.1016/j.brainres.2004.10.058
   Bancroft MJ, 2016, FRONT HUM NEUROSCI, V10, DOI 10.3389/fnhum.2016.00635
   Bastian AJ, 2008, CURR OPIN NEUROL, V21, P628, DOI 10.1097/WCO.0b013e328315a293
   Bekey G. A., 1986, Proceedings 1986 IEEE International Conference on Robotics and Automation (Cat. No.86CH2282-2), P240
   Bellardita C, 2015, CURR BIOL, V25, P1426, DOI 10.1016/j.cub.2015.04.005
   BERGER W, 1984, J PHYSIOL-LONDON, V357, P109, DOI 10.1113/jphysiol.1984.sp015492
   Blickhan R, 2015, J THEOR BIOL, V382, P187, DOI 10.1016/j.jtbi.2015.06.036
   Bonnot A, 2002, BRAIN RES REV, V40, P141, DOI 10.1016/S0165-0173(02)00197-2
   Bonnot AS, 2002, J NEUROSCI, V22, DOI 10.1523/JNEUROSCI.22-03-j0001.2002
   Boone GN, 1997, AUTON ROBOT, V4, P259, DOI 10.1023/A:1008891909459
   Bouvier J, 2015, CELL, V163, P1191, DOI 10.1016/j.cell.2015.10.074
   Britz O, 2015, ELIFE, V4, DOI [10.7554/eLife.13038, 10.7554/eLife.04718]
   Brocard F, 2013, NEURON, V77, P1047, DOI 10.1016/j.neuron.2013.01.026
   Brocard F, 2010, NEUROSCIENTIST, V16, P139, DOI 10.1177/1073858409346339
   Brown TG, 1914, J PHYSIOL-LONDON, V48, P18
   Brownstone RM, 2008, BRAIN RES REV, V57, P64, DOI 10.1016/j.brainresrev.2007.06.025
   Buschges A, 2008, BRAIN RES REV, V57, P162, DOI 10.1016/j.brainresrev.2007.06.028
   Buschges A, 2007, ADV INSECT PHYSIOL, V34, P193, DOI 10.1016/S0065-2806(07)34004-6
   Burke RE, 2001, J NEUROPHYSIOL, V86, P447
   Buschges A, 1998, CURR OPIN NEUROBIOL, V8, P733, DOI 10.1016/S0959-4388(98)80115-3
   Buschmann T, 2015, BIOINSPIR BIOMIM, V10, DOI 10.1088/1748-3190/10/4/041001
   Caggiano V, 2018, NATURE, V553, P455, DOI 10.1038/nature25448
   CAPADAY C, 1986, J NEUROSCI, V6, P1308
   Cazalets JR, 2000, EUR J NEUROSCI, V12, P2993, DOI 10.1046/j.1460-9568.2000.00169.x
   CAZALETS JR, 1995, J NEUROSCI, V15, P4943
   Choi JT, 2007, NAT NEUROSCI, V10, P1055, DOI 10.1038/nn1930
   Chvatal SA, 2012, J NEUROSCI, V32, P12237, DOI 10.1523/JNEUROSCI.6344-11.2012
   Chyou T, 2011, J THEOR BIOL, V285, P126, DOI 10.1016/j.jtbi.2011.06.032
   COHEN AH, 1992, BRAIN BEHAV EVOLUT, V40, P112, DOI 10.1159/000113907
   Collins S, 2005, SCIENCE, V307, P1082, DOI 10.1126/science.1107799
   Collins SH, 2005, IEEE INT CONF ROBOT, P1983
   Commissaris DACM, 2002, J NEUROSCI METH, V113, P73, DOI 10.1016/S0165-0270(01)00477-0
   CONWAY BA, 1987, EXP BRAIN RES, V68, P643
   Cordero AF, 2005, GAIT POSTURE, V21, P243, DOI 10.1016/j.gaitpost.2004.01.012
   Cordero AF, 2004, BIOL CYBERN, V91, P212, DOI 10.1007/s00422-004-0508-0
   Cote MP, 2018, FRONT PHYSIOL, V9, DOI 10.3389/fphys.2018.00784
   Cote MP, 2003, J NEUROSCI, V23, P2789
   Crespi A, 2008, AUTON ROBOT, V25, P3, DOI 10.1007/s10514-007-9071-6
   Cruse H, 1998, NEURAL NETWORKS, V11, P1435, DOI 10.1016/S0893-6080(98)00067-7
   Daeschler EB, 2006, NATURE, V440, P757, DOI 10.1038/nature04639
   Daley MA, 2006, P NATL ACAD SCI USA, V103, P15681, DOI 10.1073/pnas.0601473103
   Daley MA, 2008, CURR BIOL, V18, pR1064, DOI 10.1016/j.cub.2008.09.050
   Danner SM, 2017, ELIFE, V6, DOI 10.7554/eLife.31059
   Danner SM, 2016, J PHYSIOL-LONDON, V594, P6947, DOI 10.1113/JP272787
   DAVIS M, 1982, J NEUROSCI, V2, P791
   DAVIS M, 1989, ANN NY ACAD SCI, V563, P165, DOI 10.1111/j.1749-6632.1989.tb42197.x
   de Boer T, 2010, J BIOMECH ENG-T ASME, V132, DOI 10.1115/1.4001281
   De Groote F, 2014, FRONT COMPUT NEUROSC, V8, DOI 10.3389/fncom.2014.00115
   DELIAGINA TG, 1983, EXP BRAIN RES, V53, P81
   Dietz V, 2000, GAIT POSTURE, V11, P102, DOI 10.1016/S0966-6362(99)00052-1
   DIETZ V, 1986, BRAIN RES, V384, P166, DOI 10.1016/0006-8993(86)91233-3
   DIETZ V, 1984, NEUROSCI LETT, V44, P131, DOI 10.1016/0304-3940(84)90070-3
   DIETZ V, 1987, J PHYSIOL-LONDON, V386, P149, DOI 10.1113/jphysiol.1987.sp016527
   DIETZ V, 1994, EXP BRAIN RES, V101, P513
   DIETZ V, 1989, J NEUROPHYSIOL, V62, P680
   Dingwell JB, 2001, J BIOMECH ENG-T ASME, V123, P27, DOI 10.1115/1.1336798
   Dominici N, 2011, SCIENCE, V334, P997, DOI 10.1126/science.1210617
   Don EK, 2013, J ANAT, V222, P114, DOI 10.1111/j.1469-7580.2012.01557.x
   DREW T, 1991, J NEUROPHYSIOL, V66, P919
   Duysens J, 1998, GAIT POSTURE, V7, P131, DOI 10.1016/S0966-6362(97)00042-8
   Duysens J, 2000, PHYSIOL REV, V80, P83
   DUYSENS J, 1980, J NEUROPHYSIOL, V44, P1024
   DUYSENS J, 1980, BRAIN RES, V187, P321, DOI 10.1016/0006-8993(80)90206-1
   Duysens J, 2006, J NEUROPHYSIOL, V95, P562
   Duysens J, 2004, CAN J PHYSIOL PHARM, V82, P715, DOI 10.1139/Y04-071
   DUYSENS J, 1977, J NEUROPHYSIOL, V40, P737
   Duysens J, 1996, J NEUROPHYSIOL, V76, P301
   DUYSENS J, 1990, EXP BRAIN RES, V82, P351
   Duysens J, 2002, J BIOMECH, V35, P447, DOI 10.1016/S0021-9290(01)00187-7
   Duysens J, 1998, EUR J MORPHOL, V36, P293, DOI 10.1076/ejom.36.4.293.5820
   DUYSENS J, 1976, EXP BRAIN RES, V24, P245
   Duysens J, 2013, FRONT COMPUT NEUROSC, V7, DOI 10.3389/fncom.2013.00014
   Dzeladini F, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00371
   Edwards D H, 2017, NEUROBIOLOGY MOTOR C, P263
   Ekeberg O, 2005, J NEUROPHYSIOL, V94, P4256, DOI 10.1152/jn.00065.2005
   Endo G, 2005, IEEE INT CONF ROBOT, P596
   Endo T, 2008, J NEUROPHYSIOL, V100, P3043, DOI 10.1152/jn.90729.2008
   ENG JJ, 1994, EXP BRAIN RES, V102, P339
   Englsberger J, 2015, IEEE T ROBOT, V31, P355, DOI 10.1109/TRO.2015.2405592
   Englsberger J, 2011, IEEE INT C INT ROBOT, P4420, DOI 10.1109/IROS.2011.6048045
   Ernst M, 2014, HUM MOVEMENT SCI, V38, P293, DOI 10.1016/j.humov.2014.05.012
   Esposito MS, 2016, CURR BIOL, V26, pR291, DOI 10.1016/j.cub.2016.02.043
   Faist M, 1999, EXP BRAIN RES, V125, P265, DOI 10.1007/s002210050682
   Faist M, 2006, BRAIN RES, V1076, P87, DOI 10.1016/j.brainres.2005.12.069
   Falgairolle M, 2007, J PHYSIOL-LONDON, V580, P87, DOI 10.1113/jphysiol.2006.115709
   Fayemi PE, 2017, BIOINSPIR BIOMIM, V12, DOI 10.1088/1748-3190/12/1/011002
   FEL'DMAN A. G., 1966, BIOFIZIKA, V11, P498
   Feng SY, 2014, IEEE-RAS INT C HUMAN, P120, DOI 10.1109/HUMANOIDS.2014.7041347
   Figliolini G, 2003, IEEE ASME INT C ADV, P747
   Forner Cordero A, 2003, GAIT POSTURE, V18, P47, DOI 10.1016/S0966-6362(02)00160-1
   Forner-Cordero A, 2006, J BIOMECH, V39, P948, DOI 10.1016/j.jbiomech.2005.01.019
   Forner-Cordero A, 2015, IEEE ENG MED BIO, P6748, DOI 10.1109/EMBC.2015.7319942
   Forner-Cordero A, 2008, WEARABLE ROBOTS BIOM, P17
   Forner-Cordero A, 2016, J MOTOR BEHAV, V48, P1
   Forner-Cordero A, 2011, IEEE ENG MED BIO, P7829, DOI 10.1109/IEMBS.2011.6091929
   FORSSBERG H, 1980, ACTA PHYSIOL SCAND, V108, P269, DOI 10.1111/j.1748-1716.1980.tb06533.x
   FORSSBERG H, 1975, BRAIN RES, V85, P103, DOI 10.1016/0006-8993(75)91013-6
   Fourtner C R, 1976, NEURAL CONTROL LOCOM, P401
   Frigon A, 2006, BIOL CYBERN, V95, P607, DOI 10.1007/s00422-006-0129-x
   Frost R, 2015, FRONT HUM NEUROSCI, V9, DOI 10.3389/fnhum.2015.00014
   Fu CL, 2008, IEEE T IND ELECTRON, V55, P2111, DOI 10.1109/TIE.2008.921205
   Fujiki S, 2015, J R SOC INTERFACE, V12, DOI 10.1098/rsif.2015.0542
   Fujiwara K, 2006, IEEE-RAS INT C HUMAN, P524, DOI 10.1109/ICHR.2006.321323
   Fukuoka Y, 2003, INT J ROBOT RES, V22, P187, DOI 10.1177/0278364903022003004
   Fukuoka Y, 2015, BIOINSPIR BIOMIM, V10, DOI 10.1088/1748-3190/10/4/046017
   Geng T, 2006, INT J ROBOT RES, V25, P243, DOI 10.1177/0278364906063822
   Geyer H, 2010, IEEE T NEUR SYS REH, V18, P263, DOI 10.1109/TNSRE.2010.2047592
   GHORI GMU, 1985, EUR J APPL PHYSIOL O, V54, P145, DOI 10.1007/BF02335921
   Giber K, 2015, NAT NEUROSCI, V18, P562, DOI 10.1038/nn.3951
   GODDERZ W, 1990, EUR J NEUROSCI, V2, P663, DOI 10.1111/j.1460-9568.1990.tb00456.x
   GOSSARD JP, 1994, EXP BRAIN RES, V98, P213
   GOSSARD JP, 1990, BRAIN RES, V537, P14, DOI 10.1016/0006-8993(90)90334-8
   Grey MJ, 2004, CAN J PHYSIOL PHARM, V82, P610, DOI 10.1139/04-077
   Griffin RJ, 2017, IEEE INT C INT ROBOT, P667, DOI 10.1109/IROS.2017.8202223
   GRILLNER S, 1978, BRAIN RES, V146, P269, DOI 10.1016/0006-8993(78)90973-3
   Grillner S, 2002, BRAIN RES REV, V40, P92, DOI 10.1016/S0165-0173(02)00193-5
   Grillner S, 2011, HDB PHYSL 1, P1179, DOI DOI 10.1002/CPHY.CP010226
   Grillner S, 2008, BRAIN RES REV, V57, P2, DOI 10.1016/j.brainresrev.2007.06.027
   Grillner S, 2006, NEURON, V52, P751, DOI 10.1016/j.neuron.2006.11.008
   Grillner S, 2018, CURR BIOL, V28, pR162, DOI 10.1016/j.cub.2017.12.040
   Groen BE, 2010, OSTEOPOROSIS INT, V21, P215, DOI 10.1007/s00198-009-0934-x
   Guertin PA, 2009, BRAIN RES REV, V62, P45, DOI 10.1016/j.brainresrev.2009.08.002
   Hagglund M, 2013, P NATL ACAD SCI USA, V110, P11589, DOI 10.1073/pnas.1304365110
   Hase K, 2002, JSME INT J C-MECH SY, V45, P1040, DOI 10.1299/jsmec.45.1040
   Hausdorff JM, 2005, J NEUROENG REHABIL, V2, P19, DOI DOI 10.1186/1743-0003-2-19
   Heiden TL, 2006, GAIT POSTURE, V24, P237, DOI 10.1016/j.gaitpost.2005.09.004
   Hiebert GW, 1996, J NEUROPHYSIOL, V75, P1126
   Hill J, 2015, ROBOTICA, V33, P264, DOI 10.1017/S0263574714000332
   Hirai K, 1998, IEEE INT CONF ROBOT, P1321, DOI 10.1109/ROBOT.1998.677288
   HIROSE S, 1984, INT J ROBOT RES, V3, P113, DOI 10.1177/027836498400300210
   Hobbelen DGE, 2007, IEEE T ROBOT, V23, P1213, DOI 10.1109/TRO.2007.904908
   Hof AL, 2018, HUM MOVEMENT SCI, V57, P69, DOI 10.1016/j.humov.2017.11.009
   Hof AL, 2005, J BIOMECH, V38, P1, DOI 10.1016/j.jbiomech.2004.03.025
   Hof AL, 2008, HUM MOVEMENT SCI, V27, P112, DOI 10.1016/j.humov.2007.08.003
   Holst E, 1971, PERCEPTUAL PROCESSIN, P41
   Hoogkamer W, 2016, J NEUROPHYSIOL, V116, P1539, DOI 10.1152/jn.00079.2016
   Hoogkamer W, 2015, J NEUROPHYSIOL, V114, P1693, DOI 10.1152/jn.00936.2014
   Hoogkamer W, 2015, J NEUROPHYSIOL, V114, P1705, DOI 10.1152/jn.00937.2014
   Hoogkamer W, 2014, EXERC SPORT SCI REV, V42, P23, DOI 10.1249/JES.0000000000000000
   Hooper S L, NEUROBIOLOGY MOTOR C
   Hooper SL, 2009, J NEUROSCI, V29, P4109, DOI 10.1523/JNEUROSCI.5510-08.2009
   Hurt CP, 2011, EXP BRAIN RES, V214, P557, DOI 10.1007/s00221-011-2854-1
   Ijspeert AJ, 2008, NEURAL NETWORKS, V21, P642, DOI 10.1016/j.neunet.2008.03.014
   Ikemoto Y, 2007, P ANN INT IEEE EMBS, P2389, DOI 10.1109/IEMBS.2007.4352808
   Ikemoto Y, 2008, IEEE ENG MED BIO, P5073, DOI 10.1109/IEMBS.2008.4650354
   Ivanenko YP, 2008, EUR J NEUROSCI, V27, P3351, DOI 10.1111/j.1460-9568.2008.06289.x
   Ivanenko YP, 2004, J PHYSIOL-LONDON, V556, P267, DOI 10.1113/jphysiol.2003.057174
   Ivanenko YP, 2005, J NEUROSCI, V25, P7238, DOI 10.1523/JNEUROSCI.1327-05.2005
   Ivanenko YP, 2007, J NEUROSCI, V27, P11149, DOI 10.1523/JNEUROSCI.2644-07.2007
   Ivanenko YP, 2006, NEUROSCIENTIST, V12, P339, DOI 10.1177/1073858406287987
   Janshen L, 2017, J EXP BIOL, V220, P807, DOI 10.1242/jeb.148957
   Jayaram K, 2016, P NATL ACAD SCI USA, V113, pE950, DOI 10.1073/pnas.1514591113
   Jeong H, 2017, IEEE INT C INT ROBOT, P5263, DOI 10.1109/IROS.2017.8206418
   Jo S, 2004, BIOL CYBERN, V91, P188, DOI 10.1007/s00422-004-0497-z
   Jo SH, 2008, MED BIOL ENG COMPUT, V46, P179, DOI 10.1007/s11517-007-0277-8
   Jo S, 2007, BIOSYSTEMS, V90, P750, DOI 10.1016/j.biosystems.2007.03.003
   Jo S, 2007, BIOL CYBERN, V96, P279, DOI 10.1007/s00422-006-0126-0
   Jong Hyeon Park, 2000, Proceedings 2000 ICRA. Millennium Conference. IEEE International Conference on Robotics and Automation. Symposia Proceedings (Cat. No.00CH37065), P3353, DOI 10.1109/ROBOT.2000.845229
   Josset N, 2018, CURR BIOL, V28, P884, DOI 10.1016/j.cub.2018.02.007
   Jung H, 2018, CELL, V172, P667, DOI 10.1016/j.cell.2018.01.013
   Juvin L, 2016, CELL REP, V15, P2377, DOI 10.1016/j.celrep.2016.05.029
   Kajita S, 2003, IEEE INT CONF ROBOT, P1620, DOI 10.1109/ROBOT.2003.1241826
   Kajita S, 2002, 2002 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS I-IV, PROCEEDINGS, P2755, DOI 10.1109/ROBOT.2002.1013649
   Kajita S., 2004, 2004 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) (IEEE Cat. No.04CH37566), P3546
   KESHNER EA, 1987, EXP BRAIN RES, V69, P77
   Kiehn O, 1998, ANN NY ACAD SCI, V860, P110, DOI 10.1111/j.1749-6632.1998.tb09043.x
   Kiehn O, 2016, NAT REV NEUROSCI, V17, P224, DOI 10.1038/nrn.2016.9
   Kim ES, 2010, INT J CONTROL AUTOM, V8, P1061, DOI 10.1007/s12555-010-0515-y
   Kim Y, 2011, BIOL CYBERN, V105, P269, DOI 10.1007/s00422-011-0464-4
   Kimura H, 1999, P ISRR99, V25, P271
   Kjaerulff O, 1996, J NEUROSCI, V16, P5777
   Klavins E, 2002, NEUROTECHNOLOGY FOR BIOMIMETIC ROBOTS, P351
   Klein TJ, 2012, J NEURAL ENG, V9, DOI 10.1088/1741-2560/9/4/046011
   Klemetti R, 2014, GAIT POSTURE, V39, P534, DOI 10.1016/j.gaitpost.2013.09.006
   Kobayashi R, 2016, NEUROSCIENCE, V335, P72, DOI 10.1016/j.neuroscience.2016.08.027
   Koolen T, 2012, INT J ROBOT RES, V31, P1094, DOI 10.1177/0278364912452673
   Krause M., 2012, ROBOT CONTROL, V45, P165, DOI DOI 10.3182/20120905-3-HR-2030.00165
   Kuo AD, 2002, MOTOR CONTROL, V6, P129, DOI 10.1123/mcj.6.2.129
   Lacquaniti F, 2016, PHYS LIFE REV, V17, P38, DOI 10.1016/j.plrev.2016.03.002
   Lafreniere-Roula M, 2005, J NEUROPHYSIOL, V94, P1120, DOI 10.1152/jn.00216.2005
   Lim H, 2002, 2002 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS I-IV, PROCEEDINGS, P3111, DOI 10.1109/ROBOT.2002.1013705
   LOEB GE, 1979, J NEUROPHYSIOL, V42, P420
   Ma G, 2015, IEEE RAS INT C HUM R, V2015, P850
   Machado TA, 2015, CELL, V162, P338, DOI 10.1016/j.cell.2015.06.036
   Manoonpong P, 2009, ROBOT AUTON SYST, V57, P1140, DOI 10.1016/j.robot.2009.06.007
   Manoonpong P, 2007, PLOS COMPUT BIOL, V3, P1305, DOI 10.1371/journal.pcbi.0030134
   MANTYH PW, 1983, J NEUROPHYSIOL, V49, P582
   Marigold DS, 2007, NEUROSCIENCE, V144, P302, DOI 10.1016/j.neuroscience.2006.09.006
   Marigold DS, 2008, EXP BRAIN RES, V188, P23, DOI 10.1007/s00221-008-1335-7
   Marigold DS, 2007, EXP BRAIN RES, V176, P32, DOI 10.1007/s00221-006-0598-0
   Marigold DS, 2003, J NEUROPHYSIOL, V89, P1727, DOI 10.1152/jn.00683.2002
   Marigold DS, 2002, J NEUROPHYSIOL, V88, P339, DOI 10.1152/jn.00691.2001
   Martinez-Gonzalez C, 2012, EUR J NEUROSCI, V35, P723, DOI 10.1111/j.1460-9568.2012.08002.x
   Martino G, 2015, J NEUROPHYSIOL, V114, P2867, DOI 10.1152/jn.00029.2015
   Masahiro S, 2010, EXP BRAIN RES, V203, P437, DOI 10.1007/s00221-010-2248-9
   MATSUOKA K, 1985, BIOL CYBERN, V52, P367, DOI 10.1007/BF00449593
   MATSUOKA K, 1987, BIOL CYBERN, V56, P345, DOI 10.1007/BF00319514
   Matthis JS, 2014, J EXP PSYCHOL HUMAN, V40, P106, DOI 10.1037/a0033101
   Maufroy Christophe, 2008, SICE 2008 - 47th Annual Conference of the Society of Instrument and Control Engineers of Japan, P2495, DOI 10.1109/SICE.2008.4655085
   Mazurek KA, 2012, J NEURAL ENG, V9, DOI 10.1088/1741-2560/9/2/026003
   Mazzaro N, 2005, J NEUROPHYSIOL, V93, P167, DOI 10.1152/jn.00283.2004
   MCCREA DA, 1995, J PHYSIOL-LONDON, V487, P527, DOI 10.1113/jphysiol.1995.sp020897
   McCrea DA, 2008, BRAIN RES REV, V57, P134, DOI 10.1016/j.brainresrev.2007.08.006
   MCFADYEN BJ, 1994, BIOL CYBERN, V72, P151, DOI 10.1007/s004220050120
   McGeer T., 1990, Proceedings 1990 IEEE International Conference on Robotics and Automation (Cat. No.90CH2876-1), P1640, DOI 10.1109/ROBOT.1990.126245
   McVea DA, 2009, ADV EXP MED BIOL, V629, P293, DOI 10.1007/978-0-387-77064-2_15
   Meyer AJ, 2016, FRONT BIOENG BIOTECH, V4, DOI 10.3389/fbioe.2016.00077
   Meyns P, 2013, GAIT POSTURE, V38, P555, DOI 10.1016/j.gaitpost.2013.02.006
   Mitobe K, 2004, MECHATRONICS, V14, P163, DOI 10.1016/S0957-4158(03)00028-X
   Mohagheghi AA, 2004, EXP BRAIN RES, V155, P459, DOI 10.1007/s00221-003-1751-7
   Molkov YI, 2017, WIRES SYST BIOL MED, V9, DOI 10.1002/wsbm.1371
   Molkov YI, 2015, PLOS COMPUT BIOL, V11, DOI 10.1371/journal.pcbi.1004270
   MORI S, 1987, PROG NEUROBIOL, V28, P161, DOI 10.1016/0301-0082(87)90010-4
   Morimoto J, 2006, IEEE INT CONF ROBOT, P1579, DOI 10.1109/ROBOT.2006.1641932
   Morimoto J, 2008, IEEE T ROBOT, V24, P185, DOI 10.1109/TRO.2008.915457
   MORTIN LI, 1989, J NEUROSCI, V9, P2285
   Morton SM, 2006, J NEUROSCI, V26, P9107, DOI 10.1523/JNEUROSCI.2622-06.2006
   Muller R, 2015, J EXP BIOL, V218, P451, DOI 10.1242/jeb.113688
   Muller R, 2012, J EXP BIOL, V215, P3072, DOI 10.1242/jeb.072314
   Mullins OJ, 2011, PROG NEUROBIOL, V93, P244, DOI 10.1016/j.pneurobio.2010.11.001
   Musienko PE, 2012, J NEUROSCI, V32, P17442, DOI 10.1523/JNEUROSCI.3757-12.2012
   Nichols R, 2009, ADV EXP MED BIOL, V629, P663, DOI 10.1007/978-0-387-77064-2_36
   Nichols TR, 2018, J NEUROPHYSIOL, V119, P1186, DOI 10.1152/jn.00216.2017
   Nieuwenhuijzen PHJA, 2000, J NEUROPHYSIOL, V84, P65
   Nijhuis LBO, 2010, J NEUROPHYSIOL, V104, P2704, DOI 10.1152/jn.01080.2009
   Ogata K, 2007, IEEE-RAS INT C HUMAN, P306, DOI 10.1109/ICHR.2007.4813885
   Ogihara N, 2001, BIOL CYBERN, V84, P1, DOI 10.1007/PL00007977
   ORSAL D, 1986, EXP BRAIN RES, V64, P217
   Pang MYC, 2000, J PHYSIOL-LONDON, V528, P389, DOI 10.1111/j.1469-7793.2000.00389.x
   Park JH, 2001, IEEE INT CONF ROBOT, P4134, DOI 10.1109/ROBOT.2001.933264
   Park JH, 2009, IEEE T SYST MAN CY B, V39, P289, DOI 10.1109/TSMCB.2008.2003451
   Pater ML, 2015, GAIT POSTURE, V41, P335, DOI 10.1016/j.gaitpost.2014.10.026
   Patla AE, 2004, EXP BRAIN RES, V155, P173, DOI 10.1007/s00221-003-1714-z
   Patla AE, 2006, NEUROSCI LETT, V397, P110, DOI 10.1016/j.neulet.2005.12.016
   PATLA AE, 1993, GAIT POSTURE, V1, P45, DOI 10.1016/0966-6362(93)90042-Y
   Patla AE, 2003, EXP BRAIN RES, V148, P133, DOI 10.1007/s00221-002-1246-y
   PATLA AE, 1991, J EXP PSYCHOL HUMAN, V17, P603, DOI 10.1037/0096-1523.17.3.603
   Paul C, 2005, BIOL CYBERN, V93, P153, DOI 10.1007/s00422-005-0559-x
   Pavol MJ, 2001, J GERONTOL A-BIOL, V56, pM428, DOI 10.1093/gerona/56.7.M428
   Pearson KG, 2008, BRAIN RES REV, V57, P222, DOI 10.1016/j.brainresrev.2007.06.014
   Pearson K G, 1976, FUNCTION SEGMENTAL R, P519
   Pearson K, 2006, TRENDS NEUROSCI, V29, P625, DOI 10.1016/j.tins.2006.08.007
   Pearson KG, 2004, PROG BRAIN RES, V143, P123, DOI 10.1016/S0079-6123(03)43012-4
   Pearson KG, 1998, ANN NY ACAD SCI, V860, P203, DOI 10.1111/j.1749-6632.1998.tb09050.x
   PEARSON KG, 1992, EXP BRAIN RES, V90, P557
   PEARSON KG, 1970, J EXP BIOL, V52, P139
   PEARSON KG, 1972, J EXP BIOL, V56, P173
   Pearson KG, 1995, CURR OPIN NEUROBIOL, V5, P786, DOI 10.1016/0959-4388(95)80107-3
   PEARSON KG, 1993, ANNU REV NEUROSCI, V16, P265, DOI 10.1146/annurev.ne.16.030193.001405
   Pearson KG, 1997, COMPUT NEUR, P225
   PERRET C, 1976, BRAIN RES, V106, P390, DOI 10.1016/0006-8993(76)91035-0
   Pijnappels M, 2006, J ELECTROMYOGR KINES, V16, P137, DOI 10.1016/j.jelekin.2005.06.011
   Pijnappels M, 2005, GAIT POSTURE, V21, P388, DOI 10.1016/j.gaitpost.2004.04.009
   Pijnappels M, 2005, EXP BRAIN RES, V160, P326, DOI 10.1007/s00221-004-2014-y
   Potocanac Z, 2017, EXP BRAIN RES, V235, P2329, DOI 10.1007/s00221-017-4967-7
   Potocanac Z, 2016, J NEUROPHYSIOL, V115, P143, DOI 10.1152/jn.00263.2015
   Prahlad V, 2008, ROBOTICA, V26, P9, DOI 10.1017/S0263574707003542
   Pratt JE, 2006, LECT NOTES CONTR INF, V340, P299
   Pratt J, 2006, IEEE-RAS INT C HUMAN, P200, DOI 10.1109/ICHR.2006.321385
   Pratt J, 2012, INT J ROBOT RES, V31, P1117, DOI 10.1177/0278364912452762
   PROCHAZKA A, 1976, J NEUROPHYSIOL, V39, P1090
   Prochazka A, 1997, J NEUROPHYSIOL, V77, P3226
   PROKOP T, 1995, EXP BRAIN RES, V106, P449
   Reisman DS, 2005, J NEUROPHYSIOL, V94, P2403, DOI 10.1152/jn.00089.2005
   Renner R, 2006, 2006 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-12, P2967, DOI 10.1109/IROS.2006.282153
   Rhea CK, 2007, NEUROSCI LETT, V418, P60, DOI 10.1016/j.neulet.2007.02.063
   Righetti L, 2006, IEEE INT CONF ROBOT, P1585, DOI 10.1109/ROBOT.2006.1641933
   Rinderknecht M D, 2011, IEEE INT C REH ROB I, P1
   ROBINSON TE, 1978, PHYSIOL BEHAV, V21, P223, DOI 10.1016/0031-9384(78)90044-6
   Roos PE, 2010, CLIN BIOMECH, V25, P873, DOI 10.1016/j.clinbiomech.2010.06.016
   Roseberry T, 2017, PHILOS T R SOC B, V372, DOI 10.1098/rstb.2016.0197
   Roseberry TK, 2016, CELL, V164, P526, DOI 10.1016/j.cell.2015.12.037
   Rossi LF, 2014, P IEEE RAS-EMBS INT, P216, DOI 10.1109/BIOROB.2014.6913779
   Rossignol S, 2006, PHYSIOL REV, V86, P89, DOI 10.1152/00028.2005
   Rybak IA, 2006, J PHYSIOL-LONDON, V577, P641, DOI 10.1113/jphysiol.2006.118711
   Rybak IA, 2015, ENEURO, V2, DOI 10.1523/ENEURO.0069-15.2015
   Saltiel P, 2017, FRONT NEURAL CIRCUIT, V11, DOI 10.3389/fncir.2017.00098
   Sawers A, 2017, J NEUROPHYSIOL, V117, P509, DOI 10.1152/jn.00699.2016
   Schillings AM, 2005, J NEUROPHYSIOL, V94, P1158, DOI 10.1152/jn.00396.2004
   Schillings AM, 1999, BRAIN RES, V816, P480, DOI 10.1016/S0006-8993(98)01198-6
   Schillings AM, 2000, J NEUROPHYSIOL, V83, P2093
   Schroder-Schetelig J, 2010, AUTON ROBOT, V29, P357, DOI 10.1007/s10514-010-9199-7
   Sharbafi MA, 2017, J BIOMECH, V53, P163, DOI 10.1016/j.jbiomech.2017.01.018
   Sharbafi MA, 2016, BIOINSPIR BIOMIM, V11, DOI 10.1088/1748-3190/11/4/046003
   SHEFCHYK SJ, 1985, J NEUROPHYSIOL, V54, P1101
   Sherman D, 2015, FRONT NEUROL, V6, DOI 10.3389/fneur.2015.00140
   Sherrington CS, 1913, J PHYSIOL-LONDON, V47, P196
   Shevtsova NA, 2016, J PHYSIOL-LONDON, V594, P6117, DOI 10.1113/JP272437
   Shevtsova NA, 2015, J PHYSIOL-LONDON, V593, P2403, DOI 10.1113/JP270121
   Shih CL, 1999, IEEE T SYST MAN CY A, V29, P255, DOI 10.1109/3468.759271
   SHIK M. L., 1966, BLOFIZIKA, V11, P659
   Shinya M, 2016, FRONT HUM NEUROSCI, V10, DOI 10.3389/fnhum.2016.00029
   Shinya M, 2009, GAIT POSTURE, V29, P483, DOI 10.1016/j.gaitpost.2008.11.009
   Shirota C, 2011, IEEE ENG MED BIO, P7833, DOI 10.1109/IEMBS.2011.6091930
   Simons-Weidenmaier NS, 2006, BMC NEUROSCI, V7, DOI 10.1186/1471-2202-7-38
   Sinkjaer T, 2000, J PHYSIOL-LONDON, V523, P817, DOI 10.1111/j.1469-7793.2000.00817.x
   Soares SC, 2017, FRONT NEUROSCI-SWITZ, V11, DOI 10.3389/fnins.2017.00067
   Soares SC, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0114724
   Soares SC, 2012, EVOL PSYCHOL-US, V10, P187, DOI 10.1177/147470491201000202
   Song S, 2017, FRONT COMPUT NEUROSC, V11, DOI 10.3389/fncom.2017.00015
   Song S, 2015, J PHYSIOL-LONDON, V593, P3493, DOI 10.1113/JP270228
   Statton MA, 2018, CEREBELLUM, V17, P111, DOI 10.1007/s12311-017-0879-0
   Stephens B J, 2011, PUSH RECOVERY CONTRO
   Stephens MJ, 1996, BRAIN RES, V743, P24, DOI 10.1016/S0006-8993(96)00977-8
   Stevenson AJT, 2015, J NEUROPHYSIOL, V113, P3151, DOI 10.1152/jn.00794.2014
   Szczecinski NS, 2017, BIOL CYBERN, V111, P105, DOI 10.1007/s00422-017-0711-4
   Taga G, 1998, BIOL CYBERN, V78, P9, DOI 10.1007/s004220050408
   TAGA G, 1995, BIOL CYBERN, V73, P113, DOI 10.1007/s004220050167
   TAGA G, 1995, BIOL CYBERN, V73, P97, DOI 10.1007/s004220050166
   Takanishi A., 1985, J ROBOTICS SOC JAPAN, V3, P325
   Takenaka T, 2009, 2009 IEEE-RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, P1084, DOI 10.1109/IROS.2009.5354662
   Tang PF, 1999, J GERONTOL A-BIOL, V54, pM89, DOI 10.1093/gerona/54.2.M89
   Tedrake R, 2015, IEEE-RAS INT C HUMAN, P936, DOI 10.1109/HUMANOIDS.2015.7363473
   Timmis MA, 2012, GAIT POSTURE, V36, P160, DOI 10.1016/j.gaitpost.2012.02.008
   Tomita N, 2006, 2006 SICE-ICASE INTERNATIONAL JOINT CONFERENCE, VOLS 1-13, P2142
   TOWNSEND MA, 1985, J BIOMECH, V18, P21, DOI 10.1016/0021-9290(85)90042-9
   Troy KL, 2006, GAIT POSTURE, V24, P441, DOI 10.1016/j.gaitpost.2005.09.009
   Troy KL, 2005, EXP BRAIN RES, V161, P343, DOI 10.1007/s00221-004-2078-8
   van den Bogert AJ, 2002, J BIOMECH, V35, P199, DOI 10.1016/S0021-9290(01)00198-1
   van der Linden MH, 2007, J NEUROPHYSIOL, V97, P3639, DOI 10.1152/jn.01272.2006
   van der Linden MH, 2009, GAIT POSTURE, V29, P255, DOI 10.1016/j.gaitpost.2008.08.017
   Van der Noot N, 2015, IEEE INT CONF ROBOT, P6267, DOI 10.1109/ICRA.2015.7140079
   VanWezel BMH, 1997, J NEUROSCI, V17, P3804
   Verdaasdonk BW, 2006, NEURAL NETWORKS, V19, P388, DOI 10.1016/j.neunet.2005.09.003
   Verdaasdonk BW, 2009, BIOL CYBERN, V101, P49, DOI 10.1007/s00422-009-0316-7
   Visser JE, 2010, NEUROSCIENCE, V168, P387, DOI 10.1016/j.neuroscience.2010.03.068
   Vogelstein RJ, 2006, BIOL CYBERN, V95, P555, DOI 10.1007/s00422-006-0119-z
   VONHOLST E, 1950, NATURWISSENSCHAFTEN, V37, P464, DOI 10.1007/BF00622503
   VUKOBRAT.M, 1969, IEEE T BIO-MED ENG, VBM16, P1, DOI 10.1109/TBME.1969.4502596
   VUKOBRATOVIC M, 1972, Mathematical Biosciences, V15, P1, DOI 10.1016/0025-5564(72)90061-2
   Vukobratovic M, 2006, INT J HUM ROBOT, V3, P153, DOI 10.1142/S0219843606000710
   Vukobratovie M., 2004, INT J HUM ROBOT, V1, P157, DOI DOI 10.1142/S0219843604000083
   Wadden T, 1998, BIOL CYBERN, V79, P161
   Wang JG, 2012, P AMER CONTR CONF, P4837
   Weerdesteyn V, 2006, GERONTOLOGY, V52, P131, DOI 10.1159/000091822
   Weerdesteyn V, 2004, HUM MOVEMENT SCI, V23, P351, DOI 10.1016/j.humov.2004.08.011
   Westervelt E R, 2007, FEEDBACK CONTROL DYN, V26
   Whelan PJ, 1996, PROG NEUROBIOL, V49, P481, DOI 10.1016/0301-0082(96)00028-7
   Wilson JM, 2005, J NEUROSCI, V25, P5710, DOI 10.1523/JNEUROSCI.0274-05.2005
   WINTER DA, 1989, J MOTOR BEHAV, V21, P337
   Wright J, 2015, J INTELL ROBOT SYST, V80, P255, DOI 10.1007/s10846-014-0149-z
   Wu M, 2011, CLIN NEUROPHYSIOL, V122, P1421, DOI 10.1016/j.clinph.2011.04.008
   Wu QD, 2009, SCI CHINA SER F, V52, P1715, DOI 10.1007/s11432-009-0169-7
   Yamaguchi J, 1999, ADV ROBOTICS, V13, P297, DOI 10.1163/156855399X01431
   Yang F, 2008, J BIOMECH, V41, P1823, DOI 10.1016/j.jbiomech.2008.04.005
   YANG JF, 1991, EXP BRAIN RES, V87, P679
   YANG JF, 1990, J NEUROPHYSIOL, V63, P1109
   Yang JF, 1998, J PHYSIOL-LONDON, V507, P927, DOI 10.1111/j.1469-7793.1998.927bs.x
   Yokoyama H, 2017, P ROY SOC B-BIOL SCI, V284, DOI 10.1098/rspb.2017.0290
   Yu W, 2007, MED BIOL ENG COMPUT, V45, P1095, DOI 10.1007/s11517-007-0255-1
   Zaoui C, 2009, MULTIBODY SYST DYN, V21, P261, DOI 10.1007/s11044-008-9143-1
   Zehr EP, 1997, J NEUROPHYSIOL, V77, P3311
   Zehr EP, 2004, NEUROSCIENTIST, V10, P347, DOI 10.1177/1073858404264680
   Zhang JM, 2014, NEURON, V82, P138, DOI 10.1016/j.neuron.2014.02.013
   Zhang T, 2018, IEEE-ASME T MECH, V23, P274, DOI 10.1109/TMECH.2018.2790358
   Zhong GS, 2012, J PHYSIOL-LONDON, V590, P4735, DOI 10.1113/jphysiol.2012.240895
   Ziskind-Conhaim L, 2017, J NEUROPHYSIOL, V118, P2956, DOI 10.1152/jn.00322.2017
NR 368
TC 1
Z9 1
U1 31
U2 31
PU IOP PUBLISHING LTD
PI BRISTOL
PA TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND
SN 1748-3182
EI 1748-3190
J9 BIOINSPIR BIOMIM
JI Bioinspir. Biomim.
PD NOV
PY 2018
VL 13
IS 6
AR 061001
DI 10.1088/1748-3190/aada54
PG 35
WC Engineering, Multidisciplinary; Materials Science, Biomaterials;
   Robotics
SC Engineering; Materials Science; Robotics
GA GS7HF
UT WOS:000443870900001
PM 30109860
DA 2019-02-18
ER

PT J
AU Kermavnar, T
   Power, V
   de Eyto, A
   O'Sullivan, L
AF Kermavnar, Tjasa
   Power, Valerie
   de Eyto, Adam
   O'Sullivan, Leonard
TI Cuff Pressure Algometry in Patients with Chronic Pain as Guidance for
   Circumferential Tissue Compression for Wearable Soft Exoskeletons: A
   Systematic Review
SO SOFT ROBOTICS
LA English
DT Review
DE cuff pressure algometry; circumferential tissue compression;
   exoskeleton; chronic pain; discomfort; patient
ID SPINAL-CORD-INJURY; CHRONIC POSTOPERATIVE PAIN; TOTAL KNEE REPLACEMENT;
   TEMPORAL SUMMATION; MUSCULOSKELETAL PAIN; SPATIAL SUMMATION;
   OLDER-ADULTS; 2ND PAIN; FIBROMYALGIA SYNDROME; CENTRAL SENSITIZATION
AB In this article, we report on a systematic review of the literature on pressure-pain thresholds induced and assessed by computerized cuff pressure algometry (CPA). The motivation for this review is to provide design guidance on pressure levels for wearable soft exoskeletons and similar wearable robotics devices. In our review, we focus on CPA studies of patients who are candidates for wearable soft exoskeletons, as pain-related physiological mechanisms reportedly differ significantly between healthy subjects and patients with chronic pain. The results indicate that circumferential limb compression in patients most likely becomes painful at similar to 10-18 kPa and can become unbearable even below 25 kPa. The corresponding ranges for healthy control subjects are 20-42 kPa (painful limits) and 34-84 kPa (unbearable levels). In addition, the increase of pain with time tends to be significantly higher, and the adaptation to pain significantly lower, than in healthy subjects. The results of this review provide guidance to designers of wearable robotics for populations with chronic pain regarding rates and magnitudes of tissue compression that may be unacceptable to users.
C1 [O'Sullivan, Leonard] Univ Limerick, Sch Design, Limerick V94 T9PX, Ireland.
   [O'Sullivan, Leonard] Univ Limerick, Hlth Res Inst, Limerick V94 T9PX, Ireland.
RP O'Sullivan, L (reprint author), Univ Limerick, Sch Design, Limerick V94 T9PX, Ireland.; O'Sullivan, L (reprint author), Univ Limerick, Hlth Res Inst, Limerick V94 T9PX, Ireland.
EM leonard.osullivan@ul.ie
OI Power, Valerie/0000-0002-1518-459X; O'Sullivan,
   Leonard/0000-0002-0255-1979
FU European Union [688175]
FX This research was completed as part of the XoSoft project, which has
   received funding from the European Union's Horizon 2020 framework
   programme for research and innovation under grant agreement number
   688175.
CR Agam L, 2007, J Wound Care, V16, P336
   Amris K, 2014, INT J RHEUMATOL, DOI 10.1155/2014/417596
   Amris K, 2010, PAIN, V151, P664, DOI 10.1016/j.pain.2010.08.023
   Andersen MS, 2013, 14 INT S COMP SIM BI
   Anderson RJ, 2013, EUR J PAIN, V17, P67, DOI 10.1002/j.1532-2149.2012.00190.x
   Aranda-Villalobos P, 2013, ARTHRITIS RHEUM-US, V65, P1262, DOI 10.1002/art.37884
   Arendt-Nielsen L, 2011, J MAN MANIP THER, V19, P186, DOI 10.1179/106698111X13129729551903
   Arendt-Nielsen L, 2010, PAIN, V149, P573, DOI 10.1016/j.pain.2010.04.003
   Asbeck AT, 2014, IEEE ROBOT AUTOM MAG, V21, P22, DOI 10.1109/MRA.2014.2360283
   Bartels EM, 2014, NOVEL INSIGHTS PATHO, P38
   Bingel U, 2008, PAIN, V140, P393, DOI 10.1016/j.pain.2008.09.030
   Bouten CV, 2003, ARCH PHYS MED REHAB, V84, P616, DOI 10.1053/apmr.2003.50038
   Breuls RGM, 2003, ANN BIOMED ENG, V31, P1357, DOI 10.1114/1.1624602
   Christensen AW, 2014, BMJ OPEN, V4, DOI 10.1136/bmjopen-2013-004313
   Christmas C, 2002, J FAM PRACTICE, V51, P345
   CRENSHAW AG, 1988, ACTA ORTHOP SCAND, V59, P447, DOI 10.3109/17453678809149401
   de Kruif BJ, 2017, J BIONIC ENG, V14, P706, DOI 10.1016/S1672-6529(16)60437-7
   De Rossi SMM, 2011, SENSORS-BASEL, V11, P207, DOI 10.3390/s110100207
   Defrin R, 2003, PAIN, V106, P471, DOI 10.1016/j.pain.2003.09.010
   ERNST M, 1986, PAIN, V26, P221, DOI 10.1016/0304-3959(86)90077-1
   Finnerup NB, 2014, J PAIN, V15, P40, DOI 10.1016/j.jpain.2013.09.008
   Finocchietti S, 2012, EXP BRAIN RES, V219, P255, DOI 10.1007/s00221-012-3085-9
   Graven-Nielsen T, 2017, EUR J PAIN, V21, P552, DOI 10.1002/ejp.958
   Graven-Nielsen T, 2012, ARTHRITIS RHEUM-US, V64, P2907, DOI 10.1002/art.34466
   Graven-Nielsen T, 2000, PAIN, V85, P483, DOI 10.1016/S0304-3959(99)00308-5
   Graven-Nielsen T, 2008, FUNDAMENTALS MUSCULO, P347
   Graven-Nielsen T, 2015, PAIN, V156, P2193, DOI 10.1097/j.pain.0000000000000294
   Graven-Nielsen T, 2010, NAT REV RHEUMATOL, V6, P599, DOI 10.1038/nrrheum.2010.107
   Greenspan JD, 1997, SOMATOSENS MOT RES, V14, P107, DOI 10.1080/08990229771105
   Henriksen M, 2014, ARTHRIT CARE RES, V66, P1836, DOI 10.1002/acr.22375
   Huysamen K, 2018, APPL ERGON, V68, P125, DOI 10.1016/j.apergo.2017.11.004
   Imai Y, 2016, SOMATOSENS MOT RES, V33, P169, DOI 10.1080/08990220.2016.1229178
   Izumi M, 2014, PAIN, V155, P792, DOI 10.1016/j.pain.2014.01.008
   Jespersen A, 2007, PAIN, V131, P57, DOI 10.1016/j.pain.2006.12.012
   Jespersen A, 2013, PAIN MED, V14, P297, DOI 10.1111/pme.12021
   Johannes CB, 2010, J PAIN, V11, P1230, DOI 10.1016/j.jpain.2010.07.002
   Kanaya K, 2017, SII 2016 2016 IEEE S
   Kermavnar T, 2018, SOFT ROBOT, V5, P1, DOI 10.1089/soro.2017.0046
   Khanian BM, 2016, PAIN MED, V17, P915, DOI 10.1093/pm/pnv063
   King CD, 2009, PAIN, V143, P172, DOI 10.1016/j.pain.2008.12.027
   Kosek E, 2000, PAIN, V88, P69, DOI 10.1016/S0304-3959(00)00310-9
   Latremoliere A, 2009, J PAIN, V10, P895, DOI 10.1016/j.jpain.2009.06.012
   Lautenbacher S, 1997, CLIN J PAIN, V13, P189, DOI 10.1097/00002508-199709000-00003
   Lemming D, 2012, J REHABIL MED, V44, P648, DOI 10.2340/16501977-1006
   Linder-Ganz E, 2009, J BIOMECH ENG-T ASME, V131, DOI 10.1115/1.3005195
   Ling SM, 2003, J RHEUMATOL, V30, P114
   Mak AFT, 2001, J REHABIL RES DEV, V38, P161
   Mak AFT, 2010, ANNU REV BIOMED ENG, V12, P29, DOI 10.1146/annurev-bioeng-070909-105223
   Manafi-Khanian B, 2015, EUR J PAIN, V19, P1456, DOI 10.1002/ejp.677
   Manafi-Khanian B, 2016, MED BIOL ENG COMPUT, V54, P315, DOI 10.1007/s11517-015-1291-x
   Merskey H, 1994, CLASSIFICATION CHRON
   Morone NE, 2009, PAIN MED, V10, P693, DOI 10.1111/j.1526-4637.2009.00565.x
   Oomens CWJ, 2010, J TISSUE VIABILITY, V19, P35, DOI 10.1016/j.jtv.2009.11.002
   Peat G, 2001, ANN RHEUM DIS, V60, P91, DOI 10.1136/ard.60.2.91
   Petersen KK, 2017, CLIN J PAIN, V33, P1081, DOI 10.1097/AJP.0000000000000495
   Petersen KK, 2016, PAIN, V157, P1400, DOI 10.1097/j.pain.0000000000000531
   Polianskis R, 2002, PAIN, V100, P19, DOI 10.1016/S0304-3959(02)00162-8
   Polianskis R, 2002, J PAIN, V3, P28, DOI 10.1054/jpai.2002.27140
   Pons JL., 2008, WEARABLE ROBOTS BIOM, P154
   Price DD, 2002, PAIN, V99, P49, DOI 10.1016/S0304-3959(02)00053-2
   Pud D, 2009, PAIN, V144, P16, DOI 10.1016/j.pain.2009.02.015
   Rathleff MS, 2016, PAIN MED, V17, P980, DOI 10.1093/pm/pnv017
   Reenalda J, 2009, ASSIST TECHNOL, V21, P76, DOI 10.1080/10400430903050437
   SANGEORZAN BJ, 1989, J ORTHOPAED RES, V7, P423, DOI 10.1002/jor.1100070315
   Schaible H. -G., 2007, V177, P3
   Siddall PJ, 2003, PAIN, V103, P249, DOI 10.1016/S0304-3959(02)00452-9
   Silva PC, 2010, MULTIBODY SYST DYN, V24, P367, DOI 10.1007/s11044-010-9219-6
   Skou ST, 2013, SCAND J PAIN, V4, P111, DOI 10.1016/j.sjpain.2012.07.001
   Skou ST, 2013, PAIN, V154, P1588, DOI 10.1016/j.pain.2013.04.033
   Soriano-Maldonado A, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0149168
   Staud R, 2003, PAIN, V102, P87, DOI 10.1016/S0304-3953(02)00344-5
   Staud R, 2001, PAIN, V91, P165, DOI 10.1016/S0304-3959(00)00432-2
   Staud Roland, 2013, Int J Clin Rheumtol, V8, P639
   Stekelenburg A, 2005, PRESSURE ULCER RESEARCH: CURRENT AND FUTURE PERSPECTIVES, P187, DOI 10.1007/3-540-28804-X_12
   Stormer S, 1997, SPINAL CORD, V35, P446, DOI 10.1038/sj.sc.3100411
   Tamez-Duque J, 2015, SENSORS-BASEL, V15, P4550, DOI 10.3390/s150204550
   Treede R-D, 2013, PRAKTISCHE SCHMERZME, P3
   Vaegter HB, 2015, EUR J PAIN, V19, P973, DOI 10.1002/ejp.623
   Vaegter HB, 2017, CLIN J PAIN, V33, P475, DOI 10.1097/AJP.0000000000000428
   Vaegter HB, 2016, PAIN, V157, P1480, DOI 10.1097/j.pain.0000000000000543
   Vaegter HB, 2016, CLIN J PAIN, V32, P58, DOI 10.1097/AJP.0000000000000223
   Vaegter HB, 2017, J PAIN, V18, P973, DOI 10.1016/j.jpain.2017.03.002
   van Wijk G, 2010, J PAIN, V11, P408, DOI 10.1016/j.jpain.2009.10.009
   Vladimirova N, 2015, ARTHRITIS, DOI 10.1155/2015/434109
   Wade K, 2015, AGE AGEING, V44, P18
   Wade KF, 2017, J GERONTOL A-BIOL, V72, P403, DOI 10.1093/gerona/glw226
   Wade KF, 2016, AGE AGEING, V45, P268, DOI 10.1093/ageing/afv170
   Weaver GD, 2009, J AM GERIATR SOC, V57, P992, DOI 10.1111/j.1532-5415.2009.02263.x
   Werhagen L, 2004, SPINAL CORD, V42, P665, DOI 10.1038/sj.sc.3101641
   Yarnitsky D, 2015, EUR J PAIN, V19, P805, DOI 10.1002/ejp.605
   Yarnitsky D, 2008, PAIN, V138, P22, DOI 10.1016/j.pain.2007.10.033
   Yarnitsky D, 2015, PAIN, V156, pS24, DOI 10.1097/01.j.pain.0000460343.46847.58
   Yarnitsky D, 2010, CURR OPIN ANESTHESIO, V23, P611, DOI 10.1097/ACO.0b013e32833c348b
   Yarnitsky D, 2010, EUR J PAIN, V14, P339, DOI 10.1016/j.ejpain.2010.02.004
   Zhou LL, 2017, ROBOT AUTON SYST, V91, P337, DOI 10.1016/j.robot.2016.12.012
NR 95
TC 0
Z9 0
U1 13
U2 16
PU MARY ANN LIEBERT, INC
PI NEW ROCHELLE
PA 140 HUGUENOT STREET, 3RD FL, NEW ROCHELLE, NY 10801 USA
SN 2169-5172
EI 2169-5180
J9 SOFT ROBOT
JI Soft Robot.
PD OCT
PY 2018
VL 5
IS 5
BP 497
EP 511
DI 10.1089/soro.2017.0088
EA JUN
EY 2018
PG 15
WC Robotics
SC Robotics
GA GW9HK
UT WOS:000437382300001
PM 29957130
DA 2019-02-18
ER

PT J
AU Adamietz, R
   Giesen, T
   Mayer, P
   Johnson, A
   Bibb, R
   Seifarth, C
AF Adamietz, Raphael
   Giesen, Tim
   Mayer, Pablo
   Johnson, Andrew
   Bibb, Richard
   Seifarth, Christian
TI Reconfigurable and transportable container-integrated production system
SO ROBOTICS AND COMPUTER-INTEGRATED MANUFACTURING
LA English
DT Article
ID MANUFACTURING SYSTEMS; FRAMEWORK
AB In this paper, the concept and the prototype realization of a novel reconfigurable small-footprint manufacturing system in a transportable container is presented. The containerized format enables transportation of the system to provide on-site manufacturing, enabling the benefits of localized service delivery without duplication of equipment at multiple locations.
   Three industrial product use cases with varying manufacturing and performance requirements were analysed. All of the use cases demanded highly customized products with high quality in low production volumes. Based on their requirements, a general system specification was derived and used to develop a concept for the container-integrated factory.
   A reconfigurable, modular manufacturing system is integral to the overall container concept. Production equipment was integrated in the form of interchangeable process modules, which can be quickly connected by standard utility supply and control interfaces. A modular and self-configuring control system provides assisted production workflow programming, while a modular process chain combining Additive Manufacturing, CNC milling, precision assembly and cleaning processes has been developed.
   A prototype of the container-integrated factory with reconfigurable process modules and control system has been established, with full functionality and feasibility of the system demonstrated. (C) 2018 Elsevier Ltd. All rights reserved.
C1 [Adamietz, Raphael; Giesen, Tim; Mayer, Pablo; Seifarth, Christian] Fraunhofer Inst Mfg Engn & Automat IPA, Stuttgart, Germany.
   [Johnson, Andrew; Bibb, Richard] Loughborough Univ Technol, Loughborough Design Sch, Loughborough, Leics, England.
RP Adamietz, R (reprint author), Nobelstr 12, D-70569 Stuttgart, Germany.
EM raphael.adamietz@ipa.fraunhofer.de
OI Johnson, Andrew/0000-0002-9418-0545; Bibb, Richard/0000-0002-3975-389X
FU European Union Seventh Framework Program [609146]
FX The research leading to these results was performed within the
   CassaMobile project, which received funding from the European Union
   Seventh Framework Program under grant agreement 609146. More information
   about the project can be found on the project homepage
   (www.cassamobile.eu).
CR Adamietz R., 2013, C CHANG AG REC VIRT
   Andersen AL, 2016, PROC CIRP, V51, P7, DOI 10.1016/j.procir.2016.05.043
   [Anonymous], 2017, DHL EXPR WELT ZIEL Z
   [Anonymous], 2009, DEF IND DAIL
   [Anonymous], 2012, ELECT J, V25, P3
   [Anonymous], 2016, DEF IND DAIL
   Barata J., 2003, International Journal of Networking and Virtual Organisations, V2, P50, DOI 10.1504/IJNVO.2003.003518
   Barkley S., 2009, MOBILE PARTS HOSP RE
   Barkley S., 2016, MOBILE PARTS HOSP RE
   Bauernhansl T., 2014, IND 4 0 PRODUKTION A, P5
   Bauernhansl T., 2016, IND 4 0 ENTWICKLUNGS
   Bogers M, 2016, TECHNOL FORECAST SOC, V102, P225, DOI 10.1016/j.techfore.2015.07.024
   Chen DF, 2015, J CLEAN PROD, V107, P615, DOI 10.1016/j.jclepro.2015.05.009
   Drehtainer, 2017, SCHUTZ MACHT UNT
   ElMaraghy HA, 2005, INT J FLEX MANUF SYS, V17, P261, DOI 10.1007/s10696-006-9028-7
   Fox S, 2015, TECHNOL SOC, V42, P49, DOI 10.1016/j.techsoc.2015.03.003
   Fox S, 2012, TECHNOL FORECAST SOC, V79, P721, DOI 10.1016/j.techfore.2011.10.006
   Friedrich J, 2015, PROC CIRP, V33, P115, DOI 10.1016/j.procir.2015.06.022
   Gail L., 2012, REINRAUMTECHNIK
   Gausemeier J, 2011, ROBOT CIM-INT MANUF, V27, P772, DOI 10.1016/j.rcim.2011.02.005
   Gommel U., 2011, CLEANROOM CLEANLINES
   Guenthel J., 2016, P DIR DIG MAN C BERL
   Hernandez-Matias JC, 2008, ROBOT CIM-INT MANUF, V24, P187, DOI 10.1016/j.reim.2006.10.003
   Hopkinson N, 2003, P I MECH ENG C-J MEC, V217, P31, DOI 10.1243/095440603762554596
   Jackson M., 2007, INT J MODERN ENG, V8, P12
   Jarvenpaa E., 2013, INTERFACE, V20, P30
   Kircher C., 2005, CIRP 3 INT C REC MAN
   Koren Y, 1999, CIRP ANNALS 1999: MANUFACTURING TECHNOLOGY, VOL 48 NO 2 1999, P527, DOI 10.1016/S0007-8506(07)63232-6
   Koren Y, 2010, J MANUF SYST, V29, P130, DOI 10.1016/j.jmsy.2011.01.001
   Lindemann C., 2012, 23 ANN INT SOL FREEF
   Marik V., 2000, LECT NOTES ARTIFICIA, V8062
   Matt DT, 2015, PROC CIRP, V33, P185, DOI 10.1016/j.procir.2015.06.034
   Mehrabi MG, 2000, J INTELL MANUF, V11, P403, DOI 10.1023/A:1008930403506
   Odom H.M., 2016, CONTROLLED ENV PLANT
   Odrey NG, 2003, ROBOT CIM-INT MANUF, V19, P35, DOI 10.1016/S0736-5845(02)00060-1
   Onori M., 2006, INF TECHNOL BALANCED, V220, P500
   Peschl M, 2011, J IND ENG MANAG-JIEM, V4, P718, DOI 10.3926/jiem.371
   Petrick IJ, 2013, RES TECHNOL MANAGE, V56, P12, DOI 10.5437/08956308X5606193
   Piller FT, 2015, LECT N PROD ENG, P39, DOI 10.1007/978-3-319-12304-2_4
   Postawa A., 2012, SUSTAINABLE MANUFACT, P175
   Renna P., 2012, PRODUCTION MANUFACTU
   Scheifele S., 2015, FAIM 2015 WOLV UK
   Scheifele S, 2016, PROC TECH, V26, P349, DOI 10.1016/j.protcy.2016.08.045
   Scholz S, 2016, ROBOT CIM-INT MANUF, V40, P14, DOI 10.1016/j.rcim.2015.12.006
   Schuh G., 2003, ZWF Zeitschrift fur Wirtschaftlichen Fabrikbetrieb, V98, P210
   Schuh G, 2014, PROC CIRP, V17, P469, DOI 10.1016/j.procir.2014.01.069
   Scott C., 2016, MAKER FAIRE ORLANDO
   Shah R, 2003, J OPER MANAG, V21, P129, DOI 10.1016/S0272-6963(02)00108-0
   Stich V., 2011, CONC ENT ICE 2011 17, P1
   Suri R, 1998, QUICK RESPONSE MANUF
   Suri R., 2016, ITS TIME COMPETITIVE
   Thoben R., 1999, PARALLELROBOTER AUTO
   Thomas DS, 2014, COSTS COST EFFECTIVE
   Toffler A., 1981, 3 WAVE
   Tuokko R., 2011, MAN 2011 C OCT, P2011
   Ueda K, 2004, CIRP ANN-MANUF TECHN, V53, P385, DOI 10.1016/S0007-8506(07)60722-7
   Um Y., 2010, J BIOENVIRON CONTROL
   Warnecke HJ, 2003, MANUFACTURING TECHNOLOGIES FOR MACHINES OF THE FUTURE: 21ST CENTURY TECHNOLOGIES, P63
   Wu D., 2012, P ASME 2012 INT DES, P18
NR 59
TC 1
Z9 1
U1 6
U2 10
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0736-5845
EI 1879-2537
J9 ROBOT CIM-INT MANUF
JI Robot. Comput.-Integr. Manuf.
PD OCT
PY 2018
VL 53
BP 1
EP 20
DI 10.1016/j.rcim.2018.02.008
PG 20
WC Computer Science, Interdisciplinary Applications; Engineering,
   Manufacturing; Robotics
SC Computer Science; Engineering; Robotics
GA GL3LX
UT WOS:000437037900001
DA 2019-02-18
ER

PT J
AU Cohen-Lhyver, B
   Argentieri, S
   Gas, B
AF Cohen-Lhyver, Benjamin
   Argentieri, Sylvain
   Gas, Bruno
TI The Head Turning Modulation System: An Active Multimodal Paradigm for
   Intrinsically Motivated Exploration of Unknown Environments
SO FRONTIERS IN NEUROROBOTICS
LA English
DT Article
DE multimodal perception; attention; motivation; active learning; binaural
   audition
ID SELF-ORGANIZING MAP; VISUAL-ATTENTION; BASAL GANGLIA; COMPUTATIONAL
   MODEL; ACTION SELECTION; NEURAL-NETWORKS; HUMAN BRAIN; LOCALIZATION;
   MECHANISMS; MOVEMENTS
AB Over the last 20 years, a significant part of the research in exploratory robotics partially switches from looking for the most efficient way of exploring an unknown environment to finding what could motivate a robot to autonomously explore it. Moreover, a growing literature focuses not only on the topological description of a space (dimensions, obstacles, usable paths, etc.) but rather on more semantic components, such as multimodal objects present in it. In the search of designing robots that behave autonomously by embedding life-long learning abilities, the inclusion of mechanisms of attention is of importance. Indeed, be it endogenous or exogenous, attention constitutes a form of intrinsic motivation for it can trigger motor command toward specific stimuli, thus leading to an exploration of the space. The Head Turning Modulation model presented in this paper is composed of two modules providing a robot with two different forms of intrinsic motivations leading to triggering head movements toward audiovisual sources appearing in unknown environments. First, the Dynamic Weighting module implements a motivation by the concept of Congruence, a concept defined as an adaptive form of semantic saliency specific for each explored environment. Then, the Multimodal Fusion and Inference module implements a motivation by the reduction of Uncertainty through a self-supervised online learning algorithm that can autonomously determine local consistencies. One of the novelty of the proposed model is to solely rely on semantic inputs (namely audio and visual labels the sources belong to), in opposition to the traditional analysis of the low-level characteristics of the perceived data. Another contribution is found in the way the exploration is exploited to actively learn the relationship between the visual and auditory modalities. Importantly, the robot-endowed with binocular vision, binaural audition and a rotating head-does not have access to prior information about the different environments it will explore. Consequently, it will have to learn in real-time what audiovisual objects are of "importance" in order to rotate its head toward them. Results presented in this paper have been obtained in simulated environments as well as with a real robot in realistic experimental conditions.
C1 [Cohen-Lhyver, Benjamin; Argentieri, Sylvain; Gas, Bruno] Sorbonne Univ, Inst Syst Intelfigents & Robot, CNRS, Paris, France.
RP Argentieri, S (reprint author), Sorbonne Univ, Inst Syst Intelfigents & Robot, CNRS, Paris, France.
EM sylvain.argentieri@sorbonne-universite.fr
FU European FP7 TWO!EARS project [ICT-618075]
FX This work is supported by the European FP7 TWO!EARS project, ICT-618075,
   www.twoears.eu.
CR Alameda-Pineda X, 2015, INT J ROBOT RES, V34, P437, DOI 10.1177/0278364914548050
   Baranes A, 2010, IEEE INT C INT ROBOT, P1766, DOI 10.1109/IROS.2010.5651385
   Baranes A, 2009, IEEE T AUTON MENT DE, V1, P155, DOI 10.1109/TAMD.2009.2037513
   Bauer J., 2013, INT JOINT C ART INT, P1226
   Berlyne DE, 1950, B J PSYCHOL-GEN SECT, V41, P68, DOI 10.1111/j.2044-8295.1950.tb00262.x
   Berlyne D.E, 1965, STRUCTURE DIRECTION
   Braitenberg V., 1986, VEHICLES EXPT SYNTHE
   Bustamante G, 2016, INT CONF ACOUST SPEE, P6325, DOI 10.1109/ICASSP.2016.7472894
   CAPDEPUY P, 2007, P 2007 IEEE S ART LI, P207
   Carrillo H, 2015, IEEE INT CONF ROBOT, P487, DOI 10.1109/ICRA.2015.7139224
   Chapelle O., 2002, ADV NEURAL INFORM PR, V15, P1
   Cohen-Lhyver B, 2017, THESIS
   Cohen-Lhyver B., 2016, INT C AC
   Cohen-Lhyver B., 2015, IEEE INT C ROB BIOM
   Corbetta M, 2002, NAT REV NEUROSCI, V3, P201, DOI 10.1038/nrn755
   Corbetta M, 2008, NEURON, V58, P306, DOI 10.1016/j.neuron.2008.04.017
   Corneil BD, 2008, NAT NEUROSCI, V11, P13, DOI 10.1038/nn2023
   Cuperlier Nicolas, 2007, Front Neurorobot, V1, P3, DOI 10.3389/neuro.12.003.2007
   Downar J, 2000, NAT NEUROSCI, V3, P277
   Driver J, 1998, TRENDS COGN SCI, V2, P254, DOI 10.1016/S1364-6613(98)01188-7
   Droniou A, 2015, ROBOT AUTON SYST, V71, P83, DOI 10.1016/j.robot.2014.11.005
   Duangudom V, 2007, EUR SIGN PROC C
   Ferreira JF, 2014, IEEE T AUTON MENT DE, V6, P110, DOI 10.1109/TAMD.2014.2303072
   Girard B., 2002, ANIMALS ANIMATS, V7, P75
   Gurney K, 2001, BIOL CYBERN, V84, P411, DOI 10.1007/PL00007985
   Gurney K, 2001, BIOL CYBERN, V84, P401, DOI 10.1007/PL00007984
   Henneberger G., 1991, EPE '91. 4th European Conference on Power Electronics and Applications, P664
   Hinterstoisser S, 2012, IEEE T PATTERN ANAL, V34, P876, DOI 10.1109/TPAMI.2011.206
   Hopfinger JB, 2000, NAT NEUROSCI, V3, P284
   Hornstein J, 2006, 2006 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-12, P1170, DOI 10.1109/IROS.2006.281849
   Huang GB, 2006, IEEE T NEURAL NETWOR, V17, P863, DOI 10.1109/TNN.2006.875974
   Huang X, 2004, LECT NOTES COMPUT SC, V3058, P17
   Hunt J. M. V., 1965, NEBRASKA S MOTIVATIO, V13, P189
   Indovina I, 2007, CEREB CORTEX, V17, P1701, DOI 10.1093/cercor/bhl081
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   James W, 1890, PRINCIPLES PSYCHOL
   Kayser C, 2005, CURR BIOL, V15, P1943, DOI 10.1016/j.cub.2005.09.040
   KOHONEN T, 1982, BIOL CYBERN, V43, P59, DOI 10.1007/BF00337288
   KOHONEN T, 1990, P IEEE, V78, P1464, DOI 10.1109/5.58325
   Kohonen T, 2013, NEURAL NETWORKS, V37, P52, DOI 10.1016/j.neunet.2012.09.018
   Lanillos P., 2015, I EL EL ENG IEEE RSJ, DOI [10.1109/IROS.2015.7353967, DOI 10.1109/IROS.2015.7353967]
   Le Meur O, 2006, IEEE T PATTERN ANAL, V28, P802, DOI 10.1109/TPAMI.2006.86
   Le Meur O, 2015, VISION RES, V116, P152, DOI 10.1016/j.visres.2014.12.026
   Ma N., 2015, INTERSPEECH
   Ma N, 2017, IEEE-ACM T AUDIO SPE, V25, P2444, DOI 10.1109/TASLP.2017.2750760
   Makarenko AA, 2002, 2002 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-3, PROCEEDINGS, P534, DOI 10.1109/IRDS.2002.1041445
   May T, 2011, IEEE T AUDIO SPEECH, V19, P1, DOI 10.1109/TASL.2010.2042128
   Meyer JA, 2005, ROBOT AUTON SYST, V50, P211, DOI 10.1016/j.robot.2004.09.018
   Montemerlo M, 2002, EIGHTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-02)/FOURTEENTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE (IAAI-02), PROCEEDINGS, P593
   NAATANEN R, 1978, ACTA PSYCHOL, V42, P313, DOI 10.1016/0001-6918(78)90006-9
   Nakashima H, 2005, IEEE SYS MAN CYBERN, P3534
   Nothdurft HC, 2006, VIS COGN, V14, P514, DOI 10.1080/13506280500194162
   O'Keefe J., 1978, HIPPOCAMPUS COGNITIV
   Oliva A., 2003, P INT C IEEE, V1, P1
   Oudeyer P.Y., 2008, P 8 INT C EP ROB MOD
   Oudeyer PY, 2007, IEEE T EVOLUT COMPUT, V11, P265, DOI 10.1109/TEVC.2006.890271
   Paplinski AP, 2005, LECT NOTES ARTIF INT, V3801, P81
   Petersen SE, 2012, ANNU REV NEUROSCI, V35, P73, DOI 10.1146/annurev-neuro-062111-150525
   Redgrave P, 1999, NEUROSCIENCE, V89, P1009, DOI 10.1016/S0306-4522(98)00319-4
   Roy N., 2001, INT C MACH LEARN
   Ruesch J, 2008, IEEE INT CONF ROBOT, P962, DOI 10.1109/ROBOT.2008.4543329
   Rushworth MFS, 2011, NEURON, V70, P1054, DOI 10.1016/j.neuron.2011.05.014
   Ryan RM, 2000, CONTEMP EDUC PSYCHOL, V25, P54, DOI 10.1006/ceps.1999.1020
   Schillaci G, 2014, FOUTH JOINT IEEE INTERNATIONAL CONFERENCES ON DEVELOPMENT AND LEARNING AND EPIGENETIC ROBOTICS (IEEE ICDL-EPIROB 2014), P130, DOI 10.1109/DEVLRN.2014.6982967
   SCHMIDHUBER J, 1991, IEEE IJCNN, P1458, DOI 10.1109/IJCNN.1991.170605
   Schymura C., 2014, FOURM ACUSTICUM, DOI [10.13140/2.1.4026.4966, DOI 10.13140/2.1.4026.4966]
   Senocak Arda, 2018, 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition. Proceedings, P4358, DOI 10.1109/CVPR.2018.00458
   Smith R., 1987, 4 INT S ROB RES, P467
   THOMPSON GC, 1978, J NEUROPHYSIOL, V41, P1183
   TREISMAN AM, 1980, COGNITIVE PSYCHOL, V12, P97, DOI 10.1016/0010-0285(80)90005-5
   Tsiami A, 2016, INT CONF ACOUST SPEE, P2847, DOI 10.1109/ICASSP.2016.7472197
   Two! Ears, 2016, TECHNICAL REPORT
   Two! Ears, 2016, THE 2 EARS PROJECT
   WALTER WG, 1951, SCI AM, V185, P60, DOI DOI 10.1038/SCIENTIFICAMERICAN0851-60
   Walther D, 2005, COMPUT VIS IMAGE UND, V100, P41, DOI 10.1016/j.cviu.2004.09.004
   Walther T, 2014, FORUM ACUSTICUM
   Xiao Huang, 2002, Proceedings of the Second International Workshop on Epigenetic Robotics. Modeling Cognitive Development in Robotics Systems, P47
   Zhou D., 2004, ADV NEURAL INFORM PR, V1
NR 78
TC 0
Z9 0
U1 1
U2 1
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1662-5218
J9 FRONT NEUROROBOTICS
JI Front. Neurorobotics
PD SEP 21
PY 2018
VL 12
AR 60
DI 10.3389/fnbot.2018.00060
PG 23
WC Computer Science, Artificial Intelligence; Robotics; Neurosciences
SC Computer Science; Robotics; Neurosciences & Neurology
GA GU4UU
UT WOS:000445281100001
PM 30297995
OA DOAJ Gold, Green Published
DA 2019-02-18
ER

PT J
AU Bodden, C
   Rakita, D
   Mutlu, B
   Gleicher, M
AF Bodden, Christopher
   Rakita, Daniel
   Mutlu, Bilge
   Gleicher, Michael
TI A flexible optimization-based method for synthesizing intent-expressive
   robot arm motion
SO INTERNATIONAL JOURNAL OF ROBOTICS RESEARCH
LA English
DT Article
DE Human-robot interaction; trajectory optimization; legible robot motion;
   intent-expressive robot motion
ID PERCEPTION
AB We present an approach to synthesize robot arm trajectories that effectively communicate the robot's intent to a human collaborator while achieving task goals. Our approach uses nonlinear constrained optimization to encode task requirements and desired motion properties. Our implementation allows for a wide range of constraints and objectives. We introduce a novel objective function to optimize robot arm motions for intent-expressiveness that works in a range of scenarios and robot arm types. Our formulation supports experimentation with different theories of how viewers interpret robot motion. Through a series of human-subject experiments on real and simulated robots, we demonstrate that our method leads to improved collaborative performance against other methods, including the current state of the art. These experiments also show how our perception heuristic can affect collaborative outcomes.
C1 [Bodden, Christopher; Rakita, Daniel; Mutlu, Bilge; Gleicher, Michael] Univ Wisconsin, Dept Comp Sci, 1210 West Dayton St, Madison, WI 53706 USA.
RP Rakita, D (reprint author), Univ Wisconsin, Dept Comp Sci, 1210 West Dayton St, Madison, WI 53706 USA.
EM rakita@cs.wisc.edu
FU National Science Foundation [1208632]; University of Wisconsin-Madison
   Office of the Vice Chancellor for Research and Graduate Education;
   Wisconsin Alumni Research Foundation
FX This work was supported by the National Science Foundation (National
   Robotics Initiative Award Number 1208632) and the University of
   Wisconsin-Madison Office of the Vice Chancellor for Research and
   Graduate Education with funding from the Wisconsin Alumni Research
   Foundation.
CR ATKESON CG, 1985, J NEUROSCI, V5, P2318
   Barrett HC, 2005, EVOL HUM BEHAV, V26, P313, DOI 10.1016/j.evolhumbehav.2004.08.015
   Betts JT, 1998, J GUID CONTROL DYNAM, V21, P193, DOI 10.2514/2.4231
   Blake R, 2007, ANNU REV PSYCHOL, V58, P47, DOI 10.1146/annurev.psych.57.102904.190152
   Blakemore SJ, 2001, NAT REV NEUROSCI, V2, P561, DOI 10.1038/35086023
   Bodden C, 2016, 2016 RO MAN
   Bortot D, 2013, ACMIEEE INT CONF HUM, P89, DOI 10.1109/HRI.2013.6483515
   Busch B, 2017, INT J SOCIAL ROBOTIC
   Dragan A, 2013, P ROBOTICS SCI SYSTE
   Dragan AD, 2015, ACMIEEE INT CONF HUM, P51, DOI 10.1145/2696454.2696473
   Dragan AD, 2013, ACMIEEE INT CONF HUM, P301, DOI 10.1109/HRI.2013.6483603
   GERGELY G, 1995, COGNITION, V56, P165, DOI 10.1016/0010-0277(95)00661-H
   Gleicher M, 2001, GRAPH MODELS, V63, P107, DOI 10.1006/gmod.2001.0549
   Gleicher M, 1998, P 25 ANN C COMP GRAP, P33
   Gleicher M, 1994, THESIS
   Hoffman G, 2015, RSS WORKSH HUM ROB C
   Holladay RM, 2014, IEEE ROMAN, P217, DOI 10.1109/ROMAN.2014.6926256
   Kalakrishnan M., 2011, 2011 IEEE International Conference on Robotics and Automation (ICRA 2011), P4569, DOI 10.1109/ICRA.2011.5980280
   Kamewari K, 2005, COGNITIVE DEV, V20, P303, DOI 10.1016/j.cogdev.2005.04.004
   Kiesler S, 2008, SOC COGNITION, V26, P169, DOI 10.1521/soco.2008.26.2.169
   Lichtenthaler C., 2012, 2012 RO-MAN: The 21st IEEE International Symposium on Robot and Human Interactive Communication, P676, DOI 10.1109/ROMAN.2012.6343829
   Lichtenthaler C, 2014, P 2014 ACM IEEE INT, P228
   Lichtenthaler C, 2016, LEGIBILITY ROBOT BEH
   MORASSO P, 1981, EXP BRAIN RES, V42, P223
   Nikolaidis S, 2016, ELEVENTH ACM/IEEE INTERNATIONAL CONFERENCE ON HUMAN ROBOT INTERACTION (HRI'16), P271, DOI 10.1109/HRI.2016.7451762
   Ratliff ND, 2009, P IEEE INT C ROB AUT, P489, DOI DOI 10.1109/ROBOT.2009.5152817
   Schulman J., 2013, ROBOTICS SCI SYSTEMS, V9, P1
   Szafir D, 2014, ACMIEEE INT CONF HUM, P358, DOI 10.1145/2559636.2559672
   Szafir D, 2015, ACMIEEE INT CONF HUM, P19, DOI 10.1145/2696454.2696475
   Takayama L, 2011, ACMIEEE INT CONF HUM, P69, DOI 10.1145/1957656.1957674
   Thomas Frank, 1995, ILLUSION LIFE DISNEY
   VanBreemen A, 2004, CHI WORKSH SHAP HUM
   Witkin A., 1988, Computer Graphics, V22, P159
   Woods S, 2006, 9TH IEEE INTERNATIONAL WORKSHOP ON ADVANCED MOTION CONTROL, VOLS 1 AND 2, PROCEEDINGS, P750, DOI 10.1109/AMC.2006.1631754
   Zhao M, 2014, ISER, P639
NR 35
TC 0
Z9 0
U1 3
U2 3
PU SAGE PUBLICATIONS LTD
PI LONDON
PA 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND
SN 0278-3649
EI 1741-3176
J9 INT J ROBOT RES
JI Int. J. Robot. Res.
PD SEP
PY 2018
VL 37
IS 11
BP 1376
EP 1394
DI 10.1177/0278364918792295
PG 19
WC Robotics
SC Robotics
GA HD6JS
UT WOS:000452645000004
DA 2019-02-18
ER

PT J
AU Gombolay, M
   Yang, XJ
   Hayes, B
   Seo, N
   Liu, ZX
   Wadhwania, S
   Yu, T
   Shah, N
   Golen, T
   Shah, J
AF Gombolay, Matthew
   Yang, Xi Jessie
   Hayes, Bradley
   Seo, Nicole
   Liu, Zixi
   Wadhwania, Samir
   Yu, Tania
   Shah, Neel
   Golen, Toni
   Shah, Julie
TI Robotic assistance in the coordination of patient care
SO INTERNATIONAL JOURNAL OF ROBOTICS RESEARCH
LA English
DT Article
DE Human-robot teaming; human-robot interaction; planning and scheduling;
   situational awareness; workload; preference scheduling
ID SUPERVISORY CONTROL; AUTOMATION; PERFORMANCE; CAPACITY; RELIANCE;
   SAFETY; TRUST; AGENT; MODEL
AB We conducted a study to investigate Mist in and dependence upon robotic decision support among nurses and doctors on a labor and delivery floor. There is evidence that suggestions provided by embodied agents engender inappropriate degrees of trust and reliance among humans. This concern represents a critical barrier that must be addressed before fielding intelligent hospital service robots that take initiative to coordinate patient care. We conducted our experiment with nurses and physicians, and evaluated the subjects' levels of trust in and dependence upon high- and low-quality recommendations issued by robotic versus computer-based decision support. The decision support, generated through action-driven learning from expert demonstration, produced high-quality recommendations that were accepted by nurses and physicians at a compliance rate of 90%. Rates of Type I and Type II errors were comparable between robotic and computer-based decision support. Furthermore, embodiment appeared to benefit performance, as indicated by a higher degree of appropriate dependence after the quality of recommendations changed over the course of the experiment. These results support the notion that a robotic assistant may be able to safely and effectively assist with patient care. Finally, we conducted a pilot demonstration in which a robot-assisted resource nurses on a labor and delivery floor at a tertiary care center.
C1 [Gombolay, Matthew; Yang, Xi Jessie; Hayes, Bradley; Seo, Nicole; Liu, Zixi; Wadhwania, Samir; Yu, Tania; Shah, Julie] MIT, 77 Massachusetts Ave, Cambridge, MA 02139 USA.
   [Shah, Neel; Golen, Toni] Beth Israel Deaconess Med Ctr, Boston, MA 02215 USA.
RP Gombolay, M (reprint author), Georgia Inst Technol, North Ave NW, Atlanta, GA 30332 USA.
EM Matthew.Gombolay@cc.gatech.edu
FU National Science Foundation Graduate Research Fellowship Program
   [23883577]; CRICO Harvard Risk Management Foundation; Aldebaran Robotics
   Inc.
FX This work was supported by the National Science Foundation Graduate
   Research Fellowship Program under grant number 23883577, CRICO Harvard
   Risk Management Foundation, and Aldebaran Robotics Inc.
CR Abbeel Pieter, 2004, ICML
   Bainbridge WA, 2011, INT J SOC ROBOT, V3, P41, DOI 10.1007/s12369-010-0082-7
   Bartneck C, 2009, INT J SOC ROBOT, V1, P71, DOI 10.1007/s12369-008-0001-3
   Bertsimas D, 2005, OPTIMIZATION INTEGER
   Bloss R, 2011, IND ROBOT, V38, P567, DOI 10.1108/01439911111179075
   Brandenburg L, 2015, TECHNICAL REPORT
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Chen JYC, 2011, IEEE T SYST MAN CY C, V41, P435, DOI 10.1109/TSMCC.2010.2056682
   Cheng TH, 2006, COMP MED SY, P165
   Cummings ML, 2007, HUM FACTORS, V49, P1, DOI 10.1518/001872007779598109
   de Visser Ewart J., 2012, P HUM FACT ERG SOC A, P263, DOI DOI 10.1177/1071181312561062
   Desai M, 2013, ACMIEEE INT CONF HUM, P251, DOI 10.1109/HRI.2013.6483596
   Desai M, 2012, ACMIEEE INT CONF HUM, P73
   DiGiose N, 2013, HOSP HIRING ROBOTS
   Dismukes RK, 2007, LIMITS EXPERTISE RET
   Dixon SR, 2006, HUM FACTORS, V48, P474, DOI 10.1518/001872006778606822
   DUDA RO, 1972, COMMUN ACM, V15, P11, DOI 10.1145/361237.361242
   Gombolay M, 2014, P ROB SCI SYST RSS B
   Gombolay M, 2014, P HUM ROB INT PION W, P62
   Gombolay M, 2014, P AAAI FALL S SER AR
   Gombolay M, 2016, P ROB SCI SYST RSS A
   Gombolay M, 2017, P ASS ADV ART INT AA
   Gombolay M., 2016, P INT JOINT C ART IN
   Gombolay M, 2013, P ROB SCI S RSS HUM
   Gombolay MC, 2015, AUTON ROBOT, V39, P293, DOI 10.1007/s10514-015-9457-9
   Goodyear K, 2016, FRONT HUM NEUROSCI, V10, DOI 10.3389/fnhum.2016.00542
   Hu John, 2011, 2011 IEEE International Conference on Robotics and Automation (ICRA 2011), P6264, DOI 10.1109/ICRA.2011.5980213
   Jansen N, 2017, P AMER CONTR CONF, P1866, DOI 10.23919/ACC.2017.7963224
   Jian J., 2000, INT J COGNITIVE ERGO, V4, P53, DOI DOI 10.1207/S15327566IJCE0401_04
   Jin R., 2008, P 17 WWW BEIJ CHIN A, P397
   Kaber DB, 1997, PROCESS SAF PROG, V16, P126, DOI 10.1002/prs.680160304
   Kehle SM, 2011, J GEN INTERN MED, V26, pS689, DOI 10.1007/s11606-011-1849-8
   Kidd C. D., 2004, 2004 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) (IEEE Cat. No.04CH37566), P3559
   Kiesler S, 2008, SOC COGNITION, V26, P169, DOI 10.1521/soco.2008.26.2.169
   Konidaris G., 2011, P 25 C ART INT, P380
   Kulic D, 2016, IEEE T ROBOT, V32, P776, DOI 10.1109/TRO.2016.2587744
   Lee JD, 2004, HUM FACTORS, V46, P50, DOI 10.1518/hfes.46.1.50.30392
   Lee KM, 2006, J COMMUN, V56, P754, DOI 10.1111/j.1460-2466.2006.00318.x
   Levenshtein V, 1966, SOV PHYS DOKL, V10, P707, DOI DOI 10.1109/TVCG.2012.323
   Leyzberg D, 2014, ACMIEEE INT CONF HUM, P423, DOI 10.1145/2559636.2559671
   Li W., 2014, LNCS, P470, DOI DOI 10.1007/978-3-642-54862-8
   Mnih V, 2015, NATURE, V518, P529, DOI 10.1038/nature14236
   Molina RL, 2018, J OBSTET GYNECOLOGY
   Murai R, 2012, 2012 IEEE/SICE INTERNATIONAL SYMPOSIUM ON SYSTEM INTEGRATION (SII), P510, DOI 10.1109/SII.2012.6427311
   Murai R, 2012, 2012 IEEE/SICE INTERNATIONAL SYMPOSIUM ON SYSTEM INTEGRATION (SII), P621, DOI 10.1109/SII.2012.6426953
   Mutlu B., 2008, 2008 3rd ACM/IEEE International Conference on Human-Robot Interaction (HRI 2008), P287
   Odom P., 2015, P AAAI, P4186
   Ozkil AG, 2009, 2009 IEEE INTERNATIONAL CONFERENCE ON AUTOMATION AND LOGISTICS ( ICAL 2009), VOLS 1-3, P289, DOI 10.1109/ICAL.2009.5262912
   Pak R, 2012, ERGONOMICS, V55, P1059, DOI 10.1080/00140139.2012.691554
   Parasuraman R, 2000, IEEE T SYST MAN CY A, V30, P286, DOI 10.1109/3468.844354
   Pizer SD, 2011, J GEN INTERN MED, V26, pS676, DOI 10.1007/s11606-011-1819-1
   Raghavan H, 2006, J MACH LEARN RES, V7, P1655
   Robinette P, 2016, P HRI
   Schroder M., 2003, International Journal of Speech Technology, V6, P365, DOI 10.1023/A:1025708916924
   Sheridan TB, 2011, IEEE T SYST MAN CY A, V41, P662, DOI 10.1109/TSMCA.2010.2093888
   Shipman SA, 2013, HEALTH AFFAIR, V32, P1990, DOI 10.1377/hlthaff.2013.0539
   Takayama L, 2009, 2009 IEEE-RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, P5495, DOI 10.1109/IROS.2009.5354145
   Tapus Adriana, 2009, RO-MAN 2009 - The 18th IEEE International Symposium on Robot and Human Interactive Communication, P103, DOI 10.1109/ROMAN.2009.5326211
   Tsivtsivadze E., 2007, SIGIR 2007 WORKSH LE, P27
   Vogel A., 2012, P 26 C ART INT TOR O, P384
   Wang YC, 2005, ENG APPL ARTIF INTEL, V18, P73, DOI 10.1016/j.engappai.2004.08.018
   Wei Zhang, 1995, IJCAI-95. Proceedings of the Fourteenth International Joint Conference on Artificial Intelligence, P1114
   Wickens C. D., 2010, P HUM FACT ERG SOC A, V54, P389, DOI DOI 10.1177/154193121005400425
   Wickens CD., 2013, ENG PSYCHOL HUMAN PE
   Winston WL, 2003, INTRO MATH PROGRAMMI, V1
   Wood SB, 2004, P SIGCHI C HUM FACT, P231
   Wu J, 2011, FUTURE GENER COMP SY, V27, P430, DOI 10.1016/j.future.2010.10.009
   Zheng J, 2014, AAAI, P2198
   Ziebart B.D., 2008, AAAI, P1433
NR 69
TC 0
Z9 0
U1 1
U2 1
PU SAGE PUBLICATIONS LTD
PI LONDON
PA 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND
SN 0278-3649
EI 1741-3176
J9 INT J ROBOT RES
JI Int. J. Robot. Res.
PD SEP
PY 2018
VL 37
IS 10
SI SI
BP 1300
EP 1316
DI 10.1177/0278364918778344
PG 17
WC Robotics
SC Robotics
GA HA8TN
UT WOS:000450566600011
DA 2019-02-18
ER

PT J
AU Komatsubara, T
   Shiomi, M
   Kanda, T
   Ishiguro, H
AF Komatsubara, Tsuyoshi
   Shiomi, Masahiro
   Kanda, Takayuki
   Ishiguro, Hiroshi
TI Can Using Pointing Gestures Encourage Children to Ask Questions?
SO INTERNATIONAL JOURNAL OF SOCIAL ROBOTICS
LA English
DT Article
DE Social robot; Deictic interaction; Robots for children
ID RECOGNITION; SPEECH
AB Even though asking questions is fundamental for self-motivated learning, children often have difficulty verbalizing them. Hence, we hypothesized that a robot's capability to perceive pointing gestures will encourage children to ask more questions. We experimentally tested this hypothesis with the Wizard-of-Oz technique with 92 elementary-school students who interacted with our robot in a situation where it served as a guide who explains a museum exhibit. The children asked the robot significantly more questions when it could perceive pointing gestures than when it lacked such a capability. We also discuss the possibility of implementing autonomous robots based on the findings of our Wizard-of-Oz approach.
C1 [Komatsubara, Tsuyoshi; Shiomi, Masahiro; Kanda, Takayuki] ATR, 2-2-2 Hikaridai, Kyoto 6190288, Japan.
   [Ishiguro, Hiroshi] Osaka Univ, 1-3 Machikaneyama, Toyonaka, Osaka 5608531, Japan.
RP Shiomi, M (reprint author), ATR, 2-2-2 Hikaridai, Kyoto 6190288, Japan.
EM komatsubara.tsuyoshi@atr.jp; m-shiomi@atr.jp; kanda@atr.jp;
   ishiguro@sys.es.osaka-u.ac.jp
FU JSPS [25240042, 25280095]; JSPS KAKENHI [JP15H05322, JP16K12505]
FX We thank the assistants for their support during our experiments. This
   work was in part supported by JSPS Grants-in-aid for Scientific Research
   Nos. 25240042 and 25280095 and JSPS KAKENHI Grant Nos. JP15H05322 and
   JP16K12505.
CR Alibali MW, 1999, COGNITIVE DEV, V14, P37, DOI 10.1016/S0885-2014(99)80017-3
   ALIBALI MW, 2005, SPAT COGN COMPUT, V5, P307, DOI DOI 10.1207/S15427633SCC0504_2
   Anderson L.W., 2001, TAXONOMY LEARNING TE
   Breazeal C, 2005, 2005 IEEE/RSJ International Conference on Intelligent Robots and Systems, Vols 1-4, P383, DOI 10.1109/IROS.2005.1545011
   Bremner P, 2016, FRONT PSYCHOL, V7, P1
   Brscic D, 2013, IEEE T HUM-MACH SYST, V43, P522, DOI 10.1109/THMS.2013.2283945
   Cosgun A, 2015, INT WORKSH FRAM JOIN
   Dahlback N, 1993, P 1 INT C INT US INT, DOI 10.1016/0950-7051(93)90017-N
   Dautenhahn K, 2007, INT J ADV ROBOT SYST, V4, P15, DOI DOI 10.5772/5702
   DITTMANN AT, 1969, J PERS SOC PSYCHOL, V11, P98, DOI 10.1037/h0027035
   Droeschel D, 2011, IEEE INT CONF ROBOT, P1205
   Ghosh M, 2014, J ROBOT, DOI 10.1155/2014/876439
   Goldin-Meadow S, 2005, HEARING GESTURE OUR
   GOLDINMEADOW S, 1993, PSYCHOL REV, V100, P279, DOI 10.1037/0033-295X.100.2.279
   Han J, 2005, ROBOT HUMAN INTERACT, P378, DOI DOI 10.1109/ROMAN.2005.1513808
   Hato Y, 2010, ACMIEEE INT CONF HUM, P301, DOI 10.1109/HRI.2010.5453180
   HEWES GW, 1992, CURR ANTHROPOL, V33, P65, DOI 10.1086/204019
   Howley I, 2014, ACMIEEE INT CONF HUM, P415, DOI 10.1145/2559636.2559667
   Huang CM, 2013, P ROB SCI SYST C, P57
   Krauss RM, 1998, CURR DIR PSYCHOL SCI, V7, P54, DOI 10.1111/1467-8721.ep13175642
   Kuzuoka H., 2000, CSCW 2000. ACM 2000 Conference on Computer Supported Cooperative Work, P155
   Li Q, 2001, EUR C SPEECH COMM TE, P2671
   Lohse M, 2014, P 32 ANN ACM C HUM F, P1459
   Matlen BJ, 2012, SPATIAL COGNITION 8, P405
   McCombs Barbara L., 1997, LEARNER CTR CLASSROO
   McNeill D., 1992, HAND MIND WHAT GESTU
   Nagi J, 2014, IEEE INT C INT ROBOT, P3834, DOI 10.1109/IROS.2014.6943101
   Ng-Thow-Hing Victor, 2010, 2010 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2010), P4617, DOI 10.1109/IROS.2010.5654322
   Okuno Y., 2009, 2009 4th ACM/IEEE International Conference on Human-Robot Interaction (HRI), P53
   Pine KJ, 2007, DEVELOPMENTAL SCI, V10, P747, DOI 10.1111/j.1467-7687.2007.00610.x
   Rauscher FH, 1996, PSYCHOL SCI, V7, P226, DOI 10.1111/j.1467-9280.1996.tb00364.x
   Saerbeck M, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1613
   Sauppe A, 2014, ACMIEEE INT CONF HUM, P342, DOI 10.1145/2559636.2559657
   Sauter M, 2012, J EXP CHILD PSYCHOL, V111, P587, DOI 10.1016/j.jecp.2011.11.009
   Scassellati B, 2000, BIOROBOTICS
   Schauerte B, 2014, IEEE INT C INT ROBOT, P995, DOI 10.1109/IROS.2014.6942680
   Schauerte B, 2010, IEEE INT C INT ROBOT, P4638, DOI 10.1109/IROS.2010.5649430
   Shiomi M, 2011, INT J SOC ROBOT, V3, P27, DOI 10.1007/s12369-010-0077-4
   Sugiyama Osamu, 2007, 2007 IEEE/RSJ International Conference on Intelligent Robots and Systems, P1441
   Thrun S, 1999, ICRA '99: IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS 1-4, PROCEEDINGS, P1999, DOI 10.1109/ROBOT.1999.770401
   Van den Bergh M., 2011, 2011 RO-MAN: The 20th IEEE International Symposium on Robot and Human Interactive Communication, P357, DOI 10.1109/ROMAN.2011.6005195
NR 41
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1875-4791
EI 1875-4805
J9 INT J SOC ROBOT
JI Int. J. Soc. Robot.
PD SEP
PY 2018
VL 10
IS 4
BP 387
EP 399
DI 10.1007/s12369-017-0444-5
PG 13
WC Robotics
SC Robotics
GA GU4BV
UT WOS:000445226600002
DA 2019-02-18
ER

PT J
AU Jones, A
   Bull, S
   Castellano, G
AF Jones, Aidan
   Bull, Susan
   Castellano, Ginevra
TI "I Know That Now, I'm Going to Learn This Next" Promoting Self-regulated
   Learning with a Robotic Tutor
SO INTERNATIONAL JOURNAL OF SOCIAL ROBOTICS
LA English
DT Article
DE Robotic tutors; Personalisation; Self-regulated learning; Child-robot
   interaction
ID STUDENTS; MOTIVATION
AB Robots are increasingly being used to provide motivating, engaging and personalised support to learners. Robotic tutors have been able to increase student learning gain by providing personalised hints or problem selection. However, they have never been used to assist children in developing self regulated learning (SRL) skills. SRL skills allow a learner to more effectively self-assess and guide their own learning; learners that engage these skills have been shown to perform better academically. This paper explores how personalised tutoring by a robot achieved using an open learner model (OLM) promotes SRL processes and how this can impact learning. It presents a study where a robotic tutor supports reflection and SRL processes with an OLM. An OLM allows the learner to view the model that the system holds about them. In this study, participants take part in a geography-based task on a touch screen with different levels of adaptive feedback provided by the robot. The robotic tutor uses an OLM to prompt the learner to monitor their developing skills, set goals, and use appropriate tools. Results show that, when a robotic tutor personalises and adaptively scaffolds SRL behaviour based upon an OLM, greater indication of SRL behaviour and increased learning gain can be observed over control conditions where the robotic tutor does not provide SRL scaffolding. We also find that pressure and tension in the activity increases and perception of the robot is less favourable in conditions where the robotic tutor makes the learner aware that there are issues but does not provide specific help to address these issues.
C1 [Jones, Aidan] Univ Birmingham, Sch Engn, Dept Elect Elect & Syst Engn, Birmingham B15 2TT, W Midlands, England.
   [Bull, Susan] UCL, Inst Educ, London, England.
   [Castellano, Ginevra] Uppsala Univ, Dept Informat Technol, Uppsala, Sweden.
RP Jones, A (reprint author), Univ Birmingham, Sch Engn, Dept Elect Elect & Syst Engn, Birmingham B15 2TT, W Midlands, England.
EM axj100@bham.ac.uk
FU EU FP7 [ICT-317923]; European Commission (EC)
FX This work was supported by the European Commission (EC) and was funded
   by the EU FP7 ICT-317923 Project EMOTE (EMbOdied-perceptive Tutors for
   Empathy-based learning). The authors are solely responsible for the
   content of this publication. It does not represent the opinion of the
   EC, and the EC is not responsible for any use that might be made of data
   appearing therein.
CR Aleven V., 2006, INT J ARTIFICIAL INT, V16, P101
   Azevedo R, 2004, CONTEMP EDUC PSYCHOL, V29, P344, DOI 10.1016/j.cedpsych.2003.09.002
   Azevedo R., 2011, PSYCHOL TESTING ASSE, V53, P106
   Bull S, 2013, INT HDB METACOGNITIO, P349, DOI DOI 10.1007/978-1-4419-5546-3_23
   Bull S, 2010, STUD COMPUT INTELL, V308, P301
   Bull S, 2010, INT J ELEC ENG EDUC, V47, P307, DOI 10.7227/IJEEE.47.3.6
   Clabaugh C, 2015, 5TH INTERNATIONAL CONFERENCE ON DEVELOPMENT AND LEARNING AND ON EPIGENETIC ROBOTICS (ICDL-EPIROB), P314, DOI 10.1109/DEVLRN.2015.7346164
   Desmarais MC, 2012, USER MODEL USER-ADAP, V22, P9, DOI 10.1007/s11257-011-9106-8
   Gordon G, 2015, AAAI C ART INT
   Greczek J, 2014, IEEE ROMAN, P561, DOI 10.1109/ROMAN.2014.6926312
   Hake R. R., 2002, PHYS ED RES C, V8, P1
   Hoffman L., 2011, HRI 2011 WORKSH SOC, P14
   Jones A, 2015, UMAP 2015
   Jones A, 2015, LECT NOTES ARTIF INT, V9388, P285, DOI 10.1007/978-3-319-25554-5_29
   Jones A, 2014, LECT NOTES ARTIF INT, V8755, P186, DOI 10.1007/978-3-319-11973-1_19
   Kennedy J, 2015, ACMIEEE INT CONF HUM, P67, DOI 10.1145/2696454.2696457
   Kidd C, 2003, THESIS
   Koedinger KR, 2009, HDB METACOGNITION ED, P897
   Lajoie SP, 2005, INSTR SCI, V33, P541, DOI 10.1007/s11251-005-1279-2
   Leite I, 2013, INT J SOC ROBOT, V5, P291, DOI 10.1007/s12369-013-0178-y
   Leyzberg D, 2012, P 34 ANN C COGN SCI, P1882
   Leyzberg D, 2014, ACMIEEE INT CONF HUM, P423, DOI 10.1145/2559636.2559671
   Lin JW, 2016, J COMPUT ASSIST LEAR, V32, P77, DOI 10.1111/jcal.12120
   Mataric M, 2014, ACMIEEE INT CONF HUM, P333, DOI 10.1145/2559636.2560043
   MCAULEY E, 1989, RES Q EXERCISE SPORT, V60, P48, DOI 10.1080/02701367.1989.10607413
   Mitrovic A, 2002, 2 INT C AD HYP AD WE
   Mitrovic A., 2007, INT J ARTIFICIAL INT, V17, P121
   Mitrovic A, 2010, STUD COMPUT INTELL, V308, P63
   Ramachandran A, 2014, P WORKSH 28 AAAI C A
   Ramachandran A, 2015, P 10 ANN ACM IEEE IN, P193
   Ramachandran A, 2016, ELEVENTH ACM/IEEE INTERNATIONAL CONFERENCE ON HUMAN ROBOT INTERACTION (HRI'16), P247, DOI 10.1109/HRI.2016.7451759
   Reingold R, 2008, J INTERACT ONLINE LE, V7, P139
   Roll I, 2011, LEARN INSTR, V21, P267, DOI 10.1016/j.learninstruc.2010.07.004
   RYAN RM, 1982, J PERS SOC PSYCHOL, V43, P450, DOI 10.1037/0022-3514.43.3.450
   Sabourin J. L., 2013, THESIS
   Sabourin J, 2013, INT J ARTIF INTELL E, V23, P94, DOI 10.1007/s40593-013-0004-6
   Szafir Daniel, 2012, P SIGCHI C HUM FACT, P11, DOI [DOI 10.1145/2207676.2207679, 10.1145/2207676.2207679]
   Tanaka F, 2007, P NATL ACAD SCI USA, V104, P17954, DOI 10.1073/pnas.0707769104
   Tanaka F, 2012, J HUM-ROBOT INTERACT, V1, P78, DOI 10.5898/JHRI.1.1.Tanaka
   Tongchai N, 2008, THESIS
   Wainer Joshua, 2007, 16th IEEE International Conference on Robot and Human Interactive Communication, P872
   Yanjin Long, 2013, Artificial Intelligence in Education. Proceedings of 16th International Conference (AIED 2013): LNCS 7926, P219, DOI 10.1007/978-3-642-39112-5_23
   Yanjin Long, 2013, Artificial Intelligence in Education. Proceedings of 16th International Conference (AIED 2013): LNCS 7926, P249, DOI 10.1007/978-3-642-39112-5_26
   Zimmerman BJ, 2008, AM EDUC RES J, V45, P166, DOI 10.3102/0002831207312909
NR 44
TC 1
Z9 1
U1 6
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1875-4791
EI 1875-4805
J9 INT J SOC ROBOT
JI Int. J. Soc. Robot.
PD SEP
PY 2018
VL 10
IS 4
BP 439
EP 454
DI 10.1007/s12369-017-0430-y
PG 16
WC Robotics
SC Robotics
GA GU4BV
UT WOS:000445226600005
OA Other Gold
DA 2019-02-18
ER

PT J
AU Rosenthal-von der Putten, AM
   Hoefinghoff, J
AF Rosenthal-von der Puetten, Astrid M.
   Hoefinghoff, Jens
TI The More the Merrier? Effects of Humanlike Learning Abilities on Humans'
   Perception and Evaluation of a Robot
SO INTERNATIONAL JOURNAL OF SOCIAL ROBOTICS
LA English
DT Article
DE Intelligent robots; Experimental studies; Reinforcement learning;
   Human-robot interaction
ID DECISION-MAKING; HUMAN BRAIN; IMITATION
AB In this paper, we present three experimental studies in which subjects trained a robot to do a card game via reinforcement learning. In the first two studies participants interacted with the robot either without any learning ability (control group) or with one out of three versions of a learning algorithm implementing gradually aspects of more humanlike learning abilities. Results show that the implementation of a learning algorithm had positive effects regarding the evaluation of the robot, its learning abilities and the interaction. We found that more humanlike learning abilities do not always lead to better performance and evaluation and that results were to some extend influenced by longer or shorter interaction times. In a third study, we additionally explored the influence of other behavioral variations such as low or high verbal skills and interaction modalities in perceived intelligence of the robot irrespective of the implemented learning algorithm, but did not find significant effects. Results are discussed with regard to the socialness of future interaction scenarios.
C1 [Rosenthal-von der Puetten, Astrid M.; Hoefinghoff, Jens] Univ Duisburg Essen, Forsthausweg 2, D-47048 Duisburg, Germany.
RP Rosenthal-von der Putten, AM (reprint author), Univ Duisburg Essen, Forsthausweg 2, D-47048 Duisburg, Germany.
EM a.rosenthalvdpuetten@uni-due.de; jens.hoefinghoff@uni-due.de
CR Argall BD, 2009, ROBOT AUTON SYST, V57, P469, DOI 10.1016/j.robot.2008.10.024
   Billard A., 2008, SPRINGER HDB ROBOTIC, P1371, DOI DOI 10.1007/978-3-540-30301-5_60
   Blais AR, 2006, JUDGM DECIS MAK, V1, P33
   Calinon S, 2007, IEEE T SYST MAN CY B, V37, P286, DOI 10.1109/TSMCB.2006.886952
   Clouse Jeffery A., 1992, ICML 92, P92
   Damasio A. R., 1994, DESCARTES ERROR EMOT
   DUBE WV, 1989, J EXP ANAL BEHAV, V51, P65, DOI 10.1901/jeab.1989.51-65
   Hester T, 2010, IEEE INT CONF ROBOT, P2369, DOI 10.1109/ROBOT.2010.5509181
   Hoefinghoff J, 2012, P 25 INT FLOR ART IN, P163
   Hoefinghoff J, 2015, THESIS
   Jens H, 2015, LECT NOTES ARTIF INT, V9388, P235, DOI 10.1007/978-3-319-25554-5_24
   Hoefinghoff J, 2015, 2015 24TH IEEE INTERNATIONAL SYMPOSIUM ON ROBOT AND HUMAN INTERACTIVE COMMUNICATION (RO-MAN), P615, DOI 10.1109/ROMAN.2015.7333562
   Kober J, 2013, INT J ROBOT RES, V32, P1238, DOI 10.1177/0278364913495721
   MELTZOFF AN, 1988, CHILD DEV, V59, P217, DOI 10.2307/1130404
   Minsky M., 1975, PSYCHOL COMPUTER VIS, P211
   Nicolescu MN, 2003, P 2 INT JOINT C AUT, P241
   O'Doherty JP, 2004, CURR OPIN NEUROBIOL, V14, P769, DOI 10.1016/j.conb.2004.10.016
   Schaal S, 1999, TRENDS COGN SCI, V3, P233, DOI 10.1016/S1364-6613(99)01327-3
   Sloutsky VM, 2003, TRENDS COGN SCI, V7, P246, DOI 10.1016/S1364-6613(03)00109-8
   Sutton R. S, 1998, REINFORCEMENT LEARNI
   Tapus A, 2008, P AAAI SPRING S EM P, P133
   Tapus A., 2008, INTELLIGENT SERVICE, V1, P169, DOI DOI 10.1007/S11370-008-0017-4
   Thomaz A. L., 2006, AAAI, V1, P1000
   Wunderlich K, 2009, P NATL ACAD SCI USA, V106, P17199, DOI 10.1073/pnas.0901077106
   Zeelenberg M, 1996, ORGAN BEHAV HUM DEC, V65, P148, DOI 10.1006/obhd.1996.0013
NR 25
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1875-4791
EI 1875-4805
J9 INT J SOC ROBOT
JI Int. J. Soc. Robot.
PD SEP
PY 2018
VL 10
IS 4
BP 455
EP 472
DI 10.1007/s12369-017-0445-4
PG 18
WC Robotics
SC Robotics
GA GU4BV
UT WOS:000445226600006
DA 2019-02-18
ER

PT J
AU Andreasson, R
   Alenljung, B
   Billing, E
   Lowe, R
AF Andreasson, Rebecca
   Alenljung, Beatrice
   Billing, Erik
   Lowe, Robert
TI Affective Touch in Human-Robot Interaction: Conveying Emotion to the Nao
   Robot
SO INTERNATIONAL JOURNAL OF SOCIAL ROBOTICS
LA English
DT Article
DE Tactile interaction; Affective touch; Human-robot interaction; Emotion
   encoding; Emotion decoding; Social emotions; Nao robot
ID TACTILE INTERACTION; ARTIFICIAL SKIN; COMMUNICATION; FRAMEWORK;
   BEHAVIOR; GENDER; AGENTS
AB Affective touch has a fundamental role in human development, social bonding, and for providing emotional support in interpersonal relationships. We present, what is to our knowledge, the first HRI study of tactile conveyance of both positive and negative emotions (affective touch) on the Nao robot, and based on an experimental set-up from a study of human-human tactile communication. In the present work, participants conveyed eight emotions to a small humanoid robot via touch. We found that female participants conveyed emotions for a longer time, using more varied interaction and touching more regions on the robot's body, compared to male participants. Several differences between emotions were found such that emotions could be classified by the valence of the emotion conveyed, by combining touch amount and duration. Overall, these results show high agreement with those reported for human-human affective tactile communication and could also have impact on the design and placement of tactile sensors on humanoid robots.
C1 [Andreasson, Rebecca; Alenljung, Beatrice; Billing, Erik] Univ Skovde, Sch Informat, Skovde, Sweden.
   [Andreasson, Rebecca] Uppsala Univ, Dept Informat Technol, Uppsala, Sweden.
   [Lowe, Robert] Univ Gothenburg, Dept Appl IT, Gothenburg, Sweden.
RP Lowe, R (reprint author), Univ Gothenburg, Dept Appl IT, Gothenburg, Sweden.
EM rebecca.andreasson@it.uu.se; beatrice.alenljung@his.se;
   erik.billing@his.se; robert.lowe@gu.se
FU Region Vastra Gotaland (VGR) funding agency
FX The authors would like to thank Dr. Matthew Hertenstein for the
   important discussions regarding this work. This work has been carried
   out as part of the project "Design, Textiles and Sustainable
   Development" funded by Region Vastra Gotaland (VGR) funding agency.
CR Alenljung B, 2017, IEEE ROMAN, P1240, DOI 10.1109/ROMAN.2017.8172463
   App B, 2011, EMOTION, V11, P603, DOI 10.1037/a0023164
   Bailenson J, 2007, HUM-COMPUT INTERACT, V22, P246
   Bandstra NF, 2011, PAIN, V152, P1074, DOI 10.1016/j.pain.2011.01.024
   Barros P, 2016, ADAPT BEHAV, V24, P373, DOI 10.1177/1059712316664017
   Beer JM, 2014, J HUM-ROBOT INTERACT, V3, P74, DOI 10.5898/JHRI.3.2.Beer
   Bickmore TW, 2010, IEEE T AFFECT COMPUT, V1, P60, DOI 10.1109/T-AFFC.2010.4
   Bowlby J., 1973, ATTACHMENT LOSS, V2
   Breazeal C, 2002, DESIGNING SOCIABLE R
   Broadbent E, 2009, INT J SOC ROBOT, V1, P319, DOI 10.1007/s12369-009-0030-6
   Casper J, 2003, IEEE T SYST MAN CY B, V33, P367, DOI 10.1109/TSMCB.2003.811794
   Cho G, 2009, INT J HUM-COMPUT INT, V25, P582, DOI 10.1080/10447310902997744
   Cigales M., 1996, EARLY CHILD DEV CARE, V126, P101
   Cooney MD, 2015, INT J HUM ROBOT, V12, DOI 10.1142/S0219843615500024
   Cooney MD, 2012, IEEE RSJ INT C INT R
   Dahiya RS, 2010, IEEE T ROBOT, V26, P1, DOI 10.1109/TRO.2009.2033627
   Dautenhahn K., 2005, 2005 IEEE/RSJ International Conference on Intelligent Robots and Systems, P1192, DOI 10.1109/IROS.2005.1545189
   Dautenhahn K, 2007, PHILOS T R SOC B, V362, P679, DOI 10.1098/rstb.2006.2004
   Devillers L, 2015, INT J SOC ROBOT, V7, P451, DOI 10.1007/s12369-015-0297-8
   Field T., 2014, TOUCH
   Gallace A, 2010, NEUROSCI BIOBEHAV R, V34, P246, DOI 10.1016/j.neubiorev.2008.10.004
   Goodrich Michael A, 2007, Foundations and Trends in Human-Computer Interaction, V1, P203, DOI 10.1561/1100000005
   Hauser MD, 1996, EVOLUTION COMMUNICAT
   Hertenstein MJ, 2009, EMOTION, V9, P566, DOI 10.1037/a0016108
   Heyer C, 2010, IEEE INT C INT ROBOT, P4749, DOI 10.1109/IROS.2010.5651294
   Jones Keith S., 2011, REV HUMAN FACTORS ER, V7, P100, DOI [10.1177/1557234X11410388, DOI 10.1177/1557234X11410388]
   JOURARD SM, 1966, BRIT J SOC CLIN PSYC, V5, P221
   Kanda T, 2004, HUM-COMPUT INTERACT, V19, P61, DOI 10.1207/s15327051hci1901&2_4
   Karrer T, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1313
   Kosfeld M, 2005, NATURE, V435, P673, DOI 10.1038/nature03701
   Kuchenbrandt D, 2014, INT J SOC ROBOT, V6, P417, DOI 10.1007/s12369-014-0244-0
   Lee KM, 2006, INT J HUM-COMPUT ST, V64, P962, DOI 10.1016/j.ijhcs.2006.05.002
   Lowe R, MULTIMODAL TEC UNPUB
   Maiolino P, 2013, IEEE SENS J, V13, P3910, DOI 10.1109/JSEN.2013.2258149
   Mittendorfer P, 2015, ADV ROBOTICS, V29, P51, DOI 10.1080/01691864.2014.952493
   Montagu A., 1986, TOUCHING HUMAN SIGNI
   Mutlu B., 2006, P 15 IEEE INT S ROB, P74, DOI DOI 10.1109/ROMAN.2006.314397
   Nabi RL, 2002, COGNITION EMOTION, V16, P695, DOI 10.1080/02699930143000437
   Nass C, 2000, J SOC ISSUES, V56, P81, DOI 10.1111/0022-4537.00153
   NGUYEN T, 1975, J COMMUN, V25, P92, DOI 10.1111/j.1460-2466.1975.tb00610.x
   Nomura T, 2008, IEEE T ROBOT, V24, P442, DOI 10.1109/TRO.2007.914004
   Ogawa K, 2011, J ADV COMPUT INTELL, V15, P592, DOI 10.20965/jaciii.2011.p0592
   Oh K, 2010, INT J DES, V4, P45
   Espinosa MP, 2015, FRONT BEHAV NEUROSCI, V9, DOI 10.3389/fnbeh.2015.00088
   Schermerhorn P., 2008, 2008 3rd ACM/IEEE International Conference on Human-Robot Interaction (HRI 2008), P263
   Silvera-Tawil D, 2015, ROBOT AUTON SYST, V63, P230, DOI 10.1016/j.robot.2014.09.008
   Silvera-Tawil D, 2014, INT J SOC ROBOT, V6, P489, DOI 10.1007/s12369-013-0223-x
   Soegaard M., 2012, ENCY HUMAN COMPUTER
   Thrun S, 2004, HUM-COMPUT INTERACT, V19, P9, DOI 10.1207/s15327051hci1901&2_2
   Turkle S, 2006, DIGITAL MEDIA TRANSF, V120, P1
   Van Erp J.B.F., 2015, FRONTIERS DIGITAL HU, DOI [10.3389/fdigh.2015.00002., DOI 10.3389/FDIGH.2015.00002, 10.3389/fdigh.2015.00002]
   WEISS SJ, 1992, NURS RES, V41, P82
   Yogeswaran N, 2015, ADV ROBOTICS, V29, P1359, DOI 10.1080/01691864.2015.1095653
   Yohanan S, 2008, P AISB 2008 S REIGN, V1, P7
   Yohanan S, 2012, INT J SOC ROBOT, V4, P163, DOI 10.1007/s12369-011-0126-7
NR 55
TC 0
Z9 0
U1 6
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1875-4791
EI 1875-4805
J9 INT J SOC ROBOT
JI Int. J. Soc. Robot.
PD SEP
PY 2018
VL 10
IS 4
BP 473
EP 491
DI 10.1007/s12369-017-0446-3
PG 19
WC Robotics
SC Robotics
GA GU4BV
UT WOS:000445226600007
OA Other Gold, Green Published
DA 2019-02-18
ER

PT J
AU Savela, N
   Turja, T
   Oksanen, A
AF Savela, Nina
   Turja, Tuuli
   Oksanen, Atte
TI Social Acceptance of Robots in Different Occupational Fields: A
   Systematic Literature Review
SO INTERNATIONAL JOURNAL OF SOCIAL ROBOTICS
LA English
DT Review
DE Robots; Work; Robot acceptance; Social acceptance; Attitudes; Social
   representations
ID REMOTE PRESENCE TECHNOLOGY; HEALTH-CARE; ASSISTIVE ROBOT; ATTITUDES;
   EXPERIENCES; THERAPY; STROKE; MODELS; PHYSIOTHERAPY; COMMUNICATION
AB Robots today are working in both industrial and service sectors. Robots have evolved from one-function automatons to intelligent systems of versatile features, and the new generation of service robots are sharing same space and tasks with humans. The aim of this systematic literature review was to examine how the social acceptance of robots in different occupational fields has been studied and what kinds of attitudes the studies have discovered regarding robots as workers. The data were collected in October 2016 from four major bibliographic databases. Preliminary search results included 336 research articles from which 42 were selected to the final research through inclusion criteria. Of the studies, 69% concerned robots working in health and social services. Positive attitudes occurred more frequently in studies exposing participants to robots. Robots were considered appropriate for different work tasks. Telepresence robots were highly approved by health care staff. The criticism was directed to decreasing human contact and unnecessary deployment of new technology. Our results imply that attitudes toward robots are positive in many fields of work. Yet there is a need for validated measures and nationally representative data that would help us to further our understanding of social acceptance of robots in work.
C1 [Savela, Nina; Turja, Tuuli; Oksanen, Atte] Univ Tampere, Fac Social Sci, Tampere 33104, Finland.
RP Oksanen, A (reprint author), Univ Tampere, Fac Social Sci, Tampere 33104, Finland.
EM Savela.Nina.H@student.uta.fi; Tuuli.Turja@staff.uta.fi;
   atte.oksanen@uta.fi
OI Turja, Tuuli/0000-0001-7815-9511; Savela, Nina/0000-0002-7042-6889
FU Academy of Finland [292980]
FX This study was funded by the Academy of Finland (grant number 292980).
CR Acemoglu D., 2017, W23285 NBER
   AJZEN I, 1987, ADV EXP SOC PSYCHOL, V20, P1, DOI 10.1016/S0065-2601(08)60411-6
   Alaiad A, 2014, INT J MED INFORM, V83, P825, DOI [10.1016/j.ijmedinf.201.4.07.003, 10.1016/j.ijmedinf.2014.07.003]
   [Anonymous], 83732012 ISO
   Bauer M., 1997, RESISTANCE NEW TECHN
   Beck S, 2016, AI SOC, V31, P473, DOI 10.1007/s00146-015-0624-5
   Beedholm K, 2015, NURS HEALTH SCI, V17, P280, DOI 10.1111/nhs.12184
   Bettinelli M, 2015, TELEMED E-HEALTH, V21, P637, DOI 10.1089/tmj.2014.0162
   Boman IL, 2015, DISABIL REHABIL-ASSI, V10, P365, DOI 10.3109/17483107.2014.913712
   Broadbent E, 2009, INT J SOC ROBOT, V1, P319, DOI 10.1007/s12369-009-0030-6
   Broekens Joost, 2009, Gerontechnology, V8, P94
   Brynjolfsson E., 2014, 2 MACHINE AGE WORK P
   Carlsen H, 2014, TECHNOL FORECAST SOC, V84, P93, DOI 10.1016/j.techfore.2013.07.016
   Chen YP, 2011, AM STAT, V65, P239, DOI 10.1198/tas.2011.10115
   Cherry CO, 2017, DISABIL REHABIL-ASSI, V12, P21, DOI 10.3109/17483107.2015.1061613
   Dautenhahn K, 2007, INT J ADV ROBOT SYST, V4, P15, DOI DOI 10.5772/5702
   DAVIS FD, 1989, MANAGE SCI, V35, P982, DOI 10.1287/mnsc.35.8.982
   Destephe M, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00204
   Eagly A. H., 1993, PSYCHOL ATTITUDES
   Eftring H, 2016, Z GERONTOL GERIATR, V49, P274, DOI 10.1007/s00391-016-1064-7
   Eurobarometer, 2012, 382 EUR COMM
   Fazekas G, 2006, INT J REHABIL RES, V29, P251, DOI 10.1097/01.mrr.0000230050.16604.d9
   Fazio R. H., 1995, ATTITUDES OBJECT EVA, P247
   Fernandez-Macias E, 2012, WORK OCCUPATION, V39, P157, DOI 10.1177/0730888411427078
   Fishbein M, 1975, BELIEF ATTITUDE INTE
   Fisher RA., 1932, STAT METHODS RES WOR
   Flynn LL, 2011, EUR J CANCER CARE, V20, P686, DOI 10.1111/j.1365-2354.2011.01268.x
   Frey CB, 2013, OMS WORKING PAPERS
   Fuji S, 2011, 7 INT C NAT LANG PRO, P27, DOI [10. 1109/NLPKE. 2011. 6138243, DOI 10.1109/NLPKE.2011.6138243]
   Gacsi M, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00971
   Gamecho B, 2015, J MED SYST, V39, DOI 10.1007/s10916-015-0296-1
   Gerling K, 2016, Z GERONTOL GERIATR, V49, P288, DOI 10.1007/s00391-016-1065-6
   Gjevjon ER, 2013, J NURS MANAGE, V21, P182, DOI 10.1111/j.1365-2834.2012.01366.x
   Gustafsson C, 2015, J GERONTOL NURS, V41, P46, DOI 10.3928/00989134-20150806-44
   Hansen BG, 2015, J RURAL STUD, V41, P109, DOI 10.1016/j.jrurstud.2015.08.004
   Heerink M, 2011, ACMIEEE INT CONF HUM, P147, DOI 10.1145/1957656.1957704
   Holm SG, 2014, BMC HEALTH SERV RES, V14, DOI 10.1186/1472-6963-14-439
   Jenkins S, 2015, INT J SOC ROBOT, V7, P673, DOI 10.1007/s12369-015-0322-y
   Joffe H, 2003, BRIT J SOC PSYCHOL, V42, P55, DOI 10.1348/014466603763276126
   Jones VS, 2008, J PEDIATR SURG, V43, P1653, DOI 10.1016/j.jpedsurg.2008.01.006
   Jung J, 2017, COMPUT HUM BEHAV, V71, P291, DOI 10.1016/j.chb.2017.02.022
   Kachouie R, 2014, INT J HUM-COMPUT INT, V30, P369, DOI 10.1080/10447318.2013.873278
   Katz JE, 2014, BEHAV INFORM TECHNOL, V33, P941, DOI 10.1080/0144929X.2013.783115
   King WR, 2006, INFORM MANAGE-AMSTER, V43, P740, DOI 10.1016/j.im.2006.05.003
   Koceski S, 2016, J MED SYST, V40, DOI 10.1007/s10916-016-0481-x
   Kramer NM, 2014, TELEMED E-HEALTH, V20, P1087, DOI 10.1089/tmj.2014.0043
   Kristoffersson A, 2011, J TECHNOL HUMAN SERV, V29, P263, DOI 10.1080/15228835.2011.639509
   Kwakkel G, 2008, NEUROREHAB NEURAL RE, V22, P111, DOI 10.1177/1545968307305457
   Lee SL, 2005, IEEE INT CONF ROBOT, P2767
   Lindsay C, 2014, INT J HUM RESOUR MAN, V25, P2941, DOI 10.1080/09585192.2014.948900
   Louie WYG, 2014, ASSIST TECHNOL, V26, P140, DOI 10.1080/10400435.2013.869703
   Lu EC, 2011, DISABIL REHABIL-ASSI, V6, P420, DOI 10.3109/17483107.2010.544370
   Maj M, 2009, REV PSIQUIATR SALUD, V2, P1, DOI 10.1016/S1888-9891(09)70709-8
   Malhotra Y, 1999, 32 ANN HAW INT C SYS, P1, DOI DOI 10.1109/HICSS.1999.772658
   Manfre A, 2016, BIOL INSPIR COGN ARC, V15, P1, DOI 10.1016/j.bica.2015.09.009
   Mann JA, 2015, COMPUT HUM BEHAV, V43, P112, DOI 10.1016/j.chb.2014.10.029
   Manyika J., 2013, DISRUPTIVE TECHNOLOG
   McDonald JH, 2014, HDB BIOL STAT
   Mendez I, 2013, INT J CIRCUMPOL HEAL, V72, P381, DOI 10.3402/ijch.v72i0.21112
   Moon A, 2012, INT J SOC ROBOT, V4, P77, DOI 10.1007/s12369-011-0120-0
   Mubin O., 2013, TECHNOLOGY ED LEARNI, V1, P209, DOI DOI 10.2316/J0URNAL.209.2013.1.209-0015
   Nestel D, 2007, J TELEMED TELECARE, V13, P100, DOI 10.1258/135763307780096168
   Nieuwenhuisen M, 2013, INT J SOC ROBOT, V5, P549, DOI 10.1007/s12369-013-0206-y
   Nomura T, 2006, AI SOC, V20, P138, DOI 10.1007/s00146-005-0012-7
   Olson JM, 2003, THREE, V13, P299
   PARSONS HM, 1982, HUM FACTORS, V24, P535
   Pfadenhauer M, 2015, INT J SOC ROBOT, V7, P393, DOI 10.1007/s12369-015-0284-0
   Prange GB, 2006, J REHABIL RES DEV, V43, P171, DOI 10.1682/JRRD.2005.04.0076
   Pripfl J, 2016, Z GERONTOL GERIATR, V49, P282, DOI 10.1007/s00391-016-1067-4
   Ramnath VR, 2014, TELEMED E-HEALTH, V20, P962, DOI 10.1089/tmj.2014.0024
   Randell R, 2016, COGN TECHNOL WORK, V18, P423, DOI 10.1007/s10111-016-0368-0
   Reich-Stiebert N, 2015, INT J SOC ROBOT, V7, P875, DOI 10.1007/s12369-015-0308-9
   Reynolds EM, 2012, TELEMED E-HEALTH, V18, P507, DOI 10.1089/tmj.2011.0206
   Sabanovic S, 2014, SOC STUD SCI, V44, P342, DOI 10.1177/0306312713509704
   Sabelli AM, 2016, INT J SOC ROBOT, V8, P211, DOI 10.1007/s12369-015-0332-9
   Saborowski M, 2015, TECHNOL FORECAST SOC, V93, P133, DOI 10.1016/j.techfore.2014.05.006
   Schulman CI, 2013, TELEMED E-HEALTH, V19, P248, DOI 10.1089/tmj.2012.0102
   Sharkey A, 2012, ETHICS INF TECHNOL, V14, P27, DOI 10.1007/s10676-010-9234-6
   Sharts-Hopko Nancy C, 2014, Nurs Adm Q, V38, P5, DOI 10.1097/NAQ.0000000000000000
   Silberman J., 2011, COLUMBIA SCI TECHNOL, VXII, P272
   Suprem A, 2013, COMPUT STAND INTER, V35, P355, DOI 10.1016/j.csi.2012.09.002
   Taipale S., 2015, SOCIAL ROBOTS HUMAN, P11
   Takayama L., 2008, 2008 3rd ACM/IEEE International Conference on Human-Robot Interaction (HRI 2008), P25
   Tay B, 2014, COMPUT HUM BEHAV, V38, P75, DOI 10.1016/j.chb.2014.05.014
   Todorov Alexander, 2011, SOCIAL NEUROSCIENCE
   Trevelyan J, 1999, INT J ROBOT RES, V18, P1211, DOI 10.1177/02783649922067816
   Venkatesh V, 2000, MANAGE SCI, V46, P186, DOI 10.1287/mnsc.46.2.186.11926
   Wagner W, 2002, BRIT J SOC PSYCHOL, V41, P323, DOI 10.1348/014466602760344241
   Wasen K, 2010, INT J SOC ROBOT, V2, P431, DOI 10.1007/s12369-010-0062-y
   Waytz A, 2014, EMOTION, V14, P434, DOI 10.1037/a0036054
   Wegener D. T, 2010, ADV SOCIAL PSYCHOL S, P177
   Weng YH, 2009, INT J SOC ROBOT, V1, P267, DOI 10.1007/s12369-009-0019-1
   Wolbring G, 2014, INT J SOC ROBOT, V6, P457, DOI 10.1007/s12369-014-0229-z
   Young LB, 2011, CHEST, V139, P279, DOI 10.1378/chest.10-1795
   Zanchettin AM, 2013, APPL ERGON, V44, P982, DOI 10.1016/j.apergo.2013.03.028
NR 95
TC 3
Z9 3
U1 15
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1875-4791
EI 1875-4805
J9 INT J SOC ROBOT
JI Int. J. Soc. Robot.
PD SEP
PY 2018
VL 10
IS 4
BP 493
EP 502
DI 10.1007/s12369-017-0452-5
PG 10
WC Robotics
SC Robotics
GA GU4BV
UT WOS:000445226600008
DA 2019-02-18
ER

PT J
AU Hoorn, JF
   Winter, SD
AF Hoorn, Johan F.
   Winter, Sonja D.
TI Here Comes the Bad News: Doctor Robot Taking Over
SO INTERNATIONAL JOURNAL OF SOCIAL ROBOTICS
LA English
DT Article
DE Media Equation; CASA; Framing; Language; Communication; Healthcare
ID SOCIAL RESPONSES; ORIENTATION; COMPUTERS; TUTORS
AB To test in how far the Media Equation and Computers Are Social Actors (CASA) validly explain user responses to social robots, we manipulated how a bad health message was framed and the language that was used. In the wake of Experiment 2 of Burgers et al. (Patient Educ Couns 89(2):267-273, 2012. https://10.1016/j.pec.2012.08.008), a human versus robot doctor delivered health messages framed positively or negatively, using affirmations or negations. In using frequentist (robots are different from humans) and Bayesian (robots are the same) analyses, we found that participants liked the robot doctor and the robot's message better than the human's. The robot also compelled more compliance to the medical treatment. For the level of expected quality of life, the human and robot doctor tied. The robot was not seen as affectively distant but rather involving, ethical, skilled, and people wanted to consult her again. Note that doctor robot was not a seriously looking physician but a little girl with the voice of a young woman. We conclude that both Media Equation and CASA need to be altered when it comes to robot communication. We argue that if certain negative qualities are filtered out (e.g., strong emotion expression), credibility will increase, which lowers affective distance to the messenger. Robots sometimes outperform humans on emotional tasks, which may relieve physicians from a most demanding duty of disclosing unfavorable information to a patient.
C1 [Hoorn, Johan F.] Vrije Univ Amsterdam, Dept Commun Sci, De Boelelaan 1081, NL-1081 HV Amsterdam, Netherlands.
   [Winter, Sonja D.] Univ Calif Merced, Psychol Sci, Merced, CA USA.
RP Hoorn, JF (reprint author), Vrije Univ Amsterdam, Dept Commun Sci, De Boelelaan 1081, NL-1081 HV Amsterdam, Netherlands.
EM j.f.hoorn@vu.nl
OI Winter, Sonja/0000-0002-2203-002X
FU Dutch Ministry of Education, Culture, and Science [NWO 646.000.003]
FX This study is part of the Services of Electro-mechanical Care Agencies
   (SELEMCA) project and was supported by a grant from the Dutch Ministry
   of Education, Culture, and Science (Grant Number NWO 646.000.003). Many
   thanks go to Christian Burgers for making available the data on the
   human doctor and for his comments and advices. Marcel Nihot is kindly
   thanked for data collection in the robot experiment. We acknowledge with
   much appreciation Elly A. Konijn who reviewed an earlier draft of this
   paper. We gratefully acknowledge the comments and suggestions of the
   anonymous reviewers for the profound improvement of this paper.
CR Baile W F, 2000, Oncologist, V5, P302, DOI 10.1634/theoncologist.5-4-302
   Bickmore T, 2005, PATIENT EDUC COUNS, V59, P21, DOI 10.1016/j.pec.2004.09.008
   Bickmore T., 2001, CHI 2001 Conference Proceedings. Conference on Human Factors in Computing Systems, P396
   Brave S, 2005, INT J HUM-COMPUT ST, V62, P161, DOI 10.1016/j.ijhcs.2004.11.002
   Brown VA, 2011, EUR J CANCER CARE, V20, P56, DOI 10.1111/j.1365-2354.2009.01156.x
   Buhlmann H, 2006, COURSE CREDIBILITY T
   Burgers C, 2012, PATIENT EDUC COUNS, V89, P267, DOI 10.1016/j.pec.2012.08.008
   Culnan M. J, 1987, HDB ORG COMMUNICATIO, P420
   de Melo C. M., 2011, 10 INT C AUT AG MULT, V3, P937
   Derks D, 2008, CYBERPSYCHOL BEHAV, V11, P99, DOI 10.1089/cpb.2007.9926
   Fischer K, 2011, INTERACT STUD, V12, P134, DOI 10.1075/is.12.1.06fis
   Gelman A., 2014, BAYESIAN DATA ANAL
   Gray K, 2012, COGNITION, V125, P125, DOI 10.1016/j.cognition.2012.06.007
   Hoorn Johan F., 2015, 7th International Conference on Agents and Artificial Intelligence (ICAART 2015). Proceedings, P464
   Jeffreys H, 1961, THEORY PROBABILITY
   Johnson SC, 2003, PHILOS T R SOC B, V358, P549, DOI 10.1098/rstb.2002.1237
   Kahneman Daniel, 2000, CHOICES VALUES FRAME
   Kanda T, 2004, HUM-COMPUT INTERACT, V19, P61, DOI 10.1207/s15327051hci1901&2_4
   Kelsey S, 2008, HDB RES COMPUTER MED
   Konijn EA, 2015, COMMUN METHODS MEAS, V9, P280, DOI 10.1080/19312458.2015.1096332
   Kuster D, 2016, FRONT ARTIF INTEL AP, V290, P340, DOI 10.3233/978-1-61499-708-5-340
   Latour B, 1992, SHAPING TECHNOLOGY B, P225
   Lee KM, 2006, J COMMUN, V56, P754, DOI 10.1111/j.1460-2466.2006.00318.x
   Lee M. D, 2013, BAYESIAN MODELING CO
   Lee MK, 2010, 2010 ACM CONFERENCE ON COMPUTER SUPPORTED COOPERATIVE WORK, P31
   Lee MK, 2013, P SIGCHI C HUM FACT, P695
   Lorenz T, 2016, INT J SOC ROBOT, V8, P125, DOI 10.1007/s12369-015-0325-8
   Love J, 2015, JAVA BASED STAT PROC
   Monden Kimberley R, 2016, Proc (Bayl Univ Med Cent), V29, P101
   Morey RD, 2015, BAYESFACTOR COMPUTER
   Mutlu B., 2008, 2008 3rd ACM/IEEE International Conference on Human-Robot Interaction (HRI 2008), P287
   Nass C, 2000, J SOC ISSUES, V56, P81, DOI 10.1111/0022-4537.00153
   OHANIAN R, 1990, J ADVERTISING, V19, P39, DOI 10.1080/00913367.1990.10673191
   Raftery AE, 1995, SOCIOL METHODOL, V25, P111, DOI 10.2307/271063
   REEVES B, 2002, MEDIA EQUATION PEOPL
   Sabelli AM, 2011, ACMIEEE INT CONF HUM, P37, DOI 10.1145/1957656.1957669
   Severinson-Eklundh K, 2003, ROBOT AUTON SYST, V42, P223, DOI 10.1016/S0921-8890(02)00377-9
   Shuo Zhou, 2014, Intelligent Virtual Agents. 14th International Conference (IVA 2014). Proceedings: LNCS 8637, P528, DOI 10.1007/978-3-319-09767-1_63
   Street RL, 2009, PATIENT EDUC COUNS, V74, P295, DOI 10.1016/j.pec.2008.11.015
   Sundar SS, 2000, COMMUN RES, V27, P683, DOI 10.1177/009365000027006001
   Sung JY, 2007, LECT NOTES COMPUT SC, V4717, P145
   Takayama L, 2012, P ACM 2012 C COMP SU, P495, DOI DOI 10.1145/2145204.2145281
   Tapus A, 2008, P AAAI SPRING S EM P, P133
   Torrey C, 2013, ACMIEEE INT CONF HUM, P275, DOI 10.1109/HRI.2013.6483599
   Van de Schoot R., 2014, EUROPEAN HLTH PSYCHO, V16, P75, DOI DOI 10.1016/J.BODYIM.2013.03.002
   van Vugt HC, 2009, COMPUT ANIMAT VIRT W, V20, P195, DOI 10.1002/cav.312
   van Vugt HC, 2006, INT J HUM-COMPUT ST, V64, P874, DOI 10.1016/j.ijhcs.2006.04.008
   Winter SD, 2016, TECHNICAL REPORT
   Woods S., 2006, P 15 IEEE INT S ROB, P51, DOI DOI 10.1109/ROMAN.2006.314394
   Woods S, 2006, 9TH IEEE INTERNATIONAL WORKSHOP ON ADVANCED MOTION CONTROL, VOLS 1 AND 2, PROCEEDINGS, P750, DOI 10.1109/AMC.2006.1631754
NR 50
TC 0
Z9 0
U1 7
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1875-4791
EI 1875-4805
J9 INT J SOC ROBOT
JI Int. J. Soc. Robot.
PD SEP
PY 2018
VL 10
IS 4
BP 519
EP 535
DI 10.1007/s12369-017-0455-2
PG 17
WC Robotics
SC Robotics
GA GU4BV
UT WOS:000445226600010
OA Other Gold
DA 2019-02-18
ER

PT J
AU Mahdi, A
   Su, M
   Schlesinger, M
   Qin, J
AF Mahdi, Ali
   Su, Mei
   Schlesinger, Matthew
   Qin, Jun
TI A Comparison Study of Saliency Models for Fixation Prediction on Infants
   and Adults
SO IEEE TRANSACTIONS ON COGNITIVE AND DEVELOPMENTAL SYSTEMS
LA English
DT Article
DE Comparison; evaluation metrics; fixation; saliency models; visual
   attention
ID VISUAL SELECTIVE ATTENTION; SPATIOTEMPORAL SALIENCY;
   QUANTITATIVE-ANALYSIS; VIDEO COMPRESSION; OBJECT DETECTION; REGION
   DETECTION; SEARCH; IMAGES; BRAIN; SEGMENTATION
AB Various saliency models have been developed over the years. The performance of saliency models is typically evaluated based on databases of experimentally recorded adult eye fixations. Although studies on infant gaze patterns have attracted much attention recently, saliency-based models have not been widely applied for prediction of infant gaze patterns. In this paper, we conduct a comprehensive comparison study of eight state-of-the-art saliency models on predictions of experimentally captured fixations from infants and adults. Seven evaluation metrics are used to evaluate and compare the perfm-mance of saliency models. The results demonstrate a consistent performance of saliency models predicting adult fixations over infant fixations in terms of overlap, center fitting, intersection, information loss of approximation, and spatial distance between the distributions of saliency map and fixation map. In saliency and baselines models performance ranking, the results show that graph-based visual saliency model and Itti model are among the top three contenders, infants and adults have bias toward the centers of images, and all models and the center baseline model outperformed the chance baseline model.
C1 [Mahdi, Ali; Qin, Jun] Southern Illinois Univ, Dept Elect & Comp Engn, Carbondale, IL 62901 USA.
   [Su, Mei] Guizhou Univ, Coll Foreign Language, Guiyang 550025, Guizhou, Peoples R China.
   [Schlesinger, Matthew] Southern Illinois Univ, Dept Psychol, Carbondale, IL 62901 USA.
RP Qin, J (reprint author), Southern Illinois Univ, Dept Elect & Comp Engn, Carbondale, IL 62901 USA.
EM ali.mahdi@siu.edu; maysu555@163.com; matthews@siu.edu; jqin@siu.edu
OI Qin, Jun/0000-0002-8186-5705
CR Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   Althaus N, 2012, CHILD DEV, V83, P1122, DOI 10.1111/j.1467-8624.2012.01766.x
   Amso D, 2015, NAT REV NEUROSCI, V16, P606, DOI 10.1038/nrn4025
   Amso D, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0085701
   Amso D, 2008, INFANCY, V13, P675, DOI 10.1080/15250000802459060
   Ardizzone E, 2011, LECT NOTES COMPUT SC, V6978, P691, DOI 10.1007/978-3-642-24085-0_70
   Baluja S, 1997, ROBOT AUTON SYST, V22, P329, DOI 10.1016/S0921-8890(97)00046-8
   Bian P., 2008, INT C NEUR INF PROC, P251
   Borji A., 2015, CAT2000 LARGE SCALE
   Borji A, 2015, IEEE T IMAGE PROCESS, V24, P5706, DOI 10.1109/TIP.2015.2487833
   Borji A, 2013, IEEE I CONF COMP VIS, P921, DOI 10.1109/ICCV.2013.118
   Borji A, 2013, IEEE T IMAGE PROCESS, V22, P55, DOI 10.1109/TIP.2012.2210727
   Borji A, 2013, IEEE T PATTERN ANAL, V35, P185, DOI 10.1109/TPAMI.2012.89
   Bruce N. D. B., 2005, ADV NEURAL INFORM PR, P155
   Bruce NDB, 2009, J VISION, V9, DOI 10.1167/9.3.5
   Butko Nicholas J., 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2751, DOI 10.1109/CVPRW.2009.5206540
   Bylinskii Z., 2016, WHAT DIFFERENT EVALU
   Bylinskii Zoya, 2012, MIT SALIENCY BENCHMA
   Cerf M., 2008, ADV NEURAL INFORM PR, V20, P241
   Chang KY, 2011, IEEE I CONF COMP VIS, P914, DOI 10.1109/ICCV.2011.6126333
   Dixon ML, 2010, DEVELOPMENTAL SCI, V13, P161, DOI 10.1111/j.1467-7687.2009.00875.x
   Ehinger KA, 2009, VIS COGN, V17, P945, DOI 10.1080/13506280902834720
   Filipe S, 2015, ARTIF INTELL REV, V43, DOI 10.1007/s10462-012-9385-4
   Frintrop S., 2006, VOCUS VISUAL ATTENTI, V3899
   Frintrop S, 2010, ACM T APPL PERCEPT, V7, DOI 10.1145/1658349.1658355
   Gao D., 2004, P ADV NEUR INF PROC, V17, P1
   Gao D, 2008, J VISION, V8, DOI 10.1167/8.7.13
   Gao K, 2008, 7TH IEEE/ACIS INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION SCIENCE IN CONJUNCTION WITH 2ND IEEE/ACIS INTERNATIONAL WORKSHOP ON E-ACTIVITY, PROCEEDINGS, P191, DOI 10.1109/ICIS.2008.24
   Garcia-Diaz A, 2009, LECT NOTES COMPUT SC, V5807, P343
   Gogtay N, 2004, P NATL ACAD SCI USA, V101, P8174, DOI 10.1073/pnas.0402680101
   Guo C., 2008, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2008.4587715
   Guo CL, 2007, IEEE IJCNN, P1295, DOI 10.1109/IJCNN.2007.4371145
   Guo CL, 2010, IEEE T IMAGE PROCESS, V19, P185, DOI 10.1109/TIP.2009.2030969
   Hou X., 2009, ADV NEURAL INFORM PR, P681
   Hou X., 2007, IEEE C COMP VIS PATT, P1, DOI DOI 10.1109/CVPR.2007.383267
   Huang L, 2016, COMM COM INF SC, V663, P3, DOI 10.1007/978-981-10-3005-5_1
   Itti L, 2004, IEEE T IMAGE PROCESS, V13, P1304, DOI 10.1109/TIP.2004.834657
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Itti L., 2000, VISION RES, V1489-1506, P10, DOI DOI 10.1016/S0042-6989(99)00163-7
   Itti L, 2009, VISION RES, V49, P1295, DOI 10.1016/j.visres.2008.09.007
   Jiang H., 2011, P BRIT MACH VIS C, P1
   Jiang M, 2015, PROC CVPR IEEE, P1072, DOI 10.1109/CVPR.2015.7298710
   Jianyong L., 2015, OPEN CYBERN SYST J, V9, P648, DOI [10.2174/1874110X01509010648, DOI 10.2174/1874110X01509010648]
   Judd T., 2012, MITCSAILTR2012001
   Judd T, 2009, IEEE I CONF COMP VIS, P2106, DOI 10.1109/ICCV.2009.5459462
   Kato H., 2015, VISUAL LANGUAGE MODE
   Kienzle W, 2009, J VISION, V9, DOI 10.1167/9.5.7
   Klein DA, 2011, IEEE I CONF COMP VIS, P2214, DOI 10.1109/ICCV.2011.6126499
   Koch C, 2006, ADV NEURAL INFORM PR, P545
   Koch C., 1987, MATTERINTELLIGENCE, P115, DOI DOI 10.1007/978-94-009-3833-55
   Koch K, 2006, CURR BIOL, V16, P1428, DOI 10.1016/j.cub.2006.05.056
   Kootstra G., 2008, P BRIT MACH VIS C BM, P1115
   Kummerer M., 2014, DEEP GAZE 1 BOOSTING
   Kummerer M., 2016, DEEPGAZE 2 READING 1
   Le Meur O, 2006, IEEE T PATTERN ANAL, V28, P802, DOI 10.1109/TPAMI.2006.86
   Le Meur O, 2007, VISION RES, V47, P2483, DOI 10.1016/j.visres.2007.06.015
   Le Meur O, 2013, BEHAV RES METHODS, V45, P251, DOI 10.3758/s13428-012-0226-9
   Leboran V, 2017, IEEE T PATTERN ANAL, V39, P893, DOI 10.1109/TPAMI.2016.2567391
   Li J, 2013, IEEE T PATTERN ANAL, V35, P996, DOI 10.1109/TPAMI.2012.147
   Li YB, 2009, PROCEEDINGS OF THE 3RD INTERNATIONAL CONFERENCE ON ANTI-COUNTERFEITING, SECURITY, AND IDENTIFICATION IN COMMUNICATION, P246, DOI 10.1109/ICASID.2009.5276913
   Liu N, 2015, PROC CVPR IEEE, P362, DOI 10.1109/CVPR.2015.7298633
   Liu T., 2007, IEEE C COMP VIS PATT, P1, DOI DOI 10.1109/CVPR.2007.383047
   Liu T, 2011, IEEE T PATTERN ANAL, V33, P353, DOI 10.1109/TPAMI.2010.70
   Lu HC, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2524198
   Ma Q, 2010, J ELECTRON IMAGING, V19, P1
   Mahadevan V, 2009, PROC CVPR IEEE, P1007, DOI 10.1109/CVPRW.2009.5206573
   Mahdi A, 2015, 5TH INTERNATIONAL CONFERENCE ON DEVELOPMENT AND LEARNING AND ON EPIGENETIC ROBOTICS (ICDL-EPIROB), P106, DOI 10.1109/DEVLRN.2015.7346124
   Maki A, 2000, COMPUT VIS IMAGE UND, V78, P351, DOI 10.1006/cviu.2000.0840
   Marat S, 2009, INT J COMPUT VISION, V82, P231, DOI 10.1007/s11263-009-0215-3
   Marchesotti L, 2009, IEEE I CONF COMP VIS, P2232, DOI 10.1109/ICCV.2009.5459467
   Mishra AK, 2009, INT J HUM ROBOT, V6, P361, DOI 10.1142/S0219843609001784
   Murray N, 2011, PROC CVPR IEEE, P433, DOI 10.1109/CVPR.2011.5995506
   Ninassi A., 2007, P IEEE INT C IM PROC, P169, DOI DOI 10.1109/ICIP.2007.4379119
   Nothdurft H. C., 2005, NEUROBIOLOGY ATTENTI
   Oliva A, 2003, IEEE IMAGE PROC, P253
   Pan J., 2015, END TO END CONVOLUTI
   Parkhurst DJ, 2003, SPATIAL VISION, V16, P125, DOI 10.1163/15685680360511645
   RAMANATHAN S, 2010, EYE FIX DAT SAL DET, V6314, P30
   Rao RPN, 2005, NEUROREPORT, V16, P1843, DOI 10.1097/01.wnr.0000183900.92901.fc
   Raznahan A, 2014, P NATL ACAD SCI USA, V111, P1592, DOI 10.1073/pnas.1316911111
   Renninger L. W., 2004, ADV NEURAL INFORM PR, P1121
   Riche N, 2012, IEEE IMAGE PROC, P641, DOI 10.1109/ICIP.2012.6466941
   Rubinstein M, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360615
   Salah AA, 2002, IEEE T PATTERN ANAL, V24, P420, DOI 10.1109/34.990146
   Schlesinger M., 2013, INTRINSICALLY MOTIVA, P367, DOI DOI 10.1007/978-3-642-32375-1_
   Schlesinger M., 2011, P 1 JOINT IEEE C DEV, V2, P1
   Schlesinger M, 2007, ADAPT BEHAV, V15, P135, DOI 10.1177/1059712307078661
   Schlesinger M, 2015, 5TH INTERNATIONAL CONFERENCE ON DEVELOPMENT AND LEARNING AND ON EPIGENETIC ROBOTICS (ICDL-EPIROB), P162, DOI 10.1109/DEVLRN.2015.7346135
   Schlesinger M, 2014, FOUTH JOINT IEEE INTERNATIONAL CONFERENCES ON DEVELOPMENT AND LEARNING AND EPIGENETIC ROBOTICS (IEEE ICDL-EPIROB 2014), P275, DOI 10.1109/DEVLRN.2014.6982993
   Schlesinger M, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00441
   Schlesinger M, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00802
   Schlesinger M, 2012, DEVELOPMENTAL SCI, V15, P739, DOI 10.1111/j.1467-7687.2012.01177.x
   Seo HJ, 2009, J VISION, V9, DOI 10.1167/9.12.15
   Sowell ER, 2004, J NEUROSCI, V24, P8223, DOI 10.1523/JNEUROSCI.1798-04.2004
   Sugano Y, 2013, IEEE T PATTERN ANAL, V35, P329, DOI 10.1109/TPAMI.2012.101
   Suh B., 2003, P 16 ANN ACM S US IN, P95, DOI DOI 10.1145/964696.964707
   Syeda-Mahmood TF, 1999, COMPUT VIS IMAGE UND, V76, P93, DOI 10.1006/cviu.1999.0784
   Tatler BW, 2007, J VISION, V7, DOI 10.1167/7.14.4
   Tatler BW, 2005, VISION RES, V45, P643, DOI 10.1016/j.visres.2004.09.017
   Torralba A, 2006, PSYCHOL REV, V113, P766, DOI 10.1037/0033-295X.113.4.766
   TREISMAN AM, 1980, COGNITIVE PSYCHOL, V12, P97, DOI 10.1016/0010-0285(80)90005-5
   Vandekar SN, 2015, J NEUROSCI, V35, P599, DOI 10.1523/JNEUROSCI.3628-14.2015
   Vig E, 2014, PROC CVPR IEEE, P2798, DOI 10.1109/CVPR.2014.358
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Walther D, 2006, NEURAL NETWORKS, V19, P1395, DOI 10.1016/j.neunet.2006.10.001
   Wang JW, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2522380
   Wang W, 2011, PROC CVPR IEEE, P441, DOI 10.1109/CVPR.2011.5995423
   Wang ZS, 2008, INT CONF ACOUST SPEE, P965
   WOLFE JM, 1989, J EXP PSYCHOL HUMAN, V15, P419, DOI 10.1037/0096-1523.15.3.419
   Xiao LM, 2016, LECT NOTES COMPUT SC, V9772, P645, DOI 10.1007/978-3-319-42294-7_58
   Xie YL, 2013, IEEE T IMAGE PROCESS, V22, P1689, DOI 10.1109/TIP.2012.2216276
   Yang C, 2013, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2013.407
   YUODELIS C, 1986, VISION RES, V26, P847, DOI 10.1016/0042-6989(86)90143-4
   Zhang JM, 2016, IEEE T PATTERN ANAL, V38, P889, DOI 10.1109/TPAMI.2015.2473844
   Zhang JX, 2017, PATTERN RECOGN, V64, P39, DOI 10.1016/j.patcog.2016.10.025
   Zhang L., 2009, P 31 ANN COGN SCI C, P2944
   Zhang LY, 2008, J VISION, V8, DOI 10.1167/8.7.32
   Zhao Q, 2013, SIGNAL PROCESS, V93, P1401, DOI 10.1016/j.sigpro.2012.06.014
   Zhao Q, 2011, J VISION, V11, DOI 10.1167/11.3.9
   Zhu WJ, 2014, PROC CVPR IEEE, P2814, DOI 10.1109/CVPR.2014.360
NR 120
TC 1
Z9 1
U1 5
U2 5
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2379-8920
EI 2379-8939
J9 IEEE T COGN DEV SYST
JI IEEE Trans. Cogn. Dev. Syst.
PD SEP
PY 2018
VL 10
IS 3
BP 485
EP 498
DI 10.1109/TCDS.2017.2696439
PG 14
WC Computer Science, Artificial Intelligence; Robotics; Neurosciences
SC Computer Science; Robotics; Neurosciences & Neurology
GA GT6JO
UT WOS:000444617100001
DA 2019-02-18
ER

PT J
AU Forster, F
   Saunders, J
   Nehaniv, CL
AF Foerster, Frank
   Saunders, Joe
   Nehaniv, Chrystopher L.
TI Robots That Say "No" Affective Symbol Grounding and the Case of Intent
   Interpretations
SO IEEE TRANSACTIONS ON COGNITIVE AND DEVELOPMENTAL SYSTEMS
LA English
DT Article
DE Developmental robotics; human-robot interaction; language acquisition;
   negation; pragmatics; psycholinguistics; social robotics
ID SPEECH RECOGNITION; LANGUAGE-ACQUISITION; EARLY VOCABULARY;
   NEURAL-NETWORKS; PERCEPTION; WORDS; CHILDREN; AUTISM; VERBS; TALK
AB Modern theories on early child language acquisition tend to focus on referential words, mostly nouns, labeling concrete objects, or physical properties. In this experimental proof-of-concept study, we show how nonreferential negation words, typically belonging to a child's first ten words, may be acquired. A child-like humanoid robot is deployed in speech-wise unconstrained interaction with naive human participants. In agreement with psycholinguistic observations, we corroborate the hypothesis that affect plays a pivotal role in the socially distributed acquisition process where the adept conversation partner provides linguistic interpretations of the affective displays of the less adept speaker. Negation words are prosodically salient within intent interpretations that are triggered by the learner's display of affect. From there they can be picked up and used by the budding language learner which may involve the grounding of these words in the very affective states that triggered them in the first place. The pragmatic analysis of the robot's linguistic performance indicates that the correct timing of negative utterances is essential for the listener to infer the meaning of otherwise ambiguous negative utterances. In order to assess the robot's performance thoroughly comparative data from psycholinguistic studies of parent-child dyads is needed highlighting the need for further interdisciplinary work.
C1 [Foerster, Frank; Saunders, Joe; Nehaniv, Chrystopher L.] Univ Hertfordshire, Adapt Syst Res Grp, Hatfield AL10 9AB, Herts, England.
RP Forster, F (reprint author), Univ Hertfordshire, Adapt Syst Res Grp, Hatfield AL10 9AB, Herts, England.
EM f.foerster@herts.ac.uk
OI Foerster, Frank/0000-0003-1797-682X
FU EU Integrated Project "Integration and Transfer of Action and Language
   in Robots" through the European Commission [FP-7-214668]
FX This work was supported by the EU Integrated Project "Integration and
   Transfer of Action and Language in Robots" through the European
   Commission under Contract FP-7-214668.
CR Aubert XL, 2002, COMPUT SPEECH LANG, V16, P89, DOI 10.1006/csla.2001.0185
   Austin John, 1975, DO THINGS WORDS
   Bedford R, 2013, J CHILD LANG, V40, P29, DOI 10.1017/S0305000912000086
   Bleses D, 2008, J CHILD LANG, V35, P619, DOI 10.1017/S0305000908008714
   Bloom L., 1970, LANGUAGE DEV FUNCTIO
   Borovsky A, 2006, J CHILD LANG, V33, P759, DOI 10.1017/S0305000906007574
   Bowerman M., 1988, EXPLAINING LANGUAGE, P73
   Brooks PJ, 1999, CHILD DEV, V70, P1325, DOI 10.1111/1467-8624.00097
   Budwig N, 2002, LANGUAGE, LITERACY, AND COGNITIVE DEVELOPMENT, P59
   Bunce JP, 2017, J CHILD LANG, V44, P650, DOI 10.1017/S0305000916000180
   Cangelosi A, 2010, PHYS LIFE REV, V7, P139, DOI 10.1016/j.plrev.2010.02.001
   Cangelosi A, 2006, IEEE IJCNN, P1576
   CHOI S, 1988, J CHILD LANG, V15, P517, DOI 10.1017/S030500090001254X
   Daelemans Walter, 2005, MEMORY BASED LANGUAG
   De Mulder W, 2015, COMPUT SPEECH LANG, V30, P61, DOI 10.1016/j.csl.2014.09.005
   Dominey PF, 2005, COGN SYST RES, V6, P243, DOI 10.1016/j.cogsys.2004.11.005
   Dominey PF, 2005, ARTIF INTELL, V167, P31, DOI 10.1016/j.artint.2005.06.007
   Eugenio BD, 2000, P 2 INT C LANG RES E, P441
   FENSON L, 1994, MONOGR SOC RES CHILD, V59, pR5
   Forster F., 2009, P 10 EUR C ECAL BUD, P158, DOI 10.1007/978-3-642-21314-4_20
   Forster F., 2013, THESIS
   GALLAWAY C, 1994, INPUT INTERACTION LA
   Gelman SA, 1998, J CHILD LANG, V25, P267, DOI 10.1017/S0305000998003420
   Gold K, 2009, ARTIF INTELL, V173, P145, DOI 10.1016/j.artint.2008.09.002
   GOPNIK A, 1988, FIRST LANG, V8, P49
   Hani HB, 2013, J CHILD LANG, V40, P971, DOI 10.1017/S0305000912000426
   Hao ML, 2015, J CHILD LANG, V42, P505, DOI 10.1017/S030500091400018X
   HARNAD S, 1990, PHYSICA D, V42, P335, DOI 10.1016/0167-2789(90)90087-6
   Hastie T., 2009, ELEMENTS STAT LEARNI
   Hollich G. J., 2000, MONOGRAPHS SOC RES C, V65, P1, DOI [10.1111/1540-5834.00091, DOI 10.1111/1540-5834.00090]
   Hutchby I., 1998, CONVERSATION ANAL PR
   Jefferson G., 1989, CONVERSATION INTERDI, P166
   Kallasjoki H, 2014, IEEE-ACM T AUDIO SPE, V22, P368, DOI 10.1109/TASLP.2013.2292328
   Kousta ST, 2011, J EXP PSYCHOL GEN, V140, P14, DOI 10.1037/a0021446
   Krippendorff K., 1980, CONTENT ANAL INTRO I
   Lecouteux B, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P2122
   Levinson S, 1983, PRAGMATICS
   Levinson S. C., 2006, ROOTS HUMAN SOCIALIT, P39, DOI DOI 10.3389/FPSYG.2015.00731
   Lyon C, 2016, INT J ADV ROBOT SYST, V13, DOI 10.5772/63462
   Maas AL, 2017, COMPUT SPEECH LANG, V41, P195, DOI 10.1016/j.csl.2016.06.007
   Mastin JD, 2016, J CHILD LANG, V43, P235, DOI 10.1017/S0305000915000148
   Mavridis N., 2005, PROCEEDINGS OF AAAI, P32
   Metta G., 2006, International Journal of Advanced Robotic Systems, V3, P43
   Metta G., 2008, P 8 WORKSH PERF METR, P50, DOI DOI 10.1145/1774674.1774683
   Montgomery D. E., 2005, WHY LANGUAGE MATTERS, P106, DOI 10.1093/acprof:oso/9780195159912.003.0006
   Morse A. F., 2011, EXPANDING SPACE COGN, P3034
   Nelson K. A., 2005, WHY LANGUAGE MATTERS, P26, DOI DOI 10.1093/ACPROF:OSO/9780195159912.003.0002
   Newport E. L., 1977, COGNITIVE THEORY, V2, P177
   Olson J, 2011, J CHILD LANG, V38, P1028, DOI 10.1017/S0305000910000565
   Pea R., 1980, SOCIAL FDN LANGUAGE, P156
   Rescorla R. A, 1972, CLASSICAL CONDITION, V2, P64, DOI DOI 10.1037/A0030892
   Rietveld T., 1993, STAT TECHNIQUES STUD
   Roy D, 2005, TRENDS COGN SCI, V9, P389, DOI 10.1016/j.tics.2005.06.013
   Roy D., 2008, SYMBOLS EMBODIMENT D
   Roy DK, 2002, COGNITIVE SCI, V26, P113, DOI 10.1016/S0364-0213(01)00061-1
   Ruesch J, 2008, IEEE INT CONF ROBOT, P962, DOI 10.1109/ROBOT.2008.4543329
   RYAN J, 1974, INTEGRATION CHILD SO
   SACKS H, 1974, LANGUAGE, V50, P696, DOI 10.2307/412243
   Saunders J., 2012, P IEEE INT C DEV LEA, P1
   Saunders J., 2011, DEV LEARN ICDL 2011, P1
   Saunders J, 2011, ADV INTERACT STUD, V2, P211
   Scherer Klaus R., 2010, BLUEPRINT AFFECTIVE
   Schults A, 2012, J CHILD LANG, V39, P664, DOI 10.1017/S0305000911000225
   Searle J., 1969, SPEECH ACTS ESSAY PH
   Siskind JM, 2001, J ARTIF INTELL RES, V15, P31, DOI 10.1613/jair.790
   Slaughter V, 2009, J CHILD LANG, V36, P1053, DOI 10.1017/S0305000908009306
   Snow Catherine E., 1977, TALKING CHILDREN LAN, P31
   Steels L, 2003, ROBOT AUTON SYST, V43, P163, DOI 10.1016/S0921-8890(02)00357-3
   Steels L., 2012, LANGUAGE GROUNDING R, P1
   Steels L, 2016, PHILOS T R SOC B, V371, DOI 10.1098/rstb.2015.0447
   Steels L, 2011, PHYS LIFE REV, V8, P339, DOI 10.1016/j.plrev.2011.10.014
   Sugita Y, 2005, ADAPT BEHAV, V13, P33, DOI 10.1177/105971230501300102
   Symons DK, 2004, DEV REV, V24, P159, DOI 10.1016/j.dr.2004.03.001
   Tani J., 2016, EXPLORING ROBOTIC MI
   Tomasello M., 2003, CONSTRUCTING LANGUAG
   Varela F. J., 1991, EMBODIED MIND COGNIT
   Volterra V., 1979, DEV PRAGMATICS
   Zhong J., 2016, ARXIV160503261CSRO
NR 78
TC 0
Z9 0
U1 5
U2 5
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2379-8920
EI 2379-8939
J9 IEEE T COGN DEV SYST
JI IEEE Trans. Cogn. Dev. Syst.
PD SEP
PY 2018
VL 10
IS 3
BP 530
EP 544
DI 10.1109/TCDS.2017.2752366
PG 15
WC Computer Science, Artificial Intelligence; Robotics; Neurosciences
SC Computer Science; Robotics; Neurosciences & Neurology
GA GT6JO
UT WOS:000444617100004
OA Bronze
DA 2019-02-18
ER

PT J
AU Park, JC
   Kim, DS
   Nagai, Y
AF Park, Jun-Cheol
   Kim, Dae-Shik
   Nagai, Yukie
TI Learning for Goal-Directed Actions Using RIV\PB: Developmental Change of
   "What to Imitate"
SO IEEE TRANSACTIONS ON COGNITIVE AND DEVELOPMENTAL SYSTEMS
LA English
DT Article
DE Error-based learning; imitation learning; predictive learning; recurrent
   neural network with parametric bias (RNNPB); what to imitate
ID CHILDREN; ROBOTS; PERSPECTIVE; MOVEMENT; BEHAVIOR; INFANCY; MEMORY;
   SYSTEM
AB "What to imitate" is one of the most important and difficult issues in robot imitation learning. A possible solution from an engineering approach involves focusing on the salient properties of actions. We investigate the developmental change of what to imitate in robot action learning in this paper. Our robot is equipped with a recurrent neural network with parametric bias (RNNPB), and learned to imitate multiple goal-directed actions in two different environments (i.e., simulation and real humanoid robot). Our close analysis of the error measures and the internal representation of the RNNPB revealed that actions' most salient properties (i.e., reaching the desired end of motor trajectories) were learned first, while the less salient properties (i.e., matching the shape of motor trajectories) were learned later. Interestingly, this result was analogous to the developmental process of human infant's action imitation. We discuss the importance of our results in terms of understanding the underlying mechanisms of human development.
C1 [Park, Jun-Cheol; Kim, Dae-Shik] Korea Adv Inst Sci & Technol, Sch Elect Engn, Daejeon 34141, South Korea.
   [Nagai, Yukie] Osaka Univ, Dept Adapt Machine Syst, Osaka 5650871, Japan.
RP Park, JC (reprint author), Korea Adv Inst Sci & Technol, Sch Elect Engn, Daejeon 34141, South Korea.
EM pakjce@kaist.ac.kr; daeshik@kaist.ac.kr; yukie@ams.eng.osaka-u.ac.jp
RI Kim, Dae-Shik/C-2071-2011
FU MEXT/JSPS KAKENHI [24119003, 24000012]; Brain Research Program through
   the National Research Foundation of Korea - Ministry of Science, ICT and
   Future Planing [NRF-2010-0018837]
FX This work was supported in part by MEXT/JSPS KAKENHI under Research
   Project 24119003 and Research Project 24000012, and in part by the Brain
   Research Program through the National Research Foundation of Korea
   funded by the Ministry of Science, ICT and Future Planing under Grant
   NRF-2010-0018837.
CR Asada M, 2001, ROBOT AUTON SYST, V37, P185, DOI 10.1016/S0921-8890(01)00157-9
   Bakker P., 1996, WORKSH LEARN ROB AN, P3
   Barakova EI, 2011, INT J INTELL SYST, V26, P228, DOI 10.1002/int.20464
   Bekkering H, 2000, Q J EXP PSYCHOL-A, V53, P153, DOI 10.1080/027249800390718
   Billard A, 2004, ROBOT AUTON SYST, V47, P69, DOI 10.1016/j.robot.2004.03.002
   Bowerman M., 1982, U SHAPED BEHAV GROWT, P101
   Brass M, 2005, TRENDS COGN SCI, V9, P489, DOI 10.1016/j.tics.2005.08.007
   Breazeal C, 2002, TRENDS COGN SCI, V6, P481, DOI 10.1016/S1364-6613(02)02016-8
   Breazeal C, 2002, FROM ANIM ANIMAT, P363
   BUSHNELL EW, 1985, INFANT BEHAV DEV, V8, P139, DOI 10.1016/S0163-6383(85)80002-3
   Calinon S, 2005, IEEE INT CONF ROBOT, P299
   Carlucci L, 2007, INFORM COMPUT, V205, P1551, DOI 10.1016/j.ic.2007.04.001
   Carpenter M, 2005, DEVELOPMENTAL SCI, V8, pF13, DOI 10.1111/j.1467-7687.2004.00385.x
   Carpenter M, 1998, INFANT BEHAV DEV, V21, P315, DOI 10.1016/S0163-6383(98)90009-1
   Carpenter M, 2007, IMITATION AND SOCIAL LEARNING IN ROBOTS, HUMANS AND ANIMALS: BEHAVIOURAL, SOCIAL AND COMMUNICATIVE DIMENSIONS, P135, DOI 10.1017/CBO9780511489808.011
   Elsner B, 2007, ACTA PSYCHOL, V124, P44, DOI 10.1016/j.actpsy.2006.09.006
   Gergely G, 2003, CONNECT SCI, V15, P191, DOI 10.1080/09540090310001684604
   Gershkoff-Stowe L, 2004, J COGN DEV, V5, P11, DOI 10.1207/s15327647jcd0501_2
   Heyes C, 2009, PHILOS T R SOC B, V364, P2293, DOI 10.1098/rstb.2009.0049
   Hoffmann H., 2009, P IEEE INT C ROB AUT, P2587, DOI DOI 10.1109/ROBOT.2009.5152423
   Ito M, 2004, LECT NOTES COMPUT SC, V3316, P592
   JORDAN MI, 1986, P 8 ANN C COGN SCI S, P531
   Kilner J, 2007, SOC NEUROSCI-UK, V2, P158, DOI 10.1080/17470910701428190
   Kilner JM, 2007, NEUROREPORT, V18, P619, DOI 10.1097/WNR.0b013e3281139ed0
   Lee K, 2013, ROBOT AUTON SYST, V61, P1323, DOI 10.1016/j.robot.2013.08.003
   Loucks J, 2013, SCAND J PSYCHOL, V54, P41, DOI 10.1111/sjop.12004
   Lungarella M, 2003, CONNECT SCI, V15, P151, DOI 10.1080/09540090310001655110
   Matsubara T, 2010, IEEE INT C INT ROBOT, P1277, DOI 10.1109/IROS.2010.5651049
   MELTZOFF AN, 1995, DEV PSYCHOL, V31, P838, DOI 10.1037/0012-1649.31.5.838
   Michini B, 2013, IEEE INT CONF ROBOT, P303, DOI 10.1109/ICRA.2013.6630592
   Mohammad Y, 2012, 2012 12TH INTERNATIONAL CONFERENCE ON CONTROL, AUTOMATION AND SYSTEMS (ICCAS), P726
   Nagai Y., 2015, P IROS WORKSH SENS C
   Nagai Y, 2008, INT C DEVEL LEARN, P1, DOI 10.1109/DEVLRN.2008.4640796
   Ognibene D, 2013, COMPUTATIONAL AND RO, P81
   Park JC, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00134
   RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626
   Rozo L, 2010, P 1 IEEE INT C APPL, P331
   Rozo L, 2013, INTEL SERV ROBOT, V6, P33, DOI 10.1007/s11370-012-0128-9
   Taatgen NA, 2002, COGNITION, V86, P123, DOI 10.1016/S0010-0277(02)00176-2
   Tani J, 2004, NEURAL NETWORKS, V17, P1273, DOI 10.1016/j.neunet.2004.05.007
   WERBOS PJ, 1990, P IEEE, V78, P1550, DOI 10.1109/5.58337
   Wohlschlager A, 2003, PHILOS T R SOC B, V358, P501, DOI 10.1098/rstb.2002.1257
   Wolpert DM, 2001, TRENDS COGN SCI, V5, P487, DOI 10.1016/S1364-6613(00)01773-3
   Yamashita Y, 2008, PLOS COMPUT BIOL, V4, DOI 10.1371/journal.pcbi.1000220
   Yokoya R, 2006, 2006 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-12, P3669, DOI 10.1109/IROS.2006.281724
NR 45
TC 0
Z9 0
U1 0
U2 0
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2379-8920
EI 2379-8939
J9 IEEE T COGN DEV SYST
JI IEEE Trans. Cogn. Dev. Syst.
PD SEP
PY 2018
VL 10
IS 3
BP 545
EP 556
DI 10.1109/TCDS.2017.2679765
PG 12
WC Computer Science, Artificial Intelligence; Robotics; Neurosciences
SC Computer Science; Robotics; Neurosciences & Neurology
GA GT6JO
UT WOS:000444617100005
OA Bronze
DA 2019-02-18
ER

PT J
AU Mar, T
   Tikhanoff, V
   Natale, L
AF Mar, Tanis
   Tikhanoff, Vadim
   Natale, Lorenzo
TI What Can I Do With This Tool? Self-Supervised Learning of Tool
   Affordances From Their 3-D Geometry
SO IEEE TRANSACTIONS ON COGNITIVE AND DEVELOPMENTAL SYSTEMS
LA English
DT Article
DE 3-D features; affordances; humanoid robot; iCub; interaction learning;
   tool use
ID REPRESENTATION; SYSTEMS; ROBOT; MODELS; MONKEY
AB The ability to use tools can significantly increase the range of activities that an agent is capable of. Humans start using external objects since an early age to accomplish their goals, learning from interaction and observation the relationship between the objects used, their own actions, and the resulting effects, i.e., the tool affordances. Robots capable of autonomously learning affordances in a similar self-supervised way would be far more versatile and simpler to design than purpose-specific ones. This paper proposes and evaluates an approach to allow robots to learn tool affordances from interaction, and generalize them among similar tools based on their 3-D geometry. A set of actions is performed by the iCub robot with a large number of tools grasped in different poses, and the effects observed. Tool affordances are learned as a regression between tool-pose features and action-effect vector projections on respective self-organizing maps, which enables the system to avoid categorization and keep gradual representations of both elements. Moreover, we propose a set of robot-centric 3-D tool descriptors, and study their suitability for interaction scenarios, comparing also their performance against features derived from deep convolutional neural networks. Results show that the presented methods allow the robot to predict the effect of its tool use actions accurately, even for previously unseen tool and poses, and thereby to select the best action for a particular goal given a tool-pose.
C1 [Mar, Tanis; Tikhanoff, Vadim; Natale, Lorenzo] Italian Inst Technol, iCub Facil, I-16163 Genoa, Italy.
RP Mar, T (reprint author), Italian Inst Technol, iCub Facil, I-16163 Genoa, Italy.
EM tanis.mar@iit.it; vadim.tikhanoff@iit.it; lorenzo.natale@iit.it
FU European FP7 ICT [270273, 288382]
FX This work was supported by the European FP7 ICT under Project 270273
   (Xperience) and Project 288382 (POETICON++).
CR Abelha P, 2016, IEEE INT CONF ROBOT, P2471, DOI 10.1109/ICRA.2016.7487400
   Nguyen A, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P2765, DOI 10.1109/IROS.2016.7759429
   Baranes A, 2013, ROBOT AUTON SYST, V61, P49, DOI 10.1016/j.robot.2012.05.008
   Bartoli E, 2014, NEUROPSYCHOLOGIA, V61, P335, DOI 10.1016/j.neuropsychologia.2014.06.025
   Brown S., 2011, P ADV COGN SYST ARL, P58
   Chemero A, 2003, ECOL PSYCHOL, V15, P181, DOI 10.1207/S15326969ECO1502_5
   Dehban A., 2016, P IEEE INT C ROB AUT, P1
   Di Xu, 2012, Advances in Multimedia Information Processing - PCM 2012. 13th Pacific-Rim Conference on Multimedia. Proceedings, P476, DOI 10.1007/978-3-642-34778-8_44
   Fanello SR, 2014, IEEE-RAS INT C HUMAN, P1028, DOI 10.1109/HUMANOIDS.2014.7041491
   Fichtl S, 2014, IEEE INT CONF ROBOT, P501, DOI 10.1109/ICRA.2014.6906902
   Fitzpatrick P, 2003, IEEE INT CONF ROBOT, P3140
   Geib C., 2006, P IEEE RAS INT C HUM
   Gibson E., 2000, ECOLOGICAL APPROACH
   Gibson E. J, 1969, PRINCIPLES PERCEPTUA
   Gibson J. J, 1979, ECOLOGICAL APPROACH
   Glover A., 2014, THESIS
   Goldstone RL, 1998, ANNU REV PSYCHOL, V49, P585, DOI 10.1146/annurev.psych.49.1.585
   Goncalves A., 2014, P IEEE FIE, P1
   Goncalves A, 2014, 2014 IEEE INTERNATIONAL CONFERENCE ON AUTONOMOUS ROBOT SYSTEMS AND COMPETITIONS (ICARSC), P128, DOI 10.1109/ICARSC.2014.6849774
   Griffith S, 2012, IEEE T AUTON MENT DE, V4, P54, DOI 10.1109/TAMD.2011.2157504
   Guerin F, 2013, IEEE T AUTON MENT DE, V5, P18, DOI 10.1109/TAMD.2012.2209879
   HORN BKP, 1984, P IEEE, V72, P1671, DOI 10.1109/PROC.1984.13073
   Huang FJ, 2007, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2007.383157
   Jain R., 2011, 2011 IEEE/SICE International Symposium on System Integration (SII 2011), P814, DOI 10.1109/SII.2011.6147553
   Jain R, 2013, ARTIF LIFE ROBOT, V18, P95, DOI 10.1007/s10015-013-0105-1
   Jamone L., IEEE T COGN DEV SYST
   Kim DI, 2014, IEEE INT CONF ROBOT, P5578, DOI 10.1109/ICRA.2014.6907679
   KOHONEN T, 1990, P IEEE, V78, P1464, DOI 10.1109/5.58325
   Krizhevsky A., 2012, ADV NEURAL INFORM PR, P1097, DOI DOI 10.1145/3065386
   Kruger N, 2011, ROBOT AUTON SYST, V59, P740, DOI 10.1016/j.robot.2011.05.009
   LeCun Y, 2012, LECT NOTES COMPUT SC, V7583, P496, DOI 10.1007/978-3-642-33863-2_51
   Lee H. J., 2010, THESIS
   Mace W. M., 1982, COGNITION SYMBOLIC P, P159
   Madry M, 2012, IEEE INT C INT ROBOT, P1379, DOI 10.1109/IROS.2012.6385874
   Mar T, 2015, IEEE-RAS INT C HUMAN, P482, DOI 10.1109/HUMANOIDS.2015.7363593
   Mar T, 2015, IEEE INT CONF ROBOT, P3200, DOI 10.1109/ICRA.2015.7139640
   Matelli M, 2001, NEUROIMAGE, V14, pS27, DOI 10.1006/nimg.2001.0835
   Metta G., 2006, DEV COGN HUMANOID CU
   Metta G, 2010, NEURAL NETWORKS, V23, P1125, DOI 10.1016/j.neunet.2010.08.010
   Moldovan B, 2012, IEEE INT CONF ROBOT, P4373, DOI 10.1109/ICRA.2012.6225042
   Montesano Luis, 2007, 2007 IEEE/RSJ International Conference on Intelligent Robots and Systems, P4102, DOI 10.1109/IROS.2007.4399511
   Montesano L, 2008, IEEE T ROBOT, V24, P15, DOI 10.1109/TRO.2007.914848
   Murata A, 1997, J NEUROPHYSIOL, V78, P2226
   Myers A., 2015, P INT C ROB AUT, P5
   Nair V., 2009, ADV NEURAL INF PROCE, P1339
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Osorio P., 2010, P INT C INT ROB SYST, P1
   Oudeyer PY, 2007, IEEE T EVOLUT COMPUT, V11, P265, DOI 10.1109/TEVC.2006.890271
   Pasquale G., 2015, P 4 WORKSH MACH LEAR, V43, P21
   Qi CR, 2016, PROC CVPR IEEE, P5648, DOI 10.1109/CVPR.2016.609
   Ren CY, 2013, IEEE I CONF COMP VIS, P1561, DOI 10.1109/ICCV.2013.197
   Ridge B, 2015, INT J ADV ROBOT SYST, V12, DOI 10.5772/59654
   Ridge B, 2010, IEEE INT CONF ROBOT, P5047, DOI 10.1109/ROBOT.2010.5509544
   Roy A, 2016, LECT NOTES COMPUT SC, V9908, P186, DOI 10.1007/978-3-319-46493-0_12
   Rusu R. B., 2011, P IEEE INT C ROB AUT, P1, DOI [10.1109/ICRA.2011.5980567, DOI 10.1109/ICRA.2011.5980567]
   Sahin E, 2007, ADAPT BEHAV, V15, P447, DOI 10.1177/1059712307084689
   Schoeler M, 2016, IEEE T COGN DEV SYST, V8, P84, DOI 10.1109/TAMD.2015.2488284
   Sinapov J, 2011, INT J ROBOT RES, V30, P1250, DOI 10.1177/0278364911408368
   Sinapov J, 2008, INT C DEVEL LEARN, P91, DOI 10.1109/DEVLRN.2008.4640811
   SPECHT DF, 1991, IEEE T NEURAL NETWOR, V2, P568, DOI 10.1109/72.97934
   Srikantha A., 2016, ARXIV160502964, P1
   Stoytchev A, 2005, IEEE INT CONF ROBOT, P3060
   Stoytchev A., 2005, P AAAI S DEV ROB, P21
   Thill S, 2013, NEUROSCI BIOBEHAV R, V37, P491, DOI 10.1016/j.neubiorev.2013.01.012
   Tikhanoff V, 2013, IEEE-RAS INT C HUMAN, P130, DOI 10.1109/HUMANOIDS.2013.7029967
   Tikhanoff V., 2008, P 8 WORKSH PERF METR, P57, DOI DOI 10.1145/1774674.1774684
   Trimble, 2016, 3D MOD EV SKETCHUP
   Turvey M. T., 1992, ECOL PSYCHOL, V4, P173, DOI DOI 10.1207/S15326969EC00403_
   Ugur E., 2011, 2011 IEEE International Conference on Robotics and Automation (ICRA 2011), P4768, DOI 10.1109/ICRA.2011.5980299
   Ugur E., 2015, P INT C ROB AUT SEAT, P2621
   Ugur E., IEEE T COGN DEV SYST
   Ugur E, 2014, FOUTH JOINT IEEE INTERNATIONAL CONFERENCES ON DEVELOPMENT AND LEARNING AND EPIGENETIC ROBOTICS (IEEE ICDL-EPIROB 2014), P476, DOI 10.1109/DEVLRN.2014.6983026
   Ugur E, 2014, FOUTH JOINT IEEE INTERNATIONAL CONFERENCES ON DEVELOPMENT AND LEARNING AND EPIGENETIC ROBOTICS (IEEE ICDL-EPIROB 2014), P489, DOI 10.1109/DEVLRN.2014.6983028
   Ugur E, 2011, ROBOT AUTON SYST, V59, P580, DOI 10.1016/j.robot.2011.04.005
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Vesanto J., 2000, P MATL DSP C, P35
   Viezzer M., 2005, P INT JOINT C ART IN
   Vranic D. V., 2005, P SPRING C COMP GRAP, P89
   Wang C, 2013, IEEE INT C INT ROBOT, P2288, DOI 10.1109/IROS.2013.6696676
   Wu Z. B., 2015, P IEEE CIC INT C COM, P1
   Zhang YW, 2015, SCI REP-UK, V5, DOI 10.1038/srep10909
NR 81
TC 1
Z9 1
U1 0
U2 0
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2379-8920
EI 2379-8939
J9 IEEE T COGN DEV SYST
JI IEEE Trans. Cogn. Dev. Syst.
PD SEP
PY 2018
VL 10
IS 3
BP 595
EP 610
DI 10.1109/TCDS.2017.2717041
PG 16
WC Computer Science, Artificial Intelligence; Robotics; Neurosciences
SC Computer Science; Robotics; Neurosciences & Neurology
GA GT6JO
UT WOS:000444617100009
DA 2019-02-18
ER

PT J
AU Manson, GA
   Manzone, D
   de Grosbois, J
   Goodman, R
   Wong, J
   Reid, C
   Bhattacharjee, A
   Crainic, V
   Tremblay, L
AF Manson, Gerome A.
   Manzone, Damian
   de Grosbois, John
   Goodman, Rachel
   Wong, Joanne
   Reid, Connor
   Bhattacharjee, Arindam
   Crainic, Valentin
   Tremblay, Luc
TI Let Us Not Play It by Ear: Auditory Gating and Audiovisual Perception
   During Rapid Goal-Directed Action
SO IEEE TRANSACTIONS ON COGNITIVE AND DEVELOPMENTAL SYSTEMS
LA English
DT Article
DE Audition; multimodal perception; reaching; vision
ID MOTOR SYSTEM; MOVEMENT; SENSITIVITY; STRATEGIES; ILLUSIONS; VELOCITY;
   CONTEXT; VISION; INPUTS
AB Susceptibility to audiovisual illusions is altered during rapid upper-limb reaching movements. Although, this change in perception appears to be linked to the movement's real-time characteristics, the mechanism for this alteration remains unknown. In this paper, we examined whether this modulation of multisensory perception could be explained by a decrease in auditory perceptual sensitivity. In two protocols, participants were instructed to perform rapid reaches to a visual target and report the number of auditory events (beeps) they perceived. One or 2 brief beeps were presented with either 0, 1, or 2 brief visual flashes at 0, 100, or 200 ms (protocol 1), or 0, 200, or 400 ms (protocol 2) relative to movement onset. The results revealed a significant, stable, decrease in auditory perception when the stimuli were presented during the movement, as compared to after the movement, and no-movement trials. Overall, the findings of this paper suggest that auditory perceptual sensitivity is monotonically reduced as one engages in visually guided goal-directed actions.
C1 [Manson, Gerome A.; Manzone, Damian; de Grosbois, John; Goodman, Rachel; Wong, Joanne; Reid, Connor; Crainic, Valentin; Tremblay, Luc] Univ Toronto, Toronto, ON M5S 2W6, Canada.
   [Manson, Gerome A.] Aix Marseille Univ, F-1333 Marseille, France.
   [Bhattacharjee, Arindam] Univ Tubingen, D-72074 Tubingen, Germany.
RP Manson, GA (reprint author), Univ Toronto, Toronto, ON M5S 2W6, Canada.
EM gerome.manson@utoronto.ca; damian.manzone@mail.utoronto.ca;
   r.goodman@mail.utoronto.ca; jl.wong@mail.utoronto.ca;
   connor.reid@mail.utoronto.ca;
   arindam.bhattarcharjee@cin.uni-tubingen.de;
   valentin.crainic@utoronto.ca; luc.tremblay@mail.utoronto.ca
OI Manson, Gerome/0000-0003-0395-1760; Wong, Joanne/0000-0002-1835-3715
FU Natural Science and Engineering Research Council of Canada; Canadian
   Foundation for Innovation
FX This work was supported in part by the Natural Science and Engineering
   Research Council of Canada, and in part by the Canadian Foundation for
   Innovation.
CR Andersen TS, 2004, COGNITIVE BRAIN RES, V21, P301, DOI 10.1016/j.cogbrainres.2004.06.004
   Bernier PM, 2010, NEURON, V68, P776, DOI 10.1016/j.neuron.2010.11.002
   Blakemore SJ, 1998, J NEUROSCI, V18, P7511
   Blakemore SJ, 2000, NEUROREPORT, V11, pR11, DOI 10.1097/00001756-200008030-00002
   Blouin J, 2014, J NEUROPHYSIOL, V112, P2290, DOI 10.1152/jn.00857.2013
   BRIDGEMAN B, 1975, VISION RES, V15, P719, DOI 10.1016/0042-6989(75)90290-4
   BRUNIA CHM, 1993, PSYCHOPHYSIOLOGY, V30, P327, DOI 10.1111/j.1469-8986.1993.tb02054.x
   Chapman CE, 2006, J NEUROPHYSIOL, V96, P1664, DOI 10.1152/jn.00214.2006
   CHAPMAN CE, 1987, EXP BRAIN RES, V68, P516
   Colino FL, 2014, PHYSIOL REP, V2, DOI 10.1002/phy2.267
   Elliott D, 2010, PSYCHOL BULL, V136, P1023, DOI 10.1037/a0020958
   Ernst MO, 2004, TRENDS COGN SCI, V8, P162, DOI 10.1016/j.tics.2004.02.002
   FITTS PM, 1954, J EXP PSYCHOL, V47, P381, DOI 10.1037/h0055392
   Grunwald T, 2003, BIOL PSYCHIAT, V53, P511, DOI 10.1016/S0002-3223(03)01673-2
   Juravle G, 2017, PSYCHON B REV, V24, P1060, DOI 10.3758/s13423-016-1203-6
   Juravle G, 2015, ACTA PSYCHOL, V161, P154, DOI 10.1016/j.actpsy.2015.09.002
   Juravle G, 2010, BEHAV BRAIN RES, V208, P391, DOI 10.1016/j.bbr.2009.12.009
   Kao LS, 2008, J SURG RES, V144, P158, DOI 10.1016/j.jss.2007.02.053
   Kennedy A, 2015, J MOTOR BEHAV, V47, P465, DOI 10.1080/00222895.2015.1012579
   Lebar N, 2017, NEUROIMAGE, V150, P200, DOI 10.1016/j.neuroimage.2017.02.043
   Maselli A, 2016, SCI REP-UK, V6, DOI 10.1038/srep30628
   MATIN E, 1974, PSYCHOL BULL, V81, P899, DOI 10.1037/h0037368
   Mendoza G, 2014, PROG NEUROBIOL, V122, P73, DOI 10.1016/j.pneurobio.2014.09.001
   Saradjian AH, 2015, NEUROPHYSIOL CLIN, V45, P255, DOI 10.1016/j.neucli.2015.09.004
   Saradjian AH, 2013, J NEUROPHYSIOL, V110, P397, DOI 10.1152/jn.00905.2012
   Sarlegna FR, 2007, EXP BRAIN RES, V176, P267, DOI 10.1007/s00221-006-0613-5
   SEAMAN MA, 1991, PSYCHOL BULL, V110, P577, DOI 10.1037//0033-2909.110.3.577
   Shams L, 2000, NATURE, V408, P788, DOI 10.1038/35048669
   Sober SJ, 2005, NAT NEUROSCI, V8, P490, DOI 10.1038/nn1427
   Tremblay L, 2017, EXP BRAIN RES, V235, P29, DOI 10.1007/s00221-016-4770-x
   Tremblay L, 2013, J MOTOR BEHAV, V45, P91, DOI 10.1080/00222895.2012.747483
   Tremblay L, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0008952
NR 32
TC 0
Z9 0
U1 1
U2 1
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2379-8920
EI 2379-8939
J9 IEEE T COGN DEV SYST
JI IEEE Trans. Cogn. Dev. Syst.
PD SEP
PY 2018
VL 10
IS 3
BP 659
EP 667
DI 10.1109/TCDS.2017.2773423
PG 9
WC Computer Science, Artificial Intelligence; Robotics; Neurosciences
SC Computer Science; Robotics; Neurosciences & Neurology
GA GT6JO
UT WOS:000444617100014
DA 2019-02-18
ER

PT J
AU Murata, S
   Li, YX
   Arie, H
   Ogata, T
   Sugano, S
AF Murata, Shingo
   Li, Yuxi
   Arie, Hiroaki
   Ogata, Tetsuya
   Sugano, Shigeki
TI Learning to Achieve Different Levels of Adaptability for Human-Robot
   Collaboration Utilizing a Neuro-Dynamical System
SO IEEE TRANSACTIONS ON COGNITIVE AND DEVELOPMENTAL SYSTEMS
LA English
DT Article
DE Adaptation; generalization; human-robot collaboration; neuro-robotics;
   recurrent neural network (RNN)
ID SELF-ORGANIZATION; NETWORK MODEL; TIME; BEHAVIOR; PRIMITIVES; TASK
AB Intelligent robots are expected to collaboratively work with humans in dynamically changing daily life environments. To realize successful human-robot collaboration, robots need to deal with latent spatiotemporal complexity in the workspace and the task. To overcome this crucial issue, three levels of adaptability-motion modification, action selection, and role switching-should be considered. This paper demonstrates that a single hierarchically organized neuro-dynamical system called a multiple timescale recurrent neural network can achieve these levels of adaptability by utilizing hierarchical and bidirectional information processing. The system is implemented in a humanoid robot and the robot is required to learn to perform collaborative tasks in which some parts must be performed by a human partner and others by the robot. Experimental results show that the robot can perform collaborative tasks under dynamically changing environments, including both learned and unlearned situations, thanks to different levels of adaptability acquired in the system.
C1 [Murata, Shingo; Li, Yuxi; Arie, Hiroaki; Sugano, Shigeki] Waseda Univ, Dept Modern Mech Engn, Tokyo 1698555, Japan.
   [Ogata, Tetsuya] Waseda Univ, Dept Intermedia Art & Sci, Tokyo 1698555, Japan.
RP Murata, S (reprint author), Waseda Univ, Dept Modern Mech Engn, Tokyo 1698555, Japan.
EM murata@sugano.mech.waseda.ac.jp; yuxili@sugano.mech.waseda.ac.jp;
   arie@sugano.mech.waseda.ac; ogata@waseda.jp; sugano@waseda.jp
OI Ogata, Tetsuya/0000-0001-7015-0379
FU JST CREST [JPMJCR15E3]; MEXT [24119003]; JSPS [25220005, 16H05878];
   Research Institute for Science and Engineering, Waseda University, Japan
FX This work was supported in part by JST CREST under Grant JPMJCR15E3, in
   part by MEXT Grant-in-Aid for Scientific Research on Innovative Areas
   "Constructive Developmental Science" under Grant 24119003, in part by
   JSPS Grant-in-Aid for Scientific Research (S) under Grant 25220005, in
   part by a JSPS Grant-in-Aid for Young Scientists (A) under Grant
   16H05878, and in part by the "Fundamental Study for Intelligent Machine
   to Coexist with Nature" program of the Research Institute for Science
   and Engineering, Waseda University, Japan.
CR Alnajjar F, 2013, FRONT NEUROROBOTICS, V7, DOI 10.3389/fnbot.2013.00002
   Arbib M. A., 2002, HDB BRAIN THEORY NEU, V2, P830
   Arie H, 2012, ROBOT AUTON SYST, V60, P729, DOI 10.1016/j.robot.2011.11.005
   Arie H, 2010, LECT NOTES COMPUT SC, V6353, P256
   Awano H, 2010, 2010 IEEE International Conference on Systems, Man and Cybernetics (SMC 2010), P2533, DOI 10.1109/ICSMC.2010.5641924
   BARAGLIA J, 2016, ACMIEEE INT CONF HUM, P67
   BEER RD, 1995, ADAPT BEHAV, V3, P469, DOI 10.1177/105971239500300405
   Ben Amor H, 2014, IEEE INT CONF ROBOT, P2831, DOI 10.1109/ICRA.2014.6907265
   Billard A., 2008, SPRINGER HDB ROBOTIC, P1371, DOI DOI 10.1007/978-3-540-30301-5_60
   Bollen MHJ, 2011, P PR2 WORKSH RES CHA, P1
   Botvinick MM, 2008, TRENDS COGN SCI, V12, P201, DOI 10.1016/j.tics.2008.02.009
   Calinon S., 2009, P INT C ADV ROB ICAR, P1
   Calinon S, 2007, IEEE T SYST MAN CY B, V37, P286, DOI 10.1109/TSMCB.2006.886952
   Clark A, 2013, BEHAV BRAIN SCI, V36, P181, DOI 10.1017/S0140525X12000477
   DOYA K, 1989, NEURAL NETWORKS, V2, P375, DOI 10.1016/0893-6080(89)90022-1
   Ewerton M, 2015, IEEE INT CONF ROBOT, P1535, DOI 10.1109/ICRA.2015.7139393
   Fuster JM, 2001, NEURON, V30, P319, DOI 10.1016/S0896-6273(01)00285-9
   Hawkins KP, 2013, IEEE-RAS INT C HUMAN, P499, DOI 10.1109/HUMANOIDS.2013.7030020
   Hayes B., 2013, P COLL MAN WORKSH AC, P1
   Hohwy J., 2013, PREDICRIVE MIND
   Ijspeert AJ, 2013, NEURAL COMPUT, V25, P328, DOI 10.1162/NECO_a_00393
   Ito M, 2004, ADAPT BEHAV, V12, P93, DOI 10.1177/105971230401200202
   Ito M, 2006, NEURAL NETWORKS, V19, P323, DOI 10.1016/j.neunet.2006.02.007
   Khansari-Zadeh SM, 2011, IEEE T ROBOT, V27, P943, DOI 10.1109/TRO.2011.2159412
   Kulic D., 2011, VISUAL ANAL HUMANS, P333, DOI 10.1007/978-0-85729-997-0_17
   Lee D, 2010, INT J ROBOT RES, V29, P1684, DOI 10.1177/0278364910364164
   Lioutikov R, 2016, ADV INTELL SYST, V302, P1601, DOI 10.1007/978-3-319-08338-4_115
   Maeda G, 2014, IEEE-RAS INT C HUMAN, P527, DOI 10.1109/HUMANOIDS.2014.7041413
   Masci J, 2011, LECT NOTES COMPUT SC, V6791, P52, DOI 10.1007/978-3-642-21735-7_7
   Murata Shingo, 2014, Artificial Neural Networks and Machine Learning - ICANN 2014. 24th International Conference on Artificial Neural Networks. Proceedings: LNCS 8681, P9, DOI 10.1007/978-3-319-11179-7_2
   Murata S, 2017, IEEE T NEUR NET LEAR, V28, P830, DOI 10.1109/TNNLS.2015.2492140
   Murata S, 2013, IEEE T AUTON MENT DE, V5, P298, DOI 10.1109/TAMD.2013.2258019
   Nagai Y., 2015, P IROS WORKSH SENS C, P1
   Nakajo R, 2015, 5TH INTERNATIONAL CONFERENCE ON DEVELOPMENT AND LEARNING AND ON EPIGENETIC ROBOTICS (ICDL-EPIROB), P326, DOI 10.1109/DEVLRN.2015.7346166
   Namikawa J, 2011, PLOS COMPUT BIOL, V7, DOI 10.1371/journal.pcbi.1002221
   Namikawa J, 2010, NEURAL NETWORKS, V23, P625, DOI 10.1016/j.neunet.2009.12.006
   Nishimoto R, 2004, NEURAL NETWORKS, V17, P925, DOI 10.1016/j.neunet.2004.02.003
   Nishimoto R, 2008, ADAPT BEHAV, V16, P166, DOI 10.1177/1059712308089185
   Nishimoto R, 2009, PSYCHOL RES-PSYCH FO, V73, P545, DOI 10.1007/s00426-009-0236-0
   Noda K, 2014, ROBOT AUTON SYST, V62, P721, DOI 10.1016/j.robot.2014.03.003
   Paine RW, 2005, ADAPT BEHAV, V13, P211, DOI 10.1177/105971230501300303
   Paraschos A., 2013, NEURAL INFORM PROCES, P1
   Park G, 2015, NEURAL NETWORKS, V72, P109, DOI 10.1016/j.neunet.2015.09.004
   Rozo L, 2016, FRONT ROBOT AI, V3, DOI 10.3389/frobt.2016.00030
   Rumelhart D. E., 1986, PARALLEL DISTRIBUTED, P318, DOI DOI 10.1016/B978-1-4832-1446-7.50035-2
   Schaal S., 2006, ADAPTIVE MOTION ANIM
   Sheng WH, 2015, IEEE T CYBERNETICS, V45, P2030, DOI 10.1109/TCYB.2014.2363664
   Sugita Y, 2005, ADAPT BEHAV, V13, P33, DOI 10.1177/105971230501300102
   Takahashi K, 2015, MATH PROBL ENG, DOI 10.1155/2015/837540
   Tang HJ, 2016, IEEE C EVOL COMPUTAT, P1204, DOI 10.1109/CEC.2016.7743924
   Tani J, 2003, IEEE T SYST MAN CY A, V33, P481, DOI 10.1109/TSMCA.2003.809171
   Tani J, 2003, NEURAL NETWORKS, V16, P11, DOI 10.1016/S0893-6080(02)00214-9
   Tani J, 2014, P IEEE, V102, P586, DOI 10.1109/JPROC.2014.2308604
   Yamada T., 2016, FRONT NEUROROBOTICS, V10, P4179, DOI [10.3389/fnbot.2016.00005/abstract, DOI 10.3389/FNBOT.2016.00005/ABSTRACT]
   Yamashita Y, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0037843
   Yamashita Y, 2008, PLOS COMPUT BIOL, V4, DOI 10.1371/journal.pcbi.1000220
   Yang PC, 2017, IEEE ROBOT AUTOM LET, V2, P397, DOI 10.1109/LRA.2016.2633383
NR 57
TC 1
Z9 1
U1 5
U2 5
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2379-8920
EI 2379-8939
J9 IEEE T COGN DEV SYST
JI IEEE Trans. Cogn. Dev. Syst.
PD SEP
PY 2018
VL 10
IS 3
BP 712
EP 725
DI 10.1109/TCDS.2018.2797260
PG 14
WC Computer Science, Artificial Intelligence; Robotics; Neurosciences
SC Computer Science; Robotics; Neurosciences & Neurology
GA GT6JO
UT WOS:000444617100019
DA 2019-02-18
ER

PT J
AU Banerjee, R
   Pal, SK
AF Banerjee, Romi
   Pal, Sankar K.
TI Data-Structures for Multisensory Information Processing in an Embodied
   Machine-Mind
SO IEEE TRANSACTIONS ON COGNITIVE AND DEVELOPMENTAL SYSTEMS
LA English
DT Article
DE Autonomous mental development; data-structures; embodied cognition;
   generally intelligent man-machine systems; multimodal information
   processing; self-conscious systems; thinking machines
ID BRAIN; REPRESENTATION; INTEGRATION; ATTENTION; EPIGENETICS; KNOWLEDGE;
   COGNITION; MEMORIES; SYSTEMS; MODEL
AB The real-world is a medley of multisensory information and so are our experiences, memories, and responses. As embodied beings, we respond to the information endogenously and in ways derived from self-defining factors. Thus inspired, we attempt formalization of data-structures to facilitate generation of system-bespoke comprehension-granules of the real-world. The conceptualized structures encapsulate multisensory inputs (sourced from the real-world or memories), intrinsic and deliberate emotions, messages (bearing intermittent process-results, queries, multimodal data, etc.) across system modules and memory units, and sensorimotor responses to the inputs. The structural-schematics are anthropomorphic. These variable-length constructs are theoretically platform-independent, support genericity across data-modality and information-inclusion, and provide for representation of novel sensory-data. An epigenome-styled header node for the afferent data-units provides for the activation of intuitive "fight-flight" behavior. The documentation includes a flow-graph, depicting the translation of information across the data-structures and the different ways of thinking while interpreting a real-world scene or a mind-generated event. Applicability of the structures has been analyzed in the context of comprehension in an embodied mind-machine framework and other similar architectures. Studies herein target contribution to the design of generally intelligent man-machine symbiotic systems.
C1 [Banerjee, Romi; Pal, Sankar K.] Indian Stat Inst, Ctr Soft Comp Res, Kolkata 700108, India.
   [Banerjee, Romi] Univ Calcutta, Dept Comp Sci & Engn, Kolkata 7000098, India.
RP Banerjee, R (reprint author), Indian Stat Inst, Ctr Soft Comp Res, Kolkata 700108, India.
EM rm.banerjee@gmail.com; sankar@isical.ac.in
FU DAE Raja Ramanna Fellowship of the Government of India; J.C. Bose
   Fellowship of the Government of India
FX The authors acknowledge the DAE Raja Ramanna Fellowship of the
   Government of India. Professor Sankar K. Pal also acknowledges the J.C.
   Bose Fellowship (grant-in-aid) of the Government of India.
CR Aho AV, 1986, COMPILERS PRINCIPLES
   Arstila V., 2014, SUBJECTIVE TIME PHIL
   Balduzzi D, 2009, PLOS COMPUT BIOL, V5, DOI 10.1371/journal.pcbi.1000462
   Banerjee R., 2017, PATTERN RECOGN, P807
   Banerjee R, 2017, INFORM SCIENCES, V405, P227, DOI 10.1016/j.ins.2017.03.035
   Banerjee R, 2015, NAT COMPUT, V14, P603, DOI 10.1007/s11047-014-9478-x
   Baranes A, 2009, IEEE T AUTON MENT DE, V1, P155, DOI 10.1109/TAMD.2009.2037513
   Barsalou LW, 1999, BEHAV BRAIN SCI, V22, P577
   Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50
   Benjamin DP, 2004, PROCEEDINGS OF THE SIXTH INTERNATIONAL CONFERENCE ON COGNITIVE MODELING, P337
   Buchanan TW, 2007, PSYCHOL BULL, V133, P761, DOI 10.1037/0033-2909.133.5.761
   Callaghan C. O., 2012, OXFORD HDB PHILOS CO
   Chatterjee A, 2010, LANG COGN, V2, P79, DOI 10.1515/LANGCOG.2010.004
   Clifton C., 1995, VLDB J, V4, P45
   Coco MI, 2016, COGNITIVE SCI, V40, P1995, DOI 10.1111/cogs.12313
   Cullen KE, 2004, CURR OPIN NEUROBIOL, V14, P698, DOI 10.1016/j.conb.2004.10.002
   CULLER A, 1986, ANNU REV COMPUT SCI, V1, P225
   Damasio A., 1995, DESCARTES ERROR EMOT
   Damasio AR, 2012, SELF COMES MIND CONS
   Danker JF, 2010, PSYCHOL BULL, V136, P87, DOI 10.1037/a0017937
   deGelder B., 2004, HDB MULTISENSORY PRO, P581
   Doolittle P., 2013, YOUR WORKING MEMORY
   Eagleman DM, 2005, J NEUROSCI, V25, P10369, DOI 10.1523/JNEUROSCI.3487-05.2005
   Ebrahim S, 2012, INT J EPIDEMIOL, V41, P1, DOI 10.1093/ije/dys015
   Foxe JJ, 2005, NEUROREPORT, V16, P419, DOI 10.1097/00001756-200504040-00001
   Gallese V., 2013, PHENOMENOLOGY MIND, P269
   Gat E., 1992, AAAI-92. Proceedings Tenth National Conference on Artificial Intelligence, P809
   Gottlieb J, 2013, TRENDS COGN SCI, V17, P585, DOI 10.1016/j.tics.2013.09.001
   Harley T., 2008, PSYCHOL LANGUAGE DAT
   Holmes NP, 2005, CURR BIOL, V15, pR762, DOI 10.1016/j.cub.2005.08.058
   Hurlburt RT, 2013, CONSCIOUS COGN, V22, P1477, DOI 10.1016/j.concog.2013.10.003
   Imamizu H, 2000, NATURE, V403, P192, DOI 10.1038/35003194
   Klatzky R. L., 1998, Spatial Cognition. An Interdisciplinary Approach to Representing and Processing Spatial Knowledge, P1
   Kotseruba I., 2016, ARXIV161008602
   Lallee S, 2015, ROBOTICS, V4, P169, DOI 10.3390/robotics4020169
   Lallee S, 2012, IEEE T AUTON MENT DE, V4, P239, DOI 10.1109/TAMD.2012.2199754
   Macaluso E, 2005, TRENDS NEUROSCI, V28, P264, DOI 10.1016/j.tin.2005.03.008
   Marshall PJ, 2016, CHILD DEV PERSPECT, V10, P245, DOI 10.1111/cdep.12190
   MEAD C, 1990, P IEEE, V78, P1629, DOI 10.1109/5.58356
   Minsky M., 2006, EMOTION MACHINE COMM
   Minsky Marvin, 1986, SOC MIND
   Morgan B., 2013, THESIS
   Nandy AS, 2016, NEURON, V91, P920, DOI 10.1016/j.neuron.2016.07.026
   O'Callaghan C, 2017, MIND LANG, V32, P155, DOI 10.1111/mila.12137
   Oudeyer PY, 2017, WIRES COGN SCI, V8, DOI 10.1002/wcs.1395
   Pallas S. L., 2012, NEW HDB MULTISENSORY, P627
   Pedrycz W., 2000, FUTURE DIRECTIONS IN
   Peters RA, 2009, AUTON ROBOT, V26, P1, DOI 10.1007/s10514-008-9098-3
   Petit M, 2016, IEEE T COGN DEV SYST, V8, P201, DOI 10.1109/TAMD.2015.2507439
   Ramachandran V. S., 2010, TELL TALE BRAIN NEUR
   Schulkin J., 2004, BODILY SENSIBILITY I
   Sebastian A., 2017, NATURE COMMUN, V8, P1
   Seghier ML, 2013, NEUROSCIENTIST, V19, P43, DOI 10.1177/1073858412440596
   Sejnowski TJ, 2014, P IEEE, V102, P799, DOI 10.1109/JPROC.2014.2314297
   SHIFFRIN RM, 1977, PSYCHOL REV, V84, P127, DOI 10.1037/0033-295X.84.2.127
   Shinn-Cunningham BG, 2008, TRENDS COGN SCI, V12, P182, DOI 10.1016/j.tics.2008.02.003
   Singh P., 2005, THESIS
   Soto-Faraco S., 2004, HDB MULTISENSORY PRO, P49
   Sowa JF, 2008, FOUND ARTIF INTELL, P213, DOI 10.1016/S1574-6526(07)03005-2
   Tenorth M, 2013, IEEE T AUTOM SCI ENG, V10, P643, DOI 10.1109/TASE.2013.2244883
   TREISMAN AM, 1980, COGNITIVE PSYCHOL, V12, P97, DOI 10.1016/0010-0285(80)90005-5
   Trentelman K., 2009, DSTOTR2324
   Verschure PFMJ, 2012, BIOL INSPIR COGN ARC, V1, P55, DOI 10.1016/j.bica.2012.04.005
   Webber F. E. D. S., 2015, CISC VIS NETW IND GL
   Weinhold B, 2006, ENVIRON HEALTH PERSP, V114, pA160, DOI 10.1289/ehp.114-a160
   Zhang SQ, 2014, LECT NOTES ARTIF INT, V8755, P400, DOI 10.1007/978-3-319-11973-1_41
NR 66
TC 0
Z9 0
U1 2
U2 2
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2379-8920
EI 2379-8939
J9 IEEE T COGN DEV SYST
JI IEEE Trans. Cogn. Dev. Syst.
PD SEP
PY 2018
VL 10
IS 3
BP 726
EP 737
DI 10.1109/TCDS.2018.2816744
PG 12
WC Computer Science, Artificial Intelligence; Robotics; Neurosciences
SC Computer Science; Robotics; Neurosciences & Neurology
GA GT6JO
UT WOS:000444617100020
DA 2019-02-18
ER

PT J
AU Tang, HJ
   Yan, R
   Tan, KC
AF Tang, Huajin
   Yan, Rui
   Tan, Kay Chen
TI Cognitive Navigation by Neuro-Inspired Localization, Mapping, and
   Episodic Memory
SO IEEE TRANSACTIONS ON COGNITIVE AND DEVELOPMENTAL SYSTEMS
LA English
DT Article
DE Cognitive map; cognitive navigation; episodic memory; neuromorphic
   cognitive systems; simultaneously localization and mapping (SLAM)
ID ENTORHINAL-HIPPOCAMPAL SYSTEM; BRAIN-BASED DEVICES; SPATIAL
   REPRESENTATION; PATH-INTEGRATION; ROBOT-NAVIGATION; MOBILE ROBOT; PLACE
   CELLS; SLAM SYSTEM; GRID CELLS; MAP
AB One of the important topics in the study of robotic cognition is to enable robot to perceive, plan, and react to situations in a real-world environment. We present a novel angle on this subject, by integrating active navigation with sequence learning. We propose a neuro-inspired cognitive navigation model which integrates the cognitive mapping ability of entorhinal cortex (EC) and episodic memory ability of hippocampus to enable the robot to perform more versatile cognitive tasks. The EC layer is modeled by a 3-D continuous attractor network structure to build the map of the environment. The hippocampus is modeled by a recurrent spiking neural network to store and retrieve task-related information. The information between cognitive map and memory network are exchanged through respective encoding and decoding schemes. The cognitive system is applied on a mobile robot platform and the robot exploration, localization, and navigation are investigated. The robotic experiments demonstrate the effectiveness of the proposed system.
C1 [Tang, Huajin; Yan, Rui] Sichuan Univ, Coll Comp Sci, Neuromorph Comp Res Ctr, Chengdu 610065, Sichuan, Peoples R China.
   [Tan, Kay Chen] City Univ Hong Kong, Dept Comp Sci, Hong Kong, Hong Kong, Peoples R China.
RP Yan, R (reprint author), Sichuan Univ, Coll Comp Sci, Neuromorph Comp Res Ctr, Chengdu 610065, Sichuan, Peoples R China.
EM ryan@scu.edu.cn
FU National Key Research and Development Program of China [SQ2017YFB130092]
FX This work was supported by the National Key Research and Development
   Program of China under Grant SQ2017YFB130092.
CR BROOKS RA, 1986, IEEE T ROBOTIC AUTOM, V2, P14, DOI 10.1109/JRA.1986.1087032
   Brun VH, 2002, SCIENCE, V296, P2243, DOI 10.1126/science.1071089
   Buzsaki G, 2013, NAT NEUROSCI, V16, P130, DOI 10.1038/nn.3304
   Cangelosi A., 2015, DEV ROBOTICS BABIES
   Cutsuridis V, 2009, NEURAL NETWORKS, V22, P1120, DOI 10.1016/j.neunet.2009.07.009
   Edelman GM, 2007, SCIENCE, V318, P1103, DOI 10.1126/science.1148677
   Endo Y, 2008, IEEE INT CONF ROBOT, P2852, DOI 10.1109/ROBOT.2008.4543642
   Fleischer JG, 2009, IEEE ROBOT AUTOM MAG, V16, P33, DOI 10.1109/MRA.2009.933621
   Fyhn M, 2004, SCIENCE, V305, P1258, DOI 10.1126/science.1099901
   Giocomo LM, 2011, NEURON, V71, P589, DOI 10.1016/j.neuron.2011.07.023
   Gordon SM, 2010, IEEE T AUTON MENT DE, V2, P17, DOI 10.1109/TAMD.2010.2043530
   Hafting T, 2005, NATURE, V436, P801, DOI 10.1038/nature03721
   Hu J, 2016, IEEE COMPUT INTELL M, V11, P56, DOI 10.1109/MCI.2016.2532268
   Hwu T, 2018, IEEE T COGN DEV SYST, V10, P126, DOI 10.1109/TCDS.2017.2655539
   Jeffery KJ, 2007, CURR OPIN NEUROBIOL, V17, P684, DOI 10.1016/j.conb.2007.11.008
   Jensen O, 1996, LEARN MEMORY, V3, P257, DOI 10.1101/lm.3.2-3.257
   Jockel S, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS, VOLS 1-5, P1075, DOI 10.1109/ROBIO.2007.4522313
   Krichmar JL, 2005, P NATL ACAD SCI USA, V102, P2111, DOI 10.1073/pnas.0409792102
   Lavenex P, 2000, HIPPOCAMPUS, V10, P420, DOI 10.1002/1098-1063(2000)10:4<420::AID-HIPO8>3.0.CO;2-5
   McNaughton BL, 2006, NAT REV NEUROSCI, V7, P663, DOI 10.1038/nrn1932
   Milford M, 2010, INT J ROBOT RES, V29, P1131, DOI 10.1177/0278364909340592
   Milford MJ, 2008, IEEE T ROBOT, V24, P1038, DOI 10.1109/TRO.2008.2004520
   Moser EI, 2008, ANNU REV NEUROSCI, V31, P69, DOI 10.1146/annurev.neuro.31.061307.090723
   O'Keefe J, 1978, HIPPOCAMPUS COGNITIV, V3
   Redish A. D., 1999, COGNITIVE MAP PLACE
   Rolls E., 2008, LEARNING MEMORY COMP, P641
   Rolls ET, 2010, BEHAV BRAIN RES, V215, P180, DOI 10.1016/j.bbr.2010.03.027
   Rucinski M., 2011, P 23 ANN M COGN SCI, P20
   Samsonovich A, 1997, J NEUROSCI, V17, P5900
   Sharp PE, 2001, TRENDS NEUROSCI, V24, P289, DOI 10.1016/S0166-2236(00)01797-5
   Shim VA, 2014, IEEE INT C INT ROBOT, P2639, DOI 10.1109/IROS.2014.6942923
   Stachowicz D, 2012, IEEE T AUTON MENT DE, V4, P1, DOI 10.1109/TAMD.2011.2159004
   Tan CH, 2013, CONF CYBERN INTELL S, P134, DOI 10.1109/ICCIS.2013.6751592
   Tang HJ, 2017, NEURAL NETWORKS, V87, P27, DOI 10.1016/j.neunet.2016.08.015
   Tang HJ, 2010, NEURAL COMPUT, V22, P1899, DOI 10.1162/neco.2010.07-09-1050
   TAUBE JS, 1990, J NEUROSCI, V10, P420
   Thrun S, 1998, ARTIF INTELL, V99, P21, DOI 10.1016/S0004-3702(97)00078-7
   Tian B, 2013, IEEE INT C INT ROBOT, P1562, DOI 10.1109/IROS.2013.6696557
   TOLMAN EC, 1948, PSYCHOL REV, V55, P189, DOI 10.1037/h0061626
   Tulving E, 1998, HIPPOCAMPUS, V8, P198, DOI 10.1002/(SICI)1098-1063(1998)8:3<198::AID-HIPO2>3.0.CO;2-G
   Tulving E, 2002, ANNU REV PSYCHOL, V53, P1, DOI 10.1146/annurev.psych.53.100901.135114
   Tulving E, 1972, ORG MEMORY, P381
   WITTER MP, 1993, HIPPOCAMPUS, V3, P33
   Wyeth G, 2009, IEEE ROBOT AUTOM MAG, V16, P24, DOI 10.1109/MRA.2009.933620
   Yamaguchi Y, 2007, CURR OPIN NEUROBIOL, V17, P197, DOI 10.1016/j.conb.2007.03.007
   Yuan M., 2015, P 29 AAAI C ART INT, P586
   Zeno PJ, 2016, 2016 JOINT IEEE INTERNATIONAL CONFERENCE ON DEVELOPMENT AND LEARNING AND EPIGENETIC ROBOTICS (ICDL-EPIROB), P7, DOI 10.1109/DEVLRN.2016.7846778
NR 47
TC 2
Z9 2
U1 17
U2 17
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2379-8920
EI 2379-8939
J9 IEEE T COGN DEV SYST
JI IEEE Trans. Cogn. Dev. Syst.
PD SEP
PY 2018
VL 10
IS 3
BP 751
EP 761
DI 10.1109/TCDS.2017.2776965
PG 11
WC Computer Science, Artificial Intelligence; Robotics; Neurosciences
SC Computer Science; Robotics; Neurosciences & Neurology
GA GT6JO
UT WOS:000444617100022
DA 2019-02-18
ER

PT J
AU Horii, T
   Nagai, Y
   Asada, M
AF Horii, Takato
   Nagai, Yukie
   Asada, Minoru
TI Modeling Development of Multimodal Emotion Perception Guided by Tactile
   Dominance and Perceptual Improvement
SO IEEE TRANSACTIONS ON COGNITIVE AND DEVELOPMENTAL SYSTEMS
LA English
DT Article
DE Computational modeling; development of emotion perception;
   infant-caregiver interaction; neural networks for development;
   perceptual development; tactile interaction
ID CONGENITAL INSENSITIVITY; COMMUNICATIVE INTENT; FACE; INFANTS; VOICE;
   TOUCH; ROBOT; PAIN; INTEGRATION; ADAPTATION
AB Humans recognize others' emotional states such as delight, anger, sorrow, and pleasure through their multimodal expressions. However, it is unclear how this capability of emotion perception is acquired during infancy. This paper presents a neural network model that reproduces the developmental process of emotion perception through an infant-caregiver interaction. This network comprises hierarchically structured restricted Boltzmann machines (RBMs) that receive multimodal expressions from a caregiver (visual, audio, and tactile signals in our current experiment) and learn to estimate her/his emotional states. We hypothesize that emotional categories of multimodal stimuli are acquired in a higher layer in the network owing to two important functions: 1) tactile dominance and 2) perceptual improvement. The former refers to that tactile sensors can detect emotional valence of stimuli such as positive, negative, and zero valence more directly than can other sensors due to characteristics of the nerve systems of the skin. This function was implemented as semisupervised learning in the model. The latter refers to developmental changes in the perceptual acuity, which was replicated by refining the variance parameters of the low-layered RBMs. Experimental results demonstrated that tactile dominance and perceptual improvement have the role of facilitating the differentiation of emotional states of multimodal expressions; however, the influences only appear when both functions are included in the model together. Considering our results from the psychological perspective may help to elucidate the neural and social mechanisms of the development of emotion perception.
C1 [Horii, Takato; Asada, Minoru] Osaka Univ, Grad Sch Engn, Osaka 5650871, Japan.
   [Nagai, Yukie] Natl Inst Informat & Commun Technol, Osaka 5650871, Japan.
RP Horii, T (reprint author), Osaka Univ, Grad Sch Engn, Osaka 5650871, Japan.
EM takato.horii@ams.eng.osaka-u.ac.jp; asada@ams.eng.osaka-u.ac.jp
FU JST CREST "Cognitive Mirroring" [JPMJCR16E2];  [15J00671];  [24000012]; 
   [24119003]
FX This work was supported in part by the Grant-in-Aid for JSPS Fellows
   under Grant 15J00671, in part by the Grant-in-Aid for Specially Promoted
   Research under Grant 24000012, in part by the Grant-in-Aid for
   Scientific Research on Innovative Areas under Grant 24119003, and in
   part by the JST CREST "Cognitive Mirroring" under Grant JPMJCR16E2.
CR Asada M, 2009, IEEE T AUTON MENT DE, V1, P12, DOI 10.1109/TAMD.2009.2021702
   Beauchamp MS, 2008, NEUROIMAGE, V41, P1011, DOI 10.1016/j.neuroimage.2008.03.015
   Bjornsdotter M, 2010, EXP BRAIN RES, V207, P149, DOI 10.1007/s00221-010-2408-y
   Blanchard A., 2005, P 5 INT WORKSH EP RO, P23
   BRADLEY RM, 1975, PHYSIOL REV, V55, P352
   Breazeal C, 2002, AUTON ROBOT, V12, P83, DOI 10.1023/A:1013215010749
   Campanella S, 2007, TRENDS COGN SCI, V11, P535, DOI 10.1016/j.tics.2007.10.001
   Cho K, 2011, LECT NOTES COMPUT SC, V6791, P10, DOI 10.1007/978-3-642-21735-7_2
   Dahiya RS, 2010, IEEE T ROBOT, V26, P1, DOI 10.1109/TRO.2009.2033627
   Danziger N, 2006, BRAIN, V129, P2494, DOI 10.1093/brain/awl155
   DOBSON V, 1978, VISION RES, V18, P1469, DOI 10.1016/0042-6989(78)90001-9
   Fabrizi L, 2011, CURR BIOL, V21, P1552, DOI 10.1016/j.cub.2011.08.010
   FERNALD A, 1989, CHILD DEV, V60, P1497, DOI 10.2307/1130938
   Friston KJ, 2010, NAT REV NEUROSCI, V11, P127, DOI 10.1038/nrn2787
   Grossmann T, 2006, DEVELOPMENTAL SCI, V9, P309, DOI 10.1111/j.1467-7687.2006.00494.x
   Grossmann T, 2010, RESTOR NEUROL NEUROS, V28, P219, DOI 10.3233/RNN-2010-0499
   Hasson C., 2011, J BEHAV ROBOTICS, V2, P111, DOI DOI 10.2478/S13230-012-0005-4
   Hertenstein MJ, 2009, EMOTION, V9, P566, DOI 10.1037/a0016108
   Hertenstein MJ, 2002, HUM DEV, V45, P70, DOI 10.1159/000048154
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Hinton G. E., 2010, 2010003 UTML TR DEP
   Hiolle A, 2014, FRONT NEUROROBOTICS, V8, DOI 10.3389/fnbot.2014.00017
   Horii T., 2014, P HRI WORKSH HRI BRI, P47
   Horii T., 2013, P IEEE 3 JOINT INT C, P1
   Indo Y, 2012, CLIN GENET, V82, P341, DOI 10.1111/j.1399-0004.2012.01943.x
   Izard C. E., 1991, PSYCHOL EMOTIONS
   Jean ADL, 2009, INFANT BEHAV DEV, V32, P344, DOI 10.1016/j.infbeh.2009.04.005
   Kreifelts B, 2007, NEUROIMAGE, V37, P1445, DOI 10.1016/j.neuroimage.2007.06.020
   Lewis M, 1997, ANN NY ACAD SCI, V818, P119, DOI 10.1111/j.1749-6632.1997.tb48251.x
   Lewis M., 2008, HDB EMOTIONS
   Lim A, 2014, IEEE T AUTON MENT DE, V6, P126, DOI 10.1109/TAMD.2014.2317513
   Lones J, 2016, FRONT ROBOT AI, V3, DOI 10.3389/frobt.2016.00044
   Nadel J., 2005, EMOTIONAL DEV RECENT
   Nagai Y, 2006, ADV ROBOTICS, V20, P1165, DOI 10.1163/156855306778522497
   Ngiam J, 2011, IEEE INT C MACH LEAR, V28, P689
   OLSHO LW, 1987, J ACOUST SOC AM, V82, P454, DOI 10.1121/1.395446
   PelaezNogueras M, 1996, J APPL DEV PSYCHOL, V17, P199, DOI 10.1016/S0193-3973(96)90025-8
   PelaezNogueras M, 1996, CHILD DEV, V67, P1780, DOI 10.1111/j.1467-8624.1996.tb01827.x
   Russell JA, 2003, PSYCHOL REV, V110, P145, DOI 10.1037/0033-295X.110.1.145
   Schmidt R, 2000, NEUROSCIENCE, V98, P793, DOI 10.1016/S0306-4522(00)00189-5
   SMITH LB, 1977, J EXP CHILD PSYCHOL, V24, P279, DOI 10.1016/0022-0965(77)90007-8
   SMITH LB, 1979, CHILD DEV, V50, P705, DOI 10.2307/1128936
   Spinelli M, 2017, DEV REV, V44, P1, DOI 10.1016/j.dr.2016.12.001
   Srivastava N., 2012, INT C MACH LEARN, P1
   Srivastava N, 2014, J MACH LEARN RES, V15, P2949
   Sroufe L. A., 1997, EMOTIONAL DEV ORG EM
   Sukhbaatar S., 2011, P AS C MACH LEARN, P231
   Tada Y, 2007, ADV ROBOTICS, V21, P601, DOI 10.1163/156855307780108213
   TRAUB RJ, 1988, J NEUROPHYSIOL, V59, P41
   WalkerAndrews AS, 1997, PSYCHOL BULL, V121, P437, DOI 10.1037/0033-2909.121.3.437
   Watson R, 2014, J NEUROSCI, V34, P6813, DOI 10.1523/JNEUROSCI.4478-13.2014
NR 51
TC 0
Z9 0
U1 4
U2 4
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2379-8920
EI 2379-8939
J9 IEEE T COGN DEV SYST
JI IEEE Trans. Cogn. Dev. Syst.
PD SEP
PY 2018
VL 10
IS 3
BP 762
EP 775
DI 10.1109/TCDS.2018.2809434
PG 14
WC Computer Science, Artificial Intelligence; Robotics; Neurosciences
SC Computer Science; Robotics; Neurosciences & Neurology
GA GT6JO
UT WOS:000444617100023
OA Bronze
DA 2019-02-18
ER

PT J
AU Stepanova, K
   Klein, FB
   Cangelosi, A
   Vavrecka, M
AF Stepanova, Karla
   Klein, Frederico Belmonte
   Cangelosi, Angelo
   Vavrecka, Michal
TI Mapping Language to Vision in a Real-World Robotic Scenario
SO IEEE TRANSACTIONS ON COGNITIVE AND DEVELOPMENTAL SYSTEMS
LA English
DT Article
DE Cognitive modeling; cross-situational learning; iCub robot; language
   acquisition; symbol grounding
ID CROSS-SITUATIONAL STATISTICS; SYMBOL GROUNDING PROBLEM; WORDS; MODEL;
   ALGORITHM; SELECTION; NETWORK; SPEECH; LEVEL
AB Language has evolved over centuries and was gradually enriched and improved. The question, how people find assignment between meanings and referents, remains unanswered. There are many of computational models based on the statistical co-occurrence of meaning-reference pairs. Unfortunately, these mapping strategies show poor performance in an environment with a higher number of objects or noise. Therefore, we propose a more robust noise-resistant algorithm. We tested the performance of this novel algorithm with simulated and physical iCub robots. We developed a testing scenario consisting of objects with varying visual properties presented to the robot accompanied by utterances describing the given object. The results suggest that the proposed mapping procedure is robust, resistant against noise and shows better performance than one-step mapping for all levels of noise in the linguistic input, as well as slower performance degradation with increasing noise. Furthermore, the proposed procedure increases the clustering accuracy of both modalities.
C1 [Stepanova, Karla; Vavrecka, Michal] Czech Tech Univ, Czech Inst Informat Robot & Cybernet, Prague 16000, Czech Republic.
   [Klein, Frederico Belmonte; Cangelosi, Angelo] Plymouth Univ, Sch Comp Elect & Math, Plymouth PL4 8AA, Devon, England.
RP Stepanova, K (reprint author), Czech Tech Univ, Czech Inst Informat Robot & Cybernet, Prague 16000, Czech Republic.
EM karla.stepanova@ciirc.cvut.cz
OI Cangelosi, Angelo/0000-0002-4709-2243
FU European EU FP7 Research Project TRADR [609763]; TACR CAK [TE01020197];
   CAPES Foundation; Ministry of Education of Brazil [BEX 1084/13-5]; CNPq
   Brazil [232590/2014-1]; U.K. EPSRC Project BABEL [EP/J004561/1,
   EP/J00457X/1]
FX This work was supported in part by the European EU FP7 Research Project
   TRADR under Grant 609763, in part by TACR CAK under Grant TE01020197, in
   part by the CAPES Foundation, Ministry of Education of Brazil under
   Grant BEX 1084/13-5, in part by the CNPq Brazil under Grant
   232590/2014-1, and in part by the U.K. EPSRC Project BABEL under Grant
   EP/J004561/1 and Grant EP/J00457X/1.
CR Barsalou LW, 2008, ANNU REV PSYCHOL, V59, P617, DOI 10.1146/annurev.psych.59.103006.093639
   Brent MR, 2001, COGNITION, V81, pB33, DOI 10.1016/S0010-0277(01)00122-6
   Buchel C, 1998, NATURE, V394, P274, DOI 10.1038/28389
   Cangelosi A, 2000, CONNECT SCI, V12, P143, DOI 10.1080/09540090050129763
   Coradeschi S, 2013, KUNSTL INTELL, V27, P129, DOI 10.1007/s13218-013-0247-2
   Crick C, 2010, TOP COGN SCI, V2, P114, DOI 10.1111/j.1756-8765.2009.01073.x
   Culham JC, 2006, CURR OPIN NEUROBIOL, V16, P205, DOI 10.1016/j.conb.2006.03.005
   Daoutis M., 2014, P ART INT SIM BEH AI
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1
   Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878
   Elhamifar E., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P1873, DOI 10.1109/CVPR.2011.5995664
   Elhamifar E, 2013, IEEE T PATTERN ANAL, V35, P2765, DOI 10.1109/TPAMI.2013.57
   Fazly A, 2010, COGNITIVE SCI, V34, P1017, DOI 10.1111/j.1551-6709.2010.01104.x
   Fleischman M., 2008, P ACL 08 HLT COL OH, P121
   Frank MC, 2009, PSYCHOL SCI, V20, P578, DOI 10.1111/j.1467-9280.2009.02335.x
   Gliozzi V, 2009, COGNITIVE SCI, V33, P709, DOI 10.1111/j.1551-6709.2009.01026.x
   GOLDBERG E, 1994, IEEE EXPERT, V9, P45, DOI 10.1109/64.294135
   Gorniak P., 2005, P AIIDE, P57
   HARNAD S, 1990, PHYSICA D, V42, P335, DOI 10.1016/0167-2789(90)90087-6
   Karpathy A, 2015, PROC CVPR IEEE, P3128, DOI 10.1109/CVPR.2015.7298932
   Kennedy J, 2015, INT J SOC ROBOT, V7, P293, DOI 10.1007/s12369-014-0277-4
   Klein F. B., 2016, GWR GNG CLASSIFIER F
   Lamere P., 2003, IEEE INT C AC SPEECH, V1, P2
   Li P, 2004, NEURAL NETWORKS, V17, P1345, DOI 10.1016/j.neunet.2004.07.004
   MARKMAN EM, 1990, COGNITIVE SCI, V14, P57, DOI 10.1207/s15516709cog1401_4
   Marsland S, 2002, NEURAL NETWORKS, V15, P1041, DOI 10.1016/S0893-6080(02)00078-3
   Mavridis N., 2007, THESIS
   Mavridis N, 2015, ROBOT AUTON SYST, V63, P22, DOI 10.1016/j.robot.2014.09.031
   McMurray B, 2012, PSYCHOL REV, V119, P831, DOI 10.1037/a0029872
   Metta G., 2006, International Journal of Advanced Robotic Systems, V3, P43
   Metta G., 2008, P 8 WORKSH PERF METR, P50, DOI DOI 10.1145/1774674.1774683
   MISHKIN M, 1983, TRENDS NEUROSCI, V6, P414, DOI 10.1016/0166-2236(83)90190-X
   Monaghan P, 2015, COGNITIVE SCI, V39, P1099, DOI 10.1111/cogs.12186
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   QUINE WV, 1970, J PHILOS, V67, P178, DOI 10.2307/2023887
   Regier T, 2005, COGNITIVE SCI, V29, P819, DOI 10.1207/s15516709cog0000_31
   Roy D, 2005, COMPUT SPEECH LANG, V19, P227, DOI 10.1016/j.csl.2004.08.003
   Roy DK, 2002, COMPUT SPEECH LANG, V16, P353, DOI 10.1016/S0885-2308(02)00024-4
   SCHWARTZ RG, 1983, J CHILD LANG, V10, P57
   Siskind JM, 1996, COGNITION, V61, P39, DOI 10.1016/S0010-0277(96)00728-7
   Smith K, 2006, LECT NOTES ARTIF INT, V4211, P31
   SNOW CE, 1972, CHILD DEV, V43, P549, DOI 10.2307/1127555
   Spitsyna G, 2006, J NEUROSCI, V26, P7328, DOI 10.1523/JNEUROSCI.0559-06.2006
   Stepanova K., 2017, P COGN ART LIF KUZ 1, P155
   Stepanova K., 2016, THESIS
   Stramandinoli F, 2012, NEURAL NETWORKS, V32, P165, DOI 10.1016/j.neunet.2012.02.012
   Sugita Y, 2005, ADAPT BEHAV, V13, P33, DOI 10.1177/105971230501300102
   Taddeo M, 2005, J EXP THEOR ARTIF IN, V17, P419, DOI 10.1080/09528130500284053
   Taniguchi A., 2016, P IROS WORKSH MACH L
   Tikhanoff V., 2008, P 8 WORKSH PERF METR, P57, DOI DOI 10.1145/1774674.1774684
   Tikhanoff V, 2011, IEEE T AUTON MENT DE, V3, P17, DOI 10.1109/TAMD.2010.2100390
   TOMASELLO M, 1995, COGNITIVE DEV, V10, P201, DOI 10.1016/0885-2014(95)90009-8
   Vavrecka M, 2014, COGN COMPUT, V6, P101, DOI 10.1007/s12559-013-9212-5
   Vogt P., 2006, ARTIFICIAL COGNITION, P176
   WERKER JF, 1989, CAN J PSYCHOL, V43, P230, DOI 10.1037/h0084224
   Xu F, 2007, PSYCHOL REV, V114, P245, DOI 10.1037/0033-295X.114.2.245
   Yu C, 2007, PSYCHOL SCI, V18, P414, DOI 10.1111/j.1467-9280.2007.01915.x
   Yu C, 2012, PSYCHOL REV, V119, P21, DOI 10.1037/a0026182
   Yurovsky D, 2013, COGNITIVE SCI, V37, P891, DOI 10.1111/cogs.12035
NR 59
TC 0
Z9 0
U1 1
U2 1
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2379-8920
EI 2379-8939
J9 IEEE T COGN DEV SYST
JI IEEE Trans. Cogn. Dev. Syst.
PD SEP
PY 2018
VL 10
IS 3
BP 784
EP 794
DI 10.1109/TCDS.2018.2819359
PG 11
WC Computer Science, Artificial Intelligence; Robotics; Neurosciences
SC Computer Science; Robotics; Neurosciences & Neurology
GA GT6JO
UT WOS:000444617100025
DA 2019-02-18
ER

PT J
AU Luo, DS
   Hu, F
   Zhang, T
   Deng, Y
   Wu, XH
AF Luo, Dingsheng
   Hu, Fan
   Zhang, Tao
   Deng, Yian
   Wu, Xihong
TI How Does a Robot Develop Its Reaching Ability Like Human Infants Do?
SO IEEE TRANSACTIONS ON COGNITIVE AND DEVELOPMENTAL SYSTEMS
LA English
DT Article
DE Cognitive development; human infant; humanoid robot; internal model;
   proprioception; reaching ability
ID MOTOR CONTROL; MODEL; INTEGRATION; SYSTEMS; SLEEP
AB In this paper, we address the issue robots developing a reaching ability, as human infants do. Specifically, a novel infant-inspired framework is proposed based on recent findings that the emergence of reaching is the product of a deeply embodied process. The methodology behind our framework is to develop proprioception, fixation, and internal models (including both the forward and inverse models) in three sequential phases, with the whole developing process being driven by self-produced motor babbling. In the first phase, an autoencoder-based proprioception model is proposed. In the second phase, a simplified strategy for imitating the function of fixation is developed. In the third phase, a new forward model and two new inverse models are further proposed. We evaluated our framework and associated models with the PKU-HR6.0II physical robot and two simulated robots. Experiments confirm that the PKU-HR6.0II could successfully develop its reaching ability in a manner similar to that of human infants through our proposed framework. Better performance and adaptability are also demonstrated in comparison to existing benchmarks. It is also shown that the proposed framework has the potential to achieve other manipulation abilities such as grasping and placing.
C1 [Luo, Dingsheng; Hu, Fan; Zhang, Tao; Deng, Yian; Wu, Xihong] Peking Univ, Key Lab Machine Percept, Speech & Hearing Res Ctr, Dept Machine Intelligence,Minist Educ,Sch EECS, Beijing 100871, Peoples R China.
RP Luo, DS; Wu, XH (reprint author), Peking Univ, Key Lab Machine Percept, Speech & Hearing Res Ctr, Dept Machine Intelligence,Minist Educ,Sch EECS, Beijing 100871, Peoples R China.
EM dsluo@pku.edu.cn; fan_h@pku.edu.cn; tao_zhang@pku.edu.cn;
   yiandeng@pku.edu.cn; xhwu@pku.edu.cn
FU National Natural Science Foundation China [U1713217, 11590773]; Key
   Program of National Social Science Foundation of China [12, ZD119]
FX This work was supported in part by the National Natural Science
   Foundation China under Grant U1713217 and Grant 11590773, and in part
   the Key Program of National Social Science Foundation of China under
   Grant 12 & ZD119.
CR Aoki T, 2016, IFAC PAPERSONLINE, V49, P154, DOI 10.1016/j.ifacol.2016.10.478
   Asada M, 2001, ROBOT AUTON SYST, V37, P185, DOI 10.1016/S0921-8890(01)00157-9
   Asada M, 2009, IEEE T AUTON MENT DE, V1, P12, DOI 10.1109/TAMD.2009.2021702
   Berthier NE, 2006, EXP BRAIN RES, V169, P507, DOI 10.1007/s00221-005-0169-9
   BUSHNELL EW, 1993, CHILD DEV, V64, P1005, DOI 10.2307/1131323
   Cangelosi A., 2015, DEV ROBOTICS BABIES
   Chao F, 2014, INT J ADV ROBOT SYST, V11, DOI 10.5772/57555
   CLIFTON RK, 1993, CHILD DEV, V64, P1099
   Corbetta D, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00576
   Gerber RJ, 2010, PEDIATR REV, V31, P267, DOI 10.1542/pir.31-7-267
   Goble DJ, 2010, PHYS THER, V90, P1176, DOI 10.2522/ptj.20090399
   Haughie LJ, 1995, J MANUAL MANIPULATIV, V3, P91
   Hulse M, 2010, IEEE T AUTON MENT DE, V2, P355, DOI 10.1109/TAMD.2010.2081667
   Joblove G. H., 1978, SIGGRAPH COMPUT GRAP, V12, P20, DOI 10.1145/965139.807362
   JORDAN MI, 1992, COGNITIVE SCI, V16, P307, DOI 10.1207/s15516709cog1603_1
   Juett J, 2016, IEEE-RAS INT C HUMAN, P1141, DOI 10.1109/HUMANOIDS.2016.7803414
   Koenig N., 2004, 2004 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) (IEEE Cat. No.04CH37566), P2149
   Law J, 2014, IEEE T AUTON MENT DE, V6, P93, DOI 10.1109/TAMD.2014.2301934
   LeCun Y., 1990, ADV NEURAL INFORM PR, P396, DOI [10.1099/00221287-136-2-327, DOI 10.1111/DSU.12130]
   Lee M., 2012, P IEEE INT C DEV LEA, P1
   McCarty ME, 1999, DEV PSYCHOL, V35, P1091, DOI 10.1037/0012-1649.35.4.1091
   Metta G, 1999, NEURAL NETWORKS, V12, P1413, DOI 10.1016/S0893-6080(99)00070-2
   Min HQ, 2016, IEEE T COGN DEV SYST, V8, P237, DOI 10.1109/TCDS.2016.2614992
   Ng AKY, 2012, REG STUD, V46, P757, DOI 10.1080/00343404.2010.532117
   Oudeyer PY, 2007, IEEE T EVOLUT COMPUT, V11, P265, DOI 10.1109/TEVC.2006.890271
   Peyrache A, 2009, NAT NEUROSCI, V12, P919, DOI 10.1038/nn.2337
   Riemann BL, 2002, J ATHL TRAINING, V37, P80
   Robin DJ, 1996, DEV PSYCHOL, V32, P824, DOI 10.1037/0012-1649.32.5.824
   Rolf M, 2010, IEEE T AUTON MENT DE, V2, P216, DOI 10.1109/TAMD.2010.2062511
   Savastano P, 2013, IEEE T AUTON MENT DE, V5, P326, DOI 10.1109/TAMD.2013.2264321
   Schillaci G., 2014, THESIS
   Schillaci G, 2011, ACMIEEE INT CONF HUM, P245, DOI 10.1145/1957656.1957753
   Schmerling M, 2015, 5TH INTERNATIONAL CONFERENCE ON DEVELOPMENT AND LEARNING AND ON EPIGENETIC ROBOTICS (ICDL-EPIROB), P168, DOI 10.1109/DEVLRN.2015.7346136
   Sherrington CS, 1906, BRAIN, V29, P467
   Siciliano B., 2016, SPRINGER HDB ROBOTIC
   THELEN E, 1993, CHILD DEV, V64, P1058, DOI 10.2307/1131327
   von Hofsten C., 1979, J HUMAN MOVEMENT STU, V5, P160
   von Hofsten C, 2009, SCAND J PSYCHOL, V50, P617, DOI 10.1111/j.1467-9450.2009.00780.x
   VONHOFSTEN C, 1982, DEV PSYCHOL, V18, P450, DOI 10.1037//0012-1649.18.3.450
   VONHOFSTEN C, 1984, DEV PSYCHOL, V20, P378, DOI 10.1037/0012-1649.20.3.378
   Wagner U, 2004, NATURE, V427, P352, DOI 10.1038/nature02223
   WHITE BL, 1964, CHILD DEV, V35, P349, DOI 10.2307/1126701
   Wolovich WA, 1984, P 23 IEEE C DEC CONT, V23, P1359
   Wolpert DM, 1997, TRENDS COGN SCI, V1, P209, DOI 10.1016/S1364-6613(97)01070-X
   WOLPERT DM, 1995, SCIENCE, V269, P1880, DOI 10.1126/science.7569931
   Xue Feng, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P1759, DOI 10.1109/ICASSP.2014.6853900
NR 46
TC 0
Z9 0
U1 2
U2 2
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2379-8920
EI 2379-8939
J9 IEEE T COGN DEV SYST
JI IEEE Trans. Cogn. Dev. Syst.
PD SEP
PY 2018
VL 10
IS 3
BP 795
EP 809
DI 10.1109/TCDS.2018.2861893
PG 15
WC Computer Science, Artificial Intelligence; Robotics; Neurosciences
SC Computer Science; Robotics; Neurosciences & Neurology
GA GT6JO
UT WOS:000444617100026
DA 2019-02-18
ER

PT J
AU Lim, YX
   Ramasamy, S
   Gardi, A
   Kistan, T
   Sabatini, R
AF Lim, Yixiang
   Ramasamy, Subramanian
   Gardi, Alessandro
   Kistan, Trevor
   Sabatini, Roberto
TI Cognitive Human-Machine Interfaces and Interactions for Unmanned
   Aircraft
SO JOURNAL OF INTELLIGENT & ROBOTIC SYSTEMS
LA English
DT Article
DE Unmanned aircraft; Ground control station; Sense and avoid; Human
   factors engineering; Psychophysiological sensing; Human machine
   interfaces; Human machine interactions; Cognitive ergonomics
ID REAL-TIME ASSESSMENT; MENTAL WORKLOAD; CLASSIFICATION; FEATURES; MODEL;
   TASK
AB This paper presents the concept of Cognitive Human-Machine Interfaces and Interactions (CHMI2) for Unmanned Aircraft System (UAS) Ground Control Stations (GCS). CHMI2 represents a new approach to aviation human factors engineering that introduces adaptive functionalities in the design of operators' command, control and display functions. A CHMI2 system assesses human cognitive states based on measurement of key psycho-physiological observables. The cognitive states are used to predict and enhance operator performance in the accomplishment of aviation tasks, with the objective of improving the efficiency and effectiveness of the overall human-machine teaming. The CHMI2 system presented in this paper employs a four-layer architecture comprising sensing, extraction, classification and adaptation functionalities. An overview of each layer is provided along with the layer's metrics, algorithms and functions. Two relevant case studies are presented to illustrate the interactions between the different layers, and the conceptual design of the associated display formats is described. The results indicate that specific eye tracking variables provide discrimination between different modes of control. Furthermore, results indicate that the higher levels of automation supported by the CHMI2 are beneficial in Separation Assurance and Collision Avoidance (SA&CA) scenarios involving low-detectability obstacles and stringent time constraints to implement recovery manoeuvres. These preliminary results highlight that the introduction of CHMI2 functionalities in future UAS can significantly reduce reaction time and enhance operational effectiveness of unmanned aircraft response to collision and loss of separation events, as well as improve the overall safety and efficiency of operations.
C1 [Lim, Yixiang; Ramasamy, Subramanian; Gardi, Alessandro; Kistan, Trevor; Sabatini, Roberto] RMIT Univ, Sch Engn Aerosp Engn & Aviat, Melbourne, Vic 3083, Australia.
   [Kistan, Trevor] THALES Australia, World Trade Ctr, Melbourne, Vic 3005, Australia.
RP Sabatini, R (reprint author), RMIT Univ, Sch Engn Aerosp Engn & Aviat, Melbourne, Vic 3083, Australia.
EM roberto.sabatini@rmit.edu.au
OI Sabatini, Roberto/0000-0002-3399-2291
CR Besson P, 2013, IEEE T INTELL TRANSP, V14, P1872, DOI 10.1109/TITS.2013.2269679
   Chaouachi M, 2011, LECT NOTES COMPUT SC, V6787, P50, DOI 10.1007/978-3-642-22362-4_5
   Dalamagkidis K, 2012, INTEL SYST CONTR AUT, V54, P161, DOI 10.1007/978-94-007-2479-2_7
   Di Nocera F, 2007, J COGN ENG DECIS MAK, V1, P271, DOI 10.1518/155534307X255627
   FAA, 2013, INT CIV UNM AIRCR SY
   Gardi A., 2016, UAS TERMINAL AREA CH
   GEVINS A, 1995, BIOL PSYCHOL, V40, P169, DOI 10.1016/0301-0511(95)05105-8
   Gevins A., 2003, THEORETICAL ISSUES E, V4, P113, DOI [DOI 10.1080/14639220210159717, 10.1080/14639220210159717]
   Gilland J., 2008, DRIVING EYE TRACKING
   Glaholt M. G., 2014, EYE TRACKING COCKPIT
   Goldberg J.H., 2000, P 2000 S EYE TRACK R, P71, DOI DOI 10.1145/355017.355028
   Guhe M., 2005, P HUM FACT ERG SOC A, P1157
   Harris Sr R. L., 1986, ANAL TECHNIQUES PILO
   Henelius A, 2009, IEEE ENG MED BIO, P1836, DOI 10.1109/IEMBS.2009.5332602
   Honal M, 2008, BIOSIGNALS 2008: PROCEEDINGS OF THE FIRST INTERNATIONAL CONFERENCE ON BIO-INSPIRED SYSTEMS AND SIGNAL PROCESSING, VOL 1, P100
   ICAO, 2015, 10019 ICAO
   Jacob R. J. K., 2003, MIND, V2, P4
   Jiang T., 2017, INT J TRANSPORTATION
   Ke YF, 2015, INT J PSYCHOPHYSIOL, V98, P157, DOI 10.1016/j.ijpsycho.2015.10.004
   Kohlmorgen J., 2007, BRAIN COMPUTER INTER, P409
   Kramer AF, 1991, MULTIPLE TASK PERFOR, P279
   Lai J., 2012, FIELD OF VIEW DETECT
   Lai J, 2011, J FIELD ROBOT, V28, P137, DOI 10.1002/rob.20359
   Liu J, 2016, KNOWL-BASED SYST, V112, P37, DOI 10.1016/j.knosys.2016.08.031
   Marshall S.P., 2002, 2002 P 2002 IEEE 7 C
   Mulder M, 2006, INT J AVIAT PSYCHOL, V16, P21, DOI 10.1207/s15327108ijap1601_2
   Neville K., 2012, P HUM FACT ERG SOC A, P418
   Noel JB, 2005, COMPUT OPER RES, V32, P2713, DOI 10.1016/j.cor.2004.03.022
   Ramasamy S., 2016, LIDAR OBSTACLE WARNI
   Ramasamy S, 2016, INT CONF UNMAN AIRCR, P531, DOI 10.1109/ICUAS.2016.7502676
   ROSCOE AH, 1992, BIOL PSYCHOL, V34, P259, DOI 10.1016/0301-0511(92)90018-P
   Rubio S, 2004, APPL PSYCHOL-INT REV, V53, P61, DOI 10.1111/j.1464-0597.2004.00161.x
   Sabatini R., 2013, INT J MECH IND SCI E, V7, P1433
   Stevens Ron, 2006, AUGMENTED COGNITION, V2, P55
   Viguria A., 2016, ENCY AEROSPACE ENG
   Wang ZH, 2012, NEUROIMAGE, V59, P64, DOI 10.1016/j.neuroimage.2011.07.094
   Wilson GF, 2003, HUM FACTORS, V45, P635, DOI 10.1518/hfes.45.4.635.27088
   Yang G., 2009, BIOMED FUZZY HUMAN S, V14, P17
   Yin Z, 2016, ADV COGN NEURODYN, P469, DOI 10.1007/978-981-10-0207-6_64
   Zarjam P, 2013, COMPUT BIOL MED, V43, P2186, DOI 10.1016/j.compbiomed.2013.08.021
NR 40
TC 1
Z9 1
U1 7
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 0921-0296
EI 1573-0409
J9 J INTELL ROBOT SYST
JI J. Intell. Robot. Syst.
PD SEP
PY 2018
VL 91
IS 3-4
BP 755
EP 774
DI 10.1007/s10846-017-0648-9
PG 20
WC Computer Science, Artificial Intelligence; Robotics
SC Computer Science; Robotics
GA GR3OY
UT WOS:000442504500027
DA 2019-02-18
ER

PT J
AU Biehl, M
   Guckelsberger, C
   Salge, C
   Smith, SC
   Polani, D
AF Biehl, Martin
   Guckelsberger, Christian
   Salge, Christoph
   Smith, Simon C.
   Polani, Daniel
TI Expanding the Active Inference Landscape: More Intrinsic Motivations in
   the Perception-Action Loop
SO FRONTIERS IN NEUROROBOTICS
LA English
DT Article
DE intrinsic motivation; free energy principle; active inference;
   predictive information; empowerment; perception-action loop; universal
   reinforcement learning; variational inference
ID FREE-ENERGY PRINCIPLE; INFORMATION; BEHAVIOR; ENTROPY; SYSTEMS
AB Active inference is an ambitious theory that treats perception, inference, and action selection of autonomous agents under the heading of a single principle. It suggests biologically plausible explanations for many cognitive phenomena, including consciousness. In active inference, action selection is driven by an objective function that evaluates possible future actions with respect to current, inferred beliefs about the world. Active inference at its core is independent from extrinsic rewards, resulting in a high level of robustness across e.g., different environments or agent morphologies. In the literature, paradigms that share this independence have been summarized under the notion of intrinsic motivations. In general and in contrast to active inference, these models of motivation come without a commitment to particular inference and action selection mechanisms. In this article, we study if the inference and action selection machinery of active inference can also be used by alternatives to the originally included intrinsic motivation. The perception-action loop explicitly relates inference and action selection to the environment and agent memory, and is consequently used as foundation for our analysis. We reconstruct the active inference approach, locate the original formulation within, and show how alternative intrinsic motivations can be used while keeping many of the original features intact. Furthermore, we illustrate the connection to universal reinforcement learning by means of our formalism. Active inference research may profit from comparisons of the dynamics induced by alternative intrinsic motivations. Research on intrinsic motivations may profit from an additional way to implement intrinsically motivated agents that also share the biological plausibility of active inference.
C1 [Biehl, Martin] Araya Inc, Tokyo, Japan.
   [Guckelsberger, Christian] Goldsmiths Univ London, Dept Comp, Computat Creat Grp, London, England.
   [Salge, Christoph] NYU, Game Innovat Lab, Dept Comp Sci & Engn, New York, NY USA.
   [Salge, Christoph; Smith, Simon C.; Polani, Daniel] Univ Hertfordshire, Dept Comp Sci, Sepia Lab, Adapt Syst Res Grp, Hatfield, Herts, England.
   [Smith, Simon C.] Univ Edinburgh, Inst Percept Act & Behav, Sch Informat, Edinburgh, Midlothian, Scotland.
RP Biehl, M (reprint author), Araya Inc, Tokyo, Japan.
EM martin@araya.org
FU EPSRC [EP/L015846/1]; EU Horizon 2020 programme under the Marie
   Sklodowska-Curie grant [705643]; EC socSMCs FET Proactive project
   [H2020-641321]
FX CG is funded by EPSRC grant [EP/L015846/1] (IGGI). CS is funded by the
   EU Horizon 2020 programme under the Marie Sklodowska-Curie grant 705643.
   DP is funded in part by EC H2020-641321 socSMCs FET Proactive project.
CR Allen M, 2018, SYNTHESE, V195, P2459, DOI 10.1007/s11229-016-1288-5
   Aslanides John, 2017, P 26 INT JOINT C ART, P1403
   Attias H., 1999, ADV NEURAL INFORM PR, P209
   Attias H., 2003, P 9 INT WORKSH ART I
   Ay N, 2008, EUR PHYS J B, V63, P329, DOI 10.1140/epjb/e2008-00175-0
   Ay N, 2015, THEOR BIOSCI, V134, P105, DOI 10.1007/s12064-015-0217-3
   Ay N, 2012, THEOR BIOSCI, V131, P161, DOI 10.1007/s12064-011-0137-9
   Barber David, 2003, P NEUR INF PROC SYST, P201
   Bialek W, 1999, ARXIVCONDMAT9902341
   Bishop C.M., 2011, PATTERN RECOGNITION
   Blei DM, 2017, J AM STAT ASSOC, V112, P859, DOI 10.1080/01621459.2017.1285773
   Botvinick M, 2012, TRENDS COGN SCI, V16, P485, DOI 10.1016/j.tics.2012.08.006
   Buckley CL, 2017, J MATH PSYCHOL, V81, P55, DOI 10.1016/j.jmp.2017.09.004
   Clark A., 2015, SURFING UNCERTAINTY
   Cover T. M., 2006, ELEMENTS INFORM THEO
   Dennett D. C., 1991, CONSCIOUSNESS EXPLAI
   Doshi-Velez F, 2015, IEEE T PATTERN ANAL, V37, P394, DOI 10.1109/TPAMI.2013.191
   Ellis B, 2008, J AM STAT ASSOC, V103, P778, DOI 10.1198/016214508000000193
   Fox R, 2016, IEEE DECIS CONTR P, P5603, DOI 10.1109/CDC.2016.7799130
   Friston K. J., 2013, NEUROPSYCHOANALYSIS, V15, P38, DOI DOI 10.1080/15294145.2013.10773716
   Friston K, 2015, COGN NEUROSCI-UK, V6, P187, DOI 10.1080/17588928.2015.1020053
   Friston K, 2017, NEURAL COMPUT, V29, P1, DOI 10.1162/NECO_a_00912
   Friston K, 2016, NEUROSCI BIOBEHAV R, V68, P862, DOI 10.1016/j.neubiorev.2016.06.022
   Friston K, 2013, J R SOC INTERFACE, V10, DOI 10.1098/rsif.2013.0475
   Friston KJ, 2017, NETW NEUROSCI, V1, P381, DOI [10.1162/netn_a_00018, 10.1162/NETN_a_00018]
   Friston KJ, 2017, NEURAL COMPUT, V29, P2633, DOI [10.1162/NECO_a_00999, 10.1162/neco_a_00999]
   Friston KJ, 2012, BIOL CYBERN, V106, P523, DOI 10.1007/s00422-012-0512-8
   Friston KJ, 2010, NAT REV NEUROSCI, V11, P127, DOI 10.1038/nrn2787
   Froese T, 2009, ARTIF INTELL, V173, P466, DOI 10.1016/j.artint.2008.12.001
   Gregor K, 2016, ARXIV161107507
   Guckelsberger C, 2016, P 7 INT C COMP CREAT
   Guckelsberger C, 2018, P C COMP INT GAM MAS
   Guckelsberger C, 2016, P C COMP INT GAM FIR
   Guckelsberger C, 2016, P 15 INT C SYNTH SIM, P8
   Hutter M., 2005, TEXTS THEORETICAL CO
   Karl M, 2017, ARXIV171005101
   Klyubin AS, 2005, IEEE C EVOL COMPUTAT, P128
   Leike J., 2016, ARXIV161108944
   Linson A, 2018, FRONT ROBOT AI, V5, DOI 10.3389/frobt.2018.00021
   Little DYJ, 2013, BEHAV BRAIN SCI, V36, P220, DOI 10.1017/S0140525X12002415
   Lunn DJ, 2000, STAT COMPUT, V10, P325, DOI 10.1023/A:1008929526011
   Manzotti R, 2018, FRONT ROBOT AI, V5, DOI 10.3389/frobt.2018.00039
   Martius G, 2014, LECT NOTES ARTIF INT, V8575, P32, DOI 10.1007/978-3-319-08864-8_4
   Martius G, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0063400
   Minka T.P., 2001, UNCERTAINTY ARTIFICI, V17, P362
   Orseau L, 2013, LECT NOTES ARTIF INT, V8139, P158
   Ortega P. A., 2011, ARXIV11110708
   Ortega PA, 2014, COMPLEX ADAPT SYST M, V2, DOI 10.1186/2194-3206-2-2
   Ortega PA, 2010, J ARTIF INTELL RES, V38, P475, DOI 10.1613/jair.3062
   Oudeyer P.-Y., 2009, FRONT NUEROROBOT, V1, P6
   Oudeyer PY, 2007, IEEE T EVOLUT COMPUT, V11, P265, DOI 10.1109/TEVC.2006.890271
   Pearl J., 2000, CAUSALITY MODELS REA
   Pfeifer R, 2005, ARTIF LIFE, V11, P99, DOI 10.1162/1064546053279017
   Rezende D. J., 2015, ADV NEURAL INFORM PR, P2125
   Ross Stephane, 2008, Uncertain Artif Intell, V2008, P476
   Ryan RM, 2000, CONTEMP EDUC PSYCHOL, V25, P54, DOI 10.1006/ceps.1999.1020
   Salge C, 2018, P C COMP INT GAM MAS
   Salge C, 2017, FRONT ROBOT AI, V4, DOI 10.3389/frobt.2017.00025
   Salge C, 2014, EMERGENCE COMPLEX CO, V9, P67, DOI 10.1007/978-3-642-53734-9_4
   Santucci VG, 2013, FRONT NEUROROBOTICS, V7, DOI 10.3389/fnbot.2013.00022
   Schmidhuber J, 2010, IEEE T AUTON MENT DE, V2, P230, DOI 10.1109/TAMD.2010.2056368
   Storck J., 1995, ICANN '95. International Conference on Artificial Neural Networks. Neuronimes '95 Scientific Conference, P159
   Sutton R. S, 1998, REINFORCEMENT LEARNI
   Toussaint M., 2009, KUNSTL INTELL, V23, P23
   Vehtari A, 2014, ARXIV14124869
   Wainwright MJ, 2008, FOUND TRENDS MACH LE, V1, P1, DOI 10.1561/2200000001
   Winn J, 2005, J MACH LEARN RES, V6, P661
NR 67
TC 0
Z9 0
U1 1
U2 1
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1662-5218
J9 FRONT NEUROROBOTICS
JI Front. Neurorobotics
PD AUG 30
PY 2018
VL 12
AR 45
DI 10.3389/fnbot.2018.00045
PG 26
WC Computer Science, Artificial Intelligence; Robotics; Neurosciences
SC Computer Science; Robotics; Neurosciences & Neurology
GA GS0HW
UT WOS:000443173400001
PM 30214404
OA DOAJ Gold
DA 2019-02-18
ER

PT J
AU Belpaeme, T
   Kennedy, J
   Ramachandran, A
   Scassellati, B
   Tanaka, F
AF Belpaeme, Tony
   Kennedy, James
   Ramachandran, Aditi
   Scassellati, Brian
   Tanaka, Fumihide
TI Social robots for education: A review
SO SCIENCE ROBOTICS
LA English
DT Review
ID INTELLIGENT TUTORING SYSTEMS; LONG-TERM INTERACTION; PHYSICALLY PRESENT;
   TEACHER IMMEDIACY; CHILDREN TEACH; AGENTS; ENGAGEMENT; PARTNERS; PEER
AB Social robots can be used in education as tutors or peer learners. They have been shown to be effective at increasing cognitive and affective outcomes and have achieved outcomes similar to those of human tutoring on restricted tasks. This is largely because of their physical presence, which traditional learning technologies lack. We review the potential of social robots in education, discuss the technical challenges, and consider how the robot's appearance and behavior affect learning outcomes.
C1 [Belpaeme, Tony] Univ Ghent, Ghent, Belgium.
   [Belpaeme, Tony; Kennedy, James] Univ Plymouth, Plymouth, Devon, England.
   [Ramachandran, Aditi; Scassellati, Brian] Yale Univ, New Haven, CT 06520 USA.
   [Tanaka, Fumihide] Univ Tsukuba, Tsukuba, Ibaraki, Japan.
RP Belpaeme, T (reprint author), Univ Ghent, Ghent, Belgium.; Belpaeme, T (reprint author), Univ Plymouth, Plymouth, Devon, England.
EM tony.belpaeme@ugent.be
OI Tanaka, Fumihide/0000-0002-8443-5591
FU H2020 L2TOR project [688014]; Japan Society for the Promotion of Science
   KAKENHI [15H01708]; NSF [1139078]
FX This work is partially funded by the H2020 L2TOR project (688014), Japan
   Society for the Promotion of Science KAKENHI (15H01708), and NSF award
   1139078.
CR Alemi M, 2015, INT J SOC ROBOT, V7, P523, DOI 10.1007/s12369-015-0286-y
   Alemi M, 2014, INT J HUM ROBOT, V11, DOI 10.1142/S0219843614500224
   Bainbridge WA, 2011, INT J SOC ROBOT, V3, P41, DOI 10.1007/s12369-010-0082-7
   Bartneck C, 2009, INT J SOC ROBOT, V1, P71, DOI 10.1007/s12369-008-0001-3
   Baxter P, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0178126
   Baxter P, 2012, ACMIEEE INT CONF HUM, P105
   Belpaeme T, 2018, INT J SOC ROBOT, V10, P325, DOI 10.1007/s12369-018-0467-6
   Bloom B, 1956, TAXONOMY ED OBJECTIV, V1
   Bloom B. S., 1984, ED RES, V13, P4, DOI DOI 10.3102/0013189X013006004
   Chase CC, 2009, J SCI EDUC TECHNOL, V18, P334, DOI 10.1007/s10956-009-9180-4
   Coninx A, 2016, J HUM-ROBOT INTERACT, V5, P32, DOI 10.5898/JHRI.5.1.Coninx
   DRAPER TW, 1992, J GENET PSYCHOL, V153, P269
   Fasola J, 2013, J HUM-ROBOT INTERACT, V2, P3, DOI 10.5898/JHRI.2.2.Fasola
   Ferguson R. F., 2008, TRIPOD PROJECT FRAME, DOI 10. 1177/003172171209400306
   Fridin M, 2014, COMPUT EDUC, V70, P53, DOI 10.1016/j.compedu.2013.07.043
   Girotto V, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P919, DOI 10.1145/2858036.2858454
   Gordon G., 2015, P 29 AAAI C ART INT
   Gordon Goren, 2016, P 30 AAAI C ART INT, P3951
   GORHAM J, 1988, COMMUN EDUC, V37, P40, DOI 10.1080/03634528809378702
   Hake RR, 1998, AM J PHYS, V66, P64, DOI 10.1119/1.18809
   Han J., 2010, ROBOT AIDED LEARNING
   Han J, 2008, J INF PROCESS SYST, V4, P159, DOI 10.3745/JIPS.2008.4.4.159
   Henkemans OAB, 2013, PATIENT EDUC COUNS, V92, P174, DOI 10.1016/j.pec.2013.04.012
   Hood D, 2015, ACMIEEE INT CONF HUM, P83, DOI 10.1145/2696454.2696479
   Huang C.-M., 2013, P ROB SCI SYST C RSS
   Huang CM, 2013, J HUM-ROBOT INTERACT, V2, P80, DOI 10.5898/JHRI.2.2.Huang
   Huang CM, 2014, ACMIEEE INT CONF HUM, P57, DOI 10.1145/2559636.2559668
   Imai M, 2003, IEEE T IND ELECTRON, V50, P636, DOI 10.1109/TIE.2003.814769
   Janssen Joris B., 2011, Social Robotics. Proceedings Third International Conference (ICSR 2011), P153, DOI 10.1007/978-3-642-25504-5_16
   Jolliffe D, 2006, J ADOLESCENCE, V29, P589, DOI 10.1016/j.adolescence.2005.08.010
   Kanda T, 2004, HUM-COMPUT INTERACT, V19, P61, DOI 10.1207/s15327051hci1901&2_4
   Kennedy James, 2017, 2017 12th ACM/IEEE International Conference on Human-Robot Interaction (HRI), P82, DOI 10.1145/2909824.3020229
   Kennedy J., 2016, P ROB 4 LEARN WORKSH
   Kennedy J, 2015, ACMIEEE INT CONF HUM, P67, DOI 10.1145/2696454.2696457
   Kennedy J, 2015, LECT NOTES ARTIF INT, V9388, P327, DOI 10.1007/978-3-319-25554-5_33
   Kennedy J, 2015, INT J SOC ROBOT, V7, P293, DOI 10.1007/s12369-014-0277-4
   Kidd C. D., 2004, 2004 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) (IEEE Cat. No.04CH37566), P3559
   Kidd C. D., 2008, THESIS
   Kidd CD, 2007, P NAT C ART INT MENL, V22, P1985
   Kose H, 2015, INT J SOC ROBOT, V7, P537, DOI 10.1007/s12369-015-0311-1
   Kramer NC, 2010, EDUC PSYCHOL REV, V22, P71, DOI 10.1007/s10648-010-9123-x
   Krathwohl DR, 2002, THEOR PRACT, V41, P212, DOI 10.1207/s15430421tip4104_2
   Krathwohl DR, 1964, TAXONOMY ED OBJECTIV
   Kulik JA, 2016, REV EDUC RES, V86, P42, DOI 10.3102/0034654315581420
   Kulkarni A, 2016, ELEVENTH ACM/IEEE INTERNATIONAL CONFERENCE ON HUMAN ROBOT INTERACTION (HRI'16), P461, DOI 10.1109/HRI.2016.7451806
   Leite I., 2011, P INT WORKSH PERS AP
   Leite I, 2015, ACMIEEE INT CONF HUM, P99, DOI 10.1145/2696454.2696466
   Leite I, 2014, INT J SOC ROBOT, V6, P329, DOI 10.1007/s12369-014-0227-1
   Leite I, 2013, INT J SOC ROBOT, V5, P291, DOI 10.1007/s12369-013-0178-y
   Lemaignan S., 2017, P 11 ACM IEEE INT C
   Leyzberg D., 2014, P 9 ACM IEEE INT C H
   Leyzberg D, 2012, P 34 ANN C COGN SCI, P1882
   Leyzberg D, 2011, ACMIEEE INT CONF HUM, P347, DOI 10.1145/1957656.1957789
   Li J, 2015, INT J HUM-COMPUT ST, V77, P23, DOI 10.1016/j.ijhcs.2015.01.001
   Lipsey M. W., 2001, PRACTICAL METAANALYS
   Litoiu A., 2015, P 10 ACM IEEE INT C, P211
   Lubold N., 2017, 11 ACM IEEE INT C HU, P255
   Movellan J., 2007, P 2 ACM IEEE INT C H
   Movellan J. R., 2009, 2009 4th ACM/IEEE International Conference on Human-Robot Interaction (HRI), P307
   Mubin O., 2013, TECHNOLOGY ED LEARNI, V1, P209, DOI DOI 10.2316/J0URNAL.209.2013.1.209-0015
   Mutlu B, 2006, IEEE-RAS INT C HUMAN, P518, DOI 10.1109/ICHR.2006.321322
   Powers A., 2007, 2007 2nd Annual Conference on Human-Robot Interaction (HRI), P145
   Ramachandran Aditi, 2017, 2017 12th ACM/IEEE International Conference on Human-Robot Interaction (HRI), P146, DOI 10.1145/2909824.3020209
   Ramachandran A., 2016, P 11 ACM IEEE C HUM, P247
   Ramachandran A., 2018, P 2018 ACM IEEE INT, P59
   Richert RA, 2011, CHILD DEV, V82, P82, DOI 10.1111/j.1467-8624.2010.01542.x
   Saerbeck M, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1613
   Scassellati B., 2018, P ACM CHI C HUM FACT
   Schodde Thorten, 2017, 2017 12th ACM/IEEE International Conference on Human-Robot Interaction (HRI), P128, DOI 10.1145/2909824.3020222
   Szafir Daniel, 2012, P SIGCHI C HUM FACT, P11, DOI [DOI 10.1145/2207676.2207679, 10.1145/2207676.2207679]
   Tanaka Fumihide, 2009, RO-MAN 2009 - The 18th IEEE International Symposium on Robot and Human Interactive Communication, P558, DOI 10.1109/ROMAN.2009.5326227
   Tanaka F, 2007, P NATL ACAD SCI USA, V104, P17954, DOI 10.1073/pnas.0707769104
   Tanaka F, 2015, IEEE-RAS INT C HUMAN, P270, DOI 10.1109/HUMANOIDS.2015.7363546
   Tanaka F, 2012, J HUM-ROBOT INTERACT, V1, P78, DOI 10.5898/JHRI.1.1.Tanaka
   VanLehn K, 2011, EDUC PSYCHOL-US, V46, P197, DOI 10.1080/00461520.2011.611369
   Wainer J., 2007, P 16 IEEE INT S ROB, P872, DOI DOI 10.1109/R0MAN.2007.4415207
   Witt PL, 2004, COMMUN MONOGR, V71, P184, DOI 10.1080/036452042000228054
   Yadollahi E., 2018, P 17 ACM C INT DES C, P195
   YOU ZJ, 2006, P 6 INT C ADV LEARN, P87, DOI DOI 10.1109/ICALT.2006.1652373
   Zaga C, 2015, LECT NOTES ARTIF INT, V9388, P704, DOI 10.1007/978-3-319-25554-5_70
NR 80
TC 6
Z9 6
U1 21
U2 21
PU AMER ASSOC ADVANCEMENT SCIENCE
PI WASHINGTON
PA 1200 NEW YORK AVE, NW, WASHINGTON, DC 20005 USA
SN 2470-9476
J9 SCI ROBOT
JI Sci. Robot.
PD AUG 22
PY 2018
VL 3
IS 21
AR UNSP eaat5954
DI 10.1126/scirobotics.aat5954
PG 9
WC Robotics
SC Robotics
GA GS0XD
UT WOS:000443232300003
OA Bronze
DA 2019-02-18
ER

PT J
AU Michaelis, JE
   Mutlu, B
AF Michaelis, Joseph E.
   Mutlu, Bilge
TI Reading socially: Transforming the in-home reading experience with a
   learning-companion robot
SO SCIENCE ROBOTICS
LA English
DT Article
ID MATHEMATICS CLASSROOM; SITUATIONAL INTEREST; FIELD TRIAL; ENGAGEMENT;
   CHILDREN; SCHOOL; CONSTRUCTION; ADOLESCENTS; MOTIVATION; KNOWLEDGE
AB Social robots hold great promise as companions and peer learners for children, yet little is known about how they can be best designed for this population, what interaction scenarios can benefit from their use, and how they might fit into learning activities and environments. We aimed to close this gap by designing a learning-companion robot to augment guided reading activity and examined the robot's impact on an in-home reading experience. In this paper, we compared the experiences of early adolescent children aged 10 to 12 years (N = 24) who completed guided reading activities either with a learning-companion robot or as a paper-based activity in a 2-week-long, in-home field study. We found similar reading frequency and duration in both conditions and that both guided reading activities were described as positive experiences that helped to build reading skill and to sustain engagement. Children who read with the learning-companion robot further reported that the activities supported reading comprehension and motivated them to read and indicated a deepening social connection (i.e., companionship or affiliation) with the robot. We conclude that, rather than the activity falling off after a novelty effect, our simple prototype social robot is capable of preserving the benefits of an existing in-home learning activity while transforming the reading experience into a valuable, social one. Our findings contribute to an understanding of how we might capitalize on the capacity of social robots to serve as a transformative learning tool as robots become more widely available to the public.
C1 [Michaelis, Joseph E.] Univ Wisconsin, Dept Educ Psychol, Madison, WI 53706 USA.
   [Mutlu, Bilge] Univ Wisconsin, Dept Comp Sci, 1210 W Dayton St, Madison, WI 53706 USA.
RP Michaelis, JE (reprint author), Univ Wisconsin, Dept Educ Psychol, Madison, WI 53706 USA.
EM jemichaelis@wisc.edu
FU NSF [1149970]
FX This work was supported by the NSF under award 1149970, "Designing
   Socially Adept Robots."
CR Ainley M, 2002, J EDUC PSYCHOL, V94, P545, DOI 10.1037//0022-0663.94.3.545
   ANDERSON RC, 1988, READ RES QUART, V23, P285, DOI 10.1598/RRQ.23.3.2
   Andrist S, 2014, ACMIEEE INT CONF HUM, P25, DOI 10.1145/2559636.2559666
   Atwood S, 2010, J LEARN SCI, V19, P358, DOI 10.1080/10508406.2010.481013
   Basu SJ, 2007, J RES SCI TEACH, V44, P466, DOI 10.1002/tea.20143
   Bergin DA, 2016, EDUC PSYCHOL-US, V51, P7, DOI 10.1080/00461520.2015.1133306
   Breazeal C, 2003, INT J HUM-COMPUT ST, V59, P119, DOI 10.1016/S1071-5819(03)00018-1
   Breazeal C, 2003, ROBOT AUTON SYST, V42, P167, DOI 10.1016/S0921-8890(02)00373-1
   Breazeal C, 2002, DESIGNING SOCIABLE R
   Breazeal C., 2005, WHO NEEDS EMOTIONS B
   Cabral-Marquez C, 2015, READ TEACH, V68, P464, DOI 10.1002/trtr.1332
   Charmaz K., 2012, SAGE HDB INTERVIEW R, P347, DOI DOI 10.4135/9781452218403.N25
   DECI EL, 1991, NEBR SYM MOTIV, V38, P237
   Duke N. K., 2002, WHAT RES HAS SAY REA, V3, P205, DOI DOI 10.1598/0872071774.10
   Enyedy N, 2003, J LEARN SCI, V12, P361, DOI 10.1207/S15327809JLS1203_2
   Epley N, 2007, PSYCHOL REV, V114, P864, DOI 10.1037/0033-295X.114.4.864
   Frijda Nico, 1994, EMOTION CULTURE EMPI, P51, DOI DOI 10.1037/10152-002
   Gee JP, 2008, ASSESSMENT, EQUITY, AND OPPORTUNITY TO LEARN, P76
   Gi Hyun Lim, 2013, 2013 IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN), P155, DOI 10.1109/ROMAN.2013.6628437
   Guthrie JT, 2014, READ RES QUART, V49, P387, DOI 10.1002/rrq.81
   Guthrie JT, 2013, READ RES QUART, V48, P9, DOI 10.1002/rrq.035
   Havermans N, 2015, CHILD INDIC RES, V8, P975, DOI 10.1007/s12187-014-9275-1
   Hidi S, 2006, EDUC PSYCHOL-US, V41, P111, DOI 10.1207/s15326985ep4102_4
   Hollan J., 2000, ACM Transactions on Computer-Human Interaction, V7, P174, DOI 10.1145/353485.353487
   Jarvela S, 2014, CAMBRIDGE HANDBOOK OF THE LEARNING SCIENCES, 2ND EDITION, P668
   Jones A, 2015, LECT NOTES ARTIF INT, V9388, P285, DOI 10.1007/978-3-319-25554-5_29
   Jones T, 2011, INT J INSTR, V4, P5
   Kahn PH, 2012, DEV PSYCHOL, V48, P303, DOI 10.1037/a0027033
   Kanda T, 2004, HUM-COMPUT INTERACT, V19, P61, DOI 10.1207/s15327051hci1901&2_4
   Kanda T, 2013, HUMAN-ROBOT INTERACTION IN SOCIAL ROBOTICS, P1
   Kanda T, 2007, IEEE T ROBOT, V23, P962, DOI 10.1109/TRO.2007.904904
   Kasap Z, 2012, VISUAL COMPUT, V28, P87, DOI 10.1007/s00371-011-0630-7
   Kidd CD, 2005, P AISB 05 S ROB COMP, V5, P141
   Kidd CD, 2006, IEEE INT CONF ROBOT, P3972, DOI 10.1109/ROBOT.2006.1642311
   Knogler M, 2015, CONTEMP EDUC PSYCHOL, V43, P39, DOI 10.1016/j.cedpsych.2015.08.004
   Kory J, 2014, IEEE ROMAN, P643, DOI 10.1109/ROMAN.2014.6926325
   LEE RM, 1995, J COUNS PSYCHOL, V42, P232, DOI 10.1037//0022-0167.42.2.232
   Leite I., 2009, 18 IEEE INT S ROB HU, P367
   Leite I, 2013, INT J SOC ROBOT, V5, P291, DOI 10.1007/s12369-013-0178-y
   MCKENNA MC, 1995, READ RES QUART, V30, P934, DOI 10.2307/748205
   Mckool S. S., 2007, READING IMPROVEMENT, P111, DOI 10.1108/eb050773
   Michaelis J. E., 2015, AM SOC ENG ED  C SEA
   Michaelis JE, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P301, DOI 10.1145/3025453.302549
   MITCHELL M, 1993, J EDUC PSYCHOL, V85, P424, DOI 10.1037/0022-0663.85.3.424
   Mubin O., 2013, TECHNOLOGY ED LEARNI, V1, P209, DOI DOI 10.2316/J0URNAL.209.2013.1.209-0015
   Mutlu B, 2011, AI MAG, V32, P17, DOI 10.1609/aimag.v32i4.2376
   Nass C, 2000, J SOC ISSUES, V56, P81, DOI 10.1111/0022-4537.00153
   Palincsar A. S., 1984, COGNITION INSTRUCT, V1, P117, DOI DOI 10.1207/S1532690XCI0102_1
   Palmer DH, 2009, J RES SCI TEACH, V46, P147, DOI 10.1002/tea.20263
   Pressley M, 1995, VERBAL PROTOCOLS REA
   Rasinski T. V., 2003, FLUENT READER ORAL R
   Saerbeck M, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1613
   Sansone C, 2005, EUR PSYCHOL, V10, P175, DOI 10.1027/1016-9040.10.3.175
   Snow C, 2003, RETHINKING READING C, P1
   Spaulding S., 2016, P 15 INT C AUT AG MU, P643
   Benitti FBV, 2012, COMPUT EDUC, V58, P978, DOI 10.1016/j.compedu.2011.10.006
   Westlund JMK, 2017, FRONT HUM NEUROSCI, V11, DOI 10.3389/fnhum.2017.00295
   Wigfield A, 1997, J EDUC PSYCHOL, V89, P420, DOI 10.1037/0022-0663.89.3.420
NR 58
TC 1
Z9 1
U1 5
U2 5
PU AMER ASSOC ADVANCEMENT SCIENCE
PI WASHINGTON
PA 1200 NEW YORK AVE, NW, WASHINGTON, DC 20005 USA
SN 2470-9476
J9 SCI ROBOT
JI Sci. Robot.
PD AUG 22
PY 2018
VL 3
IS 21
AR UNSP eaat5999
DI 10.1126/scirobotics.aat5999
PG 11
WC Robotics
SC Robotics
GA GS0XD
UT WOS:000443232300004
DA 2019-02-18
ER

PT J
AU Scassellati, B
   Boccanfuso, L
   Huang, CM
   Mademtzi, M
   Qin, MY
   Salomons, N
   Ventola, P
   Shic, F
AF Scassellati, Brian
   Boccanfuso, Laura
   Huang, Chien-Ming
   Mademtzi, Marilena
   Qin, Meiying
   Salomons, Nicole
   Ventola, Pamela
   Shic, Frederick
TI Improving social skills in children with ASD using a long-term, in-home
   social robot
SO SCIENCE ROBOTICS
LA English
DT Article
ID INDIVIDUALS
AB Social robots can offer tremendous possibilities for autism spectrum disorder (ASD) interventions. To date, most studies with this population have used short, isolated encounters in controlled laboratory settings. Our study focused on a 1-month, home-based intervention for increasing social communication skills of 12 children with ASD between 6 and 12 years old using an autonomous social robot. The children engaged in a triadic interaction with a caregiver and the robot for 30 min every day to complete activities on emotional storytelling, perspective-taking, and sequencing. The robot encouraged engagement, adapted the difficulty of the activities to the child's past performance, and modeled positive social skills. The system maintained engagement over the 1-month deployment, and children showed improvement on joint attention skills with adults when not in the presence of the robot. These results were also consistent with caregiver questionnaires. Caregivers reported less prompting over time and overall increased communication.
C1 [Scassellati, Brian; Huang, Chien-Ming; Qin, Meiying; Salomons, Nicole] Yale Univ, Dept Comp Sci, POB 2158, New Haven, CT 06520 USA.
   [Boccanfuso, Laura; Mademtzi, Marilena; Ventola, Pamela; Shic, Frederick] Yale Sch Med, Ctr Child Study, New Haven, CT 06520 USA.
   [Boccanfuso, Laura] Van Robot Inc, Columbia, SC 29212 USA.
   [Huang, Chien-Ming] Johns Hopkins Univ, Dept Comp Sci, Baltimore, MD 21218 USA.
   [Shic, Frederick] Seattle Childrens Res Inst, Ctr Child Hlth Behav & Dev, Seattle, WA 98121 USA.
RP Scassellati, B (reprint author), Yale Univ, Dept Comp Sci, POB 2158, New Haven, CT 06520 USA.
EM brian.scassellati@yale.edu
RI Huang, Chien-Ming/B-9732-2019
OI Huang, Chien-Ming/0000-0002-6838-3701; Qin, Meiying/0000-0002-0983-2554;
   Shic, Frederick/0000-0002-9040-1259
FU NSF Expedition in Computing [1139078]; NIH [K01MH104739]
FX Support was provided by an NSF Expedition in Computing, B.S. is the
   principal investigator, #1139078 (Socially Assistive Robotics). F.S. was
   supported by funding by NIH grant no. K01MH104739.
CR Al Moubayed S., 2012, ACM T INTERACTIVE IN, V1, P25, DOI DOI 10.1145/2070719.2070724
   American Psychiatric Association, 2013, DIAGN STAT MAN MENT
   Baltrusaitis T, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P354, DOI 10.1109/ICCVW.2013.54
   Bean JL, 2012, RES AUTISM SPECT DIS, V6, P1304, DOI 10.1016/j.rasd.2012.04.003
   Belpaeme T, 2018, SCI ROBOT, V3, DOI 10.1126/scirobotics.aat5954
   Boccanfuso L, 2015, INT CONF AFFECT, P1, DOI 10.1109/ACII.2015.7344543
   Byiers BJ, 2012, AM J SPEECH-LANG PAT, V21, P397, DOI 10.1044/1058-0360(2012/11-0036)
   Diehl JJ, 2012, RES AUTISM SPECT DIS, V6, P249, DOI 10.1016/j.rasd.2011.05.006
   Elliott C. D., 1990, DAS ADM SCORING MANU
   Feil-Seifer D, 2005, INT C REHAB ROBOT, P465
   Guadagnoli MA, 2004, J MOTOR BEHAV, V36, P212, DOI 10.3200/JMBR.36.2.212-224
   Kanai C., 2017, HDB SOCIAL BEHAV SKI, P217
   Kim ES, 2012, J HUM-ROBOT INTERACT, V1, P26, DOI 10.5898/JHRI.1.1.Kim
   Kim ES, 2013, J AUTISM DEV DISORD, V43, P1038, DOI 10.1007/s10803-012-1645-2
   Kozima H, 2007, PROG BRAIN RES, V164, P385, DOI 10.1016/S0079-6123(07)64021-7
   Leyzberg D., 2012, P 34 ANN M COGN SCI
   Leyzberg D, 2014, ACMIEEE INT CONF HUM, P423, DOI 10.1145/2559636.2559671
   LORD C, 1994, J AUTISM DEV DISORD, V24, P659, DOI 10.1007/BF02172145
   Lord C., 1999, AUTISM DIAGNOSTIC OB
   Mackintosh VH, 2012, FOCUS AUTISM DEV DIS, V27, P51, DOI 10.1177/1088357611423542
   Mataric MJ, 2016, SPRINGER HANDBOOK OF ROBOTICS, P1973
   Pereira Andre, 2008, P 7 INT JOINT C AUT, V3, P1253
   Powers A., 2007, 2007 2nd Annual Conference on Human-Robot Interaction (HRI), P145
   Quigley M, 2009, IEEE INT CONF ROBOT, P3604
   Ramachandran Aditi, 2017, 2017 12th ACM/IEEE International Conference on Human-Robot Interaction (HRI), P146, DOI 10.1145/2909824.3020209
   Ramachandran A., 2018, P 2018 ACM IEEE INT, P59
   Ramachandran A, 2016, ELEVENTH ACM/IEEE INTERNATIONAL CONFERENCE ON HUMAN ROBOT INTERACTION (HRI'16), P247, DOI 10.1109/HRI.2016.7451759
   Robins B., 2009, 2 INT C ADV COMP HUM, P205, DOI DOI 10.1109/ACHI.2009.32
   Scassellati B, 2007, SPRINGER TRAC ADV RO, V28, P552
   Scassellati B, 2012, ANNU REV BIOMED ENG, V14, P275, DOI 10.1146/annurev-bioeng-071811-150036
   Smith T, 2007, J AUTISM DEV DISORD, V37, P354, DOI 10.1007/s10803-006-0173-3
   Tapus A, 2007, IEEE ROBOT AUTOM MAG, V14, P35, DOI 10.1109/MRA.2007.339605
   Tejima N, 2000, ADV ROBOTICS, V14, P551, DOI 10.1163/156855301742003
   Wainer J, 2014, IEEE T AUTON MENT DE, V6, P183, DOI 10.1109/TAMD.2014.2303116
   Zheng Z., 2017, AUTISM IMAGING DEVIC, V397
NR 35
TC 2
Z9 2
U1 15
U2 15
PU AMER ASSOC ADVANCEMENT SCIENCE
PI WASHINGTON
PA 1200 NEW YORK AVE, NW, WASHINGTON, DC 20005 USA
SN 2470-9476
J9 SCI ROBOT
JI Sci. Robot.
PD AUG 22
PY 2018
VL 3
IS 21
AR UNSP eaat7544
DI 10.1126/scirobotics.aat7544
PG 9
WC Robotics
SC Robotics
GA GS0XD
UT WOS:000443232300008
OA Bronze
DA 2019-02-18
ER

PT J
AU Spatola, N
   Belletier, C
   Normand, A
   Chausse, P
   Monceau, S
   Augustinova, M
   Barra, V
   Huguet, P
   Ferrand, L
AF Spatola, Nicolas
   Belletier, Clement
   Normand, Alice
   Chausse, Pierre
   Monceau, Sophie
   Augustinova, Maria
   Barra, Vincent
   Huguet, Pascal
   Ferrand, Ludovic
TI Not as bad as it seems: When the presence of a threatening humanoid
   robot improves human performance
SO SCIENCE ROBOTICS
LA English
DT Editorial Material
ID STROOP TASK; SOCIAL FACILITATION; ANTHROPOMORPHISM
AB "Bad" humanoid robots just paying attention to human performance may energize attentional control-as does human presence.
C1 [Spatola, Nicolas; Normand, Alice; Chausse, Pierre; Monceau, Sophie; Huguet, Pascal; Ferrand, Ludovic] Univ Clermont Auvergne, CNRS, LAPSCO, F-63000 Clermont Ferrand, France.
   [Belletier, Clement] Univ Fribourg, Lab Psychol Dev Cognitif, Fribourg, Switzerland.
   [Augustinova, Maria] Normandie Univ, UNIROUEN, CRFDP, F-76000 Rouen, France.
   [Barra, Vincent] Univ Clermont Auvergne, CNRS, LIMOS, F-63000 Clermont Ferrand, France.
RP Spatola, N; Ferrand, L (reprint author), Univ Clermont Auvergne, CNRS, LAPSCO, F-63000 Clermont Ferrand, France.
EM nicolas.spatola@uca.fr; ludovic.ferrand@uca.fr
OI Spatola, Nicolas/0000-0003-2693-3362; Chausse,
   Pierre/0000-0001-5861-4169; Barra, Vincent/0000-0002-8975-222X; Huguet,
   Pascal/0000-0002-0707-7655; FERRAND, Ludovic/0000-0003-1631-7849
FU Maison des Sciences de l'Homme, Clermont- Ferrand, France
FX This work was supported by a grant (Social_Robot_2017-2018) from the
   Maison des Sciences de l'Homme, Clermont-Ferrand, France.
CR Aron A, 1997, PERS SOC PSYCHOL B, V23, P363, DOI 10.1177/0146167297234003
   Augustinova M, 2012, J EXP SOC PSYCHOL, V48, P1213, DOI 10.1016/j.jesp.2012.04.014
   Baron R. S., 1986, ADV EXPT SOCIAL PSYC, V19, P1, DOI [10.1016/S0065-2601(08)60211-7, DOI 10.1016/S0065-2601(08)60211-7]
   Bartneck C, 2009, INT J SOC ROBOT, V1, P71, DOI 10.1007/s12369-008-0001-3
   Broadbent E, 2007, 2007 IEEE/RSJ International Conference on Intelligent Robots and Systems, P3703, DOI 10.1109/IROS.2007.4398982
   Carpinella Colleen M., 2017, 2017 12th ACM/IEEE International Conference on Human-Robot Interaction (HRI), P254, DOI 10.1145/2909824.3020208
   Chajut E, 2003, J PERS SOC PSYCHOL, V85, P231, DOI 10.1037/0022-3514.85.2.231
   Duffy BR, 2003, ROBOT AUTON SYST, V42, P177, DOI 10.1016/S0921-8890(02)00374-3
   Haslam N, 2014, ANNU REV PSYCHOL, V65, P399, DOI 10.1146/annurev-psych-010213-115045
   Huguet P, 1999, J PERS SOC PSYCHOL, V77, P1011, DOI 10.1037/0022-3514.77.5.1011
   Kanda T., 2017, HUMAN ROBOT INTERACT
   MACLEOD CM, 1992, J EXP PSYCHOL GEN, V121, P12, DOI 10.1037/0096-3445.121.1.12
   New B, 2004, BEHAV RES METH INS C, V36, P516, DOI 10.3758/BF03195598
   Normand A, 2013, SOC COGNITION, V31, P336, DOI 10.1521/soco.2013.31.3.336
   Sharma D, 2010, PSYCHON B REV, V17, P52, DOI 10.3758/PBR.17.1.52
   Yang GZ, 2018, SCI ROBOT, V3, DOI 10.1126/scirobotics.aar7650
NR 16
TC 1
Z9 1
U1 5
U2 5
PU AMER ASSOC ADVANCEMENT SCIENCE
PI WASHINGTON
PA 1200 NEW YORK AVE, NW, WASHINGTON, DC 20005 USA
SN 2470-9476
J9 SCI ROBOT
JI Sci. Robot.
PD AUG 22
PY 2018
VL 3
IS 21
AR UNSP eaat5843
DI 10.1126/scirobotics.aat5843
PG 2
WC Robotics
SC Robotics
GA GS0XD
UT WOS:000443232300002
DA 2019-02-18
ER

PT J
AU Vollmer, AL
   Read, R
   Trippas, D
   Belpaeme, T
AF Vollmer, Anna-Lisa
   Read, Robin
   Trippas, Dries
   Belpaeme, Tony
TI Children conform, adults resist: A robot group induced peer pressure on
   normative social conformity
SO SCIENCE ROBOTICS
LA English
DT Article
ID PRESCHOOL-CHILDREN; INTERACTIVE ROBOTS; COMPUTERS; RESPONSES; BEHAVIOR;
   AGE; MACHINES; MAJORITY; AUTISM; TASK
AB People are known to change their behavior and decisions to conform to others, even for obviously incorrect facts. Because of recent developments in artificial intelligence and robotics, robots are increasingly found in human environments, and there, they form a novel social presence. It is as yet unclear whether and to what extent these social robots are able to exert pressure similar to human peers. This study used the Asch paradigm, which shows how participants conform to others while performing a visual judgment task. We first replicated the finding that adults are influenced by their peers but showed that they resist social pressure from a group of small humanoid robots. Next, we repeated the study with 7- to 9-year-old children and showed that children conform to the robots. This raises opportunities as well as concerns for the use of social robots with young and vulnerable cross-sections of society; although conforming can be beneficial, the potential for misuse and the potential impact of erroneous performance cannot be ignored.
C1 [Vollmer, Anna-Lisa] Bielefeld Univ, Cluster Excellence Cognit Interact Technol, D-33619 Bielefeld, Germany.
   [Read, Robin; Belpaeme, Tony] Plymouth Univ, Ctr Robot & Neural Syst, Plymouth PL4 8AA, Devon, England.
   [Trippas, Dries] Max Planck Inst Human Dev, Ctr Adapt Rat, D-14195 Berlin, Germany.
   [Belpaeme, Tony] Univ Ghent, IDLab, IMEC, B-9052 Ghent, Belgium.
RP Vollmer, AL (reprint author), Bielefeld Univ, Cluster Excellence Cognit Interact Technol, D-33619 Bielefeld, Germany.; Belpaeme, T (reprint author), Plymouth Univ, Ctr Robot & Neural Syst, Plymouth PL4 8AA, Devon, England.; Belpaeme, T (reprint author), Univ Ghent, IDLab, IMEC, B-9052 Ghent, Belgium.
EM avollmer@techfak.uni-bielefeld.de; tony.belpaeme@ugent.be
FU European Union FP7 ALIZ-E project [248116]; FP7 DREAM project [611391];
   FP7 Marie Curie Actions ITN RobotDoC project [235065]; H2020 L2TOR
   project [688014]; Cluster of Excellence Cognitive Interaction
   Technology, Bielefeld University [EXC 277]
FX This work was funded by the European Union FP7 ALIZ-E (248116), FP7
   DREAM (611391), FP7 Marie Curie Actions ITN RobotDoC (235065), and H2020
   L2TOR (688014) projects and grants from the Cluster of Excellence
   Cognitive Interaction Technology (EXC 277), Bielefeld University.
CR ABRAMS D, 1990, BRIT J SOC PSYCHOL, V29, P97, DOI 10.1111/j.2044-8309.1990.tb00892.x
   ALLEN VL, 1965, ADV EXP SOC PSYCHOL, V2, P133
   Asch S. E., 1951, GROUPS LEADERSHIP ME, P222
   ASCH SE, 1955, SCI AM, V193, P31, DOI 10.1038/scientificamerican1155-31
   ASCH SE, 1956, PSYCHOL MONOGR, V70, P1, DOI 10.1037/h0093718
   Belpaeme T, 2012, J HUM-ROBOT INTERACT, V1, P33, DOI 10.5898/JHRI.1.2.Belpaeme
   BERNDT TJ, 1979, DEV PSYCHOL, V15, P662, DOI 10.1037//0012-1649.15.6.662
   Bond R, 1996, PSYCHOL BULL, V119, P111, DOI 10.1037/0033-2909.119.1.111
   Bond RM, 2012, NATURE, V489, P295, DOI 10.1038/nature11421
   Brandstetter J, 2014, IEEE INT C INT ROBOT, P1335, DOI 10.1109/IROS.2014.6942730
   Breazeal C, 2016, TOP COGN SCI, V8, P481, DOI 10.1111/tops.12192
   Breazeal Cynthia, 2000, THESIS
   Burgard W, 1999, ARTIF INTELL, V114, P3, DOI 10.1016/S0004-3702(99)00070-3
   Caliskan A, 2017, SCIENCE, V356, P183, DOI 10.1126/science.aal4230
   COSTANZO PR, 1966, CHILD DEV, V37, P967, DOI 10.1111/j.1467-8624.1966.tb05423.x
   DEUTSCH MORTON, 1955, JOUR ABNORMAL AND SOCIAL PSYCHOL, V51-31, P629, DOI 10.1037/h0046408
   EAGLY AH, 1978, PSYCHOL BULL, V85, P86, DOI 10.1037//0033-2909.85.1.86
   Fasola J, 2012, P IEEE, V100, P2512, DOI 10.1109/JPROC.2012.2200539
   Fong T, 2003, ROBOT AUTON SYST, V42, P143, DOI 10.1016/S0921-8890(02)00372-X
   Han J, 2008, J INF PROCESS SYST, V4, P159, DOI 10.3745/JIPS.2008.4.4.159
   Haun DBM, 2013, DEV COGN NEUROS-NETH, V3, P61, DOI 10.1016/j.dcn.2012.09.003
   Haun DBM, 2011, CHILD DEV, V82, P1759, DOI 10.1111/j.1467-8624.2011.01666.x
   Kahn PH, 2006, INTERACT STUD, V7, P405, DOI 10.1075/is.7.3.13kah
   Kahn PH, 2013, CHILD DEV PERSPECT, V7, P32, DOI 10.1111/cdep.12011
   Kanda T, 2004, HUM-COMPUT INTERACT, V19, P61, DOI 10.1207/s15327051hci1901&2_4
   Kennedy J., 2016, 2016 11 ACM IEEE INT
   Kim ES, 2013, J AUTISM DEV DISORD, V43, P1038, DOI 10.1007/s10803-012-1645-2
   Kramer ADI, 2014, P NATL ACAD SCI USA, V111, P8788, DOI 10.1073/pnas.1320040111
   LINDE TF, 1964, J ABNORM SOC PSYCH, V68, P115, DOI 10.1037/h0043897
   Melson GF, 2009, J APPL DEV PSYCHOL, V30, P92, DOI 10.1016/j.appdev.2008.10.011
   Mori K., 2011, PSYCHOLOGY, V2, P661, DOI DOI 10.4236/PSYCH.2011.27100
   Mori K, 2010, INT J PSYCHOL, V45, P390, DOI 10.1080/00207591003774485
   Nass C, 2000, J SOC ISSUES, V56, P81, DOI 10.1111/0022-4537.00153
   Nass C, 1999, J APPL SOC PSYCHOL, V29, P1093, DOI 10.1111/j.1559-1816.1999.tb00142.x
   Nass C, 1997, J APPL SOC PSYCHOL, V27, P864, DOI 10.1111/j.1559-1816.1997.tb00275.x
   Nass C., 1994, P SIGCHI C HUM FACT
   Pasupathi M, 1999, PSYCHOL AGING, V14, P170, DOI 10.1037//0882-7974.14.1.170
   Reeves B., 1996, MEDIA EQUATION PEOPL
   Salomons N., 2018, P 2018 ACM IEEE INT, P187
   Scassellati B, 2012, ANNU REV BIOMED ENG, V14, P275, DOI 10.1146/annurev-bioeng-071811-150036
   Sharkey N, 2010, INTERACT STUD, V11, P161, DOI 10.1075/is.11.2.o1sha
   Tanaka F, 2007, P NATL ACAD SCI USA, V104, P17954, DOI 10.1073/pnas.0707769104
   Vanderborght B., 2012, PALADYN, V3, P209, DOI [10.2478/s13230-013-0107-7, DOI 10.2478/S13230-013-0107-7]
   Wada K, 2007, IEEE T ROBOT, V23, P972, DOI 10.1109/TRO.2007.906261
   Walker MB, 1996, J SOC PSYCHOL, V136, P367, DOI 10.1080/00224545.1996.9714014
NR 45
TC 2
Z9 2
U1 18
U2 18
PU AMER ASSOC ADVANCEMENT SCIENCE
PI WASHINGTON
PA 1200 NEW YORK AVE, NW, WASHINGTON, DC 20005 USA
SN 2470-9476
J9 SCI ROBOT
JI Sci. Robot.
PD AUG 22
PY 2018
VL 3
IS 21
AR UNSP eaat7111
DI 10.1126/scirobotics.aat7111
PG 7
WC Robotics
SC Robotics
GA GS0XD
UT WOS:000443232300006
DA 2019-02-18
ER

PT J
AU Zhang, MM
   Cao, JH
   Xie, SQ
   Zhu, GL
   Zeng, XF
   Huang, XL
   Xu, Q
AF Zhang, Mingming
   Cao, Jinghui
   Xie, Sheng Q.
   Zhu, Guoli
   Zeng, Xiangfeng
   Huang, Xiaolin
   Xu, Qun
TI A Preliminary Study on Robot-Assisted Ankle Rehabilitation for the
   Treatment of Drop Foot
SO JOURNAL OF INTELLIGENT & ROBOTIC SYSTEMS
LA English
DT Article
DE Robot-assisted; Ankle; Rehabilitation; Drop foot; Stretching
ID FUNCTIONAL ELECTRICAL-STIMULATION; PARALLEL ROBOT; ORTHOSIS; DESIGN;
   THERAPY; GAIT
AB This paper involves the use of a compliant ankle rehabilitation robot (CARR) for the treatment of drop foot. The robot has a bio-inspired design by employing four Festo Fluidic muscles (FFMs) that mimic skeletal muscles actuating three rotational degrees of freedom (DOFs). A trajectory tracking controller was developed in joint task space to track the predefined trajectory of the end effector. This controller was achieved by controlling individual FFM length based on inverse kinematics. Three patients with drop foot participated in a preliminary study to evaluate the potential of the CARR for clinical applications. Ankle stretching exercises along ankle dorsiflexion and plantarflexion (DP) were delivered for treating drop foot. All patients gave positive feedback in using this ankle robot for the treatment of drop foot, although some limitations exist. The proposed controller showed satisfactory accuracy in trajectory tracking, with all root mean square deviation (RMSD) values no greater than 0.0335 rad and normalized root mean square deviation (NRMSD) values less than 6.7%. These preliminary findings support the potentials of the CARR for clinical applications. Future work will investigate the effectiveness of the robot for treating drop foot on a large sample of subjects.
C1 [Zhang, Mingming] Tongji Zhejiang Coll, Med & Rehabil Equipment Res Ctr, Jiaxing, Peoples R China.
   [Zhang, Mingming; Cao, Jinghui] Univ Auckland, Dept Mech Engn, Auckland, New Zealand.
   [Zhu, Guoli; Zeng, Xiangfeng] Huazhong Univ Sci & Technol, State Key Lab Digital Mfg Equipment & Technol, Wuhan, Hubei, Peoples R China.
   [Huang, Xiaolin; Xu, Qun] Huazhong Univ Sci & Technol, Tongji Hosp, Rehabil Dept, Wuhan, Hubei, Peoples R China.
   [Xie, Sheng Q.] Univ Leeds, Sch Elect & Elect Engn, Leeds, W Yorkshire, England.
RP Xie, SQ (reprint author), Univ Leeds, Sch Elect & Elect Engn, Leeds, W Yorkshire, England.
EM S.Q.Xie@leeds.ac.uk
FU University of Auckland, Faculty of Engineering Research Development Fund
   [3625057]; China Sponsorship Council
FX This material was based on work supported by the University of Auckland,
   Faculty of Engineering Research Development Fund 3625057 (Physical
   Robot-Human Interaction for Performance-Based Progressive Robot-Assisted
   Therapy) and the China Sponsorship Council.
CR ACC and the Ministry of Health, 2014, NZ SPIN CORD IMP ACT
   [Anonymous], 2017, FACTS STROKE STROKE
   [Anonymous], 2017, DROP FOOT
   Blaya JA, 2004, IEEE T NEUR SYS REH, V12, P24, DOI 10.1109/TNSRE.2003.823266
   Faraji A, 2014, APPL MECH MATER, V464, P129, DOI 10.4028/www.scientific.net/AMM.464.129
   Ferris DP, 2006, GAIT POSTURE, V23, P425, DOI 10.1016/j.gaitpost.2005.05.004
   Girone M, 2001, AUTON ROBOT, V10, P203, DOI 10.1023/A:1008938121020
   Guo HB, 2008, CONTROL ENG PRACT, V16, P1055, DOI 10.1016/j.conengprac.2007.11.005
   Jamwal P., 2011, THESIS
   Jamwal PK, 2014, IEEE-ASME T MECH, V19, P64, DOI 10.1109/TMECH.2012.2219065
   Kottink AIR, 2004, ARTIF ORGANS, V28, P577, DOI 10.1111/j.1525-1594.2004.07310.x
   Krishnamoorthy Vijaya, 2008, J Neurol Phys Ther, V32, P192, DOI 10.1097/NPT.0b013e31818e8fc2
   Liu GQ, 2006, IEEE ICMA 2006: PROCEEDING OF THE 2006 IEEE INTERNATIONAL CONFERENCE ON MECHATRONICS AND AUTOMATION, VOLS 1-3, PROCEEDINGS, P1109
   Lyons GM, 2002, IEEE T NEUR SYS REH, V10, P260, DOI 10.1109/TNSRE.2002.806832
   Mozaffarian D, 2015, CIRCULATION, V131, pE29, DOI 10.1161/CIR.0000000000000152
   Park YL, 2014, BIOINSPIR BIOMIM, V9, DOI 10.1088/1748-3182/9/1/016007
   Peckham PH, 2005, ANNU REV BIOMED ENG, V7, P327, DOI 10.1146/annurev.bioeng.6.040803.140103
   Pusey J, 2004, MECH MACH THEORY, V39, P761, DOI 10.1016/j.mechmachtheory.2004.02.010
   Romansky N., DIAGNOSING TREATING, V25
   Roy A, 2009, IEEE T ROBOT, V25, P569, DOI 10.1109/TRO.2009.2019783
   Saglia JA, 2009, INT J ROBOT RES, V28, P1216, DOI 10.1177/0278364909104221
   Shorter KA, 2011, J REHABIL RES DEV, V48, P459, DOI 10.1682/JRRD.2010.04.0054
   Stewart John D, 2008, Pract Neurol, V8, P158, DOI 10.1136/jnnp.2008.149393
   Syrseloudis C. E., 2008, P 8 IEEE INT C BIOIN, P1
   Tsoi Y. H., 2011, THESIS
   Tsoi YH, 2009, STUD COMPUT INTELL, V177, P377
   Ward J, 2011, ADV ROBOTICS, V25, P1879, DOI 10.1163/016918611X588907
   Yakimovich T, 2009, J REHABIL RES DEV, V46, P257, DOI 10.1682/JRRD.2008.02.0024
   Yeap JS, 2001, INT ORTHOP, V25, P114, DOI 10.1007/s002640100229
   Yoon J, 2006, J ROBOTIC SYST, V22, pS15, DOI 10.1002/rob.20150
   Zhang LQ, 2002, IEEE T NEUR SYS REH, V10, P149, DOI 10.1109/TNSRE.2002.802857
   Zhang M., 2016, THESIS
   Zhang MM, 2014, J REHABIL RES DEV, V51, P517, DOI 10.1682/JRRD.2013.03.0066
   Zhang MM, 2013, J NEUROENG REHABIL, V10, DOI 10.1186/1743-0003-10-30
NR 34
TC 0
Z9 0
U1 13
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 0921-0296
EI 1573-0409
J9 J INTELL ROBOT SYST
JI J. Intell. Robot. Syst.
PD AUG
PY 2018
VL 91
IS 2
SI SI
BP 207
EP 215
DI 10.1007/s10846-017-0652-0
PG 9
WC Computer Science, Artificial Intelligence; Robotics
SC Computer Science; Robotics
GA GP2XK
UT WOS:000440700500008
OA Other Gold, Green Published
DA 2019-02-18
ER

PT J
AU Shin, SY
   Deshpande, AD
   Sulzer, J
AF Shin, Sung Yul
   Deshpande, Ashish D.
   Sulzer, James
TI Design of a Single Degree-of-Freedom, Adaptable Electromechanical Gait
   Trainer for People With Neurological Injury
SO JOURNAL OF MECHANISMS AND ROBOTICS-TRANSACTIONS OF THE ASME
LA English
DT Article
ID BODY-WEIGHT SUPPORT; STROKE PATIENTS; SPINAL-CORD; RANDOMIZED CROSSOVER;
   HEMIPARETIC PATIENTS; WALKING; REHABILITATION; RESTORATION; ORTHOSIS;
   PHYSIOTHERAPY
AB The cost of therapy is one of the most significant barriers to recovery after neurological injury. Robotic gait trainers move the legs through repetitive, natural motions imitating gait. Recent meta-analyses conclude that such training improves walking function in neurologically impaired individuals. While robotic gait trainers promise to reduce the physical burden on therapists and allow greater patient throughput, they are prohibitively costly. Our novel approach is to design a new single degree-of-freedom (DoF) robotic trainer that maintains the key advantages of the expensive trainers but with a simplified design to reduce cost. Our primary design challenge is translating the motion of a single actuator to an array of natural gait trajectories. We address this with an eight-link Jansen mechanism that matches a generalized gait trajectory. We then optimize the mechanism to match different trajectories through link length adjustment based on nine different gait patterns obtained from gait database of 113 healthy individuals. To physically validate the range in gait patterns produced by the simulation, we tested kinematic accuracy on a motorized wooden proof-of-concept of the gait trainer. The simulation and experimental results suggested that an adjustment of two links can reasonably fit a wide range of gait patterns under typical within-subject variance. We conclude that this design could provide the basis for a low-cost, patient-based electromechanical gait trainer for neurorecovery.
C1 [Shin, Sung Yul; Deshpande, Ashish D.; Sulzer, James] Univ Texas Austin, Dept Mech Engn, 204 E Dean Keeton St, Austin, TX 78712 USA.
RP Shin, SY (reprint author), Univ Texas Austin, Dept Mech Engn, 204 E Dean Keeton St, Austin, TX 78712 USA.
EM syshin0228@utexas.edu; ashish@austin.utexas.edu;
   james.sulzer@austin.utexas.edu
FU Dr. Eugene Alford Endowed Fund for Robotics from Mission Connect
   [015-104]
FX This project is partially funded by Dr. Eugene Alford Endowed Fund for
   Robotics from Mission Connect, #015-104.
CR Banala SK, 2009, IEEE T NEUR SYS REH, V17, P2, DOI 10.1109/TNSRE.2008.2008280
   Beres-Jones JA, 2004, BRAIN, V127, P2232, DOI 10.1093/brain/awh252
   Colombo G, 2000, J REHABIL RES DEV, V37, P693
   CUNNINGHAM DA, 1982, J GERONTOL, V37, P560, DOI 10.1093/geronj/37.5.560
   Dietz V, 2002, NAT REV NEUROSCI, V3, P781, DOI 10.1038/nrn939
   DIETZ V, 1994, LANCET, V344, P1260, DOI 10.1016/S0140-6736(94)90751-X
   Duschau-Wicke A, 2010, IEEE T NEUR SYS REH, V18, P38, DOI 10.1109/TNSRE.2009.2033061
   Freivogel S, 2008, BRAIN INJURY, V22, P625, DOI 10.1080/02699050801941771
   Freivogel S, 2009, J REHABIL MED, V41, P734, DOI 10.2340/16501977-0422
   Godwin KM, 2011, TOP STROKE REHABIL, V18, P676, DOI 10.1310/tsr18s01-676
   Hesse S, 2000, J REHABIL RES DEV, V37, P701
   HESSE S, 1995, STROKE, V26, P976, DOI 10.1161/01.STR.26.6.976
   Hesse S, 2001, NEUROREHAB NEURAL RE, V15, P39, DOI 10.1177/154596830101500106
   Husemann B, 2007, STROKE, V38, P349, DOI 10.1161/01.STR.0000254607.48765.cb
   Jansen B, 2014, RAPID PROTOTYPING J, V20, P311, DOI 10.1108/RPJ-10-2012-0087
   Jung CY, 2014, IEEE INT C INT ROBOT, P2095, DOI 10.1109/IROS.2014.6942843
   Koopman B, 2014, J BIOMECH, V47, P1447, DOI 10.1016/j.jbiomech.2014.01.037
   Kora K, 2017, J MED DEVICES, V11, DOI 10.1115/1.4035127
   Laufer Y, 2001, J REHABIL RES DEV, V38, P69
   Macko RF, 2005, STROKE, V36, P2206, DOI 10.1161/01.STR.0000181076.91805.89
   Mayr A, 2007, NEUROREHAB NEURAL RE, V21, P307, DOI 10.1177/1545968307300697
   Mehrholz J., 2017, COCHRANE DB SYST REV, V5
   Mehrholz J, 2012, J REHABIL MED, V44, P193, DOI 10.2340/16501977-0943
   Morone G, 2017, NEUROPSYCH DIS TREAT, V13, P1303, DOI 10.2147/NDT.S114102
   Mozaffarian D, 2016, CIRCULATION, V133, pE38, DOI 10.1161/CIR.0000000000000350
   Nam KY, 2017, J NEUROENG REHABIL, V14, DOI 10.1186/s12984-017-0232-3
   Norton R.L., 2004, DESIGN MACHINERY INT
   Patrick M, 2014, OVERVIEW ASSESSIN 11
   Peurala SH, 2005, ARCH PHYS MED REHAB, V86, P1557, DOI 10.1016/j.apmr.2005.02.005
   Pohl M, 2007, CLIN REHABIL, V21, P17, DOI 10.1177/0269215506071281
   Ravindran A, 2006, ENG OPTIMIZATION MET
   Riener R., 2016, NEUROREHABILITATION, P395
   Robotics Business Review, 2014, HEALTHC ROB 2014 LEA
   Schmidt H., 2005, ACM T APPL PERCEPT, V2, P166, DOI DOI 10.1145/1060581.1060589
   Simons C. D. M, 2009, GAIT POSTURE, V30, pS7
   Tan AQ, 2014, J BIOMECH, V47, P949, DOI 10.1016/j.jbiomech.2014.01.025
   van Asseldonk EHF, 2008, IEEE T NEUR SYS REH, V16, P360, DOI 10.1109/TNSRE.2008.925074
   Veneman JF, 2005, INT C REHAB ROBOT, P496
   Werner C, 2002, STROKE, V33, P2895, DOI 10.1161/01.STR.0000035734.61539.f6
   Westlake KP, 2009, J NEUROENG REHABIL, V6, DOI 10.1186/1743-0003-6-18
   Yun Y, 2014, J BIOMECH, V47, P186, DOI 10.1016/j.jbiomech.2013.09.032
NR 41
TC 0
Z9 0
U1 1
U2 1
PU ASME
PI NEW YORK
PA TWO PARK AVE, NEW YORK, NY 10016-5990 USA
SN 1942-4302
EI 1942-4310
J9 J MECH ROBOT
JI J. Mech. Robot.
PD AUG
PY 2018
VL 10
IS 4
AR 044503
DI 10.1115/1.4039973
PG 7
WC Engineering, Mechanical; Robotics
SC Engineering; Robotics
GA GL6ZD
UT WOS:000437343500016
DA 2019-02-18
ER

PT J
AU Krichmar, JL
AF Krichmar, Jeffrey L.
TI Neurorobotics-A Thriving Community and a Promising Pathway Toward
   Intelligent Cognitive Robots
SO FRONTIERS IN NEUROROBOTICS
LA English
DT Article
DE brain-based devices; evolutionary robotics; embodied cognition;
   cognitive robotics; Neural Darwinism; neuromorphic engineering
ID BRAIN-BASED DEVICE; REAL-WORLD DEVICE; PERCEPTUAL CATEGORIZATION; MAZE
   NAVIGATION; MODEL; BEHAVIOR; SYSTEMS; NEUROSCIENCE; NETWORKS;
   NEUROMODULATION
AB Neurorobots are robots whose control has been modeled after some aspect of the brain. Since the brain is so closely coupled to the body and situated in the environment, Neurorobots can be a powerful tool for studying neural function in a holistic fashion. It may also be a means to develop autonomous systems that have some level of biological intelligence. The present article provides my perspective on this field, points out some of the landmark events, and discusses its future potential.
C1 [Krichmar, Jeffrey L.] Univ Calif Irvine, Dept Cognit Sci, Irvine, CA 92717 USA.
   [Krichmar, Jeffrey L.] Univ Calif Irvine, Dept Comp Sci, Irvine, CA 92697 USA.
RP Krichmar, JL (reprint author), Univ Calif Irvine, Dept Cognit Sci, Irvine, CA 92717 USA.; Krichmar, JL (reprint author), Univ Calif Irvine, Dept Comp Sci, Irvine, CA 92697 USA.
EM jkrichma@uci.edu
FU Intel Corporation
FX JK is supported by the Intel Corporation.
CR Almassy N, 1998, CEREB CORTEX, V8, P346, DOI 10.1093/cercor/8.4.346
   Arleo A, 2004, IEEE T NEURAL NETWOR, V15, P639, DOI 10.1109/TNN.2004.826221
   Asada M, 2009, IEEE T AUTON MENT DE, V1, P12, DOI 10.1109/TAMD.2009.2021702
   Ascoli GA, 2001, ANAT EMBRYOL, V204, P283, DOI 10.1007/s004290100201
   Ascoli GA, 2001, PHILOS T ROY SOC B, V356, P1131, DOI 10.1098/rstb.2001.0905
   Bakkum Douglas J, 2007, Front Neurorobot, V1, P5, DOI 10.3389/neuro.12.005.2007
   Banquet JP, 2005, NEURAL COMPUT, V17, P1339, DOI 10.1162/0899766053630369
   Beyeler M, 2015, NEURAL NETWORKS, V72, P75, DOI 10.1016/j.neunet.2015.09.005
   Braitenberg V., 1986, VEHICLES EXPT SYNTHE
   Brooks R. A., 1991, P 12 INT JOINT C ART, P1
   BROOKS RA, 1991, ARTIF INTELL, V47, P139, DOI 10.1016/0004-3702(91)90053-M
   Browne W, 2009, IEEE ROBOT AUTOM MAG, V16, P17, DOI 10.1109/MRA.2009.933617
   Caligiore D, 2010, PSYCHOL REV, V117, P1188, DOI 10.1037/a0020887
   Chavarriaga R, 2005, NEUROINFORMATICS, V3, P223, DOI 10.1385/NI:3:3:223
   Clark A., 1996, BEING THERE PUTTING
   Clark A, 2013, BEHAV BRAIN SCI, V36, P181, DOI 10.1017/S0140525X12000477
   Collins S, 2005, SCIENCE, V307, P1082, DOI 10.1126/science.1107799
   Cox BR, 2009, IEEE ROBOT AUTOM MAG, V16, P72, DOI 10.1109/MRA.2009.933628
   Cuperlier Nicolas, 2007, Front Neurorobot, V1, P3, DOI 10.3389/neuro.12.003.2007
   Davies M, 2018, IEEE MICRO, V38, P82, DOI 10.1109/MM.2018.112130359
   Dogan F. I., 2017, ARXIV171004975CSRO
   Edelman G. M, 1987, NEURAL DARWINISM THE
   EDELMAN GM, 1993, NEURON, V10, P115, DOI 10.1016/0896-6273(93)90304-A
   EDELMAN GM, 1992, P NATL ACAD SCI USA, V89, P7267, DOI 10.1073/pnas.89.15.7267
   Edelman GM, 2001, P NATL ACAD SCI USA, V98, P13763, DOI 10.1073/pnas.231499798
   Esser SK, 2016, P NATL ACAD SCI USA, V113, P11441, DOI 10.1073/pnas.1604850113
   Falotico E, 2017, FRONT NEUROROBOTICS, V11, DOI 10.3389/fnbot.2017.00002
   Fleischer Jason G., 2007, Journal of Integrative Neuroscience, V6, P403, DOI 10.1142/S0219635207001568
   Fleischer JG, 2007, P NATL ACAD SCI USA, V104, P3556, DOI 10.1073/pnas.0611571104
   Floreano D, 2010, PLOS BIOL, V8, DOI 10.1371/journal.pbio.1000292
   Friston KJ, 2009, PLOS BIOL, V7, P220, DOI 10.1371/journal.pbio.1000033
   FRISTON KJ, 1994, NEUROSCIENCE, V59, P229, DOI 10.1016/0306-4522(94)90592-4
   Girard Benoit, 2003, J Integr Neurosci, V2, P179, DOI 10.1142/S0219635203000299
   Goodman Philip H, 2007, Front Neurorobot, V1, P1, DOI 10.3389/neuro.12.001.2007
   Hawkins G., 2017, IEEE SPECTRUM MAG, P35
   Hoffmann Matej, 2012, From Animals to Animats 12. Proceedings of the 12th International Conference on Simulation of Adaptive Behavior, SAB 2012, P54, DOI 10.1007/978-3-642-33093-3_6
   Hossain D., 2016, 2 IEEJ INT WORKSH SE
   Hwu T, 2017, IEEE IJCNN, P635, DOI 10.1109/IJCNN.2017.7965912
   Ijspeert AJ, 2005, NEUROINFORMATICS, V3, P171, DOI 10.1385/NI:3:3:171
   Ijspeert AJ, 2007, SCIENCE, V315, P1416, DOI 10.1126/science.1138353
   Indiveri G, 2011, FRONT NEUROSCI-SWITZ, V5, DOI 10.3389/fnins.2011.00073
   Izhikevich EM, 2004, IEEE T NEURAL NETWOR, V15, P1063, DOI 10.1109/TNN.2004.832719
   Krakauer JW, 2017, NEURON, V93, P480, DOI 10.1016/j.neuron.2016.12.041
   Krichmar J. L., 2011, NEUROMORPHIC BRAIN B
   Krichmar JL, 2008, ADAPT BEHAV, V16, P385, DOI 10.1177/1059712308095775
   Krichmar JL, 2015, ACM J EMERG TECH COM, V11, DOI 10.1145/2629509
   Krichmar JL, 2012, BIOL INSPIR COGN ARC, V1, P73, DOI 10.1016/j.bica.2012.04.003
   Krichmar JL, 2013, FRONT NEUROROBOTICS, V7, DOI 10.3389/fnbot.2013.00001
   Krichmar JL, 2005, NEUROINFORMATICS, V3, P197, DOI 10.1385/NI:3:3:197
   Krichmar JL, 2005, P NATL ACAD SCI USA, V102, P2111, DOI 10.1073/pnas.0409792102
   Krichmar JL, 2002, CEREB CORTEX, V12, P818, DOI 10.1093/cercor/12.8.818
   KRICHMAR JL, 2000, COM ADAP SY, P41
   Kuipers B, 2017, AI MAG, V38, P88, DOI 10.1609/aimag.v38i1.2716
   Larson E. J., 2017, LIMITS MODERN AI STO
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Liu SC, 2010, CURR OPIN NEUROBIOL, V20, P288, DOI 10.1016/j.conb.2010.03.007
   Lungarella M, 2005, NEUROINFORMATICS, V3, P243, DOI 10.1385/NI:3:3:243
   Massera Gianluca, 2007, Front Neurorobot, V1, P4, DOI 10.3389/neuro.12.004.2007
   Merolla PA, 2014, SCIENCE, V345, P668, DOI 10.1126/science.1254642
   Metta G, 2010, NEURAL NETWORKS, V23, P1125, DOI 10.1016/j.neunet.2010.08.010
   Milford M, 2016, SPRINGER TRAC ADV RO, V114, P467, DOI 10.1007/978-3-319-28872-7_27
   Mnih V, 2015, NATURE, V518, P529, DOI 10.1038/nature14236
   Murata S, 2017, IEEE T NEUR NET LEAR, V28, P830, DOI 10.1109/TNNLS.2015.2492140
   Navarro-Guerrero N, 2017, FRONT NEUROROBOTICS, V11, P1, DOI 10.3389/fnbot.2017.00010
   Nolfi S, 2000, EVOLUTIONARY ROBOTIC
   Oros N., 2013, CECS TECHNICAL REPOR, p[13, 1]
   Park JC, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00134
   Parvizi J, 2001, COGNITION, V79, P135, DOI 10.1016/S0010-0277(00)00127-X
   Pearson MJ, 2011, PHILOS T R SOC B, V366, P3085, DOI 10.1098/rstb.2011.0164
   Pfeifer R., 2006, BODY SHAPES WAY WE T
   Prescott TJ, 2006, NEURAL NETWORKS, V19, P31, DOI 10.1016/j.neunet.2005.06.049
   REEKE GN, 1990, P IEEE, V78, P1498, DOI 10.1109/5.58327
   Seth AK, 2005, NEUROINFORMATICS, V3, P167, DOI 10.1385/NI:3:3:167
   Seth AK, 2004, INT J ROBOT AUTOM, V19, P222
   Seth AK, 2004, CEREB CORTEX, V14, P1185, DOI 10.1093/cercor/bhh079
   Silver D, 2016, NATURE, V529, P484, DOI 10.1038/nature16961
   Sporns O, 2002, NEURAL NETWORKS, V15, P761, DOI 10.1016/S0893-6080(02)00062-X
   Stewart TC, 2016, FRONT NEUROROBOTICS, V10, DOI 10.3389/fnbot.2016.00001
   Tani Jun, 2007, Front Neurorobot, V1, P2, DOI 10.3389/neuro.12.002.2007
   Vargas PA, 2009, INT J INTELL COMPUT, V2, P435, DOI 10.1108/17563780910982680
   Venkatraman A, 2017, FRONT NEUROANAT, V11, DOI 10.3389/fnana.2017.00015
NR 81
TC 1
Z9 1
U1 9
U2 9
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1662-5218
J9 FRONT NEUROROBOTICS
JI Front. Neurorobotics
PD JUL 16
PY 2018
VL 12
AR 42
DI 10.3389/fnbot.2018.00042
PG 11
WC Computer Science, Artificial Intelligence; Robotics; Neurosciences
SC Computer Science; Robotics; Neurosciences & Neurology
GA GN1LQ
UT WOS:000438752500001
PM 30061820
OA DOAJ Gold
DA 2019-02-18
ER

PT J
AU Sandini, G
   Mohan, V
   Sciutti, A
   Morasso, P
AF Sandini, Giulio
   Mohan, Vishwanathan
   Sciutti, Alessandra
   Morasso, Pietro
TI Social Cognition for Human-Robot Symbiosis-Challenges and Building
   Blocks
SO FRONTIERS IN NEUROROBOTICS
LA English
DT Review
DE cognitive architecture; social interaction; human robot symbiosis;
   memory system; internal model; cognitive robotics; imitation; lifelong
   learning
ID MOTOR-CONTROL; EPISODIC MEMORY; COMPUTATIONAL FRAMEWORK; EMBODIED
   SIMULATION; BODY SCHEMA; HUMAN BRAIN; REPRESENTATION; PERCEPTION; MODEL;
   MECHANISMS
AB The next generation of robot companions or robot working partners will need to satisfy social requirements somehow similar to the famous laws of robotics envisaged by Isaac Asimov time ago (Asimov, 1942). The necessary technology has almost reached the required level, including sensors and actuators, but the cognitive organization is still in its infancy and is only partially supported by the current understanding of brain cognitive processes. The brain of symbiotic robots will certainly not be a "positronic" replica of the human brain: probably, the greatest part of it will be a set of interacting computational processes running in the cloud. In this article, we review the challenges that must be met in the design of a set of interacting computational processes as building blocks of a cognitive architecture that may give symbiotic capabilities to collaborative robots of the next decades: (1) an animated body-schema; (2) an imitation machinery; (3) a motor intentions machinery; (4) a set of physical interaction mechanisms; and (5) a shared memory system for incremental symbiotic development. We would like to stress that our approach is totally un-hierarchical: the five building blocks of the shared cognitive architecture are fully bi-directionally connected. For example, imitation and intentional processes require the "services" of the animated body schema which, on the other hand, can run its simulations if appropriately prompted by imitation and/or intention, with or without physical interaction. Successful experiences can leave a trace in the shared memory system and chunks of memory fragment may compete to participate to novel cooperative actions. And so on and so forth. At the heart of the system is lifelong training and learning but, different from the conventional learning paradigms in neural networks, where learning is somehow passively imposed by an external agent, in symbiotic robots there is an element of free choice of what is worth learning, driven by the interaction between the robot and the human partner. The proposed set of building blocks is certainly a rough approximation of what is needed by symbiotic robots but we believe it is a useful starting point for building a computational framework.
C1 [Sandini, Giulio; Sciutti, Alessandra; Morasso, Pietro] Ist Italiano Tecnol, Res Unit Robot Brain & Cognit Sci RBCS, Genoa, Italy.
   [Mohan, Vishwanathan] Univ Essex, Sch Comp Sci & Elect Engn, Colchester, Essex, England.
RP Sandini, G (reprint author), Ist Italiano Tecnol, Res Unit Robot Brain & Cognit Sci RBCS, Genoa, Italy.
EM giulio.sandini@iit.it
CR Addis DR, 2011, HIPPOCAMPUS, V21, P1045, DOI 10.1002/hipo.20870
   Akshay N, 2013, IEEE IND ELEC, P6108, DOI 10.1109/IECON.2013.6700139
   Anderson JR, 1996, AM PSYCHOL, V51, P355, DOI 10.1037/0003-066X.51.4.355
   Arel I, 2010, IEEE COMPUT INTELL M, V5, P13, DOI 10.1109/MCI.2010.938364
   Asai Y, 2009, PLOS ONE, V4, DOI 10.1371/journal.pone.0006169
   ASATRYAN D. G., 1965, BIOFIZIKA, V10, P837
   Asimov I, 1942, RUNAROUND ASTOUNDING
   Benoit RG, 2015, NEUROPSYCHOLOGIA, V75, P450, DOI 10.1016/j.neuropsychologia.2015.06.034
   Bernstein N., 1967, COORDINATION REGULAT
   Bernstein N., 1935, ARCH BIOL SCI, V38, P15
   Bhat AA, 2017, AUTON ROBOT, V41, P945, DOI 10.1007/s10514-016-9563-3
   Bisio A, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0106172
   BIZZI E, 1976, J NEUROPHYSIOL, V39, P435
   Bottaro A, 2005, HUM MOVEMENT SCI, V24, P588, DOI 10.1016/j.humov.2005.07.006
   Bottaro A, 2008, HUM MOVEMENT SCI, V27, P473, DOI 10.1016/j.humov.2007.11.005
   Breazeal C, 2002, TRENDS COGN SCI, V6, P481, DOI 10.1016/S1364-6613(02)02016-8
   Breazeal C, 2009, PHILOS T R SOC B, V364, P3527, DOI 10.1098/rstb.2009.0157
   Bressler SL, 2010, TRENDS COGN SCI, V14, P277, DOI 10.1016/j.tics.2010.04.004
   Brock O., 1997, P INT S ROB RES, P117
   Buckner RL, 2008, ANN NY ACAD SCI, V1124, P1, DOI 10.1196/annals.1440.011
   Buckner RL, 2007, TRENDS COGN SCI, V11, P49, DOI 10.1016/j.tics.2006.11.004
   Busch B, 2017, INT J SOC ROBOT, V9, P765, DOI 10.1007/s12369-017-0400-4
   Casile A, 2010, CEREB CORTEX, V20, P1647, DOI 10.1093/cercor/bhp229
   Chakravarthy VS, 2003, PATTERN RECOGN LETT, V24, P1901, DOI 10.1016/S0167-8655(03)00017-5
   Chaminade T, 2008, BRAIN RES BULL, V75, P775, DOI 10.1016/j.brainresbull.2008.01.016
   Churchland MM, 2007, J NEUROPHYSIOL, V97, P4235, DOI 10.1152/jn.00095.2007
   Clark Andy., 2016, SURFING UNCERTAINTY
   CLARK J, 1995, INTRO PHONETICS PHON
   de Gelder B, 2006, NAT REV NEUROSCI, V7, P242, DOI 10.1038/nrn1872
   De Jorio Andrea, 1832, MIMICA ANTICHI INVES
   Di Cesare G, 2018, CEREB CORTEX, V28, P1348, DOI 10.1093/cercor/bhx051
   Donoso M, 2014, SCIENCE, V344, P1481, DOI 10.1126/science.1252254
   Dragan A, 2014, AUTON ROBOT, V37, P351, DOI 10.1007/s10514-014-9408-x
   Dragan AD, 2013, INT J ROBOT RES, V32, P790, DOI 10.1177/0278364913490324
   Duffy B. R., 2008, OPEN ARTIFICIAL INTE, V2, P21, DOI DOI 10.2174/1874061800802010021
   Durantin G, 2017, FRONT ROBOT AI, V4, DOI 10.3389/frobt.2017.00024
   Eichenbaum H, 2014, NAT REV NEUROSCI, V15, P732, DOI 10.1038/nrn3827
   Ellwood CA, 1901, AM J SOCIOL, V6, P721, DOI 10.1086/211015
   Erden MS, 2010, IEEE T ROBOT, V26, P370, DOI 10.1109/TRO.2010.2040202
   Fitzpatrick P., 2014, J SOFTWARE ENG ROBOT, V5, P42
   Fitzpatrick P, 2008, ROBOT AUTON SYST, V56, P29, DOI 10.1016/j.robot.2007.09.014
   Franklin DW, 2011, NEURON, V72, P425, DOI 10.1016/j.neuron.2011.10.006
   Friston K, 2011, NEURON, V72, P488, DOI 10.1016/j.neuron.2011.10.018
   Gallese V, 2011, TRENDS COGN SCI, V15, P512, DOI 10.1016/j.tics.2011.09.003
   Gallivan JP, 2011, J NEUROSCI, V31, P9599, DOI 10.1523/JNEUROSCI.0080-11.2011
   Ganesh G, 2014, SCI REP-UK, V4, DOI 10.1038/srep03824
   Gawthrop P, 2011, BIOL CYBERN, V104, P31, DOI 10.1007/s00422-010-0416-4
   Gentry S., 2003, P IEEE INT C SYST MA, P8
   Grafton ST, 2009, ANN NY ACAD SCI, V1156, P97, DOI 10.1111/j.1749-6632.2009.04425.x
   Groten R, 2013, IEEE T HAPTICS, V6, P94, DOI [10.1109/ToH.2012.2, 10.1109/TOH.2012.2]
   Grush R, 2004, BEHAV BRAIN SCI, V27, P377
   Haggard P, 2005, HIGHER ORDER MOTOR D, P261
   HARNAD S, 1990, PHYSICA D, V42, P335, DOI 10.1016/0167-2789(90)90087-6
   Haufe S, 2011, J NEURAL ENG, V8, DOI 10.1088/1741-2560/8/5/056001
   Herbort O, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00494
   Hermann M., 2016, P 49 IEEE HAW INT C, P3982
   Hersch M, 2008, INT J HUM ROBOT, V5, P161, DOI 10.1142/S0219843608001376
   Hesslow G, 2012, BRAIN RES, V1428, P71, DOI 10.1016/j.brainres.2011.06.026
   Hickok G., 2014, MYTH MIRROR NEURONS
   Hopfield J. J., 2008, NEURAL COMPUT, V20, P512, DOI DOI 10.1162/NEC0.2007.09-06-345
   Iacoboni M, 1999, SCIENCE, V286, P2526, DOI 10.1126/science.286.5449.2526
   Iriki A, 2008, PHILOS T R SOC B, V363, P2229, DOI 10.1098/rstb.2008.2274
   IVALDI FAM, 1988, BIOL CYBERN, V60, P1
   Jacob P, 2005, TRENDS COGN SCI, V9, P21, DOI 10.1016/j.tics.2004.11.003
   Jeannerod M, 2001, NEUROIMAGE, V14, pS103, DOI 10.1006/nimg.2001.0832
   Jordan MI, 2015, SCIENCE, V349, P255, DOI 10.1126/science.aaa8415
   Kendon Adam, 2000, GESTURE NAPLES GESTU
   Khatib O, 1999, INT J ROBOT RES, V18, P684, DOI 10.1177/02783649922066501
   Kilner JM, 2011, TRENDS COGN SCI, V15, P352, DOI 10.1016/j.tics.2011.06.005
   Knoblich G, 2006, CURR DIR PSYCHOL SCI, V15, P99, DOI 10.1111/j.0963-7214.2006.00415.x
   Kumova B. I., 2017, P IEEE INT ART INT D, P1
   Laird JE, 2012, SOAR COGNITIVE ARCHITECTURE, P1
   Laird JE, 2017, AI MAG, V38, P13
   Lashley KS, 1933, PHYSIOL REV, V13, P0001
   Licklider J.C.R., 1960, Institute of Radio Engineers Transactions on Human Factors in Electronics, VHFE-1, P4, DOI 10.1109/THFE2.1960.4503259
   Liepmann H., 1908, DREI AUFSATZE APRAXI
   Lieto A, 2018, COGN SYST RES, V48, P1, DOI 10.1016/j.cogsys.2017.08.003
   Maravita A, 2004, TRENDS COGN SCI, V8, P79, DOI 10.1016/j.tics.2003.12.008
   Martin A., 2009, COGNITIVE NEUROSCIEN, P1031
   Martin A, 2016, PSYCHON B REV, V23, P979, DOI 10.3758/s13423-015-0842-3
   Masumoto J, 2013, J NEUROPHYSIOL, V109, P1307, DOI 10.1152/jn.00776.2012
   Mavridis N, 2015, ROBOT AUTON SYST, V63, P22, DOI 10.1016/j.robot.2014.09.031
   MCNEILL D, 1993, DISCOURSE PROCESS, V16, P363, DOI 10.1080/01638539309544845
   McNeill D., 2005, IMAGERY LANGUAGE GES
   Metta G., 2006, International Journal of Advanced Robotic Systems, V3, P43
   Metta G, 2010, NEURAL NETWORKS, V23, P1125, DOI 10.1016/j.neunet.2010.08.010
   Michalski RSE, 1984, MACHINE LEARNING ART
   Mireles EJA, 2017, IEEE T NEUR SYS REH, V25, P832, DOI 10.1109/TNSRE.2017.2700839
   Mohan V, 2009, AUTON ROBOT, V27, P291, DOI 10.1007/s10514-009-9127-x
   Mohan V, 2007, INT J NEURAL SYST, V17, P329, DOI 10.1142/S0129065707001172
   Mohan Vishwanathan, 2018, Phys Life Rev, DOI 10.1016/j.plrev.2018.04.005
   Mohan V, 2014, NEURAL COMPUT, V26, P2692, DOI 10.1162/NECO_a_00664
   Mohan V, 2013, COGN COMPUT, V5, P355, DOI 10.1007/s12559-013-9205-4
   Mohan Vishwanathan, 2011, Front Neurorobot, V5, P4, DOI 10.3389/fnbot.2011.00004
   Mohan V, 2011, AUTON ROBOT, V31, P21, DOI 10.1007/s10514-011-9229-0
   MORASSO P, 1982, BIOL CYBERN, V45, P131, DOI 10.1007/BF00335240
   MORASSO P, 1992, HUM MOVEMENT SCI, V11, P169, DOI 10.1016/0167-9457(92)90058-J
   Morasso P., 1995, J MOTOR BEHAV, V26, P131, DOI [10.1080/00222895.1995.9941699, DOI 10.1080/00222895.1995.9941699]
   Morasso P, 2015, FRONT HUM NEUROSCI, V9, DOI 10.3389/fnhum.2015.00083
   Morasso P, 2010, BIOL CYBERN, V102, P45, DOI 10.1007/s00422-009-0349-y
   Newell Allen, 1990, UNIFIED THEORIES COG
   O'Shea H, 2017, FRONT HUM NEUROSCI, V11, DOI 10.3389/fnhum.2017.00072
   Oguz S Ozgur, 2010, 2010 IEEE Haptics Symposium (Formerly known as Symposium on Haptic Interfaces for Virtual Environment and Teleoperator Systems), P371, DOI 10.1109/HAPTIC.2010.5444628
   Oztop E, 2006, NEURAL NETWORKS, V19, P254, DOI 10.1016/j.neunet.2006.02.002
   Pacherie E, 2000, MIND LANG, V15, P400
   Palinko O, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P5048, DOI 10.1109/IROS.2016.7759741
   Passenberg C, 2013, IEEE T HAPTICS, V6, P440, DOI [10.1109/TOH.2013.34, 10.1109/ToH.2013.34]
   Patterson K, 2007, NAT REV NEUROSCI, V8, P976, DOI 10.1038/nrn2277
   Pfeifer R., 2006, BODY SHAPES WAY WE T
   Pfeifer R., 2008, HDB COGNITIVE SCI EM, P121
   Pickering MJ, 2014, TRENDS COGN SCI, V18, P451, DOI 10.1016/j.tics.2014.05.006
   Ptak R, 2017, TRENDS COGN SCI, V21, P589, DOI 10.1016/j.tics.2017.05.002
   Quigley M., 2007, AAAI 2007 ROB WORKSH, P22
   Quigley M., 2009, P ICRA WORKSH OP SOU, V3, P1
   Quinlan S., 1993, Proceedings IEEE International Conference on Robotics and Automation (Cat. No.93CH3247-4), P802, DOI 10.1109/ROBOT.1993.291936
   Raichle ME, 2001, P NATL ACAD SCI USA, V98, P676, DOI 10.1073/pnas.98.2.676
   Reed K, 2006, PSYCHOL SCI, V17, P365, DOI 10.1111/j.1467-9280.2006.01712.x
   Reed KB, 2008, IEEE T HAPTICS, V1, P108, DOI 10.1109/ToH.2008.13
   Rizzolatti G, 2004, ANNU REV NEUROSCI, V27, P169, DOI 10.1146/annurev.neuro.27.070203.144230
   Rizzolatti G, 2015, AM J PSYCHOL, V128, P527, DOI 10.5406/amerjpsyc.128.4.0527
   Rizzolatti G, 2014, PHILOS T R SOC B, V369, DOI 10.1098/rstb.2013.0420
   Rizzolatti G, 2010, NAT REV NEUROSCI, V11, P264, DOI 10.1038/nrn2805
   Ruhland K, 2015, COMPUT GRAPH FORUM, V34, P299, DOI 10.1111/cgf.12603
   Sandini G, 2018, PHYS LIFE REV, V24, P107, DOI 10.1016/j.plrev.2018.01.004
   Saxe R, 2003, NEUROIMAGE, V19, P1835, DOI 10.1016/S1053-8119(03)00230-1
   Schacter DL, 2016, MEM STUD, V9, P245, DOI 10.1177/1750698016645230
   Sciutti A, 2018, IEEE TECHNOL SOC MAG, V37, P22, DOI 10.1109/MTS.2018.2795095
   Sciutti A, 2017, IEEE T NEUR SYS REH, V25, P2295, DOI 10.1109/TNSRE.2017.2753879
   Sciutti A, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.01362
   Sciutti A, 2013, INTERACT STUD, V14, P329, DOI 10.1075/is.14.3.02sci
   Sciutti A, 2014, IEEE T AUTON MENT DE, V6, P80, DOI 10.1109/TAMD.2014.2312399
   Sciutti A, 2012, INT J SOC ROBOT, V4, P223, DOI 10.1007/s12369-012-0143-1
   SHADMEHR R, 1994, J NEUROSCI, V14, P3208
   Sisbot EA, 2012, IEEE T ROBOT, V28, P1045, DOI 10.1109/TRO.2012.2196303
   Steele M, 2001, HUMAN FACTORS ERGONO, V45, P1671, DOI DOI 10.1177/154193120104502323
   Sturm J, 2009, J PHYSIOL-PARIS, V103, P220, DOI 10.1016/j.jphysparis.2009.08.005
   Suddendorf T, 2013, TRENDS COGN SCI, V17, P151, DOI 10.1016/j.tics.2013.01.011
   Tenorth M, 2013, IEEE T AUTOM SCI ENG, V10, P643, DOI 10.1109/TASE.2013.2244883
   Tenorth M, 2012, IEEE INT C INT ROBOT, P1351, DOI 10.1109/IROS.2012.6385529
   Tsuji T, 2002, IEEE T SYST MAN CY C, V32, P426, DOI 10.1109/TSMCC.2002.807273
   Umilta MA, 2008, P NATL ACAD SCI USA, V105, P2209, DOI 10.1073/pnas.0705985105
   Vallverdu J, 2016, ADAPT BEHAV, V24, P320, DOI 10.1177/1059712316668238
   van der Wel RPRD, 2011, J EXP PSYCHOL HUMAN, V37, P1420, DOI 10.1037/a0022337
   Vanderelst D, 2018, COGN SYST RES, V48, P56, DOI 10.1016/j.cogsys.2017.04.002
   Vernon D, 2015, FRONT ROBOT AI, V2, P19, DOI [10.3389/frobt.2015.00019, DOI 10.3389/FROBT.2015.00019]
   Vernon D, 2016, BIOL INSPIR COGN ARC, V18, P116, DOI 10.1016/j.bica.2016.10.004
   Vernon D, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.01660
   Vignolo A, 2017, FRONT ROBOT AI, V4, DOI 10.3389/frobt.2017.00014
   Vygotsky L. S., 1978, MIND SOC DEV HIGHER
   Waibel M, 2011, IEEE ROBOT AUTOM MAG, V18, P69, DOI 10.1109/MRA.2011.941632
   Wang HB, 2012, IEEE T HAPTICS, V5, P264, DOI 10.1109/TOH.2012.36
   Welberg L., 2012, NATURE REV NEUROSCIE, V11, P223, DOI [10.1038/nrn3224, DOI 10.1038/NRN3224]
   Wiese E, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.01663
   Wilson M, 2002, PSYCHON B REV, V9, P625, DOI 10.3758/BF03196322
   Wolpert DM, 2003, PHILOS T R SOC B, V358, P593, DOI 10.1098/rstb.2002.1238
   Wu W, 2006, EXP BRAIN RES, V175, P197, DOI 10.1007/s00221-006-0556-x
   ZAK M, 1988, PHYS LETT A, V133, P18, DOI 10.1016/0375-9601(88)90728-1
   Zeithamova D, 2012, NEURON, V75, P168, DOI 10.1016/j.neuron.2012.05.010
NR 158
TC 0
Z9 0
U1 7
U2 7
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1662-5218
J9 FRONT NEUROROBOTICS
JI Front. Neurorobotics
PD JUL 11
PY 2018
VL 12
AR 34
DI 10.3389/fnbot.2018.00034
PG 19
WC Computer Science, Artificial Intelligence; Robotics; Neurosciences
SC Computer Science; Robotics; Neurosciences & Neurology
GA GM6QD
UT WOS:000438295700001
PM 30050425
OA DOAJ Gold
DA 2019-02-18
ER

PT J
AU Bing, ZS
   Meschede, C
   Rohrbein, F
   Huang, K
   Knoll, AC
AF Bing, Zhenshan
   Meschede, Claus
   Roehrbein, Florian
   Huang, Kai
   Knoll, Alois C.
TI A Survey of Robotics Control Based on Learning-Inspired Spiking Neural
   Networks
SO FRONTIERS IN NEUROROBOTICS
LA English
DT Review
DE spiking neural network; brain-inspired robotics; neurorobotics; learning
   control; survey
ID DEPENDENT SYNAPTIC PLASTICITY; MOBILE ROBOTS; COMPUTATIONAL MODEL;
   FEATURE-EXTRACTION; AUTONOMOUS ROBOTS; NEURONS; SPARSE; SYSTEM; BRAIN;
   RECOGNITION
AB Biological intelligence processes information using impulses or spikes, which makes those living creatures able to perceive and act in the real world exceptionally well and outperform state-of-the-art robots in almost every aspect of life. To make up the deficit, emerging hardware technologies and software knowledge in the fields of neuroscience, electronics, and computer science have made it possible to design biologically realistic robots controlled by spiking neural networks (SNNs), inspired by the mechanism of brains. However, a comprehensive review on controlling robots based on SNNs is still missing. In this paper, we survey the developments of the past decade in the field of spiking neural networks for control tasks, with particular focus on the fast emerging robotics-related applications. We first highlight the primary impetuses of SNN-based robotics tasks in terms of speed, energy efficiency, and computation capabilities. We then classify those SNN-based robotic applications according to different learning rules and explicate those learning rules with their corresponding robotic applications. We also briefly present some existing platforms that offer an interaction between SNNs and robotics simulations for exploration and exploitation. Finally, we conclude our survey with a forecast of future challenges and some associated potential research topics in terms of controlling robots based on SNNs.
C1 [Bing, Zhenshan; Meschede, Claus; Roehrbein, Florian; Knoll, Alois C.] Tech Univ Munich, Dept Informat, Chair Robot Artificial Intelligence & Real Time S, Munich, Germany.
   [Huang, Kai] Sun Yat Sen Univ, Dept Data & Comp Sci, Guangzhou, Guangdong, Peoples R China.
RP Bing, ZS (reprint author), Tech Univ Munich, Dept Informat, Chair Robot Artificial Intelligence & Real Time S, Munich, Germany.
EM bing@in.tum.de
FU European Union [720270]; Chinese Scholarship Council; German Research
   Foundation (DFG); Technical University of Munich (TUM)
FX The research leading to these results has received funding from the
   European Union Research and Innovation Programme Horizon 2020
   (H2020/2014-2020) under grant agreement No. 720270 (The Human Brain
   Project, HBP) and the Chinese Scholarship Council. Meanwhile it was also
   supported by the German Research Foundation (DFG) and the Technical
   University of Munich (TUM) in the framework of the Open Access
   Publishing Program.
CR Adrian ED, 1926, J PHYSIOL-LONDON, V61, P49, DOI 10.1113/jphysiol.1926.sp002273
   Allaire JJ, 2016, TENSORFLOW R INTERFA
   Allard J, 2007, STUD HEALTH TECHNOL, V125, P13
   Alnajjar F, 2006, PROCEEDINGS OF THE 3RD INTERNATIONAL SYMPOSIUM ON AUTONOMOUS MINIROBOTS FOR RESEARCH AND EDUTAINMENT (AMIRE 2005), P255, DOI 10.1007/3-540-29344-2_38
   Ambrosano A., 2016, BIOM BIOH SYST 5 INT
   American Association for the Advancement of Science, 2016, SCIENCE, V354, P1445, DOI [10.1126/science.354.6318.1445-b, DOI 10.1126/SCIENCE.354.6318.1445-B]
   Andrew A. M., 2003, KYBERNETES, V32, DOI [10. 1108/k. 2003. 06732gae. 003, DOI 10.1108/K.2003.06732GAE.003]
   Arena E, 2017, FRONT NEUROROBOTICS, V11, DOI 10.3389/fnbot.2017.00012
   Arena P., 2009, SPIE C SERIES
   Arena P., 2010, NEURAL NETWORKS IJCN, P1
   Arena P, 2009, IEEE T NEURAL NETWOR, V20, P202, DOI 10.1109/TNN.2008.2005134
   Batllori R, 2011, PROCEDIA COMPUT SCI, V6, DOI 10.1016/j.procs.2011.08.060
   Bekolay T, 2014, FRONT NEUROINFORM, V7, DOI 10.3389/fninf.2013.00048
   Benjamin B, 2014, P IEEE, V102, P699, DOI 10.1109/JPROC.2014.2313565
   Bi GQ, 1998, J NEUROSCI, V18, P10464
   Bing ZS, 2017, BIOINSPIR BIOMIM, V12, P1, DOI 10.1088/1748-3190/aa644c
   Bishop C. M., 1995, NEURAL NETWORKS PATT
   Bohte SM, 2002, IEEE T NEURAL NETWOR, V13, P426, DOI 10.1109/72.991428
   Bouganis A., 2010, P IJCNN, P1
   Braitenberg V., 1978, Theoretical approaches to complex systems, P171
   Brette R, 2007, J COMPUT NEUROSCI, V23, P349, DOI 10.1007/s10827-007-0038-6
   Burgsteiner H., 2005, P 9 INT C ENG APPL N, P129
   Burkitt AN, 2006, BIOL CYBERN, V95, P1, DOI 10.1007/s00422-006-0068-6
   Carey MR, 2005, NAT NEUROSCI, V8, P813, DOI 10.1038/nn1470
   Carrillo RR, 2008, BIOSYSTEMS, V94, P18, DOI 10.1016/j.biosystems.2008.05.008
   Casellato C, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0112265
   Cassidy Andrew, 2006, 2006 IEEE Biomedical Circuits and Systems Conference - Healthcare Technology (BioCas), P45, DOI 10.1109/BIOCAS.2006.4600304
   Cateau H, 2003, NEURAL COMPUT, V15, P597, DOI 10.1162/089976603321192095
   Chadderdon GL, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0047251
   Cheung K, 2016, FRONT NEUROSCI-SWITZ, V9, DOI 10.3389/fnins.2015.00516
   Chou TS, 2015, FRONT NEUROROBOTICS, V9, DOI 10.3389/fnbot.2015.00006
   CHUN MM, 1995, J EXP PSYCHOL HUMAN, V21, P109
   Clawson TS, 2016, IEEE DECIS CONTR P, P3381, DOI 10.1109/CDC.2016.7798778
   Cofer D, 2010, J NEUROSCI METH, V187, P280, DOI 10.1016/j.jneumeth.2010.01.005
   Collobert  Ronan, 2011, BIGLEARN NIPS WORKSH
   Cyr A, 2015, J ROBOT, DOI 10.1155/2015/643869
   Cyr A, 2014, FRONT NEUROROBOTICS, V8, P1, DOI 10.3389/fnbot.2014.00021
   Cyr A, 2012, ADAPT BEHAV, V20, P257, DOI 10.1177/1059712312442231
   DasGupta B., 1992, NIPS, P615
   Diehl PU, 2015, FRONT COMPUT NEUROSC, V9, DOI 10.3389/fncom.2015.00099
   Dong YP, 2009, 2009 IEEE 8TH INTERNATIONAL CONFERENCE ON ASIC, VOLS 1 AND 2, PROCEEDINGS, P891, DOI 10.1109/ASICON.2009.5351550
   Drubach D., 2000, THE BRAIN EXPLAINED
   Dumesnil E, 2016, 2016 IEEE 15TH INTERNATIONAL CONFERENCE ON COGNITIVE INFORMATICS & COGNITIVE COMPUTING (ICCI*CC), P322, DOI 10.1109/ICCI-CC.2016.7862055
   Dumesnil E, 2016, IEEE IJCNN, P5241, DOI 10.1109/IJCNN.2016.7727892
   Dura-Bernal S, 2015, FRONT NEUROROBOTICS, V9, DOI 10.3389/fnbot.2015.00013
   Eliasmith C, 2012, SCIENCE, V338, P1202, DOI 10.1126/science.1225266
   Evans R., 2012, ARXIV150206096
   Evans R., 2015, ARXIV150206096
   Faghihi F, 2017, NEURAL NETWORKS, V87, P96, DOI 10.1016/j.neunet.2016.11.002
   Falotico E, 2017, FRONT NEUROROBOTICS, V11, DOI 10.3389/fnbot.2017.00002
   FERSTER D, 1995, SCIENCE, V270, P756, DOI 10.1126/science.270.5237.756
   Fiasche M., 2015, ADV NEURAL NETWORKS, V37
   Floreano D., 2001, LECT NOTES COMPUTER, V2217
   Floreano D, 2006, INT J INTELL SYST, V21, P1005, DOI 10.1002/int.20173
   Florian RV, 2007, NEURAL COMPUT, V19, P1468, DOI 10.1162/neco.2007.19.6.1468
   Foderaro G, 2010, IEEE DECIS CONTR P, P911, DOI 10.1109/CDC.2010.5717260
   Fremaux N, 2013, PLOS COMPUT BIOL, V9, DOI 10.1371/journal.pcbi.1003024
   Friedrich J, 2016, J NEUROSCI, V36, P1529, DOI 10.1523/JNEUROSCI.2854-15.2016
   Furber SB, 2014, P IEEE, V102, P652, DOI 10.1109/JPROC.2014.2304638
   Furber SB, 2013, IEEE T COMPUT, V62, P2454, DOI 10.1109/TC.2012.142
   Gabbiani F, 1996, NATURE, V384, P564, DOI 10.1038/384564a0
   Gamez D, 2012, BIOINSPIR BIOMIM, V7, DOI 10.1088/1748-3182/7/2/025008
   GERSTNER W, 1993, BIOL CYBERN, V69, P503, DOI 10.1007/BF00199450
   Gerstner W, 2002, BIOL CYBERN, V87, P404, DOI 10.1007/s00422-002-0353-y
   Gerstner W, 1996, NATURE, V383, P76, DOI 10.1038/383076a0
   Gerstner W., 1999, PULSED NEURAL NETWOR, P353
   Ghosh-Dastidar S, 2009, INT J NEURAL SYST, V19, P295, DOI 10.1142/S0129065709002002
   Gong CH, 2016, INT J ROBOT RES, V35, P100, DOI 10.1177/0278364915593793
   Goodman DFM, 2009, FRONT NEUROSCI-SWITZ, V3, P192, DOI 10.3389/neuro.01.026.2009
   Gruning A., 2014, ESANN BRUGES
   Gspandl S, 2012, IEEE INT CONF ROBOT, P2992, DOI 10.1109/ICRA.2012.6225078
   Gutig R, 2006, NAT NEUROSCI, V9, P420, DOI 10.1038/nn1643
   Guyonneau R, 2004, J PHYSIOL-PARIS, V98, P487, DOI 10.1016/j.jphysparis.2005.09.004
   Hagras H, 2004, IEEE INT CONF ROBOT, P4620, DOI 10.1109/ROBOT.2004.1302446
   Han J, 1995, LECT NOTES COMPUT SC, V930, P195
   Harris A, 2011, IEEE SOUTHEASTCON, P243, DOI 10.1109/SECON.2011.5752942
   Hasselmo ME, 1999, TRENDS COGN SCI, V3, P351, DOI 10.1016/S1364-6613(99)01365-0
   Hastie T., 2001, SPRINGER SERIES STAT
   Hebb D. O, 1949, ORG BEHAV NEUROPSYCH
   Hecht -Nielsen R., 1992, NEURAL NETWORKS PERC, P65, DOI DOI 10.1016/B978-0-12-741252-8.50002-9
   Helgadottir LI, 2013, I IEEE EMBS C NEUR E, P891, DOI 10.1109/NER.2013.6696078
   Herculano-Houzel S, 2014, FRONT NEUROANAT, V8, DOI 10.3389/fnana.2014.00046
   Herculano-Houzel S, 2012, P NATL ACAD SCI USA, V109, P10661, DOI 10.1073/pnas.1201895109
   Hinton G. E, 1999, UNSUPERVISED LEARNIN
   HODGKIN AL, 1952, J PHYSIOL-LONDON, V117, P500, DOI 10.1113/jphysiol.1952.sp004764
   HOPFIELD JJ, 1982, P NATL ACAD SCI-BIOL, V79, P2554, DOI 10.1073/pnas.79.8.2554
   HOPFIELD JJ, 1995, NATURE, V376, P33, DOI 10.1038/376033a0
   HORNIK K, 1989, NEURAL NETWORKS, V2, P359, DOI 10.1016/0893-6080(89)90020-8
   Houweling AR, 2008, NATURE, V451, P65, DOI 10.1038/nature06447
   Howard D., 2014, P INT C ART LIF ALIF, P431
   Huber D, 2008, NATURE, V451, P61, DOI 10.1038/nature06445
   Hwu T, 2017, IEEE IJCNN, P635, DOI 10.1109/IJCNN.2017.7965912
   Ijspeert AJ, 2008, NEURAL NETWORKS, V21, P642, DOI 10.1016/j.neunet.2008.03.014
   Ijspeert AJ, 2007, SCIENCE, V315, P1416, DOI 10.1126/science.1138353
   Ivaldi S, 2014, IEEE-RAS INT C HUMAN, P842, DOI 10.1109/HUMANOIDS.2014.7041462
   Iwadate K, 2014, ADV INTELL SYST, V270, P143, DOI 10.1007/978-3-319-05515-2_13
   Izhikevich EM, 2004, IEEE T NEURAL NETWOR, V15, P1063, DOI 10.1109/TNN.2004.832719
   Izhikevich EM, 2007, CEREB CORTEX, V17, P2443, DOI 10.1093/cercor/bhl152
   Jimenez-Romero C., 2016, P 9 EAI INT C BIOINS, P197
   Jimenez-Romero C., 2015, ARXIV150708467
   Jimenez-Romero C., 2017, THESIS
   Kaiser J, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON SIMULATION, MODELING, AND PROGRAMMING FOR AUTONOMOUS ROBOTS (SIMPAR), P127, DOI 10.1109/SIMPAR.2016.7862386
   Kandel ER, 2000, PRINCIPLES NEURAL SC, V4
   KAWATO M, 1992, BIOL CYBERN, V68, P95, DOI 10.1007/BF00201431
   Kempter R, 1999, PHYS REV E, V59, P4498, DOI 10.1103/PhysRevE.59.4498
   KNUDSEN EI, 1994, J NEUROSCI, V14, P3985
   Kocaturk M, 2015, FRONT NEUROROBOTICS, V9, DOI 10.3389/fnbot.2015.00008
   Koenig N., 2004, 2004 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) (IEEE Cat. No.04CH37566), P2149
   Krogh A., 1995, Advances in Neural Information Processing Systems 7, P231
   Kubat Miroslav, 1999, KNOWL ENG REV, V13, P409
   Kubota N, 2004, IEEE SYS MAN CYBERN, P5783
   Kubota N, 2006, IEEE INT CONF FUZZY, P122, DOI 10.1109/FUZZY.2006.1681704
   Lee CS, 2016, IEEE COMPUT INTELL M, V11, P68, DOI 10.1109/MCI.2016.2572559
   Lee JH, 2016, FRONT NEUROSCI-SWITZ, V10, DOI 10.3389/fnins.2016.00508
   Lei Wang, 2012, Autonomous and Intelligent Systems. Proceedings Third International Conference, AIS 2012, P59, DOI 10.1007/978-3-642-31368-4_8
   Lewis M. A., 2000, Proceedings 2000 ICRA. Millennium Conference. IEEE International Conference on Robotics and Automation. Symposia Proceedings (Cat. No.00CH37065), P494, DOI 10.1109/ROBOT.2000.844103
   Lichtsteiner P, 2008, IEEE J SOLID-ST CIRC, V43, P566, DOI 10.1109/JSSC.2007.914337
   Lillicrap Timothy P., 2015, ARXIV150902971
   Loiselle S, 2005, IEEE IJCNN, P2076
   Maass W, 2001, THEOR COMPUT SCI, V261, P157, DOI 10.1016/S0304-3975(00)00137-7
   Maass W, 1997, NEURAL NETWORKS, V10, P1659, DOI 10.1016/S0893-6080(97)00011-7
   Markowska-Kaczmar U, 2015, SOFT COMPUT, V19, P3465, DOI 10.1007/s00500-014-1515-2
   Markram H, 1997, SCIENCE, V275, P213, DOI 10.1126/science.275.5297.213
   Mazumder P, 2016, INTEGRATION, V54, P109, DOI 10.1016/j.vlsi.2016.01.002
   McCulloch Warren S., 1943, BULL MATH BIOPHYS, V5, P115, DOI 10.1007/BF02478259
   Merolla PA, 2014, SCIENCE, V345, P668, DOI 10.1126/science.1254642
   Meschede C., 2017, THESIS
   Metzner W, 1998, J NEUROSCI, V18, P2283
   Miall RC, 1996, NEURAL NETWORKS, V9, P1265, DOI 10.1016/S0893-6080(96)00035-4
   Michalewicz Z., 1996, GENETIC ALGORITHMS D
   Montgomery J, 2002, BIOL BULL, V203, P238, DOI 10.2307/1543417
   Neymotin SA, 2013, NEURAL COMPUT, V25, P3263, DOI 10.1162/NECO_a_00521
   Nichols E, 2013, IEEE T CYBERNETICS, V43, P115, DOI 10.1109/TSMCB.2012.2200674
   Nichols E, 2010, INT J NEURAL SYST, V20, P501, DOI 10.1142/S0129065710002577
   Pavlov I P, 2003, CONDITIONED REFLEXES
   Perrinet L, 2004, NEUROCOMPUTING, V57, P125, DOI [10.1016/j.neucom.2004.01.010, 10.1016/j.neucom.2003.01.010]
   Ponulak F, 2011, ACTA NEUROBIOL EXP, V71, P409
   Potjans W, 2009, NEURAL COMPUT, V21, P301, DOI 10.1162/neco.2008.08-07-593
   Probst D., 2012, LECT NOTES COMPUTER, V7552
   Qiao H, 2003, IEEE T SYST MAN CY B, V33, P925, DOI 10.1109/TSMCB.2002.804368
   Qiao H, 2016, IEEE T CYBERNETICS, V46, P2335, DOI 10.1109/TCYB.2015.2476706
   Qiao H, 2015, IEEE T CYBERNETICS, V45, P2612, DOI 10.1109/TCYB.2014.2377196
   Qiao H, 2014, IEEE T CYBERNETICS, V44, P1485, DOI 10.1109/TCYB.2013.2287014
   Richter C, 2016, IEEE ROBOT AUTOM MAG, V23, P128, DOI 10.1109/MRA.2016.2535081
   Roberts PD, 1999, J COMPUT NEUROSCI, V7, P235, DOI 10.1023/A:1008910918445
   Rochel O., 2002, 16 EUR C SOL STAT TR, V4
   Rohmer E, 2013, IEEE INT C INT ROBOT, P1321, DOI 10.1109/IROS.2013.6696520
   Rossello J., 2014, C DES CIRC INT CIRC, P1
   Ru D, 2014, 2014 IEEE 14TH INTERNATIONAL CONFERENCE ON NANOTECHNOLOGY (IEEE-NANO), P873, DOI 10.1109/NANO.2014.6968000
   Rubin J, 2001, PHYS REV LETT, V86, P364, DOI 10.1103/PhysRevLett.86.364
   Rueckert E, 2016, SCI REP-UK, V6, DOI 10.1038/srep21142
   Ruf B., 1997, LECT NOTES COMPUTER, V1327
   Sarim M., 2016, ASME 2016 DYN SYST C
   Sarim M, 2016, PROC NAECON IEEE NAT, P241, DOI 10.1109/NAECON.2016.7856805
   Schoettle B., 2014, UMTRI201421
   Schuller I. K., 2015, TECHNICAL REPORT
   Schultz W, 1998, J NEUROPHYSIOL, V80, P1
   Sengupta B, 2014, P IEEE, V102, P738, DOI 10.1109/JPROC.2014.2307755
   Senn W., 1997, LECT NOTES COMPUTER, V1327
   Shen W., 1999, Knowledge and Information Systems, V1, P129
   Shin JH, 2010, IEEE T NEURAL NETWOR, V21, P1697, DOI 10.1109/TNN.2010.2050600
   Silver D, 2016, NATURE, V529, P484, DOI 10.1038/nature16961
   Skorheim S, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0090821
   Song S, 2000, NAT NEUROSCI, V3, P919
   Soula H., 2005, P AAAI SPRING S DEV
   Spuler M., 2015, NEUR NETW IJCNN 2015, P1, DOI [10.1109/IJCNN.2015.7280521, DOI 10.1109/IJCNN.2015.7280521]
   Staranowicz A., 2011, P 4 INT C PERVASIVE, V56
   STEIN RB, 1965, BIOPHYS J, V5, P173, DOI 10.1016/S0006-3495(65)86709-1
   Thach WT, 1996, BEHAV BRAIN SCI, V19, P501, DOI 10.1017/S0140525X00082017
   Theano Development Team, 2016, ABS160502688 ARXIV T
   Thorpe S, 2001, NEURAL NETWORKS, V14, P715, DOI 10.1016/S0893-6080(01)00083-1
   Urbanczik R, 2009, NAT NEUROSCI, V12, P250, DOI 10.1038/nn.2264
   VanRullen R, 2005, TRENDS NEUROSCI, V28, P1, DOI 10.1016/j.tins.2004.10.010
   Vasilaki E, 2009, PLOS COMPUT BIOL, V5, DOI 10.1371/journal.pcbi.1000586
   Voegtlin T., 2011, BMC NEUROSCI, V12, pP363, DOI [10.1186/1471-2202-12-S1-P363, DOI 10.1186/1471-2202-12-S1-P363]
   Vreeken J., 2003, SPIKING NEURAL NETWO
   Wade JJ, 2010, IEEE T NEURAL NETWOR, V21, P1817, DOI 10.1109/TNN.2010.2074212
   Walter F, 2016, NEURAL PROCESS LETT, V44, P103, DOI 10.1007/s11063-015-9478-6
   Walter F, 2015, NEURAL NETWORKS, V72, P152, DOI 10.1016/j.neunet.2015.07.004
   Wang XQ, 2008, NEUROCOMPUTING, V71, P655, DOI 10.1016/j.neucom.2007.08.025
   Wang XQ, 2014, NEUROCOMPUTING, V134, P230, DOI 10.1016/j.neucom.2013.07.055
   Wang XQ, 2009, 2009 INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND COMPUTATIONAL INTELLIGENCE, VOL I, PROCEEDINGS, P194, DOI 10.1109/AICI.2009.448
   Wikipedia, 2017, SYN WIK FREE ENC
   Wikipedia, 2017, OP DYN ENG OD WIK FR
   Wikipedia, 2017, NEUR WIK FREE ENC
   Wikipedia, 2017, CLASS COND WIK FREE
   Wikipedia, 2017, REC NEUR NETW WIK FR
   Wolfe J, 2010, CURR OPIN NEUROBIOL, V20, P306, DOI 10.1016/j.conb.2010.03.006
   Yamazaki T, 2007, NEURAL NETWORKS, V20, P290, DOI 10.1016/j.neunet.2007.04.004
   Yu JZ, 2014, IEEE T NEUR NET LEAR, V25, P441, DOI 10.1109/TNNLS.2013.2280596
   Zhang X, 2013, IEEE DECIS CONTR P, P6798, DOI 10.1109/CDC.2013.6760966
   Zhang X, 2012, ADV ARTIF NEURAL SYS, V2012, P10, DOI DOI 10.1155/2012/713581
NR 192
TC 0
Z9 0
U1 9
U2 11
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1662-5218
J9 FRONT NEUROROBOTICS
JI Front. Neurorobotics
PD JUL 6
PY 2018
VL 12
AR 35
DI 10.3389/fnbot.2018.00035
PG 22
WC Computer Science, Artificial Intelligence; Robotics; Neurosciences
SC Computer Science; Robotics; Neurosciences & Neurology
GA GL9ZZ
UT WOS:000437704700001
PM 30034334
OA DOAJ Gold
DA 2019-02-18
ER

PT J
AU Lazzeri, N
   Mazzei, D
   Ben Moussa, M
   Magnenat-Thalmann, N
   De Rossi, D
AF Lazzeri, Nicole
   Mazzei, Daniele
   Ben Moussa, Maher
   Magnenat-Thalmann, Nadia
   De Rossi, Danilo
TI The influence of dynamics and speech on understanding humanoid facial
   expressions
SO INTERNATIONAL JOURNAL OF ADVANCED ROBOTIC SYSTEMS
LA English
DT Article
DE Human-robot interaction; humanoid robot; facial expression recognition;
   social interaction
ID EMOTIONAL EXPRESSION; FACE; PERCEPTION; RECOGNITION; ROBOTS; MOTION;
   VOCALIZATIONS; INTENSITY; IDENTITY; JAPANESE
AB Human communication relies mostly on nonverbal signals expressed through body language. Facial expressions, in particular, convey emotional information that allows people involved in social interactions to mutually judge the emotional states and to adjust its behavior appropriately. First studies aimed at investigating the recognition of facial expressions were based on static stimuli. However, facial expressions are rarely static, especially in everyday social interactions. Therefore, it has been hypothesized that the dynamics inherent in a facial expression could be fundamental in understanding its meaning. In addition, it has been demonstrated that nonlinguistic and linguistic information can contribute to reinforce the meaning of a facial expression making it easier to be recognized. Nevertheless, few studies have been performed on realistic humanoid robots. This experimental work aimed at demonstrating the human-like expressive capability of a humanoid robot by examining whether the effect of motion and vocal content influenced the perception of its facial expressions. The first part of the experiment aimed at studying the recognition capability of two kinds of stimuli related to the six basic expressions (i.e. anger, disgust, fear, happiness, sadness, and surprise): static stimuli, that is, photographs, and dynamic stimuli, that is, video recordings. The second and third parts were focused on comparing the same six basic expressions performed by a virtual avatar and by a physical robot under three different conditions: (1) muted facial expressions, (2) facial expressions with nonlinguistic vocalizations, and (3) facial expressions with an emotionally neutral verbal sentence. The results show that static stimuli performed by a human being and by the robot were more ambiguous than the corresponding dynamic stimuli on which motion and vocalization were associated. This hypothesis has been also investigated with a 3-dimensional replica of the physical robot demonstrating that even in case of a virtual avatar, dynamic and vocalization improve the emotional conveying capability.
C1 [Lazzeri, Nicole; De Rossi, Danilo] Univ Pisa, Fac Engn, Res Ctr E Piaggio, Pisa, Italy.
   [Mazzei, Daniele] Univ Pisa, Dept Comp Sci, Pisa, Italy.
   [Ben Moussa, Maher] Univ Geneva, Ctr Comp Sci, Geneva, Switzerland.
   [Magnenat-Thalmann, Nadia] Univ Geneva, CUI, MIRALab, Geneva, Switzerland.
RP Lazzeri, N (reprint author), Univ Pisa, Largo Lucio Lazzarino 1, I-56122 Pisa, Italy.
EM n.lazzeri@centropiaggio.unipi.it
FU European research project EASEL (Expressive Agents for Symbiotic
   Education and Learning) [FP7-ICT-611971]; European research project
   CaMe-Li [AAL-2012-5]; European research project Miraculous-Life
   [FP7-ICT-611421]
FX The author(s) disclosed receipt of the following financial support for
   the research, authorship, and/or publication of this article: The
   research has been funded by the European research projects EASEL
   (Expressive Agents for Symbiotic Education and Learning)
   (FP7-ICT-611971), CaMe-Li (AAL-2012-5), and Miraculous-Life
   (FP7-ICT-611421).
CR Adolphs R, 2003, BRAIN COGNITION, V52, P61, DOI 10.1016/S0278-2626(03)00009-5
   Adolphs Ralph, 2002, Behav Cogn Neurosci Rev, V1, P21, DOI 10.1177/1534582302001001003
   Ambadar Z, 2005, PSYCHOL SCI, V16, P403, DOI 10.1111/j.0956-7976.2005.01548.x
   Arellano D, 2008, COMPUT ANIMAT VIRT W, V19, P259, DOI 10.1002/cav.234
   Barrett LF, 2006, PERSPECT PSYCHOL SCI, V1, P28, DOI 10.1111/j.1745-6916.2006.00003.x
   BASSILI JN, 1979, J PERS SOC PSYCHOL, V37, P2049, DOI 10.1037//0022-3514.37.11.2049
   BASSILI JN, 1978, J EXP PSYCHOL HUMAN, V4, P373, DOI 10.1037//0096-1523.4.3.373
   Becker-Asano C., 2011, 2011 IEEE WORKSH AFF, P22, DOI DOI 10.1109/WACI.2011.5953147
   Bell Charles, 1824, ESSAYS ANATOMY PHILO
   Ben Moussa M, 2010, P SUMM SCH ENG ZERM
   Ben Moussa M, 2013, COMPUT ANIMAT VIRT W, V24, P327, DOI 10.1002/cav.1515
   Berns K, 2006, 2006 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-12, P3119, DOI 10.1109/IROS.2006.282331
   Blow M., 2006, 1st Annual Conference on Human-Robot Interaction, P331
   Bould E, 2008, BRIT J PSYCHOL, V99, P167, DOI 10.1348/000712607X206702
   Breazeal C, 2003, INT J HUM-COMPUT ST, V59, P119, DOI 10.1016/S1071-5819(03)00018-1
   BRUCE V, 1986, BRIT J PSYCHOL, V77, P305, DOI 10.1111/j.2044-8295.1986.tb02199.x
   Calvo MG, 2008, BEHAV RES METHODS, V40, P109, DOI 10.3758/BRM.40.1.109
   Christensen HI, 2013, ROADMAP US ROBOTICS
   COHEN J, 1992, PSYCHOL BULL, V112, P155, DOI 10.1037//0033-2909.112.1.155
   Crichton-Browne J, 1895, T J P DUM GALL NATUR, V11, P72
   Crivelli C, 2016, P NATL ACAD SCI USA, V113, P12403, DOI 10.1073/pnas.1611622113
   Cunningham DW, 2009, J VISION, V9, DOI 10.1167/9.13.7
   Darwin C., 1872, EXPRESSION EMOTIONS
   de Gelder B, 2000, COGNITION EMOTION, V14, P289, DOI 10.1080/026999300378824
   de Rosis F, 2003, INT J HUM-COMPUT ST, V59, P81, DOI 10.1016/S1071-5819(03)00020-X
   Dyck M, 2008, PLOS ONE, V3, DOI 10.1371/journal.pone.0003628
   EKMAN P, 1971, J PERS SOC PSYCHOL, V17, P124, DOI 10.1037/h0030377
   EKMAN P, 1992, PSYCHOL REV, V99, P550, DOI 10.1037/0033-295X.99.3.550
   Ekman P, 2005, WHAT FACE REVEALS BA
   Ekman P, 1969, SEMIOTICA, V1, P49
   Ekman  P., 1982, EMOTION HUMAN FACE
   Ekman P., 1976, PICTURES FACIAL AFFE
   Ekman P., 1971, NEBRASKA S MOTIVATIO, P207
   Faita C, 2015, LECT NOTES COMPUT SC, V9254, P409, DOI 10.1007/978-3-319-22888-4_30
   Fiorentini C, 2011, J VISION, V11, DOI 10.1167/11.3.17
   Fong T, 2003, ROBOT AUTON SYST, V42, P143, DOI 10.1016/S0921-8890(02)00372-X
   Fox E, 2000, COGNITION EMOTION, V14, P61, DOI 10.1080/026999300378996
   Frijda N. H., 1987, COGNITION EMOTION, V1, P115, DOI [10. 1080/ 02699938708408043, DOI 10.1080/02699938708408043]
   Garchery S, 2005, P MEAS BEH WAG NETH
   Gockley R., 2006, 1st Annual Conference on Human-Robot Interaction, P186
   Gruneberg M. M., 1988, PRACTICAL ASPECTS ME, V1, P169
   Hanson D, 2004, PROC SPIE, V5385, P29, DOI 10.1117/12.543095
   Hanson D., 2006, P ICCS COGSCI 2006 L, P16
   Hawk ST, 2009, EMOTION, V9, P293, DOI 10.1037/a0015178
   Hegel F, 2006, IEEE-RAS INT C HUMAN, P56, DOI 10.1109/ICHR.2006.321363
   HUMPHREYS GW, 1993, NEUROPSYCHOLOGIA, V31, P173, DOI 10.1016/0028-3932(93)90045-2
   Igor SP, 2003, MPEG 4 FACIAL ANIMAT
   Jack RE, 2014, CURR BIOL, V24, P187, DOI 10.1016/j.cub.2013.11.064
   Juslin PN, 2001, EMOTION, V1, P381, DOI 10.1037//1528-3542.1.4.381
   Kamachi M, 2001, PERCEPTION, V30, P875, DOI 10.1068/p3131
   KIROUAC G, 1984, PERCEPT MOTOR SKILL, V59, P147, DOI 10.2466/pms.1984.59.1.147
   Kshirsagar S, 2001, INT FED INFO PROC, V68, P24
   LaBar KS, 2003, CEREB CORTEX, V13, P1023, DOI 10.1093/cercor/13.10.1023
   LANDIS JR, 1977, BIOMETRICS, V33, P159, DOI 10.2307/2529310
   Lazzeri Nicole, 2015, Front Bioeng Biotechnol, V3, P64, DOI 10.3389/fbioe.2015.00064
   Leppanen JM, 2004, PSYCHOL RES-PSYCH FO, V69, P22, DOI 10.1007/s00426-003-0157-2
   Lima CF, 2013, BEHAV RES METHODS, V45, P1234, DOI 10.3758/s13428-013-0324-3
   Matsumoto D, 2000, J NONVERBAL BEHAV, V24, P179, DOI 10.1023/A:1006668120583
   MATSUMOTO D, 1989, MOTIV EMOTION, V13, P143, DOI 10.1007/BF00992959
   Mazzei D, 2012, P IEEE RAS-EMBS INT, P195
   McQuiggan SW, 2008, CHI 2008: 26TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS VOLS 1 AND 2, CONFERENCE PROCEEDINGS, P1511
   Moors A, 2009, COGNITION EMOTION, V23, P625, DOI 10.1080/02699930802645739
   Mori M., 1970, ENERGY, V7, P33, DOI DOI 10.1109/MRA.2012.2192811
   Mori M, 2012, IEEE ROBOT AUTOM MAG, V19, P98, DOI 10.1109/MRA.2012.2192811
   Mower E, 2008, INT CONF ACOUST SPEE, P2201, DOI 10.1109/ICASSP.2008.4518081
   OriginLab Corporation, 2012, OR
   PAKOSZ M, 1982, LINGUA, V58, P309, DOI 10.1016/0024-3841(82)90038-9
   Pelc M., 2007, AAMAS 08 P 7 INT JOI, V2, P20
   Russell JA, 2009, COGNITION EMOTION, V23, P1259, DOI 10.1080/02699930902809375
   Saldien J, 2010, INT J SOC ROBOT, V2, P377, DOI 10.1007/s12369-010-0067-6
   Sauter DA, 2010, Q J EXP PSYCHOL, V63, P2251, DOI 10.1080/17470211003721642
   Scherer KR, 2009, PHILOS T R SOC B, V364, P3459, DOI 10.1098/rstb.2009.0141
   Scherer KR, 2005, SOC SCI INFORM, V44, P695, DOI 10.1177/0539018405058216
   SCHERER KR, 1991, MOTIV EMOTION, V15, P123, DOI 10.1007/BF00995674
   Scherer KR, 2003, SPEECH COMMUN, V40, P227, DOI 10.1016/S0167-6393(02)00084-5
   Schrober M, 2003, SPEECH COMMUN, V40, P99, DOI 10.1016/S0167-6393(02)00078-X
   Schultz J, 2009, EXP BRAIN RES, V194, P465, DOI 10.1007/s00221-009-1721-9
   Schwaninger A, 2006, PROG BRAIN RES, V156, P321, DOI 10.1016/S0079-6123(06)56018-2
   Shayganfar M, 2012, IEEE INT C INT ROBOT, P4577, DOI 10.1109/IROS.2012.6385901
   Simon-Thomas ER, 2009, EMOTION, V9, P838, DOI 10.1037/a0017810
   Tao H, 1999, IEEE T CIRC SYST VID, V9, P264, DOI 10.1109/76.752094
   Tinwell A., 2014, UNCANNY VALLEY GAMES
   Tinwell A, 2011, INT J ARTS TECHNOL, V4, P326, DOI 10.1504/IJART.2011.041485
   Trovato G, 2013, INT J HUM ROBOT, V10, DOI 10.1142/S0219843613500138
   Wallraven C, 2008, ACM T APPL PERCEPT, V4, DOI 10.1145/1278760.1278764
   Wehrle T, 2000, J PERS SOC PSYCHOL, V78, P105, DOI 10.1037//0022-3514.78.1.105
   Young AW, 1997, COGNITION, V63, P271, DOI 10.1016/S0010-0277(97)00003-6
NR 87
TC 1
Z9 1
U1 5
U2 5
PU SAGE PUBLICATIONS INC
PI THOUSAND OAKS
PA 2455 TELLER RD, THOUSAND OAKS, CA 91320 USA
SN 1729-8814
J9 INT J ADV ROBOT SYST
JI Int. J. Adv. Robot. Syst.
PD JUL 5
PY 2018
VL 15
IS 4
AR 1729881418783158
DI 10.1177/1729881418783158
PG 16
WC Robotics
SC Robotics
GA GM6GS
UT WOS:000438262100001
OA DOAJ Gold
DA 2019-02-18
ER

PT J
AU Mannella, F
   Santucci, VG
   Somogyi, E
   Jacquey, L
   O'Regan, KJ
   Baldassarre, G
AF Mannella, Francesco
   Santucci, Vieri G.
   Somogyi, Eszter
   Jacquey, Lisa
   O'Regan, Kevin J.
   Baldassarre, Gianluca
TI Know Your Body Through Intrinsic Goals
SO FRONTIERS IN NEUROROBOTICS
LA English
DT Article
DE developmental robotics; developmental psychology; intrinsic motivations;
   goals; body
ID TOY-ORIENTED CHANGES; EARLY ARM MOVEMENTS; COMPUTATIONAL MODEL; INVERSE
   KINEMATICS; KNOWLEDGE-GRADIENT; HUMAN INFANTS; SELF; DOPAMINE;
   MOTIVATION; BEHAVIOR
AB The first "object" that newborn children play with is their own body. This activity allows them to autonomously form a sensorimotor map of their own body and a repertoire of actions supporting future cognitive and motor development. Here we propose the theoretical hypothesis, operationalized as a computational model, that this acquisition of body knowledge is not guided by random motor-babbling, but rather by autonomously generated goals formed on the basis of intrinsic motivations. Motor exploration leads the agent to discover and form representations of the possible sensory events it can cause with its own actions. When the agent realizes the possibility of improving the competence to re-activate those representations, it is intrinsically motivated to select and pursue them as goals. The model is based on four components: (1) a self-organizing neural network, modulated by competence-based intrinsic motivations, that acquires abstract representations of experienced sensory (touch) changes; (2) a selector that selects the goal to pursue, and the motor resources to train to pursue it, on the basis of competence improvement; (3) an echo-state neural network that controls and learns, through goal-accomplishment and competence, the agent's motor skills; (4) a predictor of the accomplishment of the selected goals generating the competence-based intrinsic motivation signals. The model is tested as the controller of a simulated simple planar robot composed of a torso and two kinematic 3-DoF 2D arms. The robot explores its body covered by touch sensors by moving its arms. The results, which might be used to guide future empirical experiments, show how the system converges to goals and motor skills allowing it to touch the different parts of own body and how the morphology of the body affects the formed goals. The convergence is strongly dependent on competence-based intrinsic motivations affecting not only skill learning and the selection of formed goals, but also the formation of the goal representations themselves.
C1 [Mannella, Francesco; Santucci, Vieri G.; Baldassarre, Gianluca] Natl Res Council CNR, Inst Cognit Sci & Technol, Rome, Italy.
   [Somogyi, Eszter; Jacquey, Lisa; O'Regan, Kevin J.] Paris Descartes CPSC, Lab Psychol Percept UMR 8242, Paris, France.
RP Mannella, F (reprint author), Natl Res Council CNR, Inst Cognit Sci & Technol, Rome, Italy.
EM francesco.mannella@istc.cnr.it
FU European Union's Horizon 2020 Research and Innovation Program [713010];
   ERC Advanced Grant FEEL [323674]
FX This project has received funding from the European Union's Horizon 2020
   Research and Innovation Program under Grant Agreement no. 713010
   (GOAL-Robots-Goal-based Open-ended Autonomous Learning Robots). KO, ES,
   and LJ were also partially funded by ERC Advanced Grant FEEL, number
   323674.
CR Ali JB, 2015, CURR BIOL, V25, pR978, DOI 10.1016/j.cub.2015.08.055
   Baldassarre G, 2011, P INT C DEV LEARN EP, pE1
   Baldassarre G., 2013, INTRINSICALLY MOTIVA
   Baldassarre G, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00985
   Baldassarre G, 2013, NEURAL NETWORKS, V41, P168, DOI 10.1016/j.neunet.2012.09.015
   Balleine BW, 1998, NEUROPHARMACOLOGY, V37, P407, DOI 10.1016/S0028-3908(98)00033-1
   Baranes A, 2013, ROBOT AUTON SYST, V61, P49, DOI 10.1016/j.robot.2012.05.008
   Barto A. G., 2004, P 3 INT C DEV LEARN, P112
   Barto Andrew, 2013, Front Psychol, V4, P907, DOI 10.3389/fpsyg.2013.00907
   Berlyne DE, 1950, B J PSYCHOL-GEN SECT, V41, P68, DOI 10.1111/j.2044-8295.1950.tb00262.x
   Berlyne D. E, 1960, CONFLICT AROUSAL CUR
   Bhat A, 2006, INFANT BEHAV DEV, V29, P358, DOI 10.1016/j.infbeh.2006.01.005
   Blasco-Alberto J, 1995, HARDWARE ORIENTED MO
   Bremner AJ, 2008, J EXP PSYCHOL GEN, V137, P149, DOI 10.1037/0096-3445.137.1.149
   Caligiore D, 2014, PSYCHOL REV, V121, P389, DOI 10.1037/a0037016
   Chinn L. K., 2017, DEV LEARN EP ROB ICD
   CHIODO LA, 1980, BRAIN RES, V189, P544, DOI 10.1016/0006-8993(80)90366-2
   CLIFTON RK, 1991, J EXP PSYCHOL HUMAN, V17, P323, DOI 10.1037//0096-1523.17.2.323
   Deci E. L., 1985, INTRINSIC MOTIVATION
   DEVRIES JIP, 1982, EARLY HUM DEV, V7, P301, DOI 10.1016/0378-3782(82)90033-0
   Fiore VG, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00124
   Forestier S., 2017, ARXIV170802190
   Frazier PI, 2008, SIAM J CONTROL OPTIM, V47, P2410, DOI 10.1137/070693424
   GLOW PH, 1978, ANIM LEARN BEHAV, V6, P1, DOI 10.3758/BF03211996
   Graziano MSA, 2002, NEURON, V34, P841, DOI 10.1016/S0896-6273(02)00698-0
   HARLOW HF, 1950, J COMP PHYSIOL PSYCH, V43, P289, DOI 10.1037/h0058114
   Hart S, 2011, IEEE T AUTON MENT DE, V3, P216, DOI 10.1109/TAMD.2010.2103311
   Horvitz JC, 2000, NEUROSCIENCE, V96, P651, DOI 10.1016/S0306-4522(00)00019-1
   Hull C. L, 1943, PRINCIPLES BEHAV INT
   Jaeger H, 2001, 48 GMD GER NAT CTR I
   Jaegera H, 2007, NEURAL NETWORKS, V20, P335, DOI 10.1016/j.neunet.2007.04.016
   Kahrs BA, 2013, CHILD DEV, V84, P810, DOI 10.1111/cdev.12000
   KISH GB, 1955, J COMP PHYSIOL PSYCH, V48, P261, DOI 10.1037/h0040782
   Kohonen T, 1998, NEUROCOMPUTING, V21, P1, DOI 10.1016/S0925-2312(98)00030-7
   KOHONEN T, 1982, BIOL CYBERN, V43, P59, DOI 10.1007/BF00337288
   Kompella V. R., 2015, ARTIF INTELL, V247, P313
   Kulkarni T.D., 2016, ADV NEURAL INFORM PR, P3675
   Lee HM, 2008, INFANT BEHAV DEV, V31, P447, DOI 10.1016/j.infbeh.2007.12.018
   Mannella F, 2007, PHILOS T R SOC B, V362, P383, DOI 10.1098/rstb.2006.1966
   Mannella F, 2016, FRONT BEHAV NEUROSCI, V10, DOI 10.3389/fnbeh.2016.00181
   Mannella F, 2015, BIOL CYBERN, V109, P575, DOI 10.1007/s00422-015-0662-6
   Mannella F, 2013, FRONT BEHAV NEUROSCI, V7, DOI 10.3389/fnbeh.2013.00135
   Merrick KE, 2012, IEEE T AUTON MENT DE, V4, P315, DOI 10.1109/TAMD.2012.2208457
   Miller EK, 2001, ANNU REV NEUROSCI, V24, P167, DOI 10.1146/annurev.neuro.24.1.167
   Mirolli M, 2013, NEURAL NETWORKS, V39, P40, DOI 10.1016/j.neunet.2012.12.012
   MONTGOMERY KC, 1954, J COMP PHYSIOL PSYCH, V47, P60, DOI 10.1037/h0054833
   Mori Hiroki, 2010, 2010 IEEE 9th International Conference on Development and Learning (ICDL 2010), P82, DOI 10.1109/DEVLRN.2010.5578860
   Oudeyer P., 2007, IEEE T EVOLUTIONARY, V11, P703
   Oudeyer P.-Y., 2016, 6 JOINT IEEE INT C D
   Oudeyer Pierre-Yves, 2007, Front Neurorobot, V1, P6, DOI 10.3389/neuro.12.006.2007
   Piontelli A, 2014, DEV NORMAL FETAL MOV, DOI [10.1007/978-88-470-5373-1, DOI 10.1007/978-88-470-5373-1]
   Redgrave P, 2006, NAT REV NEUROSCI, V7, P967, DOI 10.1938/nrn2022
   Rochat P, 1997, EARLY DEV PARENTING, V6, P105
   Rochat P, 2000, INFANT BEHAV DEV, V23, P513, DOI 10.1016/S0163-6383(01)00055-8
   Rolf M., 2011, P IEEE INT C DEV LEA, P1, DOI DOI 10.1109/DEVLRN.2011.6037368
   Rolf M, 2014, IEEE T NEUR NET LEAR, V25, P1147, DOI 10.1109/TNNLS.2013.2287890
   Rolf M, 2010, IEEE T AUTON MENT DE, V2, P216, DOI 10.1109/TAMD.2010.2062511
   ROVEECOLLIER CK, 1980, SCIENCE, V208, P1159, DOI 10.1126/science.7375924
   Russell S. J., 2003, ARTIFICIAL INTELLIGE
   Ryan RM, 2000, CONTEMP EDUC PSYCHOL, V25, P54, DOI 10.1006/ceps.1999.1020
   Santucci V. G., 2014, EVOLUTION COMPLEXITY, P107
   Santucci V. G, 2012, DEV LEARN EP ROB ICD, P1, DOI DOI 10.1109/DEVLRN.2012.6400835
   Santucci VG, 2014, FOUTH JOINT IEEE INTERNATIONAL CONFERENCES ON DEVELOPMENT AND LEARNING AND EPIGENETIC ROBOTICS (IEEE ICDL-EPIROB 2014), P434
   Santucci VG, 2013, FRONT NEUROROBOTICS, V7, DOI 10.3389/fnbot.2013.00022
   Santucci VG, 2016, IEEE T COGN DEV SYST, V8, P214, DOI 10.1109/TCDS.2016.2538961
   Schembri M., 2007, P 6 IEEE INT C DEV L, P282
   Schembri M., 2007, P 7 INT C EP ROB EPI, P141
   Schmidhuber J., 1991, P INT C SIM AD BEH A, P222
   Schmidhuber J, 2010, IEEE T AUTON MENT DE, V2, P230, DOI 10.1109/TAMD.2010.2056368
   Scott W, 2011, SIAM J OPTIMIZ, V21, P996, DOI 10.1137/100801275
   Seepanomwan K., 2017, DEV LEARN EP ROB EPI
   Sutton R. S., 1998, REINFORCEMENT LEARNI, V1
   THELEN E, 1995, AM PSYCHOL, V50, P79, DOI 10.1037/0003-066X.50.2.79
   Thill S, 2013, NEUROSCI BIOBEHAV R, V37, P491, DOI 10.1016/j.neubiorev.2013.01.012
   Thomas BL, 2015, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.01526
   Umilta MA, 2001, NEURON, V31, P155, DOI 10.1016/S0896-6273(01)00337-3
   Vigorito CM, 2010, IEEE T AUTON MENT DE, V2, P132, DOI 10.1109/TAMD.2010.2050205
   VONHOFSTEN C, 1991, J MOTOR BEHAV, V23, P280, DOI 10.1080/00222895.1991.9942039
   Wallace PS, 2003, NEUROPSYCHOLOGIA, V41, P1912, DOI 10.1016/S0028-3932(03)00128-3
   WHITE RW, 1959, PSYCHOL REV, V66, P297, DOI 10.1037/h0040934
   Williams JL, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.00587
   Wu J., 2017, ADV NEURAL INFORM PR, P5273
   Zoia S, 2007, EXP BRAIN RES, V176, P217, DOI 10.1007/s00221-006-0607-3
NR 83
TC 0
Z9 0
U1 5
U2 5
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1662-5218
J9 FRONT NEUROROBOTICS
JI Front. Neurorobotics
PD JUL 3
PY 2018
VL 12
AR 30
DI 10.3389/fnbot.2018.00030
PG 17
WC Computer Science, Artificial Intelligence; Robotics; Neurosciences
SC Computer Science; Robotics; Neurosciences & Neurology
GA GL5KO
UT WOS:000437205300001
PM 30018547
OA DOAJ Gold
DA 2019-02-18
ER

PT J
AU Tejera, G
   Llofriu, M
   Barrera, A
   Weitzenfeld, A
AF Tejera, Gonzalo
   Llofriu, Martin
   Barrera, Alejandra
   Weitzenfeld, Alfredo
TI Bio-Inspired Robotics: A Spatial Cognition Model integrating Place
   Cells, Grid Cells and Head Direction Cells
SO JOURNAL OF INTELLIGENT & ROBOTIC SYSTEMS
LA English
DT Article
DE Spatial cognition; Robot navigation; Place cells; Grid cells; Head
   direction cells
ID PATH-INTEGRATION; NETWORK MODEL; WATER-MAZE; HIPPOCAMPAL; RAT; MAP;
   REPRESENTATION; NAVIGATION; CA3; INTERFERENCE
AB The paper presents a bio-inspired robotics model for spatial cognition derived from neurophysiological and experimental studies in rats. The model integrates Hippocampus place cells providing long-term spatial localization with Enthorinal Cortex grid cells providing short-term spatial localization in the form of "neural odometry". Head direction cells provide for orientation in the rat brain. The spatial cognition model is evaluated in simulation and experimentation showing a reduced number of localization errors during robot navigation when contrasted to previous versions of our model.
C1 [Tejera, Gonzalo] Univ Republica, Fac Ingn, Montevideo, Uruguay.
   [Llofriu, Martin; Weitzenfeld, Alfredo] Univ S Florida, Comp Sci & Engn, Tampa, FL 33620 USA.
   [Barrera, Alejandra] Inst Tecnol Autonomo Mexico, Dept Comp, Mexico City, DF, Mexico.
RP Weitzenfeld, A (reprint author), Univ S Florida, Comp Sci & Engn, Tampa, FL 33620 USA.
EM gtejera@fing.edu.uy; mllofriualon@mail.usf.edu; abarrera@itam.mx;
   aweitzenfeld@usf.edu
FU NSF IIS Robust Intelligence research collaboration grant at USF
   [1117303]; Agencia Nacional de Investigacion e Innovacion (ANII);
   Asociacion Mexicana de Cultura, A. C; U. Arizona
FX This work was funded in part by NSF IIS Robust Intelligence research
   collaboration grant #1117303 at USF and U. Arizona entitled
   "Investigations of the Role of Dorsal versus Ventral Place and Grid
   Cells during Multi-Scale Spatial Navigation in Rats and Robots," and
   also supported in part by the "Agencia Nacional de Investigacion e
   Innovacion (ANII)" and by the "Asociacion Mexicana de Cultura, A. C."
CR Agster KL, 2013, BEHAV BRAIN RES, V254, P50, DOI 10.1016/j.bbr.2013.07.005
   Alvernhe A, 2012, ANIM COGN, V15, P359, DOI 10.1007/s10071-011-0460-z
   Antonelo EA, 2009, LECT NOTES COMPUT SC, V5768, P747
   Arleo A, 2004, IEEE T NEURAL NETWOR, V15, P639, DOI 10.1109/TNN.2004.826221
   Barrera A, 2008, AUTON ROBOT, V25, P147, DOI 10.1007/s10514-007-9074-3
   Barrera A, 2015, SPAT COGN COMPUT, V15, P27, DOI 10.1080/13875868.2014.961602
   Barrera A, 2011, J INTELL ROBOT SYST, V63, P361, DOI 10.1007/s10846-010-9467-y
   Barto AG, 1995, MODELS INFORM PROCES, P215
   Borenstein J, 1996, IEEE T ROBOTIC AUTOM, V12, P869, DOI 10.1109/70.544770
   BROWN MA, 1995, HIPPOCAMPUS, V5, P171, DOI 10.1002/hipo.450050304
   Burak Y., 2009, PLOS COMPUT BIOL
   BURGESS N, 1994, NEURAL NETWORKS, V7, P1065, DOI 10.1016/S0893-6080(05)80159-5
   Burgess N, 2007, HIPPOCAMPUS, V17, P801, DOI 10.1002/hipo.20327
   Bush D, 2014, J NEUROSCI, V34, P5065, DOI 10.1523/JNEUROSCI.4017-13.2014
   Caluwaerts K, 2012, BIOINSPIR BIOMIM, V7, DOI 10.1088/1748-3182/7/2/025009
   Cheung A, 2012, PLOS COMPUT BIOL, V8, DOI 10.1371/journal.pcbi.1002651
   Cho JW, 2001, BEHAV NEUROSCI, V115, P3, DOI 10.1037//0735-7044.115.1.3
   Dolle L, 2010, BIOL CYBERN, V103, P299, DOI 10.1007/s00422-010-0400-z
   Etienne AS, 2004, HIPPOCAMPUS, V14, P180, DOI 10.1002/hipo.10173
   Filliat D., 2002, P 7 INT C SIM AD BEH, P131
   Fuhs MC, 2006, J NEUROSCI, V26, P4266, DOI 10.1523/JNEUROSCI.1353-05.2006
   Fyhn M, 2004, SCIENCE, V305, P1258, DOI 10.1126/science.1099901
   Gaussier P, 2002, BIOL CYBERN, V86, P15, DOI 10.1007/s004220100269
   Gibson J. J., 1977, PERCEIVING ACTING KN, P67
   GIBSON JJ, 1954, PSYCHOL REV, V61, P304, DOI 10.1037/h0061885
   Granon S, 2000, PSYCHOBIOLOGY, V28, P229
   Guazzelli A, 1998, ADAPT BEHAV, V6, P435, DOI 10.1177/105971239800600305
   Guzowski JF, 2004, NEURON, V44, P581, DOI 10.1016/j.neuron.2004.11.003
   Hafting T, 2005, NATURE, V436, P801, DOI 10.1038/nature03721
   Hasselmo ME, 2007, HIPPOCAMPUS, V17, P1252, DOI 10.1002/hipo.20374
   Hebb D. O, 1949, ORG BEHAV NEUROPSYCH
   Houk J. C., 1995, MODELS INFORM PROCES, P249
   Jeffery KJ, 1999, EXP BRAIN RES, V127, P151, DOI 10.1007/s002210050785
   Kelley AE, 2004, NEUROSCI BIOBEHAV R, V27, P765, DOI 10.1016/j.neubiorev.2003.11.015
   Krupic J, 2012, SCIENCE, V337, P853, DOI 10.1126/science.1222403
   Leutgeb S, 2004, SCIENCE, V305, P1295, DOI 10.1126/science.1100265
   Leutgeb S, 2007, LEARN MEMORY, V14, P745, DOI 10.1101/lm.703907
   MCNAUGHTON BL, 1994, CEREB CORTEX, V4, P27, DOI 10.1093/cercor/4.1.27
   McNaughton BL, 2006, NAT REV NEUROSCI, V7, P663, DOI 10.1038/nrn1932
   McNaughton Bruce L., 1995, P585
   Mhatre H, 2012, HIPPOCAMPUS, V22, P320, DOI 10.1002/hipo.20901
   Milford M, 2007, LECT NOTES COMPUT SC, V4736, P203
   Milford M, 2010, INT J ROBOT RES, V29, P1131, DOI 10.1177/0278364909340592
   Mittelstaedt M., 1982, AVIAN NAVIGATION, P290
   MORRIS R, 1984, J NEUROSCI METH, V11, P47, DOI 10.1016/0165-0270(84)90007-4
   MORRIS RGM, 1981, LEARN MOTIV, V12, P239, DOI 10.1016/0023-9690(81)90020-5
   Moser EI, 2008, ANNU REV NEUROSCI, V31, P69, DOI 10.1146/annurev.neuro.31.061307.090723
   Navratilova Z., 2011, HIPPOCAMPUS, DOI 10.1002/hipo.20939
   O'Keefe J., 1978, HIPPOCAMPUS COGNITIV
   OKEEFE J, 1971, BRAIN RES, V34, P171, DOI 10.1016/0006-8993(71)90358-1
   OKEEFE J, 1978, EXP BRAIN RES, V31, P573
   OKEEFE J, 1983, NEUROBIOLOGY HIPPOCA, P375
   Parron C, 2004, EXP BRAIN RES, V159, P349, DOI 10.1007/s00221-004-1960-8
   POUCET B, 1993, PSYCHOL REV, V100, P163, DOI 10.1037/0033-295X.100.2.163
   QUIRK GJ, 1990, J NEUROSCI, V10, P2008
   RANCK J B JR, 1984, Society for Neuroscience Abstracts, V10, P599
   Redish AD, 1997, HIPPOCAMPUS, V7, P15
   Rolls E. T., 2005, HEAD DIRECTION CELLS, P299
   Samu D, 2009, BIOL CYBERN, V101, P19, DOI 10.1007/s00422-009-0311-z
   Schultz W, 1998, NEUROPHARMACOLOGY, V37, P421, DOI 10.1016/S0028-3908(98)00071-9
   Solstad T, 2006, HIPPOCAMPUS, V16, P1026, DOI 10.1002/hipo.20244
   Taube JS, 1998, PROG NEUROBIOL, V55, P225, DOI 10.1016/S0301-0082(98)00004-5
   TAUBE JS, 1990, J NEUROSCI, V10, P436
   Tejera G, 2015, IEEE IJCNN
   Tejera G, 2013, 2013 16TH INTERNATIONAL CONFERENCE ON ADVANCED ROBOTICS (ICAR)
   TOLMAN EC, 1948, PSYCHOL REV, V55, P189, DOI 10.1037/h0061626
   Towse B., 2013, PHILOS T ROYAL SOC
NR 67
TC 0
Z9 0
U1 3
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 0921-0296
EI 1573-0409
J9 J INTELL ROBOT SYST
JI J. Intell. Robot. Syst.
PD JUL
PY 2018
VL 91
IS 1
SI SI
BP 85
EP 99
DI 10.1007/s10846-018-0852-2
PG 15
WC Computer Science, Artificial Intelligence; Robotics
SC Computer Science; Robotics
GA GO1TN
UT WOS:000439739400008
DA 2019-02-18
ER

PT J
AU El-Hussieny, H
   Assal, SFM
   Ryu, JH
AF El-Hussieny, Haitham
   Assal, Samy F. M.
   Ryu, Jee-Hwan
TI SoTCM: a scene-oriented task complexity metric for gaze-supported
   teleoperation tasks
SO INTELLIGENT SERVICE ROBOTICS
LA English
DT Article
DE Human-robot interaction; Teleoperation; Eye-gaze tracking; Task
   workload; Complexity metrics
ID MENTAL WORKLOAD; SHARED CONTROL; BEHAVIOR
AB Recent developments in human-robot interaction (HRI) research have heightened the need to incorporate indirect human signals to implicitly facilitate intuitive human-guided interactions. Eye-gaze has been widely used nowadays as an input interface in multi-modal teleoperation scenarios due to their advantage in revealing human intentions and forthcoming actions. However, to date, there has been no discussion about how the structure of the environment, that the human is interacting with, could affect the complexity of the teleoperation task. In this paper, a new metric named "Scene-oriented Task Complexity Metric" (SoTCM) is proposed to estimate the complexity of a certain scene that is involved in eye-gaze-supported teleoperation tasks. The proposed SoTCM objectively estimates the effort that could be exerted by the human operator in terms of the expected time required to point at all the informative locations retrieved from the scene under discussion. The developed SoTCM depends on both the density and distribution of the informative locations in the scene, while incorporates the eye movement behavior found in the psychology literature. The proposed SoTCM is subjectively validated by using the time-to-complete index in addition to the standard (NASA-TLX) workload measure in eight varying structure scenes. Results confirmed a significant relation between SoTCM and the measured task workload which endorses the applicability of using SoTCM in predicting scene complexities and subsequently the task workload in advance.
C1 [El-Hussieny, Haitham; Ryu, Jee-Hwan] Korea Univ Technol & Educ, Sch Mech Engn, Cheonan, South Korea.
   [El-Hussieny, Haitham] Benha Univ, Fac Engn Shoubra, Elect Engn Dept, Banha, Egypt.
   [Assal, Samy F. M.] E JUST, Sch Innovat Design Engn, Mechatron & Robot Engn Dept, New Borg El Arab, Egypt.
   [Assal, Samy F. M.] Tanta Univ, Dept Prod Engn & Mech Design, Fac Engn, Tanta, Egypt.
RP El-Hussieny, H (reprint author), Korea Univ Technol & Educ, Sch Mech Engn, Cheonan, South Korea.; El-Hussieny, H (reprint author), Benha Univ, Fac Engn Shoubra, Elect Engn Dept, Banha, Egypt.
EM haitham.elhussieny@feng.bu.edu.eg
OI Assal, Samy F. M./0000-0002-7997-4363; El-Hussieny,
   Haitham/0000-0002-2296-616X
FU Civil-Military Technology Cooperation Program [15-CM-RB-09]; National
   Research Foundation of Korea (NRF) - Korea government (MSIP) [NRF-
   2016R1E1A1A02921594]; Korea University of Education and Technology
   (KOREATECH)
FX This research was partially supported by the Civil-Military Technology
   Cooperation Program (15-CM-RB-09) and the National Research Foundation
   of Korea (NRF) grant funded by the Korea government (MSIP) (No. NRF-
   2016R1E1A1A02921594). The first author is also supported by a
   Post-doctoral fellowship from Korea University of Education and
   Technology (KOREATECH) which is gratefully acknowledged.
CR Anderson RJ, 1996, IEEE INT CONF ROBOT, P2025, DOI 10.1109/ROBOT.1996.506169
   Aronson RM, 2018, P 2018 ACM IEEE INT, P4
   Bonev B, 2013, PATTERN RECOGN LETT, V34, P723, DOI 10.1016/j.patrec.2012.05.007
   Bruce V, 2003, VISUAL PERCEPTION PH
   Carpenter RH, 1988, MOVEMENTS EYES
   Castaldo R, 2017, EMBEC NBC 2017, P69
   Cheng MM, 2015, IEEE T PATTERN ANAL, V37, P569, DOI 10.1109/TPAMI.2014.2345401
   Cumming L, 1976, ACAD MANAGE REV, V1, P23
   Dautenhahn K, 2007, INT J ADV ROBOT SYST, V4, P15, DOI DOI 10.5772/5702
   De Waard D., 1996, MEASUREMENT DRIVERS
   Donderi DC, 2006, PSYCHOL BULL, V132, P73, DOI 10.1037/0033-2909.132.1.73
   Dragan AD, 2013, INT J ROBOT RES, V32, P790, DOI 10.1177/0278364913490324
   Drewes H., 2010, THESIS
   El-Hussieny H, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON MECHATRONICS (ICM), P204, DOI 10.1109/ICMECH.2015.7083975
   FITTS PM, 1954, J EXP PSYCHOL, V47, P381, DOI 10.1037/h0055392
   Freixenet J, 2002, LECT NOTES COMPUT SC, V2352, P408
   FU KS, 1981, PATTERN RECOGN, V13, P3, DOI 10.1016/0031-3203(81)90028-5
   Gomes J, 2016, IEEE IND ELEC, P704, DOI 10.1109/IECON.2016.7792996
   Hansen J. P., 2014, P S EYE TRACK RES AP, P27
   HART S G, 1988, P139
   Hayhoe M, 2005, TRENDS COGN SCI, V9, P188, DOI 10.1016/j.tics.2005.02.009
   Heyer C, 2010, IEEE INT C INT ROBOT, P4749, DOI 10.1109/IROS.2010.5651294
   Hou X., 2007, IEEE C COMP VIS PATT, P1, DOI DOI 10.1109/CVPR.2007.383267
   Jacob R. J., 1995, VIRTUAL ENV ADV INTE, P258
   JORNA PGAM, 1992, BIOL PSYCHOL, V34, P237, DOI 10.1016/0301-0511(92)90017-O
   Kim DJ, 2012, IEEE T SYST MAN CY A, V42, P2, DOI 10.1109/TSMCA.2011.2159589
   Kramer J, 2012, HACKING THE KINECT, P173
   Liu P, 2011, LECT NOTES COMPUT SC, V6775, P192, DOI 10.1007/978-3-642-21660-2_22
   MacKenzie I. S., 1992, Human-Computer Interaction, V7, P91, DOI 10.1207/s15327051hci0701_3
   Marquart G, 2015, PROCEDIA MANUF, V3, P2854, DOI 10.1016/j.promfg.2015.07.783
   Niemeyer G, 2008, SPRINGER HDB ROBOTIC, P741
   Omer H, 2009, 2009 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS (ROBIO 2009), VOLS 1-4, P711, DOI 10.1109/ROBIO.2009.5420585
   ROUSE WB, 1979, IEEE T SYST MAN CYB, V9, P720
   Rubio S, 2004, APPL PSYCHOL-INT REV, V53, P61, DOI 10.1111/j.1464-0597.2004.00161.x
   Rusu R. B., 2011, P IEEE INT C ROB AUT, P1, DOI [10.1109/ICRA.2011.5980567, DOI 10.1109/ICRA.2011.5980567]
   Saeb S, 2011, PLOS COMPUT BIOL, V7, DOI 10.1371/journal.pcbi.1002253
   Sibert L. E., 2000, CHI 2000 Conference Proceedings. Conference on Human Factors in Computing Systems. CHI 2000. The Future is Here, P281
   Vertegaal R., 2008, P 10 INT C MULT INT, P241, DOI DOI 10.1145/1452392.1452443
   Wolfe JM, 2004, NAT REV NEUROSCI, V5, P495, DOI 10.1038/nrn1411
   Xiao L, 2007, 2007 IEEE SYMPOSIUM ON COMPUTATIONAL INTELLIGENCE AND DATA MINING, VOLS 1 AND 2, P10, DOI 10.1109/CIDM.2007.368846
   You EK, 2012, ROBOTICS: SCIENCE AND SYSTEMS VII, P354
   Zhang LY, 2008, J VISION, V8, DOI 10.1167/8.7.32
   Zhang XA, 2007, LECT NOTES COMPUT SC, V4552, P779
   Zijlstra FRH, 1993, EFFICIENCY WORK BEHA
NR 44
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER HEIDELBERG
PI HEIDELBERG
PA TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY
SN 1861-2776
EI 1861-2784
J9 INTEL SERV ROBOT
JI Intell. Serv. Robot.
PD JUL
PY 2018
VL 11
IS 3
BP 279
EP 288
DI 10.1007/s11370-018-0253-1
PG 10
WC Robotics
SC Robotics
GA GK0TS
UT WOS:000435825400005
DA 2019-02-18
ER

PT J
AU Rudovic, O
   Lee, J
   Dai, M
   Schuller, B
   Picard, RW
AF Rudovic, Ognjen
   Lee, Jaeryoung
   Dai, Miles
   Schuller, Bjoen
   Picard, Rosalind W.
TI Personalized machine learning for robot perception of affect and
   engagement in autism therapy
SO SCIENCE ROBOTICS
LA English
DT Article
ID INDIVIDUALS; CHILD
AB Robots have the potential to facilitate future therapies for children on the autism spectrum. However, existing robots are limited in their ability to automatically perceive and respond to human affect, which is necessary for establishing and maintaining engaging interactions. Their inference challenge is made even harder by the fact that many individuals with autism have atypical and unusually diverse styles of expressing their affective-cognitive states. To tackle the heterogeneity in children with autism, we used the latest advances in deep learning to formulate a personalized machine learning (ML) framework for automatic perception of the children's affective states and engagement during robot-assisted autism therapy. Instead of using the traditional one-size-fits-all ML approach, we personalized our framework to each child using their contextual information (demographics and behavioral assessment scores) and individual characteristics. We evaluated this framework on a multimodal (audio, video, and autonomic physiology) data set of 35 children (ages 3 to 13) with autism, from two cultures (Asia and Europe), and achieved an average agreement (intraclass correlation) of similar to 60% with human experts in the estimation of affect and engagement, also outperforming nonpersonalized ML solutions. These results demonstrate the feasibility of robot perception of affect and engagement in children with autism and have implications for the design of future autism therapies.
C1 [Rudovic, Ognjen; Dai, Miles; Picard, Rosalind W.] MIT Media Lab, Cambridge, MA 02139 USA.
   [Lee, Jaeryoung] Chubu Univ, Dept Robot Sci & Technol, Kasugai, Aichi 4878501, Japan.
   [Schuller, Bjoen] Imperial Coll London, Dept Comp, London SW7 2AZ, England.
   [Schuller, Bjoen] Univ Augsburg, Chair Embedded Intelligence Hlth Care & Wellbeing, D-86159 Augsburg, Germany.
RP Rudovic, O (reprint author), MIT Media Lab, Cambridge, MA 02139 USA.
EM orudovic@mit.edu
OI Schuller, Bjorn/0000-0002-6478-8699
FU Chubu University [27IS04I]; EU HORIZON 2020 grant [701236, 688835]; 
   [16K16106]
FX This work was supported by Grant-in-Aid for Young Scientists B, grant
   no. 16K16106, Chubu University grant no. 27IS04I, and EU HORIZON 2020
   grant nos. 701236 (EngageME) and 688835 (DE-ENIGMA).
CR Abadi M., 2016, P 12 USENIX S OP SYS, P265, DOI DOI 10.1038/NN.3331
   American Psychiatric Association, 2013, DIAGNOSTIC STAT MANU
   Anzalone SM, 2015, INT J SOC ROBOT, V7, P465, DOI 10.1007/s12369-015-0298-7
   Bainbridge WA, 2011, INT J SOC ROBOT, V3, P41, DOI 10.1007/s12369-010-0082-7
   BARONCOHEN S, 1985, COGNITION, V21, P37, DOI 10.1016/0010-0277(85)90022-8
   Belpaeme T, 2012, J HUM-ROBOT INTERACT, V1, P33, DOI 10.5898/JHRI.1.2.Belpaeme
   Bengio Y., 2013, ADV NEURAL INFORM PR, P899
   Bishop C. M., 2006, PATTERN RECOGNITION
   Cao Z, 2017, PROC CVPR IEEE, P1302, DOI 10.1109/CVPR.2017.143
   Chen SY, 2011, INT J ROBOT RES, V30, P1343, DOI 10.1177/0278364911410755
   Chen T., 2016, INT C LEARN REPR ICL
   Chollet F., 2015, KERAS
   Christensen DL, 2016, J DEV BEHAV PEDIATR, V37, P1, DOI 10.1097/DBP.0000000000000235
   Cohn J., 2015, OXFORD HDB AFFECTIVE
   Colton M. B., 2009, AISB NEW FRONTIERS H, V24, P25
   Dautenhahn K, 2004, PRAGMAT COGN, V12, P1, DOI DOI 10.1075/PC.12.1.03DAU
   Diehl JJ, 2012, RES AUTISM SPECT DIS, V6, P249, DOI 10.1016/j.rasd.2011.05.006
   Esteban P. G., 2017, PALADYN J BEHAV ROBO, V25, P18
   Eyben F., 2013, P 21 ACM INT C MULT, P835, DOI [10.1145/2502081.2502224, DOI 10.1145/2502081.2502224]
   Freeman D, 2017, PSYCHOL MED, V47, P2393, DOI 10.1017/S003329171700040X
   Friedman JH, 2001, ANN STAT, V29, P1189, DOI 10.1214/aos/1013203451
   Fukuda T, 2017, SCI ROBOT, V2, DOI 10.1126/scirobotics.aar4043
   Hadwin J. A., 2015, TEACHING CHILDREN AU
   Harker S., 2011, ENCY CHILD BEHAV DEV, P135
   Hernandez J, 2014, UBICOMP'14: PROCEEDINGS OF THE 2014 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING, P307, DOI 10.1145/2632048.2636065
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Hoque M. E., 2008, P ACM ASSETS 2008 C, P311
   Jordan MI, 2015, SCIENCE, V349, P255, DOI 10.1126/science.aaa8415
   Kanda T., 2017, HUMAN ROBOT INTERACT
   Kim ES, 2012, J HUM-ROBOT INTERACT, V1, P26, DOI 10.5898/JHRI.1.1.Kim
   Kim JC, 2017, INT CONF UBIQ ROBOT, P39
   Krebs HI, 2003, AUTON ROBOT, V15, P7, DOI 10.1023/A:1024494031121
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Lee C.-Y., 2015, ARTIF INTELL, P562
   Mataric MJ, 2017, SCI ROBOT, V2, DOI 10.1126/scirobotics.aam5410
   McDuff D, 2016, P 2016 CHI C EXT HUM, P3723, DOI DOI 10.1145/2851581.2890247
   Mnih V, 2015, NATURE, V518, P529, DOI 10.1038/nature14236
   Mollahosseini A., 2017, IEEE T AFFECT COMPUT
   Paul E., 2005, FACIAL EXPRESSIONS
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Picard R. W., 2008, AUTISM ADVOCATE, V50, P32
   Riek LD, 2017, COMMUN ACM, V60, P68, DOI 10.1145/3127874
   Robinson TL, 2016, ACTA HORTIC, V1119, P1, DOI 10.17660/ActaHortic.2016.1119.1
   Rudovic O, 2017, FRONT ROBOT AI, V4, P1, DOI 10.3389/frobt.2017.00036
   Salakhutdinov R, 2013, IEEE T PATTERN ANAL, V35, P1958, DOI 10.1109/TPAMI.2012.269
   Sanghvi J, 2011, ACMIEEE INT CONF HUM, P305, DOI 10.1145/1957656.1957781
   Scassellati B, 2012, ANNU REV BIOMED ENG, V14, P275, DOI 10.1146/annurev-bioeng-071811-150036
   Schopler E, 2010, CHILDHOOD AUTISM RAT
   Schuller B. W., 2013, INTELLIGENT AUDIO AN
   Settles B., 2012, SYNTHESIS LECT ARTIF, V6, P1, DOI DOI 10.2200/S00429ED1V01Y201207AIM018
   Shrikumar A., 2016, NOT JUST BLACK BOX L
   SHROUT PE, 1979, PSYCHOL BULL, V86, P420, DOI 10.1037//0033-2909.86.2.420
   Taylor S. A., 2017, IEEE T AFFECT COMPUT
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Zhang Y, 2018, NATL SCI REV, V5, P30, DOI 10.1093/nsr/nwx105
NR 55
TC 2
Z9 2
U1 9
U2 9
PU AMER ASSOC ADVANCEMENT SCIENCE
PI WASHINGTON
PA 1200 NEW YORK AVE, NW, WASHINGTON, DC 20005 USA
SN 2470-9476
J9 SCI ROBOT
JI Sci. Robot.
PD JUN 27
PY 2018
VL 3
IS 19
AR UNSP eaao6760
DI 10.1126/scirobotics.aao6760
PG 11
WC Robotics
SC Robotics
GA GS0WT
UT WOS:000443231100001
OA Bronze
DA 2019-02-18
ER

PT J
AU Nakamura, T
   Nagai, T
   Taniguchi, T
AF Nakamura, Tomoaki
   Nagai, Takayuki
   Taniguchi, Tadahiro
TI SERKET: An Architecture for Connecting Stochastic Models to Realize a
   Large-Scale Cognitive Model
SO FRONTIERS IN NEUROROBOTICS
LA English
DT Article
DE cognitive models; probabilistic generative models; symbol emergence in
   robotics; concept formation; unsupervised learning
ID LATENT DIRICHLET ALLOCATION; ACTION RECOGNITION; BODY SCHEMA; ROBOT
AB To realize human-like robot intelligence, a large-scale cognitive architecture is required for robots to understand their environment through a variety of sensors with which they are equipped. In this paper, we propose a novel framework named Serket that enables the construction of a large-scale generative model and its inferences easily by connecting sub-modules to allow the robots to acquire various capabilities through interaction with their environment and others. We consider that large-scale cognitive models can be constructed by connecting smaller fundamental models hierarchically while maintaining their programmatic independence. Moreover, the connected modules are dependent on each other and their parameters must be optimized as a whole. Conventionally, the equations for parameter estimation have to be derived and implemented depending on the models. However, it has become harder to derive and implement equations of large-scale models. Thus, in this paper, we propose a parameter estimation method that communicates the minimum parameters between various modules while maintaining their programmatic independence. Therefore, Serket makes it easy to construct large-scale models and estimate their parameters via the connection of modules. Experimental results demonstrated that the model can be constructed by connecting modules, the parameters can be optimized as a whole, and they are comparable with the original models that we have proposed.
C1 [Nakamura, Tomoaki; Nagai, Takayuki] Univ Electrocommun, Dept Mech Engn & Intelligent Syst, Tokyo, Japan.
   [Taniguchi, Tadahiro] Ritsumeikan Univ, Dept Informat Sci & Engn, Kyoto, Shiga, Japan.
RP Nakamura, T (reprint author), Univ Electrocommun, Dept Mech Engn & Intelligent Syst, Tokyo, Japan.
EM tnakmaura@uec.ac.jp
FU JST CREST [JPMJCR15E3]
FX This work was supported by JST CREST Grant Number JPMJCR15E3.
CR Abadi M., 2016, ARXIV160304467
   Adams R. P., 2010, NIPS, P19
   Amodei D, 2016, INT C MACH LEARN, P173
   Anderson J., 2009, CAN HUMAN MIND OCCUR
   Ando Y, 2013, IEEE INT C INT ROBOT, P2272, DOI 10.1109/IROS.2013.6696674
   Asada M, 2009, IEEE T AUTON MENT DE, V1, P12, DOI 10.1109/TAMD.2009.2021702
   Attamimi M, 2016, ADV ROBOTICS, V30, P806, DOI 10.1080/01691864.2016.1172507
   Blei DM, 2010, J ACM, V57, DOI 10.1145/1667053.1667056
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Blei DM, 2003, P 26 ANN INT ACM SIG, P127, DOI DOI 10.1145/860435.860460
   Cangelosi A., 2015, DEV ROBOTICS BABIES
   Carpenter B, 2017, J STAT SOFTW, V76, P1, DOI 10.18637/jss.v076.i01
   Chen YX, 2015, 5TH INTERNATIONAL CONFERENCE ON DEVELOPMENT AND LEARNING AND ON EPIGENETIC ROBOTICS (ICDL-EPIROB), P129, DOI 10.1109/DEVLRN.2015.7346129
   Chollet F., 2015, KERAS
   Francoise Jules, 2013, 21 ACM INT C MULT MM, P705, DOI [10.1145/2502081.2502184, DOI 10.1145/2502081.2502184]
   Goodman Noah, 2012, ARXIV12063255
   He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123
   Kim D.-k., 2013, ICML, P55
   Laird JE, 2008, FR ART INT, V171, P224
   Lallee S, 2013, ADAPT BEHAV, V21, P274, DOI 10.1177/1059712313488423
   Le Q. V., 2014, ADV NEURAL INFORM PR, V27, P3104, DOI DOI 10.1007/S10107-014-0839-0
   Li HP, 2011, INT CONF ACOUST SPEE, P1297
   Li W., 2006, P 23 INT C MACH LEAR, P577, DOI DOI 10.1145/1143844.1143917
   Mangin O., 2013, P 2013 IEEE 3 JOINT, P1
   Mangin O, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0140732
   Margaritis D., 2003, TECHNICAL REPORT
   Mimura T, 2017, ADV ROBOTICS, V31, P118, DOI 10.1080/01691864.2016.1270854
   Minka T, 2002, P 18 C UNC ART INT, P352
   Mochihashi D., 2009, P JOINT C 47 ANN M A, P100
   Nakamura Tomoaki, 2007, 2007 IEEE/RSJ International Conference on Intelligent Robots and Systems, P2415
   Nakamura T., 2016, IROS2016 WORKSH MACH
   Nakamura T, 2014, IEEE INT C INT ROBOT, P600, DOI 10.1109/IROS.2014.6942621
   Nakamura T, 2009, 2009 IEEE-RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, P3943, DOI 10.1109/IROS.2009.5354736
   Nguyen V.-A., 2014, ADV NEURAL INFORM PR, V27, P3671
   Nishihara J, 2017, IEEE T COGN DEV SYST, V9, P255, DOI 10.1109/TCDS.2016.2552579
   Ogata T, 2010, PATTERN RECOGN LETT, V31, P1560, DOI 10.1016/j.patrec.2010.05.002
   Patil A, 2010, J STAT SOFTW, V35, P1
   Piaget J, 1970, AM BEHAV SCI, V13, P459
   Putthividhya D, 2010, PROC CVPR IEEE, P3408, DOI 10.1109/CVPR.2010.5540000
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ridge B, 2010, IEEE INT CONF ROBOT, P5047, DOI 10.1109/ROBOT.2010.5509544
   Roy DK, 2002, COGNITIVE SCI, V26, P113, DOI 10.1016/S0364-0213(01)00061-1
   Silver D, 2017, NATURE, V550, P354, DOI 10.1038/nature24270
   Taniguchi A., 2017, IEEE RSJ INT C INT R
   Taniguchi T., 2010, 11 IFAC IFIP IFORS I, V43, P460
   Taniguchi T, 2016, ADV ROBOTICS, V30, P770, DOI 10.1080/01691864.2016.1159981
   Taniguchi T, 2011, ADV ROBOTICS, V25, P2143, DOI 10.1163/016918611X594775
   Tokui S., 2015, WORKSH MACH LEARN SY
   Tran Dustin, 2016, ARXIV161009787
   Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935
   Wang CL, 2009, IEEE T COMMUN, V57, P1903, DOI 10.1109/TCOMM.2009.07.070156
   Wermter S, 2004, ROBOT AUTON SYST, V47, P171, DOI 10.1016/j.robot.2004.03.011
   Wood Frank, 2014, P 17 INT C ART INT S, P1024
   Wu Q, 2016, PROC CVPR IEEE, P4622, DOI 10.1109/CVPR.2016.500
   Yang S, 2014, INT C PATT RECOG, P2613, DOI 10.1109/ICPR.2014.451
   Yuruten O, 2013, ADAPT BEHAV, V21, P437, DOI 10.1177/1059712313497976
   Zhang Z., 2017, IEEE INT C COMP VIS
NR 57
TC 0
Z9 0
U1 1
U2 1
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1662-5218
J9 FRONT NEUROROBOTICS
JI Front. Neurorobotics
PD JUN 26
PY 2018
VL 12
AR 25
DI 10.3389/fnbot.2018.00025
PG 16
WC Computer Science, Artificial Intelligence; Robotics; Neurosciences
SC Computer Science; Robotics; Neurosciences & Neurology
GA GK6QB
UT WOS:000436312800001
PM 29997493
OA DOAJ Gold
DA 2019-02-18
ER

PT J
AU Kumar, S
   Shaw, P
   Giagkos, A
   Braud, R
   Lee, M
   Shen, Q
AF Kumar, Suresh
   Shaw, Patricia
   Giagkos, Alexandros
   Braud, Raphael
   Lee, Mark
   Shen, Qiang
TI Developing Hierarchical Schemas and Building Schema Chains Through
   Practice Play Behavior
SO FRONTIERS IN NEUROROBOTICS
LA English
DT Article
DE Dev-PSchema; practice play; schemas; action sequencing; schema chains;
   play and playthings; modeling of behavior
ID NONOBVIOUS OBJECT PROPERTIES; MANIPULATIVE EXPLORATION; HUMANOID ROBOT;
   INFANTS; PERCEPTION; ATTENTION; SHAPE; COORDINATION; INFERENCES; ABILITY
AB Examining the different stages of learning through play in humans during early life has been a topic of interest for various scholars. Play evolves from practice to symbolic and then later to play with rules. During practice play, infants go through a process of developing knowledge while they interact with the surrounding objects, facilitating the creation of new knowledge about objects and object related behaviors. Such knowledge is used to form schemas in which the manifestation of sensorimotor experiences is captured. Through subsequent play, certain schemas are further combined to generate chains able to achieve behaviors that require multiple steps. The chains of schemas demonstrate the formation of higher level actions in a hierarchical structure. In this work we present a schema-based play generator for artificial agents, termed Dev-PSchema. With the help of experiments in a simulated environment and with the iCub robot, we demonstrate the ability of our system to create schemas of sensorimotor experiences from playful interaction with the environment. We show the creation of schema chains consisting of a sequence of actions that allow an agent to autonomously perform complex tasks. In addition to demonstrating the ability to learn through playful behavior, we demonstrate the capability of Dev-PSchema to simulate different infants with different preferences toward novel vs. familiar objects.
C1 [Kumar, Suresh; Shaw, Patricia; Giagkos, Alexandros; Braud, Raphael; Lee, Mark; Shen, Qiang] Aberystwyth Univ, Dept Comp Sci, Aberystwyth, Dyfed, Wales.
   [Kumar, Suresh] Sukkur IBA Univ, Dept Elect Engn, Sukkur, Pakistan.
RP Kumar, S; Shaw, P (reprint author), Aberystwyth Univ, Dept Comp Sci, Aberystwyth, Dyfed, Wales.; Kumar, S (reprint author), Sukkur IBA Univ, Dept Elect Engn, Sukkur, Pakistan.
EM suk9@aberac.uk; phs@aber.ac.uk
OI Shaw, Patricia/0000-0002-6994-8647
FU Aberystwyth University Doctoral Training Program, Faculty Development
   Program Sukkur IBA University Pakistan; UK Engineering and Physical
   Sciences Research Council (EPSRC) [EP/M013510/1]
FX This research is supported by the Aberystwyth University Doctoral
   Training Program, Faculty Development Program Sukkur IBA University
   Pakistan and the UK Engineering and Physical Sciences Research Council
   (EPSRC), grant No. EP/M013510/1. We are grateful for contributions from
   our recent research colleagues, in particularly Dr Michael Sheldon, for
   the development of the PSchema tool.
CR Aguilar W, 2015, COGN SYST RES, V33, P17, DOI 10.1016/j.cogsys.2014.09.002
   BAILLARGEON R, 1994, CURR DIR PSYCHOL SCI, V3, P133, DOI 10.1111/1467-8721.ep10770614
   BALDWIN DA, 1993, CHILD DEV, V64, P711, DOI 10.2307/1131213
   Colombo J, 2004, INFANCY, V5, P1, DOI 10.1207/s15327078in0501_1
   Colombo J, 2001, ANNU REV PSYCHOL, V52, P337, DOI 10.1146/annurev.psych.52.1.337
   DRESCHER G, 1991, MADE UP MINDS CONSTR
   Earland K, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0084240
   FURBY L, 1982, J GENET PSYCHOL, V140, P207, DOI 10.1080/00221325.1982.10534193
   Gelman SA, 2016, COGNITION, V155, P146, DOI 10.1016/j.cognition.2016.06.016
   Giagkos A, 2017, IEEE T COGN DEV SYST, V9, P127, DOI 10.1109/TCDS.2017.2652129
   Hirsh-Pasek K, 2008, ENCY EARLY CHILDHOOD, P1
   HUNTER MA, 1983, DEV PSYCHOL, V19, P338, DOI 10.1037/0012-1649.19.3.338
   JONSSON CO, 1993, SCAND J PSYCHOL, V34, P86, DOI 10.1111/j.1467-9450.1993.tb01103.x
   Kansky K., 2017, P INT C MACH LEARN, P1809
   KELLMAN PJ, 1983, COGNITIVE PSYCHOL, V15, P483, DOI 10.1016/0010-0285(83)90017-8
   Kirkham NZ, 2002, COGNITION, V83, pB35, DOI 10.1016/S0010-0277(02)00004-5
   Kruger N, 2011, ROBOT AUTON SYST, V59, P740, DOI 10.1016/j.robot.2011.05.009
   Kumar S, 2016, 2016 JOINT IEEE INTERNATIONAL CONFERENCE ON DEVELOPMENT AND LEARNING AND EPIGENETIC ROBOTICS (ICDL-EPIROB), P33, DOI 10.1109/DEVLRN.2016.7846785
   Kumar S, 2016, LECT NOTES COMPUT SC, V9825, P329, DOI 10.1007/978-3-319-43488-9_29
   Lashley K. S., 1951, CEREBRAL MECH BEHAV, P112
   Law J, 2014, FRONT NEUROROBOTICS, V8, DOI 10.3389/fnbot.2014.00001
   Law J, 2014, IEEE T AUTON MENT DE, V6, P93, DOI 10.1109/TAMD.2014.2301934
   Lee M. H., 2011, 2011 IEEE INT C DEV, V2, P1, DOI [10.1109/DEVLRN.2011.6037375, DOI 10.1109/DEVLRN.2011.6037375]
   Lewkowicz D, 2016, 2016 JOINT IEEE INTERNATIONAL CONFERENCE ON DEVELOPMENT AND LEARNING AND EPIGENETIC ROBOTICS (ICDL-EPIROB), P278, DOI 10.1109/DEVLRN.2016.7846832
   Mather E, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00491
   McCarty ME, 1999, DEV PSYCHOL, V35, P1091, DOI 10.1037/0012-1649.35.4.1091
   Metta G., 2008, P 8 WORKSH PERF METR, P50, DOI DOI 10.1145/1774674.1774683
   Montesano L, 2008, IEEE T ROBOT, V24, P15, DOI 10.1109/TRO.2007.914848
   Nicolopoulou A, 2010, HUM DEV, V53, P1, DOI 10.1159/000268135
   Oudeyer PY, 2007, IEEE T EVOLUT COMPUT, V11, P265, DOI 10.1109/TEVC.2006.890271
   Petit M, 2016, INTERACT STUD, V17, P248, DOI 10.1075/is.17.2.04pet
   Piaget J., 1952, ORIGINS INTELLIGENCE, V8
   ROCHAT P, 1992, J MOTOR BEHAV, V24, P210, DOI 10.1080/00222895.1992.9941616
   Rosander K, 2004, COGNITION, V91, P1, DOI 10.1016/S0010-0277(03)00166-5
   Rosenbaum DA, 2007, HUM MOVEMENT SCI, V26, P525, DOI 10.1016/j.humov.2007.04.001
   RUFF HA, 1986, CHILD DEV, V57, P105
   Samuelsson IP, 2006, EARLY CHILD DEV CARE, V176, P47, DOI 10.1080/0300443042000302654
   Sann C, 2007, DEVELOPMENTAL SCI, V10, P399, DOI 10.1111/j.1467-7687.2007.00593.x
   Schmuckler MA, 2007, INFANCY, V12, P105, DOI 10.1111/j.1532-7078.2007.tb00236.x
   Shaw P, 2015, 5TH INTERNATIONAL CONFERENCE ON DEVELOPMENT AND LEARNING AND ON EPIGENETIC ROBOTICS (ICDL-EPIROB), P47, DOI 10.1109/DEVLRN.2015.7346114
   Sheldon M., 2013, THESIS
   Sheldon M., 2011, DEV LEARN ICDL 2011, P1
   SIGMAN M, 1976, CHILD DEV, V47, P606
   SLATER A, 1989, INFANT DEV
   STEELE D, 1977, CHILD DEV, V48, P104
   Ugur E., 2007, DEV LEARN 2007 ICDL, P13
   Welder AN, 2001, CHILD DEV, V72, P1653, DOI 10.1111/1467-8624.00371
   Wilcox T, 1999, COGNITION, V72, P125, DOI 10.1016/S0010-0277(99)00035-9
   WILLATTS P, 1989, BIENN M SOC RES CHIL
   Worgotter F, 2009, ROBOT AUTON SYST, V57, P420, DOI 10.1016/j.robot.2008.06.011
NR 50
TC 0
Z9 0
U1 2
U2 2
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1662-5218
J9 FRONT NEUROROBOTICS
JI Front. Neurorobotics
PD JUN 25
PY 2018
VL 12
AR 33
DI 10.3389/fnbot.2018.00033
PG 20
WC Computer Science, Artificial Intelligence; Robotics; Neurosciences
SC Computer Science; Robotics; Neurosciences & Neurology
GA GK4RS
UT WOS:000436152100001
PM 29988610
OA DOAJ Gold
DA 2019-02-18
ER

PT J
AU Jouaiti, M
   Caron, L
   Henaff, P
AF Jouaiti, Melanie
   Caron, Lancelot
   Henaff, Patrick
TI Hebbian Plasticity in CPG Controllers Facilitates Self-Synchronization
   for Human-Robot Handshaking
SO FRONTIERS IN NEUROROBOTICS
LA English
DT Article
DE physical human robot interaction; hebbian learning; central pattern
   generator (CPG); adaptive behavior; handshaking; plasticity; neural
   oscillators
ID CENTRAL PATTERN GENERATORS; LOCOMOTION CONTROL; FREQUENCY ADAPTATION;
   SOCIAL COORDINATION; RHYTHMIC MOVEMENTS; NEURAL OSCILLATORS; WALKING;
   MODEL; ENVIRONMENT; MECHANISMS
AB It is well-known that human social interactions generate synchrony phenomena which are often unconscious. If the interaction between individuals is based on rhythmic movements, synchronized and coordinated movements will emerge from the social synchrony. This paper proposes a plausible model of plastic neural controllers that allows the emergence of synchronized movements in physical and rhythmical interactions. The controller is designed with central pattern generators (CPG) based on rhythmic Rowat-Selverston neurons endowed with neuronal and synaptic Hebbian plasticity. To demonstrate the interest of the proposed model, the case of handshaking is considered because it is a very common, both physically and socially, but also, a very complex act in the point of view of robotics, neuroscience and psychology. Plastic CPGs controllers are implemented in the joints of a simulated robotic arm that has to learn the frequency and amplitude of an external force applied to its effector, thus reproducing the act of handshaking with a human. Results show that the neural and synaptic Hebbian plasticity are working together leading to a natural and autonomous synchronization between the arm and the external force even if the frequency is changing during the movement. Moreover, a power consumption analysis shows that, by offering emergence of synchronized and coordinated movements, the plasticity mechanisms lead to a significant decrease in the energy spend by the robot actuators thus generating a more adaptive and natural human/robot handshake.
C1 [Jouaiti, Melanie; Henaff, Patrick] Univ Lorraine, CNRS, Inria, LORIA, Nancy, France.
   [Caron, Lancelot; Henaff, Patrick] Ecole Natl Super Mines, Informat & Syst Dept, Nancy, France.
RP Jouaiti, M (reprint author), Univ Lorraine, CNRS, Inria, LORIA, Nancy, France.
EM melanie.jouaiti@loria.fr
CR Amrollah Elmira, 2010, Front Neurorobot, V4, P113, DOI 10.3389/fnbot.2010.00113
   Arikan KB, 2011, CONTROL ENG APPL INF, V13, P76
   Avrin G, 2017, P INT C INF CONTR AU, P486
   Avrin G, 2017, J NEUROPHYSIOL, V118, P2470, DOI 10.1152/jn.00054.2017
   Bastin J, 2006, HUM MOVEMENT SCI, V25, P718, DOI 10.1016/j.humov.2006.04.001
   Bernieri FJ, 2011, SOC INFLUENCE, V6, P78, DOI 10.1080/15534510.2011.566706
   Cattaert D, 2001, PROG NEUROBIOL, V63, P199, DOI 10.1016/S0301-0082(00)00030-7
   Chaplin WF, 2000, J PERS SOC PSYCHOL, V79, P110, DOI 10.1037/0022-3514.79.1.110
   Cruse H, 1998, NEURAL NETWORKS, V11, P1435, DOI 10.1016/S0893-6080(98)00067-7
   Danner SM, 2016, J PHYSIOL-LONDON, V594, P6947, DOI 10.1113/JP272787
   Debnath S, 2014, IEEE-RAS INT C HUMAN, P1016, DOI 10.1109/HUMANOIDS.2014.7041489
   Degallier S, 2011, AUTON ROBOT, V31, P155, DOI 10.1007/s10514-011-9235-2
   Degallier S, 2010, BIOL CYBERN, V103, P319, DOI 10.1007/s00422-010-0403-9
   Delaherche E, 2012, IEEE T AFFECT COMPUT, V3, P349, DOI 10.1109/T-AFFC.2012.12
   Der R, 2017, FRONT NEUROROBOTICS, V11, DOI 10.3389/fnbot.2017.00008
   Dumas G, 2014, P NATL ACAD SCI USA, V111, pE3726, DOI 10.1073/pnas.1407486111
   Giannopoulos E, 2011, BRAIN RES BULL, V85, P276, DOI 10.1016/j.brainresbull.2010.11.012
   GRILLNER S, 1985, ANNU REV NEUROSCI, V8, P233, DOI 10.1146/annurev.ne.08.030185.001313
   Grillner S, 2006, NEURON, V52, P751, DOI 10.1016/j.neuron.2006.11.008
   HALL PM, 1983, SEMIOTICA, V45, P249, DOI 10.1515/semi.1983.45.3-4.249
   Harris-Warrick RM, 2011, CURR OPIN NEUROBIOL, V21, P685, DOI 10.1016/j.conb.2011.05.011
   HODGKIN AL, 1952, J PHYSIOL-LONDON, V117, P500, DOI 10.1113/jphysiol.1952.sp004764
   Ijspeert AJ, 2008, NEURAL NETWORKS, V21, P642, DOI 10.1016/j.neunet.2008.03.014
   Kasuga T, 2005, IEEE INT CONF ROBOT, P3802
   LEE DN, 1976, PERCEPTION, V5, P437, DOI 10.1068/p050437
   Low LA, 2006, STRUCT CONTROL HLTH, V13, P417, DOI 10.1002/stc.133
   Marder E, 2001, CURR BIOL, V11, pR986, DOI 10.1016/S0960-9822(01)00581-4
   Marder E, 1996, PHYSIOL REV, V76, P687
   MATSUOKA K, 1987, BIOL CYBERN, V56, P345, DOI 10.1007/BF00319514
   Mottet D, 1999, BIOL CYBERN, V80, P235, DOI 10.1007/s004220050521
   Nachstedt T, 2017, FRONT NEUROROBOTICS, V11, DOI [10.3389/Thbot.2017.00014, 10.3389/fnbot.2017.00014]
   Nassour J, 2014, BIOL CYBERN, V108, P291, DOI 10.1007/s00422-014-0592-8
   Oullier O, 2008, SOC NEUROSCI, V3, P178, DOI 10.1080/17470910701563392
   Pearson KG, 2004, PROG BRAIN RES, V143, P123, DOI 10.1016/S0079-6123(03)43012-4
   Petric T, 2011, INT J ROBOT RES, V30, P1775, DOI 10.1177/0278364911421511
   Pikovsky A., 2003, SYNCHRONIZATION UNIV, V12
   Righetti L, 2006, PHYSICA D, V216, P269, DOI 10.1016/j.phvsd.2006.02.009
   Righetti L, 2006, IEEE INT CONF ROBOT, P1585, DOI 10.1109/ROBOT.2006.1641933
   Rossignol S, 2006, PHYSIOL REV, V86, P89, DOI 10.1152/00028.2005
   ROWAT PF, 1993, J NEUROPHYSIOL, V70, P1030
   Rowat PF, 1997, J COMPUT NEUROSCI, V4, P103, DOI 10.1023/A:1008869411135
   Rybak IA, 2006, J PHYSIOL-LONDON, V577, P617, DOI 10.1113/jphysiol.2006.118703
   Schiffrin D., 1974, SEMIOTICA, V12, P189, DOI [10.1515/semi.1974.12.3.189, DOI 10.1515/SEMI.1974.12.3.189]
   SCHMIDT RC, 1990, J EXP PSYCHOL HUMAN, V16, P227, DOI 10.1037//0096-1523.16.2.227
   Shadmehr R., 2010, COMPUTATIONAL APPROA
   Spardy LE, 2011, J NEURAL ENG, V8, DOI 10.1088/1741-2560/8/6/065004
   Taga G, 1998, BIOL CYBERN, V78, P9, DOI 10.1007/s004220050408
   TAGA G, 1991, BIOL CYBERN, V65, P147, DOI 10.1007/BF00198086
   Tagne G, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P674, DOI 10.1109/IROS.2016.7759125
   Teka WW, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0179288
   Tognoli E, 2007, P NATL ACAD SCI USA, V104, P8190, DOI 10.1073/pnas.0611453104
   Troje NF, 2006, J VISION, V6, P850, DOI 10.1167/6.8.7
   Walker E. J., 2013, JOINT ACT M COGN SCI
   Yazdani M, 2018, ROBOT AUTON SYST, V101, P20, DOI 10.1016/j.robot.2017.12.003
   Yonekura K, 2012, EURASIP J AUDIO SPEE, P1, DOI 10.1186/1687-4722-2012-12
   Yu JZ, 2014, IEEE T NEUR NET LEAR, V25, P441, DOI 10.1109/TNNLS.2013.2280596
   Zehr EP, 2004, CAN J PHYSIOL PHARM, V82, P556, DOI 10.1139/Y04-056
NR 57
TC 0
Z9 0
U1 5
U2 10
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1662-5218
J9 FRONT NEUROROBOTICS
JI Front. Neurorobotics
PD JUN 8
PY 2018
VL 12
AR 29
DI 10.3389/fnbot.2018.00029
PG 15
WC Computer Science, Artificial Intelligence; Robotics; Neurosciences
SC Computer Science; Robotics; Neurosciences & Neurology
GA GI7HE
UT WOS:000434672500001
PM 29937725
OA DOAJ Gold
DA 2019-02-18
ER

PT J
AU White, O
   Karniel, A
   Papaxanthis, C
   Barbiero, M
   Nisky, I
AF White, Olivier
   Karniel, Amir
   Papaxanthis, Charalambos
   Barbiero, Marie
   Nisky, Ilana
TI Switching in Feedforward Control of Grip Force During Tool-Mediated
   Interaction With Elastic Force Fields
SO FRONTIERS IN NEUROROBOTICS
LA English
DT Article
DE phase transition; grip force; internal model; stiffness; uncertainty
ID DELAYED STIFFNESS; PRECISION GRIP; MOTOR CONTROL; ARM MOVEMENTS; LOAD
   FORCE; MINIMUM ACCELERATION; PREDICTIVE CONTROL; MANUAL TRACKING; VISUAL
   FEEDBACK; LINEAR-SYSTEMS
AB Switched systems are common in artificial control systems. Here, we suggest that the brain adopts a switched feedforward control of grip forces during manipulation of objects. We measured how participants modulated grip force when interacting with soft and rigid virtual objects when stiffness varied continuously between trials. We identified a sudden phase transition between two forms of feedforward control that differed in the timing of the synchronization between the anticipated load force and the applied grip force. The switch occurred several trials after a threshold stiffness level in the range 100-200 N/m. These results suggest that in the control of grip force, the brain acts as a switching control system. This opens new research questions as to the nature of the discrete state variables that drive the switching.
C1 [White, Olivier; Papaxanthis, Charalambos; Barbiero, Marie] Univ Bourgogne Franche Comte, INSERM CAPS UMR1093, UFR Sci Sport, Dijon, France.
   [White, Olivier] Univ East Anglia, Sch Hlth Sci, Acquired Brain Injury Rehabil Alliance, Norwich, Norfolk, England.
   [Karniel, Amir; Nisky, Ilana] Ben Gurion Univ Negev, Dept Biomed Engn, Beer Sheva, Israel.
   [Karniel, Amir; Nisky, Ilana] Ben Gurion Univ Negev, Zlotowski Ctr Neurosci, Beer Sheva, Israel.
RP Nisky, I (reprint author), Ben Gurion Univ Negev, Dept Biomed Engn, Beer Sheva, Israel.; Nisky, I (reprint author), Ben Gurion Univ Negev, Zlotowski Ctr Neurosci, Beer Sheva, Israel.
EM nisky@bgu.ac.il
OI Nisky, Ilana/0000-0003-4128-9771
FU Institut National de la Sante et de la Recherche Medicale; Conseil
   General de Bourgogne; Fonds europeen de developpement regional; Leona M.
   and Harry B. Helmsley Charitable Trust through the Agricultural,
   Biological and Cognitive Robotics Initiative of Ben-Gurion University of
   the Negev; Israeli Science Foundation [823/15]
FX This research was supported by the Institut National de la Sante et de
   la Recherche Medicale, the Conseil General de Bourgogne and the Fonds
   europeen de developpement regional. AK and IN were supported by the
   Leona M. and Harry B. Helmsley Charitable Trust through the
   Agricultural, Biological and Cognitive Robotics Initiative of Ben-Gurion
   University of the Negev, and the Israeli Science Foundation (grant
   number 823/15).
CR Asai Y, 2009, PLOS ONE, V4, DOI 10.1371/journal.pone.0006169
   Augurelle AS, 2003, EXP BRAIN RES, V148, P533, DOI 10.1007/s00221-002-1322-3
   Barbiero M, 2017, FRONT PHYSIOL, V8, DOI 10.3389/fphys.2017.00290
   Ben-Itzhak S, 2008, NEURAL COMPUT, V20, P779, DOI 10.1162/neco.2007.12-05-077
   Binsted G, 1999, EXP BRAIN RES, V127, P193, DOI 10.1007/s002210050789
   Bleyenheuft Y, 2009, J MOTOR BEHAV, V41, P411, DOI 10.3200/35-08-084
   Bottaro A, 2005, HUM MOVEMENT SCI, V24, P588, DOI 10.1016/j.humov.2005.07.006
   Chib VS, 2006, J NEUROPHYSIOL, V95, P1068, DOI 10.1152/jn.00610.2005
   Craik KJW, 1947, B J PSYCHOL-GEN SECT, V38, P56, DOI 10.1111/j.2044-8295.1947.tb01141.x
   Danion F, 2007, J NEUROSCI, V27, P12839, DOI 10.1523/JNEUROSCI.3110-07.2007
   Descoins M, 2006, EXP BRAIN RES, V172, P331, DOI 10.1007/s00221-005-0340-3
   Doeringer JA, 1998, J NEUROPHYSIOL, V80, P1787
   Ebner-Karestinos D, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0165549
   Farajian M, 2018, BIORXIV, DOI [10.1101/203604, DOI 10.1101/203604]
   FLANAGAN JR, 1995, EXP BRAIN RES, V105, P455
   FLANAGAN JR, 1994, J EXP PSYCHOL HUMAN, V20, P944, DOI 10.1037//0096-1523.20.5.944
   Flanagan JR, 2003, CURR BIOL, V13, P146, DOI 10.1016/S0960-9822(03)00007-1
   FLANAGAN JR, 1993, NEUROSCI LETT, V152, P53, DOI 10.1016/0304-3940(93)90481-Y
   FOLEY JM, 1993, NMR BIOMED, V6, P32, DOI 10.1002/nbm.1940060106
   Gawthrop P, 2014, BIOL CYBERN, V108, P159, DOI 10.1007/s00422-014-0587-5
   Gawthrop P, 2013, BIOL CYBERN, V107, P637, DOI 10.1007/s00422-013-0564-4
   Gibo TL, 2014, IEEE T HAPTICS, V7, P37, DOI 10.1109/TOH.2013.60
   Gross J, 2002, P NATL ACAD SCI USA, V99, P2299, DOI 10.1073/pnas.032682099
   Gysin P, 2008, J NEUROPHYSIOL, V100, P2477, DOI 10.1152/jn.90561.2008
   Hamilton AFD, 2004, EXP BRAIN RES, V157, P417, DOI 10.1007/s00221-004-1856-7
   Han G, 2010, LECT NOTES COMPUT SC, V6191, P117
   Helsen WF, 2000, J MOTOR BEHAV, V32, P241, DOI 10.1080/00222890009601375
   JOHANSSON RS, 1988, EXP BRAIN RES, V71, P72
   JOHANSSON RS, 1984, EXP BRAIN RES, V56, P550
   JOHANSSON RS, 1992, EXP BRAIN RES, V89, P181, DOI 10.1007/BF00229015
   Jones KE, 2002, J NEUROPHYSIOL, V88, P1533, DOI 10.1152/jn.00985.2001
   JONES LA, 1990, EXP BRAIN RES, V79, P150
   Karniel A, 2002, EXP BRAIN RES, V143, P520, DOI 10.1007/s00221-002-1054-4
   Karniel A, 2011, J INTEGR NEUROSCI, V10, P385, DOI 10.1142/S0219635211002749
   Kelso J. A. S., 1984, AM J PHYSIOL-REG I, V15, P1000, DOI DOI 10.1152/AJPREGU.1984.246.6.R1000
   Leib R, 2016, J NEUROSCI, V36, P10545, DOI 10.1523/JNEUROSCI.1178-16.2016
   Leib R, 2015, J NEUROPHYSIOL, V113, P3076, DOI 10.1152/jn.00229.2014
   Leib R, 2012, J NEUROPHYSIOL, V108, P1646, DOI 10.1152/jn.00224.2012
   Levy-Tzedek S, 2011, BRAIN RES BULL, V85, P283, DOI 10.1016/j.brainresbull.2010.11.010
   Levy-Tzedek S, 2010, EXP BRAIN RES, V202, P733, DOI 10.1007/s00221-010-2176-8
   Liberzon D., 2003, SWITCHING SYSTEMS CO
   Lin H, 2009, IEEE T AUTOMAT CONTR, V54, P308, DOI 10.1109/TAC.2008.2012009
   Loewenstein Y, 2005, NAT NEUROSCI, V8, P202, DOI 10.1038/nn1393
   Loram ID, 2011, J PHYSIOL-LONDON, V589, P307, DOI 10.1113/jphysiol.2010.194712
   Malakhovski E, 2006, AUTOMATICA, V42, P1041, DOI 10.1016/j.automatica.2006.01.024
   Margaliot M, 2006, SYST CONTROL LETT, V55, P8, DOI 10.1016/j.sysconle.2005.04.011
   Mawase F, 2012, FRONT SYST NEUROSCI, V6, DOI 10.3389/fnsys.2012.00060
   Mawase F, 2010, EXP BRAIN RES, V203, P447, DOI 10.1007/s00221-010-2249-8
   MIALL RC, 1993, J MOTOR BEHAV, V25, P53, DOI 10.1080/00222895.1993.9941639
   Mugge W, 2009, J NEUROSCI, V29, P5476, DOI 10.1523/JNEUROSCI.0116-09.2009
   NAVAS F, 1968, BIOPHYS J, V8, P252, DOI 10.1016/S0006-3495(68)86488-4
   NEILSON PD, 1988, BIOL CYBERN, V58, P101, DOI 10.1007/BF00364156
   Nisky I, 2011, IEEE T HAPTICS, V4, P155, DOI [10.1109/TOH.2011.30, 10.1109/ToH.2011.30]
   Nisky I, 2010, J NEUROPHYSIOL, V103, P3017, DOI 10.1152/jn.00939.2009
   Nisky I, 2008, IEEE T HAPTICS, V1, P73, DOI 10.1109/ToH.2008.17
   Nowak DA, 2004, EXP BRAIN RES, V157, P241, DOI 10.1007/s00221-004-1839-8
   Pressman A, 2008, ADV ROBOTICS, V22, P119, DOI 10.1163/156855308X291863
   Pressman A, 2007, INT J ROBOT RES, V26, P1191, DOI 10.1177/0278364907082611
   Pressman A, 2011, J NEUROSCI, V31, P6595, DOI 10.1523/JNEUROSCI.4656-10.2011
   Quek ZF, 2015, IEEE T HAPTICS, V8, P209, DOI 10.1109/TOH.2015.2398448
   Quek ZF, 2014, IEEE T HUM-MACH SYST, V44, P731, DOI 10.1109/THMS.2014.2348865
   Sarlegna FR, 2010, J NEUROPHYSIOL, V104, P641, DOI 10.1152/jn.00174.2010
   Serrien DJ, 1999, EXP BRAIN RES, V124, P100, DOI 10.1007/s002210050604
   Sih BL, 2003, MED SCI SPORT EXER, V35, P623, DOI 10.1249/01.MSS.0000058435.67376.49
   Squeri V, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0011189
   Sridharan D, 2008, P NATL ACAD SCI USA, V105, P12569, DOI 10.1073/pnas.0800005105
   Turrell YN, 1999, EXP BRAIN RES, V128, P86, DOI 10.1007/s002210050822
   White O, 2011, NEUROSCIENCE, V189, P269, DOI 10.1016/j.neuroscience.2011.04.055
   White O, 2008, J NEUROPHYSIOL, V100, P2738, DOI 10.1152/jn.90593.2008
   White O, 2018, FRONT PHYSIOL, V9, DOI 10.3389/fphys.2018.00131
   White O, 2015, FRONT INTEGR NEUROSC, V9, DOI 10.3389/fnint.2015.00007
   White O, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0083812
   White O, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0044291
   Wicks M, 1998, EUR J CONTROL, V4, P140, DOI 10.1016/S0947-3580(98)70108-6
   Yartsev MM, 2009, FRONT SYST NEUROSCI, V3, DOI 10.3389/neuro.06.002.2009
NR 75
TC 0
Z9 0
U1 2
U2 4
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1662-5218
J9 FRONT NEUROROBOTICS
JI Front. Neurorobotics
PD JUN 7
PY 2018
VL 12
AR 31
DI 10.3389/fnbot.2018.00031
PG 12
WC Computer Science, Artificial Intelligence; Robotics; Neurosciences
SC Computer Science; Robotics; Neurosciences & Neurology
GA GI5OI
UT WOS:000434419900001
PM 29930504
OA DOAJ Gold, Green Published
DA 2019-02-18
ER

PT J
AU Broadbent, E
   Feerst, DA
   Lee, SH
   Robinson, H
   Albo-Canals, J
   Ahn, HS
   MacDonald, BA
AF Broadbent, Elizabeth
   Feerst, Danielle Alexis
   Lee, Seung Ho
   Robinson, Hayley
   Albo-Canals, Jordi
   Ahn, Ho Seok
   MacDonald, Bruce A.
TI How Could Companion Robots Be Useful in Rural Schools?
SO INTERNATIONAL JOURNAL OF SOCIAL ROBOTICS
LA English
DT Article
DE Education robots; Companion; Age; Gender; Students; Teachers
ID CHILDREN; EDUCATION; STUDENTS; TRIAL
AB Robots in schools are generally seen as useful for teaching students about engineering and robotics, and as teaching assistants for scientific or foreign language subjects. Robots may be particularly useful in rural schools, due to the challenges rural areas face with low student numbers, low funding, a lack of specialist teachers, and isolation. To date, no studies have specifically investigated how companion robots might be useful in rural schools. This cross-sectional study aimed to investigate student and teacher views about how two companion robots could be useful in rural educational settings. 207 students and 22 teachers participated in 30-min sessions with two popular companion robots, Paro and iRobiQ. Questionnaires were given to all participants and observer ratings were made of student interactions with the robots. Overall, the robots were well-received. The majority of participants said they would like to have the robots at their schools. Girls gave significantly more positive responses about the robots than boys, although boys were more engaged with iRobiQ than girls. Children aged 5-12 and their teachers responded the most positively. Participants wanted the robots to be more interactive, and perceived that the most useful functions were helping children with autism, comforting children in sick bay, and repeating exercises for children who need help. This study suggests that in addition to having an assistant teacher role, companion robots may have a useful comforting role. The results inform designers about which applications to develop for robots in rural schools and which age groups to develop them for.
C1 [Broadbent, Elizabeth; Robinson, Hayley] Univ Auckland, Dept Psychol Med, Auckland, New Zealand.
   [Feerst, Danielle Alexis] Tufts Univ, Occupat Therapy, Boston, MA 02111 USA.
   [Lee, Seung Ho; Ahn, Ho Seok; MacDonald, Bruce A.] Univ Auckland, Dept Elect & Comp Engn, Auckland, New Zealand.
   [Albo-Canals, Jordi] Ramon Lull Univ, La Salle BCN, Barcelona, Spain.
RP Broadbent, E (reprint author), Univ Auckland, Dept Psychol Med, Auckland, New Zealand.
EM e.broadbent@auckland.ac.nz
OI Broadbent, Elizabeth/0000-0003-3626-9100
FU University of Auckland Cares Seed Funding grant; Buller and Central
   Plateau REAPs
FX This study was funded by a University of Auckland Cares Seed Funding
   grant. We acknowledge the support of Buller and Central Plateau REAPs.
CR Causo A, 2016, MECH MACH SCI, V37, P75, DOI 10.1007/978-3-319-22368-1_8
   Feil-Seifer D, 2009, SPRINGER TRAC ADV RO, V54, P201
   Fleming TM, 2014, AUST NZ J PSYCHIAT, V48, P472, DOI 10.1177/0004867413514489
   Han J, 2005, 2005 IEEE International Workshop on Robot and Human Interactive Communication (RO-MAN), P378
   Han J, 2010, HUMAN ROBOT INTERACT, DOI [10.5772/8143, DOI 10.5772/8143]
   Han J, 2008, J INF PROCESS SYST, V4, P159, DOI 10.3745/JIPS.2008.4.4.159
   Howley A, 2009, J EDUC GIFTED, V32, P515, DOI 10.1177/016235320903200404
   Hsiao HS, 2015, INTERACT LEARN ENVIR, V23, P269, DOI 10.1080/10494820.2012.745435
   Hyun E, 2009, IEEE INT C ROB HUM I, P675
   Jung Y, 2004, P 7 INT WORKSH PRES, P80, DOI DOI 10.1145/1349822.1349866
   Kanda T, 2004, HUM-COMPUT INTERACT, V19, P61, DOI 10.1207/s15327051hci1901&2_4
   Lee E., 2008, P ED MEDIA 2008 WORL, P175
   Lee KM, 2006, INT J HUM-COMPUT ST, V64, P962, DOI 10.1016/j.ijhcs.2006.05.002
   Leite I, 2014, INT J SOC ROBOT, V6, P329, DOI 10.1007/s12369-014-0227-1
   Liu EZ, 2010, BR J ED TECHNOL, V41, pE41
   Malec J., 2001, AAAI SPRING S ROB ED
   Mubin O., 2013, TECHNOLOGY ED LEARNI, V1, P209, DOI DOI 10.2316/J0URNAL.209.2013.1.209-0015
   Owens E. W., 1995, Journal of Educational Technology Systems, V24, P83
   Papert S., 1993, MINDSTORMS CHILDREN
   Reich-Stiebert N, 2015, INT J SOC ROBOT, V7, P875, DOI 10.1007/s12369-015-0308-9
   Resnick M., 1996, INTERACTIONS, V3, P40, DOI DOI 10.1145/234757.234762
   Robinson H, 2013, J AM MED DIR ASSOC, V14, P661, DOI 10.1016/j.jamda.2013.02.007
   Rus D, 2006, IEEE ROBOT AUTOM MAG, V13, P15, DOI 10.1109/MRA.2006.1598048
   Sandygulova A, 2017, INVESTIGATING EFFECT
   Sans-Cope O, 2014, WORKSH CHILD ROB INT, P1
   Shibata T, 2001, IEEE ASME INT C ADV, P1053, DOI 10.1109/AIM.2001.936838
   Tanaka F, 2010, INTERACT STUD, V11, P263, DOI 10.1075/is.11.2.14tan
   Toh LPE, 2016, EDUC TECHNOL SOC, V19, P148
   Werner-Seidler A, 2017, CLIN PSYCHOL REV, V51, P30, DOI 10.1016/j.cpr.2016.10.005
NR 29
TC 0
Z9 0
U1 6
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1875-4791
EI 1875-4805
J9 INT J SOC ROBOT
JI Int. J. Soc. Robot.
PD JUN
PY 2018
VL 10
IS 3
SI SI
BP 295
EP 307
DI 10.1007/s12369-017-0460-5
PG 13
WC Robotics
SC Robotics
GA GJ5LP
UT WOS:000435423100002
DA 2019-02-18
ER

PT J
AU Gomoll, A
   Sabanovic, S
   Tolar, E
   Hmelo-Silver, CE
   Francisco, M
   Lawlor, O
AF Gomoll, Andrea
   Sabanovic, Selma
   Tolar, Erin
   Hmelo-Silver, Cindy E.
   Francisco, Matthew
   Lawlor, Orion
TI Between the Social and the Technical: Negotiation of Human-Centered
   Robotics Design in a Middle School Classroom
SO INTERNATIONAL JOURNAL OF SOCIAL ROBOTICS
LA English
DT Article
DE Human-centered robotics; STEM education; Problem-based learning;
   Sociotechnical systems; Engineering design cycle; Qualitative case study
ID LEARNING-ENVIRONMENT; ACHIEVEMENT; ENGAGEMENT; SCIENCE
AB This paper presents a middle school human-centered robotics (HCR) learning experience and the ways in which it supported students' orientation to technical and social aspects of Science, Technology, Engineering, and Mathematics (STEM). The interdisciplinary project associated with this analysis aims to engage diverse students in authentic STEM practices by creating robotic technologies that can assist people in their school, and connect with remote peers. The goal of this project is to increase student interest in and knowledge of STEM topics, and to help students recognize STEM as relevant to their daily lives and broader societal issues. The human-centered focus of the curriculum encouraged thinking from multiple perspectives (e.g. design, social science, programming) and allowed for diverse STEM exploration. We present samples from student work and classroom interactions. These samples show challenges and successes in engaging students with STEM as a combination of social and technical questions and skills. We trace the trajectory of one group's work to highlight moments in which students navigated an engineering design cycle, analyzed and designed social environments, and crossed disciplinary domains through HCR design-using a phenomena, mechanisms, components framework (PMC) to explore systems thinking. Phenomena refers to attention to the function of the robotic technology in the classroom environment. Components included a focus on single parts of the robot, while mechanism addressed how parts of the robot worked together. This qualitative case study demonstrates the capacity social robotics and inquiry-based learning experiences hold for broadening notions of STEM as a social and multidisciplinary learning domain.
C1 [Sabanovic, Selma; Francisco, Matthew] Indiana Univ, Sch Informat & Comp, 901 E 10th St, Bloomington, IN 47408 USA.
   [Gomoll, Andrea; Tolar, Erin; Hmelo-Silver, Cindy E.] Indiana Univ, Sch Educ, 201 N Rose Ave, Bloomington, IN 47405 USA.
   [Lawlor, Orion] Univ Alaska Fairbanks, Coll Engn & Mines, POB 756660, Fairbanks, AK 99775 USA.
RP Gomoll, A (reprint author), Indiana Univ, Sch Educ, 201 N Rose Ave, Bloomington, IN 47405 USA.
EM agomoll@indiana.edu
FU National Science Foundation [DRL-1433414, DRL-1433841]
FX This research was funded by National Science Foundation awards
   DRL-1433414 and DRL-1433841.
CR BAKER D, 1995, J RES SCI TEACH, V32, P3, DOI 10.1002/tea.3660320104
   Baker WD, 2007, PEDAGOGIES, V2, P191, DOI 10.1080/15544800701366613
   Barker BS, 2007, J RES TECHNOL EDUC, V39, P229, DOI 10.1080/15391523.2007.10782481
   BLUMENFELD PC, 1991, EDUC PSYCHOL, V26, P369, DOI 10.1207/s15326985ep2603&4_8
   Buchanan R., 1992, DESIGN ISSUES, V8, P5, DOI DOI 10.2307/1511637
   Castanheira M. L, 2009, INVESTIGATING CLASSR, P145
   Danish JA, 2018, INT HDB LEARNING SCI
   DiSalvo Carl, 2008, P 10 ANN C PART DES, P41
   Gomoll A, 2016, J SCI EDUC TECHNOL, V25, P899, DOI 10.1007/s10956-016-9647-z
   Hamner E, 2008, AAAI SPRING S US AI, P38
   Hmelo CE, 2000, J LEARN SCI, V9, P247, DOI 10.1207/S15327809JLS0903_2
   Hmelo-Silver CE, 2004, EDUC PSYCHOL REV, V16, P235, DOI 10.1023/B:EDPR.0000034022.16470.f3
   Hmelo-Silver CE, 2007, EDUC PSYCHOL-US, V42, P99, DOI 10.1080/00461520701263368
   Jordan B, 1995, J LEARN SCI, V4, P39, DOI 10.1207/s15327809jls0401_2
   Kolodner J. L., 2002, J IND TEACH ED, V39, P3
   Kolodner JL, 2003, J LEARN SCI, V12, P495, DOI 10.1207/S15327809JLS1204_2
   Mataric M, 2007, AAAI SPRING S SEM SC, P99
   NGSS Lead States, 2013, NEXT GENERATION SCIE
   Powell A., 2003, J MATH BEHAV, V22, P405, DOI DOI 10.1016/J.JMATHB.2003.09.002
   Qidwai Uvais A, 2007, SIGCSE Bulletin, V39, P41, DOI 10.1145/1345375.1345411
   Resnick M, 2007, CC2007-CREATIVITY AND COGNITION 2007 SEEDING CREATIVITY: TOOLS, MEDIA, AND ENVIRONMENTS, P1
   Sabanovic S, 2010, INT J SOC ROBOT, V2, P439, DOI 10.1007/s12369-010-0066-7
   Scassellati B, 2012, ANNU REV BIOMED ENG, V14, P275, DOI 10.1146/annurev-bioeng-071811-150036
   Schaal S, 2007, HFSP J, V1, P115, DOI 10.2976/1.2748612
   Sinha S, 2015, INT J COMP-SUPP COLL, V10, P273, DOI 10.1007/s11412-015-9218-y
   Turkle Sherry, 1992, J MATH BEHAV, V11, P33
   Weinberg JB, 2007, ROB SCI SYST RSS WOR
   Whittier LE, 2007, AM SEC ED, V35, P19
   Williams D., 2010, J COMPUTERS MATH SCI, V29, P51
NR 29
TC 1
Z9 1
U1 10
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1875-4791
EI 1875-4805
J9 INT J SOC ROBOT
JI Int. J. Soc. Robot.
PD JUN
PY 2018
VL 10
IS 3
SI SI
BP 309
EP 324
DI 10.1007/s12369-017-0454-3
PG 16
WC Robotics
SC Robotics
GA GJ5LP
UT WOS:000435423100003
DA 2019-02-18
ER

PT J
AU Belpaeme, T
   Vogt, P
   van den Berghe, R
   Bergmann, K
   Goksun, T
   de Haas, M
   Kanero, J
   Kennedy, J
   Kuntay, AC
   Oudgenoeg-Paz, O
   Papadopoulos, F
   Schodde, T
   Verhagen, J
   Wallbridge, D
   Willemsen, B
   de Wit, J
   Geckin, V
   Hoffmann, L
   Kopp, S
   Krahmer, E
   Mamus, E
   Montanier, JM
   Oranc, C
   Pandey, AK
AF Belpaeme, Tony
   Vogt, Paul
   van den Berghe, Rianne
   Bergmann, Kirsten
   Goksun, Tilbe
   de Haas, Mirjam
   Kanero, Junko
   Kennedy, James
   Kuntay, Aylin C.
   Oudgenoeg-Paz, Ora
   Papadopoulos, Fotios
   Schodde, Thorsten
   Verhagen, Josje
   Wallbridge, Christopher D.
   Willemsen, Bram
   de Wit, Jan
   Geckin, Vasfiye
   Hoffmann, Laura
   Kopp, Stefan
   Krahmer, Emiel
   Mamus, Ezgi
   Montanier, Jean-Marc
   Oranc, Cansu
   Pandey, Amit Kumar
TI Guidelines for Designing Social Robots as Second Language Tutors
SO INTERNATIONAL JOURNAL OF SOCIAL ROBOTICS
LA English
DT Article
DE Social robot; Second language learning; Robot tutor; Human-robot
   interaction
ID DUAL LANGUAGE EXPOSURE; YOUNG-CHILDREN; VOCABULARY INTERVENTION;
   BILINGUAL INFANTS; ASSISTIVE ROBOT; KINDERGARTEN; ACQUISITION; SPEECH;
   ENGAGEMENT; CLASSROOM
AB In recent years, it has been suggested that social robots have potential as tutors and educators for both children and adults. While robots have been shown to be effective in teaching knowledge and skill-based topics, we wish to explore how social robots can be used to tutor a second language to young children. As language learning relies on situated, grounded and social learning, in which interaction and repeated practice are central, social robots hold promise as educational tools for supporting second language learning. This paper surveys the developmental psychology of second language learning and suggests an agenda to study how core concepts of second language learning can be taught by a social robot. It suggests guidelines for designing robot tutors based on observations of second language learning in human-human scenarios, various technical aspects and early studies regarding the effectiveness of social robots as second language tutors.
C1 [Belpaeme, Tony; Kennedy, James; Papadopoulos, Fotios; Wallbridge, Christopher D.] Plymouth Univ, Ctr Robot & Neural Syst, Plymouth, Devon, England.
   [Belpaeme, Tony] Univ Ghent, IMEC, IDLab, Ghent, Belgium.
   [Vogt, Paul; de Haas, Mirjam; Willemsen, Bram; de Wit, Jan; Krahmer, Emiel] Tilburg Univ, Tilburg Ctr Cognit & Commun, Tilburg, Netherlands.
   [Bergmann, Kirsten; Schodde, Thorsten; Hoffmann, Laura; Kopp, Stefan] Bielefeld Univ, Cluster Excellence Cognit Interact Technol, Bielefeld, Germany.
   [van den Berghe, Rianne; Oudgenoeg-Paz, Ora; Verhagen, Josje] Univ Utrecht, Dept Special Educ Cognit & Motor Disabil, Utrecht, Netherlands.
   [Goksun, Tilbe; Kanero, Junko; Kuntay, Aylin C.; Geckin, Vasfiye; Mamus, Ezgi; Oranc, Cansu] Koc Univ, Coll Social Sci & Humanities, Dept Psychol, Istanbul, Turkey.
   [Montanier, Jean-Marc; Pandey, Amit Kumar] SoftBank Robot, Paris, France.
RP Vogt, P (reprint author), Tilburg Univ, Tilburg Ctr Cognit & Commun, Tilburg, Netherlands.
EM p.a.vogt@uvt.nl
OI Oranc, Cansu/0000-0002-2341-2038; Kopp, Stefan/0000-0002-4047-9277;
   Kuntay, Aylin/0000-0001-9057-7556; Hoffmann, Laura/0000-0002-1258-4192
FU EC [688014]
FX The L2TOR project is funded by the H2020 Framework Programme of the EC,
   Grant Number: 688014.
CR Alemi M, 2015, INT J SOC ROBOT, V7, P523, DOI 10.1007/s12369-015-0286-y
   Alemi M, 2014, INT J HUM ROBOT, V11, DOI 10.1142/S0219843614500224
   Ates-Sen AB, 2015, ACQUISITION REFERENC, V15, P241, DOI DOI 10.1075/TILAR.15
   Barcelona European Council, 2002, PRES CONCL 1
   Baxter P, 2017, COMP P 2017 ACM IEEE
   Baxter P, 2017, COMP P 2017 ACM IEEE
   Baxter P, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0178126
   Belpaeme T, 2015, P 1 INT WORKSH ED RO
   Belpaeme T, 2012, J HUM-ROBOT INTERACT, V1, P33, DOI 10.5898/JHRI.1.2.Belpaeme
   Bornstein MH, 2008, DEV PSYCHOL, V44, P867, DOI 10.1037/0012-1649.44.3.867
   Brojde CL, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00155
   Bus AG, 2012, APA ED PSYCHOL HDB, V3, P227
   Chien NC, 2010, CHILD DEV, V81, P1534, DOI 10.1111/j.1467-8624.2010.01490.x
   Cicchetti D., 1994, PSYCHOL ASSESSMENTS, V6, P284, DOI [10.1037/1040-3590.6.4.284, DOI 10.1037/1040-3590.6.4.284]
   Clark H. H, 1996, USING LANGUAGE
   de Haas M, 2016, P LONG TERM CHILD RO
   Denham SA, 2003, CHILD DEV, V74, P238, DOI 10.1111/1467-8624.00533
   Dominey PF, 2004, J NEUROLINGUIST, V17, P121, DOI 10.1016/S0911-6044(03)00056-3
   ERBER NP, 1975, J SPEECH HEAR DISORD, V40, P481, DOI 10.1044/jshd.4004.481
   European Commission, 2012, SPEC EUR 386 EUR THE
   Fridin M, 2014, COMPUT HUM BEHAV, V30, P262, DOI 10.1016/j.chb.2013.09.005
   Fridin M, 2014, COMPUT EDUC, V70, P53, DOI 10.1016/j.compedu.2013.07.043
   Glenberg A. M, 2008, HDB COGNITIVE SCI EM, P355, DOI DOI 10.1016/B978-0-08-046616-3.00018-9
   Gordon G, 2015, ACMIEEE INT CONF HUM, P91, DOI 10.1145/2696454.2696469
   Hald LA, 2016, EDUC PSYCHOL REV, V28, P495, DOI 10.1007/s10648-015-9334-2
   Herberg JS, 2015, 2015 24TH IEEE INTERNATIONAL SYMPOSIUM ON ROBOT AND HUMAN INTERACTIVE COMMUNICATION (RO-MAN), P153, DOI 10.1109/ROMAN.2015.7333620
   Hirsh-Pasek K, 2015, PSYCHOL SCI, V26, P1071, DOI 10.1177/0956797615581493
   Hockema SA, 2009, LINGUISTICS, V47, P453, DOI 10.1515/LING.2009.016
   Hoff E, 2014, EARLY CHILD RES Q, V29, P433, DOI 10.1016/j.ecresq.2014.04.012
   Hoff E, 2013, DEV PSYCHOL, V49, P4, DOI 10.1037/a0027238
   Hoff E, 2012, J CHILD LANG, V39, P1, DOI 10.1017/S0305000910000759
   Hurtado N, 2008, DEVELOPMENTAL SCI, V11, pF31, DOI 10.1111/j.1467-7687.2008.00768.x
   Kaser T, 2014, LECT NOTES COMPUT SC, V8474, P188, DOI 10.1007/978-3-319-07221-0_23
   Kanda T, 2004, HUM-COMPUT INTERACT, V19, P61, DOI 10.1207/s15327051hci1901&2_4
   Kennedy James, 2017, 2017 12th ACM/IEEE International Conference on Human-Robot Interaction (HRI), P82, DOI 10.1145/2909824.3020229
   Kennedy J, 2016, P 11 ACM IEEE INT C, P67
   Kennedy J, 2015, ACMIEEE INT CONF HUM, P67, DOI 10.1145/2696454.2696457
   Konishi H, 2014, DEV NEUROPSYCHOL, V39, P404, DOI 10.1080/87565641.2014.931961
   Kuhl PK, 2007, DEVELOPMENTAL SCI, V10, P110, DOI 10.1111/j.1467-7687.2007.00572.x
   Kuhl PK, 2010, NEURON, V67, P713, DOI 10.1016/j.neuron.2010.08.038
   Laevers F, 2012, EVERY CHILD, V18, P26
   Lee S, 2011, RECALL, V23, P25, DOI 10.1017/S0958344010000273
   Leitner S., 1972, SO LERNT MAN LERNEN
   Leseman PPM, 2001, EARLY CHILD RES Q, V16, P363, DOI 10.1016/S0885-2006(01)00103-X
   Leyzberg D., 2012, P 34 ANN C COGN SCI
   Li J, 2015, INT J HUM-COMPUT ST, V77, P23, DOI 10.1016/j.ijhcs.2015.01.001
   Marulis LM, 2010, REV EDUC RES, V80, P300, DOI 10.3102/0034654310377087
   Mol SE, 2009, REV EDUC RES, V79, P979, DOI 10.3102/0034654309332561
   Moriguchi Y, 2011, INTERACT STUD, V12, P107, DOI 10.1075/is.12.1.04mor
   Movellan J. R., 2009, 2009 4th ACM/IEEE International Conference on Human-Robot Interaction (HRI), P307
   Neuman SB, 2011, READ RES QUART, V46, P249, DOI 10.1598/RRQ.46.3.3
   Newcombe N., 2013, OXFROD HDB DEV PSYCH, V1, P564, DOI DOI 10.1093/0XF0RDHB/9780199958450
   Oudgenoeg-Paz O, 2017, TECH REP
   Pearson BZ, 1997, APPL PSYCHOLINGUIST, V18, P41, DOI 10.1017/S0142716400009863
   PEARSON BZ, 1993, LANG LEARN, V43, P93, DOI 10.1111/j.1467-1770.1993.tb00174.x
   Place S, 2011, CHILD DEV, V82, P1834, DOI 10.1111/j.1467-8624.2011.01660.x
   Proctor CP, 2005, J EDUC PSYCHOL, V97, P246, DOI 10.1037/0022-0663.97.2.246
   Rosenthal-von der Putten AM, 2016, LECT NOTES ARTIF INT, V10011, P256, DOI 10.1007/978-3-319-47665-0_23
   Rowe ML, 2013, CONTEMP EDUC PSYCHOL, V38, P109, DOI 10.1016/j.cedpsych.2012.12.001
   Saerbeck M, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1613
   Schodde T, 2017, P 12 ACM IEEE INT C
   Sidner CL, 2005, ARTIF INTELL, V166, P140, DOI 10.1016/j.artint.2005.03.005
   Spaulding S, 2016, P 2016 INT C AUT AG, P864
   Tanaka F, 2012, J HUM-ROBOT INTERACT, V1, P78, DOI 10.5898/JHRI.1.1.Tanaka
   Tellier M, 2008, GESTURE, V8, P219, DOI 10.1075/gest.8.2.06tel
   TOMASELLO M, 1983, FIRST LANG, V4, P197, DOI DOI 10.1177/014272378300401202
   Unsworth S, 2014, INPUT EXPERIENCE BIL, P181, DOI DOI 10.1075/TILAR.13.10UNS
   Vlaar R, 2017, P R4L WORKSH HRI 17
   Vogt P, 2017, FRONT HUM NEUROSCI, V11, DOI 10.3389/fnhum.2017.00073
   Vygotsky Lev S, 1978, MIND SOC
   Wermelinger S, 2017, J EXP CHILD PSYCHOL, V155, P84, DOI 10.1016/j.jecp.2016.11.005
   Westlund JMK, 2016, ELEVENTH ACM/IEEE INTERNATIONAL CONFERENCE ON HUMAN ROBOT INTERACTION (HRI'16), P459, DOI 10.1109/HRI.2016.7451805
   Westlund JMK, 2016, IEEE ROMAN, P688, DOI 10.1109/ROMAN.2016.7745193
   Westlund JK, 2015, P 1 INT C SOC ROB TH
   White J, 1996, THESIS
   Yow WQ, 2011, J COGN DEV, V12, P12, DOI 10.1080/15248372.2011.539524
NR 76
TC 3
Z9 3
U1 5
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1875-4791
EI 1875-4805
J9 INT J SOC ROBOT
JI Int. J. Soc. Robot.
PD JUN
PY 2018
VL 10
IS 3
SI SI
BP 325
EP 341
DI 10.1007/s12369-018-0467-6
PG 17
WC Robotics
SC Robotics
GA GJ5LP
UT WOS:000435423100004
OA Other Gold
DA 2019-02-18
ER

PT J
AU Mwangi, E
   Barakova, EI
   Diaz-Boladeras, M
   Mallofre, AC
   Rauterberg, M
AF Mwangi, Eunice
   Barakova, Emilia I.
   Diaz-Boladeras, Marta
   Mallofre, Andreu Catala
   Rauterberg, Matthias
TI Directing Attention Through Gaze Hints Improves Task Solving in
   Human-Humanoid Interaction
SO INTERNATIONAL JOURNAL OF SOCIAL ROBOTICS
LA English
DT Article
DE Gaze-based interactions; Gaze perception; Game-based human-robot
   interaction; Embodied cues; Attentional cues; Directed attention; Facial
   orientation
ID ROBOT; CHILDREN; EYES
AB In this paper, we report an experimental study designed to examine how participants perceive and interpret social hints from gaze exhibited by either a robot or a human tutor when carrying out a matching task. The underlying notion is that knowing where an agent is looking at provides cues that can direct attention to an object of interest during the activity. In this regard, we asked human participants to play a card matching game in the presence of either a human or a robotic tutor under two conditions. In one case, the tutor gave hints to help the participant find the matching cards by gazing toward the correct match, in the other case, the tutor only looked at the participants and did not give them any help. The performance was measured based on the time and the number of tries taken to complete the game. Results show that gaze hints (helping tutor) made the matching task significantly easier (fewer tries) with the robot tutor. Furthermore, we found out that the robots' gaze hints were recognized significantly more often than the human tutor gaze hints, and consequently, the participants performed significantly better with the robot tutor. The reported study provides new findings towards the use of non-verbal gaze hints in human-robot interaction, and lays out new design implications, especially for robot-based educative interventions.
C1 [Mwangi, Eunice; Barakova, Emilia I.; Rauterberg, Matthias] Eindhoven Univ Technol, Dept Ind Design, Eindhoven, Netherlands.
   [Diaz-Boladeras, Marta; Mallofre, Andreu Catala] Univ Politecn Cataluna, Tech Res Ctr Dependency Care & Autonomous Living, Barcelona, Spain.
RP Mwangi, E (reprint author), Eindhoven Univ Technol, Dept Ind Design, Eindhoven, Netherlands.
EM njeri.eunice@gmail.com
FU Erasmus Mundus Joint Doctorate in Interactive and Cognitive
   Environments; EACEA Agency of the European Commission under EMJD ICE FPA
   [2010-0012]
FX This work was supported in part by the Erasmus Mundus Joint Doctorate in
   Interactive and Cognitive Environments, which is funded by the EACEA
   Agency of the European Commission under EMJD ICE FPA no 2010-0012. We
   thank Mehrnoosh Vahdat, for her invaluable support during the the
   experiment, and we are also grateful to all the participants who made
   this study possible.
CR Admoni H, 2017, J HUM-ROBOT INTERACT, V6, P25, DOI 10.5898/JHRI.6.1.Admoni
   Admoni H, 2013, ACMIEEE INT CONF HUM, P389, DOI 10.1109/HRI.2013.6483614
   Andrist S, 2014, ACMIEEE INT CONF HUM, P25, DOI 10.1145/2559636.2559666
   Argyle M, 1973, SEMIOTICA, V7, P19, DOI DOI 10.1515/SEMI.1973.7.1.19
   Barakova EI, 2015, EXPERT SYST, V32, P698, DOI 10.1111/exsy.12098
   Baron-Cohen S., 1997, MINDBLINDNESS ESSAY
   Bemelmans R, 2012, J AM MED DIR ASSOC, V13, P114, DOI 10.1016/j.jamda.2010.10.002
   Boucher Jean-David, 2012, Front Neurorobot, V6, P3, DOI 10.3389/fnbot.2012.00003
   Breazeal C, 2005, 2005 IEEE/RSJ International Conference on Intelligent Robots and Systems, Vols 1-4, P383, DOI 10.1109/IROS.2005.1545011
   Brooks R, 2002, DEV PSYCHOL, V38, P958, DOI 10.1037//0012-1649.38.6.958
   Brooks R., 2014, MECH SOCIAL CONNECTI, P167
   Broz F, 2012, ACMIEEE INT CONF HUM, P491
   Cuijpers RH, 2013, LECT NOTES COMPUTER, V8239
   Delaunay F, 2010, ACMIEEE INT CONF HUM, P39, DOI 10.1109/HRI.2010.5453271
   Diaz Boladeras M, 2017, THESIS
   Emery NJ, 2000, NEUROSCI BIOBEHAV R, V24, P581, DOI 10.1016/S0149-7634(00)00025-7
   Feldman R. S., 1991, FUNDAMENTALS NONVERB
   Frischen A, 2007, PSYCHOL BULL, V133, P694, DOI 10.1037/0033-2909.133.4.694
   Huskens B, 2013, DEV NEUROREHABIL, V16, P345, DOI 10.3109/17518423.2012.739212
   Imai M, 2002, IEEE ROMAN 2002, PROCEEDINGS, P411, DOI 10.1109/ROMAN.2002.1045657
   KENDON A, 1967, ACTA PSYCHOL, V26, P22, DOI 10.1016/0001-6918(67)90005-4
   Kirchner N, 2011, ACMIEEE INT CONF HUM, P497, DOI 10.1145/1957656.1957824
   KLEINKE CL, 1986, PSYCHOL BULL, V100, P78, DOI 10.1037//0033-2909.100.1.78
   Kozima H, 2005, 2005 IEEE International Workshop on Robot and Human Interactive Communication (RO-MAN), P341
   Lourens T, 2010, ROBOT AUTON SYST, V58, P1256, DOI 10.1016/j.robot.2010.08.006
   Moon A, 2014, ACMIEEE INT CONF HUM, P334, DOI 10.1145/2559636.2559656
   Mutlu B., 2009, 2009 4th ACM/IEEE International Conference on Human-Robot Interaction (HRI), P69
   Mutlu B, 2006, IEEE-RAS INT C HUMAN, P518, DOI 10.1109/ICHR.2006.321322
   Mwangi E., 2016, P 4 INT C HUM AG INT, P329
   Palinko O, 2016, 2016 IEEE RSJ INT C
   Palinko O, 2015, 2015 24TH IEEE INTERNATIONAL SYMPOSIUM ON ROBOT AND HUMAN INTERACTIVE COMMUNICATION (RO-MAN), P369, DOI 10.1109/ROMAN.2015.7333640
   Perugia G, 2017, P 2017 INT C REH ROB, P1945
   Pfeiffer-Lessmann N, 2012, P 34 ANN C COGN SCI, P851
   Robotics A, 2010, NAO ROBOT REFERENCE
   Ruhland K, 2014, EUROGRAPHICS STATE A, P69
   Vertegaal R., 2001, CHI 2001 Conference Proceedings. Conference on Human Factors in Computing Systems, P301
   Yoshikawa Y., 2006, ROBOTICS SCI SYSTEMS
   Yu C., 2012, ACM T INTERACTIVE IN, V1, P13
NR 38
TC 0
Z9 0
U1 4
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1875-4791
EI 1875-4805
J9 INT J SOC ROBOT
JI Int. J. Soc. Robot.
PD JUN
PY 2018
VL 10
IS 3
SI SI
BP 343
EP 355
DI 10.1007/s12369-018-0473-8
PG 13
WC Robotics
SC Robotics
GA GJ5LP
UT WOS:000435423100005
OA Other Gold
DA 2019-02-18
ER

PT J
AU Jones, A
   Castellano, G
AF Jones, Aidan
   Castellano, Ginevra
TI Adaptive Robotic Tutors that Support Self-Regulated Learning: A
   Longer-Term Investigation with Primary School Children
SO INTERNATIONAL JOURNAL OF SOCIAL ROBOTICS
LA English
DT Article
DE Longitudinal study; Robotic tutors; Personalisation; Self-regulated
   learning; Child-robot interaction
AB Robots are increasingly being used to provide motivating, engaging and personalised support to learners. These robotic tutors have been able to increase student learning gain by providing personalised hints or problem selection. However, they have never been used to assist children in developing self regulated learning (SRL) skills. SRL skills allow a learner to more effectively self-assess and guide their own learning; learners that engage these skills have been shown to perform better academically. This paper explores how personalised tutoring by a robot achieved using an open learner model (OLM) promotes SRL processes and how this can impact learning and SRL skills compared to personalised domain support alone. An OLM allows the learner to view the model that the system holds about them. We present a longer-term study where participants take part in a geography-based task on a touch screen with adaptive feedback provided by the robot. In addition to domain support the robotic tutor uses an OLM to prompt the learner to monitor their developing skills, set goals, and use appropriate tools. Results show that, when a robotic tutor personalises and adaptively scaffolds SRL behaviour based upon an OLM, greater indication of SRL behaviour can be observed over the control condition where the robotic tutor only provides domain support and not SRL scaffolding.
C1 [Jones, Aidan] Univ Birmingham, Sch Engn, Dept Elect Elect & Syst Engn, Birmingham B15 2TT, W Midlands, England.
   [Castellano, Ginevra] Uppsala Univ, Dept Informat Technol, Uppsala, Sweden.
RP Jones, A (reprint author), Univ Birmingham, Sch Engn, Dept Elect Elect & Syst Engn, Birmingham B15 2TT, W Midlands, England.
EM axj100@bham.ac.uk
OI Jones, Aidan/0000-0001-8881-5842
FU European Commission [EU FP7 ICT-317923]
FX This studywas funded by European Commission (Grant Number EU FP7
   ICT-317923).
CR Aleven V., 2006, INT J ARTIFICIAL INT, V16, P101
   Azevedo R, 2004, CONTEMP EDUC PSYCHOL, V29, P344, DOI 10.1016/j.cedpsych.2003.09.002
   Azevedo R., 2011, PSYCHOL TESTING ASSE, V53, P106
   Baxter P, 2012, ACMIEEE INT CONF HUM, P105
   Begum M, 2016, INT J SOC ROBOT, V8, P157, DOI 10.1007/s12369-016-0346-y
   Bull S, 2013, INT HDB METACOGNITIO, P349, DOI DOI 10.1007/978-1-4419-5546-3_23
   Bull S, 2010, STUD COMPUT INTELL, V308, P301
   Bull S, 2010, INT J ELEC ENG EDUC, V47, P307, DOI 10.7227/IJEEE.47.3.6
   Clabaugh C, 2015, 5TH INTERNATIONAL CONFERENCE ON DEVELOPMENT AND LEARNING AND ON EPIGENETIC ROBOTICS (ICDL-EPIROB), P314, DOI 10.1109/DEVLRN.2015.7346164
   Desmarais MC, 2012, USER MODEL USER-ADAP, V22, P9, DOI 10.1007/s11257-011-9106-8
   Fasola J, 2013, J HUM-ROBOT INTERACT, V2, P3, DOI 10.5898/JHRI.2.2.Fasola
   Feil-Seifer D, 2005, INT C REHAB ROBOT, P465
   Gordon G, 2015, AAAI C ART INT
   Graesser A. C., 1999, Cognitive Systems Research, V1, P35, DOI 10.1016/S1389-0417(99)00005-4
   Greczek J, 2014, IEEE ROMAN, P561, DOI 10.1109/ROMAN.2014.6926312
   Hake R. R., 2002, PHYS ED RES C, V8, P1
   Hoffman L., 2011, HRI 2011 WORKSH SOC, P14
   Jones A, 2015, DEM POST P UMAP 2015
   Jones A, 2013, AIED 2013 WORKSH P S, V2, P29
   Jones A, 2018, INT J SOC ROBOT, V10, P439, DOI 10.1007/s12369-017-0430-y
   Jones A, 2015, LECT NOTES ARTIF INT, V9388, P285, DOI 10.1007/978-3-319-25554-5_29
   Jones A, 2014, LECT NOTES ARTIF INT, V8755, P186, DOI 10.1007/978-3-319-11973-1_19
   Kennedy J, 2015, ACMIEEE INT CONF HUM, P67, DOI 10.1145/2696454.2696457
   Kerly A, 2008, KNOWL-BASED SYST, V21, P238, DOI 10.1016/j.knosys.2007.11.015
   Kidd C, 2003, THESIS
   Koedinger KR, 2009, HDB METACOGNITION ED, P897
   Lajoie SP, 2005, INSTR SCI, V33, P541, DOI 10.1007/s11251-005-1279-2
   Leite I, 2013, THESIS
   Leite I, 2013, INT J SOC ROBOT, V5, P291, DOI 10.1007/s12369-013-0178-y
   Leyzberg D, 2012, P 34 ANN C COGN SCI, P1882
   Leyzberg D, 2014, ACMIEEE INT CONF HUM, P423, DOI 10.1145/2559636.2559671
   Mataric M, 2014, ACMIEEE INT CONF HUM, P333, DOI 10.1145/2559636.2560043
   Mitrovic A, 2002, 2 INT C AD HYP AD WE
   Mitrovic A., 2007, INT J ARTIFICIAL INT, V17, P121
   Mitrovic A, 2010, STUD COMPUT INTELL, V308, P63
   Ramachandran A, 2014, P WORKSH 28 AAAI C A
   Ramachandran A, 2015, P 10 ANN ACM IEEE IN, P193
   Ramachandran A, 2016, ELEVENTH ACM/IEEE INTERNATIONAL CONFERENCE ON HUMAN ROBOT INTERACTION (HRI'16), P247, DOI 10.1109/HRI.2016.7451759
   Reingold R, 2008, J INTERACT ONLINE LE, V7, P139
   Roll I., 2014, DESIGN RECOMMENDATIO, P169, DOI DOI 10.1007/978-3-540-30139-4_
   Roll I, 2011, LEARN INSTR, V21, P267, DOI 10.1016/j.learninstruc.2010.07.004
   RYAN RM, 1989, J PERS SOC PSYCHOL, V57, P749, DOI 10.1037//0022-3514.57.5.749
   Scassellati B, 2016, SOCIALLY ASSISTIVE R
   Schraw G, 2009, METACOGN LEARN, V4, P33, DOI 10.1007/s11409-008-9031-3
   Shute VJ, 2011, COMPUTER GAMES AND INSTRUCTION, P503
   Sottilare RA, 2014, DESIGN RECOMMENDATIO, V2
   Szafir Daniel, 2012, P SIGCHI C HUM FACT, P11, DOI [DOI 10.1145/2207676.2207679, 10.1145/2207676.2207679]
   Tanaka F, 2007, P NATL ACAD SCI USA, V104, P17954, DOI 10.1073/pnas.0707769104
   Tanaka F, 2012, J HUM-ROBOT INTERACT, V1, P78, DOI 10.5898/JHRI.1.1.Tanaka
   Tapus A, 2007, IEEE ROBOT AUTOM MAG, V14, P35, DOI 10.1109/MRA.2007.339605
   Tobias S., 2002, 20023 COLL BOARD
   Valdez A., 2013, INT J HIGHER ED, V2, P141, DOI [10.5430/ijhe.v2n2p141, DOI 10.5430/IJHE.V2N2P141]
   Wainer Joshua, 2007, 16th IEEE International Conference on Robot and Human Interactive Communication, P872
   Yanjin Long, 2013, Artificial Intelligence in Education. Proceedings of 16th International Conference (AIED 2013): LNCS 7926, P219, DOI 10.1007/978-3-642-39112-5_23
   Zimmerman BJ, 2008, AM EDUC RES J, V45, P166, DOI 10.3102/0002831207312909
NR 55
TC 2
Z9 2
U1 5
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1875-4791
EI 1875-4805
J9 INT J SOC ROBOT
JI Int. J. Soc. Robot.
PD JUN
PY 2018
VL 10
IS 3
SI SI
BP 357
EP 370
DI 10.1007/s12369-017-0458-z
PG 14
WC Robotics
SC Robotics
GA GJ5LP
UT WOS:000435423100006
OA Green Published, Other Gold
DA 2019-02-18
ER

PT J
AU Albo-Canals, J
   Martelo, AB
   Relkin, E
   Hannon, D
   Heerink, M
   Heinemann, M
   Leidl, K
   Bers, MU
AF Albo-Canals, Jordi
   Martelo, Alexandre Barco
   Relkin, Emily
   Hannon, Daniel
   Heerink, Marcel
   Heinemann, Martina
   Leidl, Kaitlyn
   Bers, Marina Umaschi
TI A Pilot Study of the KIBO Robot in Children with Severe ASD
SO INTERNATIONAL JOURNAL OF SOCIAL ROBOTICS
LA English
DT Article
DE Education; Robots; Social activities; KIBO; Learning; Social skills;
   Autism spectrum disorder; Programming
ID SOCIAL-SKILLS INTERVENTIONS; EARLY-CHILDHOOD; CURRICULUM; AUTISM;
   KINDERGARTEN; ACHIEVEMENT; CLASSROOM; LEGO(C)
AB This pilot study explores the feasibility of using the KIBO Robot as an engaging platform to positively impact social and emotional development in children with ASD. KIBO is a programmable toy robot originally designed to teach coding and sequencing to neuro-typical children between 4 and 7 years of age. To assess its use in children with severe ASD, twelve participants were introduced to KIBO and engaged in a variety of activities with the robot over four consecutive days. Their interactions were observed on site by raters and simultaneously videotaped for later analysis. We performed a detailed quantitative and qualitative analysis in two subjects who completed six or more of the eight planned KIBO play sessions. We observed that most of the participants showed sustained interest in the KIBO robot and increased the frequency of their interactions with adults across play sessions. Although the participants demonstrated only a limited understanding of programming principles during the study, they managed to manipulate the KIBO appropriately, engaged socially with the adults in the room and interacted positively with the robot during individual play. The findings suggest that the KIBO robot warrants further study as an engaging educational platform for children with ASD.
C1 [Albo-Canals, Jordi; Hannon, Daniel] Tufts Univ, Ctr Engn Educ & Outreach, Boston, MA 02111 USA.
   [Relkin, Emily; Bers, Marina Umaschi] Tufts Univ, DevTech Res Grp, Boston, MA 02111 USA.
   [Leidl, Kaitlyn] Tufts Univ, DevTech Res Grp, Eliot Pearson Dept Child Study & Human Dev, Boston, MA 02111 USA.
   [Martelo, Alexandre Barco] Univ Amsterdam, Amsterdam Sch Commun Res ASCoR, Amsterdam, Netherlands.
   [Heerink, Marcel; Heinemann, Martina] Windesheim Flevoland, Robot Lab, Almere, Netherlands.
RP Albo-Canals, J (reprint author), Tufts Univ, Ctr Engn Educ & Outreach, Boston, MA 02111 USA.
EM Jordi.Albo_Canals@tufts.edu
FU NSF [DRL-1118897]; Government of Panama; Tufts University FRAC Grant
FX This research project is funded by NSF Grant No. DRL-1118897 and the
   Government of Panama, as well as a Tufts University FRAC Grant.
CR Albo-Canals Jordi, 2013, 2013 IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN), P638, DOI 10.1109/ROMAN.2013.6628420
   American Psychiatric Association, 1987, DIAGN STAT MAN MENT, P107
   Bers Marina Umaschi, 2013, Journal of Technology and Teacher Education, V21, P355
   Bers M. U., 2012, DESIGNING DIGITAL EX
   Bers MU, 2014, COMPUT EDUC, V72, P145, DOI [10.1016/j.compedu.2013.10.02, 10.1016/j.compedu.2013.10.020]
   Bers MU, 2017, CODING PLAYGROUND PR, V39
   Bers MU, 2014, GO TO GUIDE ENG CURR, P133
   Dautenhahn K, 2002, 2002 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-3, PROCEEDINGS, P1132, DOI 10.1109/IRDS.2002.1043883
   Dautenhahn K, 2002, MU S ART SOC SIM ORG, V3, P117
   Dautenhahn K, 2004, PRAGMAT COGN, V12, P1, DOI DOI 10.1075/PC.12.1.03DAU
   Elkin M, 2014, J INF TECHNOL EDUC-I, V13, P153
   Elkin M, 2016, COMPUT SCH, V33, P169, DOI 10.1080/07380569.2016.1216251
   Ferrari Ester, 2009, RO-MAN 2009 - The 18th IEEE International Symposium on Robot and Human Interactive Communication, P108, DOI 10.1109/ROMAN.2009.5326251
   Flannery LP, 2013, J RES TECHNOL EDUC, V46, P81, DOI 10.1080/15391523.2013.10782614
   Friard O, 2016, METHODS ECOL EVOL, V7, P1325, DOI 10.1111/2041-210X.12584
   Happe F, 2009, PHILOS T R SOC B, V364, P1369, DOI 10.1098/rstb.2008.0332
   Hauck M, 1995, J AUTISM DEV DISORD, V25, P579, DOI 10.1007/BF02178189
   Heerink M., 2012, 2012 RO-MAN: The 21st IEEE International Symposium on Robot and Human Interactive Communication, P1045, DOI 10.1109/ROMAN.2012.6343887
   Kazakoff ER, 2013, EARLY CHILD EDUC J, V41, P245, DOI 10.1007/s10643-012-0554-5
   Kazakoff ER, 2014, J EDUC COMPUT RES, V50, P553, DOI 10.2190/EC.50.4.f
   Lee KTH, 2013, COMPUT SCH, V30, P271, DOI 10.1080/07380569.2013.805676
   Legoff DB, 2006, AUTISM, V10, P317, DOI 10.1177/1362361306064403
   LeGoff DB, 2004, J AUTISM DEV DISORD, V34, P557, DOI 10.1007/s10803-004-2550-0
   Lewis V, 2000, INT J LANG COMM DIS, V35, P117
   Mazzone L, 2016, PSYCHIAT SYMPTOMS CO
   Owens G, 2008, J AUTISM DEV DISORD, V38, P1944, DOI 10.1007/s10803-008-0590-6
   Reichow B, 2010, J AUTISM DEV DISORD, V40, P149, DOI 10.1007/s10803-009-0842-0
   Robins B., 2005, Universal Access in the Information Society, V4, P105, DOI 10.1007/s10209-005-0116-3
   Rogers C, 2015, P 10 ANN ACM IEEE IN, P173
   Sanson F, 2016, P INT C SOC ROB THER
   SICILEKIRA C, 2004, AUTISM SPECTRUM DISO
   Strawhacker AL, 2014, INT J TECHNOL DES ED
   Sullivan A., 2015, P 14 INT C INT DES C
   Sullivan A, 2015, INT J TECHNOL DES ED
   Sullivan A, 2018, INT J TECHNOL DES ED, V28, P325, DOI 10.1007/s10798-017-9397-0
   Sullivan A, 2013, J INF TECHNOL EDUC-I, V12, P203
   Sullivan A, 2013, INT J TECHNOL DES ED, V23, P691, DOI 10.1007/s10798-012-9210-z
   Valenzuela E, 2015, P INT C SOC ROB THER
   Wainer J, 2010, PERS UBIQUIT COMPUT, V14, P445, DOI 10.1007/s00779-009-0266-z
   Werry I, 2001, P AAATE
NR 40
TC 0
Z9 0
U1 9
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1875-4791
EI 1875-4805
J9 INT J SOC ROBOT
JI Int. J. Soc. Robot.
PD JUN
PY 2018
VL 10
IS 3
SI SI
BP 371
EP 383
DI 10.1007/s12369-018-0479-2
PG 13
WC Robotics
SC Robotics
GA GJ5LP
UT WOS:000435423100007
DA 2019-02-18
ER

PT J
AU Kachergis, G
   Yu, C
AF Kachergis, George
   Yu, Chen
TI Observing and Modeling Developing Knowledge and Uncertainty During
   Cross-Situational Word Learning
SO IEEE TRANSACTIONS ON COGNITIVE AND DEVELOPMENTAL SYSTEMS
LA English
DT Article
DE Cross-situational word learning; language acquisition; memory-guided
   attention; statistical learning
ID MAPPINGS; ACCOUNT
AB Being able to learn word meanings across multiple scenes consisting of multiple words and referents (i.e., cross-situationally) is thought to be important for language acquisition. The ability has been studied in infants, children, and adults, and yet there is much debate about the basic storage and retrieval mechanisms that operate during cross-situational word learning. It has been difficult to uncover the learning mechanics in part because the standard experimental paradigm, which presents a few words and objects on each of a series of training trials, measures learning only at the end of training, after several occurrences of each word-object pair. Diverse models are able to match the final level of performance of the standard paradigm, while the rich history and context of the learning trajectories remain obscured. This paper examines accuracy and uncertainty over time in a version of the cross-situational learning task in which words are tested throughout training, as well as in a final test. With similar levels of performance to the standard task, we examine how well the online response trajectories match recent hypothesis-and association-based computational models of word learning.
C1 [Kachergis, George] Radboud Univ Nijmegen, Donders Inst Brain Cognit & Behav, Dept Artificial Intelligence, NL-10003 Nijmegen, Netherlands.
   [Yu, Chen] Indiana Univ, Dept Psychol & Brain Sci, Bloomington, IN 47408 USA.
RP Kachergis, G (reprint author), Radboud Univ Nijmegen, Donders Inst Brain Cognit & Behav, Dept Artificial Intelligence, NL-10003 Nijmegen, Netherlands.
EM g.kachergis@donders.ru.nl
OI Kachergis, George/0000-0003-4153-4167
FU National Institute of Health [R01HD056029, R01HD074601]
FX This work was supported by the National Institute of Health under Grant
   R01HD056029 and Grant R01HD074601.
CR Berns GS, 1997, SCIENCE, V276, P1272, DOI 10.1126/science.276.5316.1272
   Blythe RA, 2010, COGNITIVE SCI, V34, P620, DOI 10.1111/j.1551-6709.2009.01089.x
   CARRIER M, 1992, MEM COGNITION, V20, P633, DOI 10.3758/BF03202713
   Fazly A, 2010, COGNITIVE SCI, V34, P1017, DOI 10.1111/j.1551-6709.2010.01104.x
   Gleitman Lelia, 1990, LANG ACQUIS, V1, P3, DOI DOI 10.1207/S15327817LA0101_2
   Kachergis G, 2012, P 34 ANN C COGN SCI, P533
   Kachergis G., 2009, P 31 ANN M COGN SCI, P1704
   Kachergis G., 2012, 2012 IEEE INT C DEV, P1
   Kachergis G, 2017, COGNITIVE SCI, V41, P590, DOI 10.1111/cogs.12353
   Kachergis G, 2014, FOUTH JOINT IEEE INTERNATIONAL CONFERENCES ON DEVELOPMENT AND LEARNING AND EPIGENETIC ROBOTICS (IEEE ICDL-EPIROB 2014), P20, DOI 10.1109/DEVLRN.2014.6982949
   Kachergis G, 2012, PSYCHON B REV, V19, P317, DOI 10.3758/s13423-011-0194-6
   Lopes LS, 2007, INTERACT STUD, V8, P53, DOI 10.1075/is.8.1.05lop
   Lyon C, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0038236
   Medina TN, 2011, P NATL ACAD SCI USA, V108, P9014, DOI 10.1073/pnas.1105040108
   Perruchet P, 2006, TRENDS COGN SCI, V10, P233, DOI 10.1016/j.tics.2006.03.006
   REBER AS, 1967, J VERB LEARN VERB BE, V6, P855, DOI 10.1016/S0022-5371(67)80149-X
   ROUSSEEUW PJ, 1987, J COMPUT APPL MATH, V20, P53, DOI 10.1016/0377-0427(87)90125-7
   Saffran JR, 1996, J MEM LANG, V35, P606, DOI 10.1006/jmla.1996.0032
   Siskind JM, 1996, COGNITION, V61, P39, DOI 10.1016/S0010-0277(96)00728-7
   SMITH LB, 2000, BECOMING WORD LEARNE, P51
   Suanda SH, 2014, J EXP CHILD PSYCHOL, V126, P395, DOI 10.1016/j.jecp.2014.06.003
   Suanda SH, 2012, COGNITIVE SCI, V36, P545, DOI 10.1111/j.1551-6709.2011.01218.x
   Trueswell JC, 2013, COGNITIVE PSYCHOL, V66, P126, DOI 10.1016/j.cogpsych.2012.10.001
   Vlach H. A., 2012, FRONT PSYCHOL, V3, P1
   Vouloumanos A, 2008, COGNITION, V107, P729, DOI 10.1016/j.cognition.2007.08.007
   Yu C, 2007, PSYCHOL SCI, V18, P414, DOI 10.1111/j.1467-9280.2007.01915.x
   Yu C, 2012, PSYCHOL REV, V119, P21, DOI 10.1037/a0026182
   Yu C, 2008, LANG LEARN DEV, V4, P32, DOI 10.1080/15475440701739353
   Yurovsky D, 2015, COGNITION, V145, P53, DOI 10.1016/j.cognition.2015.07.013
NR 29
TC 2
Z9 2
U1 2
U2 3
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2379-8920
EI 2379-8939
J9 IEEE T COGN DEV SYST
JI IEEE Trans. Cogn. Dev. Syst.
PD JUN
PY 2018
VL 10
IS 2
SI SI
BP 227
EP 236
DI 10.1109/TCDS.2017.2735540
PG 10
WC Computer Science, Artificial Intelligence; Robotics; Neurosciences
SC Computer Science; Robotics; Neurosciences & Neurology
GA GJ3MC
UT WOS:000435198600010
DA 2019-02-18
ER

PT J
AU Kawai, Y
   Nagai, Y
   Asada, M
AF Kawai, Yuji
   Nagai, Yukie
   Asada, Minoru
TI Prediction Error in the PMd As a Criterion for Biological Motion
   Discrimination: A Computational Account
SO IEEE TRANSACTIONS ON COGNITIVE AND DEVELOPMENTAL SYSTEMS
LA English
DT Article
DE Biological motion; dorsal premotor area (PMd); one-third power law;
   predictive learning; recurrent neural network
ID 2-THIRDS POWER-LAW; FACE-LIKE STIMULI; ARM MOVEMENTS; BRAIN-AREAS;
   CORTICAL REPRESENTATION; EMOTION PERCEPTION; DRAWING MOVEMENTS; FMRI
   ACTIVATION; DIFFERENT PARTS; MIRROR NEURONS
AB Neuroscientific studies suggest that the dorsal premotor area is activated by biological motions, and is also related to the prediction errors of observed and self-induced motions. We hypothesize that biological and nonbiological motions can be discriminated by such prediction errors. We therefore propose a model to verify this hypothesis. A neural network model is constructed that learns to predict the velocity of the self's next body movement from that of the present one and produces a smooth movement. Consequently, a property of the input sequence is represented. The trained network evaluates observed motions based on the prediction errors. If these errors are small, the movements share a representation with the self-motor property, and therefore, are regarded as biological ones. To verify our hypothesis, we examined how the network represents the biological motions. The results show that predictive learning, supported by a recurrent structure, helps to obtain the representation that discriminates between biological and nonbiological motions. Moreover, this recurrent neural network can discriminate the ankle and wrist trajectories of a walking human as biological motion, regardless of the subject's sex, or emotional state.
C1 [Kawai, Yuji; Nagai, Yukie; Asada, Minoru] Osaka Univ, Grad Sch Engn, Osaka 5650871, Japan.
RP Kawai, Y (reprint author), Osaka Univ, Grad Sch Engn, Osaka 5650871, Japan.
EM kawai@ams.eng.osaka-u.ac.jp; yukie@ams.eng.osaka-u.ac.jp;
   asada@ams.eng.osaka-u.ac.jp
FU JSPS [24000012];  [13J00756]
FX This work was supported in part by the JSPS Grants-in-Aid for Specially
   Promoted Research under Grant 24000012, and in part by the Grants-in-Aid
   for JSPS Fellows under Grant 13J00756.
CR Atkinson AP, 2004, PERCEPTION, V33, P717, DOI 10.1068/p5096
   BARCLAY CD, 1978, PERCEPT PSYCHOPHYS, V23, P145, DOI 10.3758/BF03208295
   Bardi L, 2011, DEVELOPMENTAL SCI, V14, P353, DOI 10.1111/j.1467-7687.2010.00985.x
   Beets IAM, 2010, J NEUROPHYSIOL, V104, P1612, DOI 10.1152/jn.00974.2009
   Bonda E, 1996, J NEUROSCI, V16, P3737
   Brass M, 2005, TRENDS COGN SCI, V9, P489, DOI 10.1016/j.tics.2005.08.007
   Brodmann K, 1909, VERGLEICHENDE LOKALI
   CAMINITI R, 1990, J NEUROSCI, V10, P2039
   CAMINITI R, 1991, J NEUROSCI, V11, P1182
   Casile A, 2010, CEREB CORTEX, V20, P1647, DOI 10.1093/cercor/bhp229
   Centelles L, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0015749
   Chang DHF, 2008, J VISION, V8, DOI 10.1167/8.5.3
   Clark A, 2013, BEHAV BRAIN SCI, V36, P181, DOI 10.1017/S0140525X12000477
   Cook JL, 2013, BRAIN, V136, P2816, DOI 10.1093/brain/awt208
   Copete JL, 2016, 2016 JOINT IEEE INTERNATIONAL CONFERENCE ON DEVELOPMENT AND LEARNING AND EPIGENETIC ROBOTICS (ICDL-EPIROB), P223, DOI 10.1109/DEVLRN.2016.7846823
   Cottrell G. W., 1988, ADV COGNITIVE SCI, V2, P208
   Courtine G, 2005, BRAIN, V128, P2338, DOI 10.1093/brain/awh604
   Culham JC, 2003, EXP BRAIN RES, V153, P180, DOI 10.1007/s00221-003-1591-5
   Dayal V. S., 1973, CAN J OTOLARYNGOL, V2, P136
   Dayan E, 2007, P NATL ACAD SCI USA, V104, P20582, DOI 10.1073/pnas.0710033104
   deSperati C, 1997, J NEUROSCI, V17, P3932
   Di Dio C, 2013, NEUROIMAGE, V64, P425, DOI 10.1016/j.neuroimage.2012.09.026
   Diedrichsen J, 2005, J NEUROSCI, V25, P9919, DOI 10.1523/JNEUROSCI.1874-05.2005
   DIPELLEGRINO G, 1992, EXP BRAIN RES, V91, P176, DOI 10.1007/BF00230027
   Dominey PF, 2009, BRAIN LANG, V109, P80, DOI 10.1016/j.bandl.2008.08.002
   Emberson LL, 2015, P NATL ACAD SCI USA, V112, P9585, DOI 10.1073/pnas.1510343112
   Fadiga L, 2000, INT J PSYCHOPHYSIOL, V35, P165, DOI 10.1016/S0167-8760(99)00051-3
   Filimon F, 2007, NEUROIMAGE, V37, P1315, DOI 10.1016/j.neuroimage.2007.06.008
   FLASH T, 1985, J NEUROSCI, V5, P1688
   Friston KJ, 2009, PHILOS T R SOC B, V364, P1211, DOI 10.1098/rstb.2008.0300
   Fuke S, 2007, INT J HUM ROBOT, V4, P347, DOI 10.1142/S0219843607001096
   Gallese V, 2004, TRENDS COGN SCI, V8, P396, DOI 10.1016/j.tics.2004.07.002
   Gallese V, 1998, TRENDS COGN SCI, V2, P493, DOI 10.1016/S1364-6613(98)01262-5
   Giese MA, 2003, NAT REV NEUROSCI, V4, P179, DOI 10.1038/nrn1057
   GOREN CC, 1975, PEDIATRICS, V56, P544
   Gribble PL, 1996, J NEUROPHYSIOL, V76, P2853
   Grossman E, 2000, J COGNITIVE NEUROSCI, V12, P711, DOI 10.1162/089892900562417
   Harada A., 1998, TECH REP IEICE NEURO, V97, P237
   HOUK JC, 1993, TRENDS NEUROSCI, V16, P27, DOI 10.1016/0166-2236(93)90049-R
   Howard RJ, 1996, CURR BIOL, V6, P1015, DOI 10.1016/S0960-9822(02)00646-2
   Irie B., 1990, Transactions of the Institute of Electronics, Information and Communication Engineers D-II, VJ73D-II, P1173
   Ishiguro H, 2006, CONNECT SCI, V18, P319, DOI 10.1080/09540090600873953
   Ivanenko YP, 2002, J NEUROPHYSIOL, V87, P3070, DOI 10.1152/jn.2002.87.6.3070
   JOHNSON MH, 1991, COGNITION, V40, P1, DOI 10.1016/0010-0277(91)90045-6
   Kandel E. R, 2012, PRINCIPLES NEURAL SC
   Karklinsky M, 2015, J NEUROPHYSIOL, V113, P2490, DOI 10.1152/jn.00421.2014
   Kawai Y, 2014, FOUTH JOINT IEEE INTERNATIONAL CONFERENCES ON DEVELOPMENT AND LEARNING AND EPIGENETIC ROBOTICS (IEEE ICDL-EPIROB 2014), P249, DOI 10.1109/DEVLRN.2014.6982989
   LACQUANITI F, 1983, ACTA PSYCHOL, V54, P115, DOI 10.1016/0001-6918(83)90027-6
   Ma YL, 2006, BEHAV RES METHODS, V38, P134, DOI 10.3758/BF03192758
   Malfait N, 2010, J COGNITIVE NEUROSCI, V22, P1493, DOI 10.1162/jocn.2009.21281
   Matelli M, 2001, NEUROIMAGE, V14, pS27, DOI 10.1006/nimg.2001.0835
   MAUNSELL JHR, 1983, J NEUROPHYSIOL, V49, P1127
   Meary D, 2007, PLOS ONE, V2, DOI 10.1371/journal.pone.0000186
   Meirovitch Y, 2015, J NEUROSCI, V35, P1627, DOI 10.1523/JNEUROSCI.5371-13.2015
   MELTZOFF AN, 1977, SCIENCE, V198, P75, DOI 10.1126/science.198.4312.75
   Meltzoff AN, 1997, EARLY DEV PARENTING, V6, P179, DOI 10.1002/(SICI)1099-0917(199709/12)6:3/4<179::AID-EDP157>3.3.CO;2-I
   Mori M., 1970, ENERGY, V7, P33, DOI DOI 10.1109/MRA.2012.2192811
   Nagai Y., 2015, P IROS WORKSH SENS C
   Nehaniv CL, 2002, FROM ANIM ANIMAT, P41
   Peuskens H, 2005, EUR J NEUROSCI, V21, P2864, DOI 10.1111/j.1460-9568.2005.04106.x
   Prinz W, 1997, EUR J COGN PSYCHOL, V9, P129, DOI 10.1080/713752551
   Prinz W., 1990, COMMON CODING APPROA
   Rizzolatti G, 2004, ANNU REV NEUROSCI, V27, P169, DOI 10.1146/annurev.neuro.27.070203.144230
   Saegusa R, 2004, NEUROCOMPUTING, V61, P57, DOI 10.1016/j.neucom.2004.03.004
   Sawaragi T, 2003, IEEE T IND ELECTRON, V50, P903, DOI 10.1109/TIE.2003.817608
   Saygin AP, 2012, SOC COGN AFFECT NEUR, V7, P413, DOI 10.1093/scan/nsr025
   Schaal S, 2001, EXP BRAIN RES, V136, P60, DOI 10.1007/s002210000505
   Schillaci G, 2013, ACMIEEE INT CONF HUM, P223, DOI 10.1109/HRI.2013.6483582
   Schrodt F, 2015, FRONT COMPUT NEUROSC, V9, DOI 10.3389/fncom.2015.00079
   Schubotz RI, 2007, TRENDS COGN SCI, V11, P211, DOI 10.1016/j.tics.2007.02.006
   Schwartz AB, 1999, J NEUROPHYSIOL, V82, P2705
   SCHWARTZ AB, 1994, SCIENCE, V265, P540, DOI 10.1126/science.8036499
   Simion F, 2008, P NATL ACAD SCI USA, V105, P809, DOI 10.1073/pnas.0707021105
   Song W., 2009, P 2 INT C COGN NEUR, P441
   Stadler W, 2011, HUM BRAIN MAPP, V32, P677, DOI 10.1002/hbm.20949
   Stanley J, 2010, NEUROIMAGE, V52, P389, DOI 10.1016/j.neuroimage.2010.04.025
   Troje N.F., 2008, SENSES COMPREHENSIVE, P231
   Uemura K., 2000, NEUROCOMPUTING, V99, P71
   VIVIANI P, 1995, J EXP PSYCHOL HUMAN, V21, P32, DOI 10.1037/0096-1523.21.1.32
   VONHOFSTEN C, 1991, J MOTOR BEHAV, V23, P280, DOI 10.1080/00222895.1991.9942039
   Wang Y, 2012, FRONT HUM NEUROSCI, V6, DOI 10.3389/fnhum.2012.00153
   Wing A., 2001, P EUROHAPTICS, P76
   Wolfensteller U, 2007, NEUROIMAGE, V36, pT33, DOI 10.1016/j.neuroimage.2007.03.040
   Wolpert DM, 2003, PHILOS T R SOC B, V358, P593, DOI 10.1098/rstb.2002.1238
   Zoia S, 2007, EXP BRAIN RES, V176, P217, DOI 10.1007/s00221-006-0607-3
NR 85
TC 0
Z9 0
U1 1
U2 1
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2379-8920
EI 2379-8939
J9 IEEE T COGN DEV SYST
JI IEEE Trans. Cogn. Dev. Syst.
PD JUN
PY 2018
VL 10
IS 2
SI SI
BP 237
EP 249
DI 10.1109/TCDS.2017.2668446
PG 13
WC Computer Science, Artificial Intelligence; Robotics; Neurosciences
SC Computer Science; Robotics; Neurosciences & Neurology
GA GJ3MC
UT WOS:000435198600011
OA Bronze
DA 2019-02-18
ER

PT J
AU Miwa, T
   Sakai, Y
   Hashimoto, S
AF Miwa, Takanobu
   Sakai, Yukihito
   Hashimoto, Shuji
TI Learning 4-D Spatial Representations Through Perceptual Experience With
   Hypercubes
SO IEEE TRANSACTIONS ON COGNITIVE AND DEVELOPMENTAL SYSTEMS
LA English
DT Article
DE 4-D interaction; perspective taking; spatial representations; spatial
   transformations; spatial visualization ability
ID MENTAL ROTATION; ABILITY; PERFORMANCE; DISSOCIATION
AB Imagine a day when humans can form mental representations of higher-dimensional space and objects. These higher-dimensional spatial representations may enable us to gain unique insights into scientific and cultural advancements. To augment human spatial cognition from three to four dimensions, we have developed an interactive 4-D visualization system for acquiring an understanding of 4-D space and objects. In this paper, we examine whether humans are capable of formulating 4-D spatial representations through perceptual experience in 4-D space with 4-D objects. Participants learn about 4-U space and hypercubes through an interactive system, and are then examined on a series of 4-D spatial ability tests. They demonstrate the ability to perform perspective taking, navigation, and mental spatial transformation tasks in 4-U space. The results provide empirical evidence that humans are capable of learning 4-U spatial representations. Moreover, the results support the interpretation that humans form a cognitive coordinate system, consisting of an origin and four directional axes, to understand 4-U space and objects.
C1 [Miwa, Takanobu; Hashimoto, Shuji] Waseda Univ, Fac Sci & Engn, Tokyo 1698555, Japan.
   [Sakai, Yukihito] Fukuoka Univ, Fac Engn, Fukuoka, Fukuoka 8140180, Japan.
RP Miwa, T (reprint author), Waseda Univ, Fac Sci & Engn, Tokyo 1698555, Japan.
EM takmiwa@shalab.phys.waseda.ac.jp
FU Waseda University [2015S-084]; Waseda University Future Robotics
   Organization
FX This work was supported in part by Waseda University Grant for Special
   Research Projects (Project number: 2015S-084), and in part by the Waseda
   University Future Robotics Organization.
CR Aflalo TN, 2008, J EXP PSYCHOL HUMAN, V34, P1066, DOI 10.1037/0096-1523.34.5.1066
   Aguilera J. C., 2006, P SOC PHOTO-OPT INS, V6055, P605
   Ambinder MS, 2009, PSYCHON B REV, V16, P818, DOI 10.3758/PBR.16.5.818
   Blanke O, 2005, J NEUROSCI, V25, P550, DOI 10.1523/JNEUROSCI.2612-04.2005
   Branoff T. J., 2000, ENG DESIGN GRAPHICS, V64, P14
   Charstil E. R., 2014, PLOS ONE, V9
   Cheng YL, 2014, J COGN DEV, V15, P2, DOI 10.1080/15248372.2012.725186
   D'Zmura M, 2000, PRESENCE-TELEOP VIRT, V9, P616, DOI 10.1162/105474600300040411
   Davis P. J., 1995, MATH EXPERIENCE, P442
   Dewdney A. K., 1986, SCI AM, V254, P8
   Estes Z, 2012, ARCH SEX BEHAV, V41, P557, DOI 10.1007/s10508-011-9875-5
   FOLEY JD, 1995, COMPUTER GRAPHICS PR
   Hanson A. J., 1998, COURSE NOTES SIGGRAP
   Hanson AJ, 2005, IEEE Visualization 2005, Proceedings, P263
   HAUSMANN B, 1994, COMPUT GRAPH FORUM, V13, pC305
   Hegarty M, 2004, TRENDS COGN SCI, V8, P280, DOI 10.1016/j.tics.2004.04.001
   Hegarty M, 2004, INTELLIGENCE, V32, P175, DOI 10.1016/j.intell.2003.12.001
   Hegarty M, 2002, INTELLIGENCE, V30, P425, DOI 10.1016/S0160-2896(02)00116-2
   Hollasch Steven Richard, 1991, THESIS
   Ishihara K, 1989, 4 DIMENSIONAL GRAPHI
   JUST MA, 1985, PSYCHOL REV, V92, P137, DOI 10.1037/0033-295X.92.2.137
   Kondo K., 1988, Transactions of the Information Processing Society of Japan, V29, P686
   Kozhevnikov M, 2006, APPL COGNITIVE PSYCH, V20, P397, DOI 10.1002/acp.1192
   Kozhevnikov M, 2001, MEM COGNITION, V29, P745, DOI 10.3758/BF03200477
   Lynch Kevin., 1960, IMAGE CITY
   Matsuoka K., 2009, JPN J MENT IMAG, V7, P19
   McGlone MS, 2006, J APPL DEV PSYCHOL, V27, P486, DOI 10.1016/j.appdev.2006.06.003
   Miwa Takanobu, 2015, Computer-Human Interaction. Cognitive Effects of Spatial Interaction, Learning and Ability. 25th Australian Computer-Human Interaction Conference, OzCHI 2013. Revised and Extended Papers: LNCS 8433, P21, DOI 10.1007/978-3-319-16940-8_2
   Miwa T., 2013, J SOC ART SCI, V4, P162
   Miwa T., 2015, P ACM SIGGRAPH S APP, P75
   Miwa T., 2013, P 25 AUSTR COMP HUM, P95
   Miyazaki K., 2005, SCI HIGHER DIMENSION
   Neophytou N, 2002, IEEE/ACM SIGGRAPH SYMPOSIUM ON VOLUME VISUALIZATION AND GRAPHICS 2002, PROCEEDINGS, P97, DOI 10.1109/SWG.2002.1226515
   PETERS M, 1995, BRAIN COGNITION, V28, P39, DOI 10.1006/brcg.1995.1032
   Piaget J, 1967, CHILDS CONCEPTION SP
   PRESSON CC, 1994, PERCEPTION, V23, P1447, DOI 10.1068/p231447
   Sakai Y., 2006, Journal of the Institute of Image Information and Television Engineers, V60, P1630, DOI 10.3169/itej.60.1630
   Sakai Yukihito, 2007, Journal of the Institute of Image Electronics Engineers of Japan, V36, P371
   Sakai Y., 2007, B SOC SCI FORM, V21, P274
   Sakai Y, 2011, FORMA, V26, P11
   Sakai Y, 2011, J VISUAL-JAPAN, V14, P129, DOI 10.1007/s12650-011-0079-9
   Schwartz DL, 1996, COGNITIVE SCI, V20, P457, DOI 10.1207/s15516709cog2004_1
   SHEPARD RN, 1971, SCIENCE, V171, P701, DOI 10.1126/science.171.3972.701
   Stieff M, 2007, LEARN INSTR, V17, P219, DOI 10.1016/j.learninstruc.2007.01.012
   TOLMAN EC, 1948, PSYCHOL REV, V55, P189, DOI 10.1037/h0061626
   Wai J, 2009, J EDUC PSYCHOL, V101, P817, DOI 10.1037/a0016127
   Wang R. F., 2014, SPACE MIND CONCEPTS, P119
   Wang RF, 2014, SPAT COGN COMPUT, V14, P91, DOI 10.1080/13875868.2013.870569
   Wang RF, 2009, FCST 2009: PROCEEDINGS OF THE 4TH INTERNATIONAL CONFERENCE ON FRONTIER OF COMPUTER SCIENCE AND TECHNOLOGY, P519, DOI 10.1109/FCST.2009.93
   Wohlschlager A, 2003, PHILOS T R SOC B, V358, P501, DOI 10.1098/rstb.2002.1257
   Woodring J, 2003, IEEE VISUALIZATION 2003, PROCEEDINGS, P417, DOI 10.1109/VISUAL.2003.1250402
   Wraga M, 2003, BRAIN COGNITION, V52, P135, DOI 10.1016/S0278-2626(03)00033-2
   Yan XQ, 2012, COMPUTER, V45, P80, DOI 10.1109/MC.2012.77
   Zhang H, 2007, IEEE T VIS COMPUT GR, V13, P1688, DOI 10.1109/TVCG.2007.70593
NR 54
TC 0
Z9 0
U1 3
U2 3
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2379-8920
EI 2379-8939
J9 IEEE T COGN DEV SYST
JI IEEE Trans. Cogn. Dev. Syst.
PD JUN
PY 2018
VL 10
IS 2
SI SI
BP 250
EP 266
DI 10.1109/TCDS.2017.2710420
PG 17
WC Computer Science, Artificial Intelligence; Robotics; Neurosciences
SC Computer Science; Robotics; Neurosciences & Neurology
GA GJ3MC
UT WOS:000435198600012
DA 2019-02-18
ER

PT J
AU Zeng, Y
   Wang, GX
   Xu, B
AF Zeng, Yi
   Wang, Guixiang
   Xu, Bo
TI A Basal Ganglia Network Centric Reinforcement Learning Model and Its
   Application in Unmanned Aerial Vehicle
SO IEEE TRANSACTIONS ON COGNITIVE AND DEVELOPMENTAL SYSTEMS
LA English
DT Article
DE Basal ganglia (BG) network; brain-inspired intelligence; precise
   encoding; reinforcement learning model; unmanned aerial vehicle (UAV)
   autonomous learning
ID ORBITOFRONTAL CORTEX; FUNCTIONAL-ANATOMY; DECISION-MAKING; BRAIN;
   CIRCUITS
AB Reinforcement learning brings flexibility and generality for machine learning, while most of them are mathematical optimization driven approaches, and lack of cognitive and neural evidence. In order to provide a more cognitive and neural mechanisms driven foundation and validate its applicability in complex task, we develop a basal ganglia (BG) network centric reinforcement learning model. Compared to existing work on modeling BG, this paper is unique from the following perspectives: 1) the orbitofrontal cortex (OFC) is taken into consideration. OFC is critical in decision making because of its responsibility for reward representation and is critical in controlling the learning process, while most of the BG centric models do not include OFC; 2) to compensate the inaccurate memory of numeric values, precise encoding is proposed to enable working memory system remember important values during the learning process. The method combines vector convolution and the idea of storage by digit bit and is efficient for accurate value storage; and 3) for information coding, the Hodgkin-Huxley model is used to obtain a more biological plausible description of action potential with plenty of ionic activities. To validate the effectiveness of the proposed model, we apply the model to the unmanned aerial vehicle (UAV) autonomous learning process in a 3-D environment. Experimental results show that our model is able to give the UAV the ability of free exploration in the environment and has comparable learning speed as the Q learning algorithm, while the major advances for our model is that it is with solid cognitive and neural basis.
C1 [Zeng, Yi; Wang, Guixiang; Xu, Bo] Chinese Acad Sci, Inst Automat, Beijing 100190, Peoples R China.
   [Zeng, Yi; Xu, Bo] Chinese Acad Sci, Ctr Excellence Brain Sci & Intelligence Technol, Shanghai 200031, Peoples R China.
RP Zeng, Y (reprint author), Chinese Acad Sci, Inst Automat, Beijing 100190, Peoples R China.
EM yi.zeng@ia.ac.cn
OI Zeng, Yi/0000-0002-9595-9091
FU Chinese Academy of Sciences [XDB02060007]; Beijing Municipal Commission
   of Science and Technology [Z151100000915070, Z161100000216124]
FX This work was supported in part by the Strategic Priority Research
   Program of the Chinese Academy of Sciences under Grant XDB02060007, and
   in part by the Beijing Municipal Commission of Science and Technology
   under Grants Z151100000915070 and Z161100000216124.
CR ALBIN RL, 1989, TRENDS NEUROSCI, V12, P366, DOI 10.1016/0166-2236(89)90074-X
   Bar-Gad I., 2011, CURRENT OPIN NEUROBI, V11, P689
   Bekolay T., 2011, P COMP SYST NEUR C S, P24
   Cessac B, 2010, J PHYSIOL-PARIS, V104, P5, DOI 10.1016/j.jphysparis.2009.11.002
   Chakravarthy VS, 2010, BIOL CYBERN, V103, P237, DOI 10.1007/s00422-010-0401-y
   Chee KY, 2013, SENSOR ACTUAT A-PHYS, V190, P66, DOI 10.1016/j.sna.2012.11.017
   Dayan P., 2003, COMPUTATIONAL MATH M
   Dethier J, 2011, I IEEE EMBS C NEUR E, P396, DOI 10.1109/NER.2011.5910570
   Eliasmith C., 2013, HOW TO BUILD A BRAIN, P121
   Eliasmith C, 2012, SCIENCE, V338, P1202, DOI 10.1126/science.1225266
   Eliasmith Chris, 2003, NEURAL ENG COMPUTATI
   Frank MJ, 2006, NEURAL NETWORKS, V19, P1120, DOI 10.1016/j.neunet.2006.03.006
   Frank MJ, 2006, PSYCHOL REV, V113, P300, DOI 10.1037/0033-295X.113.2.300
   Frank MJ, 2005, J COGNITIVE NEUROSCI, V17, P51, DOI 10.1162/0898929052880093
   Frith C, 1996, COGNITIVE BRAIN RES, V5, P175, DOI 10.1016/S0926-6410(96)00054-7
   Gerstner W., 2002, SPIKING NEURON MODEL
   Gurney K, 2001, BIOL CYBERN, V84, P401, DOI 10.1007/PL00007984
   Gurney K, 2004, TRENDS NEUROSCI, V27, P453, DOI 10.1016/j.tins.2004.06.003
   HODGKIN AL, 1952, J PHYSIOL-LONDON, V117, P500, DOI 10.1113/jphysiol.1952.sp004764
   IARC, 2015, OFF RUL INT AER ROB
   Igarashi J, 2011, NEURAL NETWORKS, V24, P950, DOI 10.1016/j.neunet.2011.06.008
   Ito M, 2011, CURR OPIN NEUROBIOL, V21, P368, DOI 10.1016/j.conb.2011.04.001
   Izhikevich E. M., 2004, DYNAMICAL SYSTEMS NE
   Kringelbach ML, 2005, NAT REV NEUROSCI, V6, P691, DOI 10.1038/nrn1747
   Kusterer R, 2013, JMONKEYENGINE 3 0 BE
   Lenay C, 2012, FRONT HUM NEUROSCI, V6, DOI 10.3389/fnhum.2012.00098
   Long L. N., 2010, P AIAA INFOTECH AER, P2010
   Maass W, 1997, NEURAL NETWORKS, V10, P1659, DOI 10.1016/S0893-6080(97)00011-7
   MacNeil D, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0022885
   Maia TV, 2009, COGN AFFECT BEHAV NE, V9, P343, DOI 10.3758/CABN.9.4.343
   Nelson M. E., 2004, DATABASING BRAIN DAT
   Prescott TJ, 2006, NEURAL NETWORKS, V19, P31, DOI 10.1016/j.neunet.2005.06.049
   Redgrave P, 2010, NAT REV NEUROSCI, V11, P760, DOI 10.1038/nrn2915
   Stewart T. C., 2010, P 10 INT C COGN MOD, P5
   Stewart TC, 2014, P IEEE, V102, P881, DOI 10.1109/JPROC.2014.2306061
   Stocco A, 2010, PSYCHOL REV, V117, P541, DOI 10.1037/a0019077
   Szepesvari C., 2010, ALGORITHMS REINFORCE
   Takahashi YK, 2009, NEURON, V62, P269, DOI 10.1016/j.neuron.2009.03.005
   Utter AA, 2008, NEUROSCI BIOBEHAV R, V32, P333, DOI 10.1016/j.neubiorev.2006.11.003
   Vasarhelyi G, 2014, IEEE INT C INT ROBOT, P3866, DOI 10.1109/IROS.2014.6943105
   Wang G. X., 2016, LNCS, V10023, P125
   Wang J, 2007, CHAOS SOLITON FRACT, V31, P247, DOI 10.1016/j.chaos.2005.09.060
   Weber C., 2008, REINFORCEMENT LEARNI
   Wells R. B., 2010, INTRO BIOL SIGNAL PR
   Yang S., 2014, HKUST IARC TEAM PROG
NR 45
TC 1
Z9 2
U1 8
U2 15
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2379-8920
EI 2379-8939
J9 IEEE T COGN DEV SYST
JI IEEE Trans. Cogn. Dev. Syst.
PD JUN
PY 2018
VL 10
IS 2
SI SI
BP 290
EP 303
DI 10.1109/TCDS.2017.2649564
PG 14
WC Computer Science, Artificial Intelligence; Robotics; Neurosciences
SC Computer Science; Robotics; Neurosciences & Neurology
GA GJ3MC
UT WOS:000435198600015
DA 2019-02-18
ER

PT J
AU Acevedo-Valle, JM
   Angulo, C
   Moulin-Frier, C
AF Manuel Acevedo-Valle, Juan
   Angulo, Cecilio
   Moulin-Frier, Clement
TI Autonomous Discovery of Motor Constraints in an Intrinsically Motivated
   Vocal Learner
SO IEEE TRANSACTIONS ON COGNITIVE AND DEVELOPMENTAL SYSTEMS
LA English
DT Article
DE Active learning; early vocal development; Gaussian mixture models
   (GMMs); intrinsic motivations; sensorimotor exploration
ID SPEECH-PERCEPTION; ACQUISITION; ROBOTICS; MODELS
AB This paper introduces new results on the modeling of early vocal development using artificial intelligent cognitive architectures and a simulated vocal tract. The problem is addressed using intrinsically motivated learning algorithms for autonomous sensorimotor exploration, a kind of algorithm belonging to the active learning architectures family. The artificial agent is able to autonomously select goals to explore its own sensorimotor system in regions, where its competence to execute intended goals is improved. We propose to include a somatosensory system to provide a proprioceptive feedback signal to reinforce learning through the autonomous discovery of motor constraints. Constraints are represented by a somatosensory model which is unknown beforehand to the learner. Both the sensorimotor and somatosensory system are modeled using Gaussian mixture models. We argue that using an architecture which includes a somatosensory model would reduce redundancy in the sensorimotor model and drive the learning process more efficiently than algorithms taking into account only auditory feedback. The role of this proposed system is to predict whether an undesired collision within the vocal tract under a certain motor configuration is likely to occur. Thus, compromised motor configurations are rejected, guaranteeing that the agent is less prone to violate its own constraints.
C1 [Manuel Acevedo-Valle, Juan; Angulo, Cecilio] Univ Politecn Cataluna, GREC Res Grp, E-08028 Barcelona, Spain.
   [Moulin-Frier, Clement] Inria, ENSTA Paristech, Flowers Team, F-33405 Bordeaux, France.
   [Moulin-Frier, Clement] Univ Pompeu Fabra, SPECS Lab, Barcelona 08018, Spain.
RP Acevedo-Valle, JM (reprint author), Univ Politecn Cataluna, GREC Res Grp, E-08028 Barcelona, Spain.
EM juan.manuel.acevedo.valle@upc.edu
OI Acevedo-Valle, Juan Manuel/0000-0002-4005-2441; Moulin-Frier,
   Clement/0000-0002-7258-7256
FU PATRICIA Research Project through the Spanish Ministry of Economy and
   Competitiveness [TIN2012-38416-C03-01]; CONACYT [216872]
FX This work was supported by the PATRICIA Research Project through the
   Spanish Ministry of Economy and Competitiveness under Grant
   TIN2012-38416-C03-01. The work of J. M. Acevedo-Valle was supported by
   CONACYT under Grant 216872.
CR Acevedo-Valle J. M., 2015, P 18 INT C CAT ASS A, P9
   Asada M, 2009, IEEE T AUTON MENT DE, V1, P12, DOI 10.1109/TAMD.2009.2021702
   Baranes A, 2013, ROBOT AUTON SYST, V61, P49, DOI 10.1016/j.robot.2012.05.008
   Calinon S., 2009, ROBOT PROGRAMMING DE
   Cohn DA, 1996, J ARTIF INTELL RES, V4, P129, DOI 10.1613/jair.295
   Ejiri K, 1998, PHONETICA, V55, P226, DOI 10.1159/000028434
   Galantucci B, 2006, PSYCHON B REV, V13, P361, DOI 10.3758/BF03193857
   Gottlieb J, 2013, TRENDS COGN SCI, V17, P585, DOI 10.1016/j.tics.2013.09.001
   Guenther FH, 2006, BRAIN LANG, V96, P280, DOI 10.1016/j.bandl.2005.06.001
   Howard IS, 2011, MOTOR CONTROL, V15, P85, DOI 10.1123/mcj.15.1.85
   Ito T, 2009, P NATL ACAD SCI USA, V106, P1245, DOI 10.1073/pnas.0810063106
   Iyer SN, 2008, VOLTA REV, V108, P115
   Kroger BJ, 2009, SPEECH COMMUN, V51, P793, DOI 10.1016/j.specom.2008.08.002
   Kuhl PK, 2004, NAT REV NEUROSCI, V5, P831, DOI 10.1038/nrn1533
   Moulin-Frier C., 2014, P 1 MULT C REINF LEA
   Moulin-Frier C., 2013, IEEE 3 JOINT INT C D, P1, DOI DOI 10.1109/DEVLRN.2013.6652535
   Moulin-Frier C., 2013, P INTERSPEECH, P1268
   Moulin-Frier C, 2014, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.01006
   Nasir SM, 2008, NAT NEUROSCI, V11, P1217, DOI 10.1038/nn.2193
   OLLER DK, 1988, CHILD DEV, V59, P441, DOI 10.2307/1130323
   Oudeyer PY, 2007, IEEE T EVOLUT COMPUT, V11, P265, DOI 10.1109/TEVC.2006.890271
   Perkell J., 2001, P 1 INT S MEAS AN MO, P359
   PFEIFER R, 1999, UNDERSTANDING INTELL
   Pfeifer R, 2007, SCIENCE, V318, P1088, DOI 10.1126/science.1145803
   Ribes A, 2016, IEEE T COGN DEV SYST, V8, P26, DOI 10.1109/TAMD.2015.2441375
   Rolf M, 2010, IEEE T AUTON MENT DE, V2, P216, DOI 10.1109/TAMD.2010.2062511
   Schwartz JL, 2012, J NEUROLINGUIST, V25, P336, DOI 10.1016/j.jneuroling.2009.12.004
   Scott DW, 2015, WILEY SER PROBAB ST, P1, DOI 10.1002/9781118575574
   Thrun S., 1995, HDB BRAIN SCI NEURAL, P381
   Tremblay S, 2003, NATURE, V423, P866, DOI 10.1038/nature01710
   Warlaumont AS, 2013, NEURAL NETWORKS, V38, P64, DOI 10.1016/j.neunet.2012.11.012
NR 31
TC 1
Z9 1
U1 1
U2 1
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2379-8920
EI 2379-8939
J9 IEEE T COGN DEV SYST
JI IEEE Trans. Cogn. Dev. Syst.
PD JUN
PY 2018
VL 10
IS 2
SI SI
BP 314
EP 325
DI 10.1109/TCDS.2017.2699578
PG 12
WC Computer Science, Artificial Intelligence; Robotics; Neurosciences
SC Computer Science; Robotics; Neurosciences & Neurology
GA GJ3MC
UT WOS:000435198600017
DA 2019-02-18
ER

PT J
AU Sperati, V
   Baldassarre, G
AF Sperati, Valerio
   Baldassarre, Gianluca
TI Bio-Inspired Model Learning Visual Goals and Attention Skills Through
   Contingencies and Intrinsic Motivations
SO IEEE TRANSACTIONS ON COGNITIVE AND DEVELOPMENTAL SYSTEMS
LA English
DT Article
DE Goal-directed behavior; intrinsic motivations (IMs); overt attention
   routines/skills; reinforcement learning (RL); superior colliculus (SC)
   and basal ganglia (BG); top-down and bottom-up attention
ID AUTONOMOUS MENTAL-DEVELOPMENT; POSTERIOR PARIETAL CORTEX; SACCADIC
   EYE-MOVEMENTS; SUPERIOR COLLICULUS; BASAL GANGLIA; SHORT-LATENCY;
   SYSTEMS; EXPLORATION; INHIBITION; RETURN
AB Animal learning is driven not only by biological needs but also by intrinsic motivations (IMs) serving the acquisition of knowledge. Computational modeling involving IMs is indicating that learning of motor skills requires that autonomous agents self-generate tasks/goals and use them to acquire skills solving/leading to them. We propose a neural architecture driven by IMs that is able to self-generate goals on the basis of the environmental changes caused by the agent's actions. The main novelties of the model are that it is focused on the acquisition of attention (looking) skills and that its architecture and functioning are broadly inspired by the functioning of relevant primate brain areas (superior colliculus, basal ganglia, and frontal cortex). These areas, involved in IM-based behavior learning, play important functions for reflexive and voluntary attention. The model is tested within a simple simulated pan-tilt camera robot engaged in learning to switch on different lights by looking at them, and is able to self-generate visual goals and learn attention skills under IM guidance. The model represents a novel hypothesis on how primates and robots might autonomously learn attention skills and has a potential to account for developmental psychology experiments and the underlying brain mechanisms.
C1 [Sperati, Valerio; Baldassarre, Gianluca] CNR, Inst Cognit Sci & Technol, I-00185 Rome, Italy.
   [Sperati, Valerio] Plymouth Univ, Sch Comp & Math, Plymouth PL4 8AA, Devon, England.
RP Sperati, V (reprint author), CNR, Inst Cognit Sci & Technol, I-00185 Rome, Italy.
EM valerio.sperati@istc.cnr.it
OI Baldassarre, Gianluca/0000-0002-1277-4447; sperati,
   valerio/0000-0002-0135-1078
FU European Union Horizon 2020 Research and Innovation Programme [713010]
FX This work was supported by the European Union Horizon 2020 Research and
   Innovation Programme under Grant 713010 (Project: GOAL-Robots-Goal-Based
   Open-Ended Autonomous Learning Robots).
CR Anastasio TJ, 2010, TUTORIAL ON NEURAL SYSTEMS MODELING, P1
   Andersen RA, 2002, ANNU REV NEUROSCI, V25, P189, DOI 10.1146/annurev.neuro.25.112701.142922
   Andersen RA, 1997, ANNU REV NEUROSCI, V20, P303, DOI 10.1146/annurev.neuro.20.1.303
   Baldacchino G, 2013, INT POLIT ECON SER, P1
   Baldassarre G, 2011, P INT C DEV LEARN EP, pE1
   Baldassarre G., 2013, INTRINSICALLY MOTIVA
   Balkenius C., 2000, COGNITIVE SCI Q, V1, P171
   Baranes A, 2013, ROBOT AUTON SYST, V61, P49, DOI 10.1016/j.robot.2012.05.008
   Barto A. G., 2004, P 3 INT C DEV LEARN, P112
   Barto Andrew, 2013, Front Psychol, V4, P907, DOI 10.3389/fpsyg.2013.00907
   Benureau FCY, 2016, FRONT ROBOT AI, V3, DOI 10.3389/frobt.2016.00008
   Berlyne D.E., 1978, MOTIV EMOTION, V2, P97, DOI DOI 10.1007/BF00993037
   BERLYNE DE, 1966, SCIENCE, V153, P25, DOI 10.1126/science.153.3731.25
   Bratman M., 1987, INTENTIONS PLANS PRA
   Caligiore D, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0118705
   Comoli E, 2003, NAT NEUROSCI, V6, P974, DOI 10.1038/nn1113
   Dayan P., 2001, THEORETICAL NEUROSCI
   DEAN P, 1989, TRENDS NEUROSCI, V12, P137, DOI 10.1016/0166-2236(89)90052-0
   Deligianni F, 2011, DEV PSYCHOL, V47, P1499, DOI 10.1037/a0025659
   DesJardin JT, 2013, J NEUROSCI, V33, P150, DOI 10.1523/JNEUROSCI.2924-12.2013
   Di Domenico SI, 2017, FRONT HUM NEUROSCI, V11, DOI 10.3389/fnhum.2017.00145
   di Sorrentino EP, 2014, ANIM COGN, V17, P1081, DOI 10.1007/s10071-014-0740-5
   Diuk C., 2013, COMPUTATIONAL ROBOTI, P271
   Dommett E, 2005, SCIENCE, V307, P1476, DOI 10.1126/science.1107026
   Dorris MC, 2002, J COGNITIVE NEUROSCI, V14, P1256, DOI 10.1162/089892902760807249
   Elsner B, 2004, PSYCHOL RES-PSYCH FO, V68, P138, DOI 10.1007/s00426-003-0151-8
   Forestier S, 2016, 2016 JOINT IEEE INTERNATIONAL CONFERENCE ON DEVELOPMENT AND LEARNING AND EPIGENETIC ROBOTICS (ICDL-EPIROB), P238, DOI 10.1109/DEVLRN.2016.7846825
   Gilbert SJ, 2008, CURR BIOL, V18, pR110, DOI 10.1016/j.cub.2007.12.014
   Gottlieb J, 2013, TRENDS COGN SCI, V17, P585, DOI 10.1016/j.tics.2013.09.001
   Hikosaka O, 2000, PHYSIOL REV, V80, P953
   Ibbotson M, 2011, CURR OPIN NEUROBIOL, V21, P553, DOI 10.1016/j.conb.2011.05.012
   Joel D, 2002, NEURAL NETWORKS, V15, P535, DOI 10.1016/S0893-6080(02)00047-3
   KISH GB, 1955, J COMP PHYSIOL PSYCH, V48, P261, DOI 10.1037/h0040782
   KISH GB, 1961, J COMP PHYSIOL PSYCH, V54, P713, DOI 10.1037/h0046683
   Klein RM, 2000, TRENDS COGN SCI, V4, P138, DOI 10.1016/S1364-6613(00)01452-2
   Krauzlis RJ, 2013, ANNU REV NEUROSCI, V36, P165, DOI 10.1146/annurev-neuro-062012-170249
   Kulkarni T.D., 2016, ADV NEURAL INFORM PR, P3675
   Lupianez J, 2006, COGN NEUROPSYCHOL, V23, P1003, DOI 10.1080/02643290600588095
   Marraffa R., 2012, IEEE INT C DEV LEARN, pe1
   McGovern A., 2001, COMPUT SCI DEP FACUL
   McHaffie JG, 2005, TRENDS NEUROSCI, V28, P401, DOI 10.1016/j.tins.2005.06.006
   Merrick K, 2017, COGN SYST RES, V41, P38, DOI 10.1016/j.cogsys.2016.08.001
   Miller EK, 2001, ANNU REV NEUROSCI, V24, P167, DOI 10.1146/annurev.neuro.24.1.167
   Mirolli M., 2013, INTRINSICALLY MOTIVA, P49, DOI DOI 10.1007/978-3-642-32375-1_3
   MOON LE, 1956, AM J PSYCHOL, V69, P288, DOI 10.2307/1418162
   Nguyen Sao Mai, 2013, 2013 IEEE 3 JOINT IN, P1
   Ognibene D, 2010, 2010 IEEE 9th International Conference on Development and Learning (ICDL 2010), P231, DOI 10.1109/DEVLRN.2010.5578839
   Ognibene D, 2008, LECT NOTES ARTIF INT, V5040, P220
   Ognibene D, 2015, IEEE T AUTON MENT DE, V7, P3, DOI 10.1109/TAMD.2014.2341351
   Oudeyer P.-Y., 2007, FRONT NEUROROBOTICS, V1, P1, DOI DOI 10.3389/NEUR0.12.006.2007
   Oudeyer PY, 2007, IEEE T EVOLUT COMPUT, V11, P265, DOI 10.1109/TEVC.2006.890271
   Paletta L, 2000, ROBOT AUTON SYST, V31, P71, DOI 10.1016/S0921-8890(99)00079-2
   Polani D, 2011, P IEEE S AD DYN PROG, P105
   Redgrave P, 1999, NEUROSCIENCE, V89, P1009, DOI 10.1016/S0306-4522(98)00319-4
   Redgrave P., 2013, INTRINSICALLY MOTIVA, P129, DOI DOI 10.1007/978-3-642-32375-1-6
   Redgrave P, 2006, NAT REV NEUROSCI, V7, P967, DOI 10.1938/nrn2022
   Reinhart RF, 2017, AUTON ROBOT, V41, P1521, DOI 10.1007/s10514-016-9613-x
   Rolf M., IEEE T AUTON MENTAL
   Rolf M, 2014, FOUTH JOINT IEEE INTERNATIONAL CONFERENCES ON DEVELOPMENT AND LEARNING AND EPIGENETIC ROBOTICS (IEEE ICDL-EPIROB 2014), P187, DOI 10.1109/DEVLRN.2014.6982980
   Rolf M, 2010, IEEE T AUTON MENT DE, V2, P216, DOI 10.1109/TAMD.2010.2062511
   Ross J, 2001, TRENDS NEUROSCI, V24, P113, DOI 10.1016/S0166-2236(00)01685-4
   Santucci V. G., 2013, FRONT NEUROROBOTICS, V7, pel
   Santucci V. G, 2012, DEV LEARN EP ROB ICD, P1, DOI DOI 10.1109/DEVLRN.2012.6400835
   Santucci VG, 2016, IEEE T COGN DEV SYST, V8, P214, DOI 10.1109/TCDS.2016.2538961
   Sapir A, 2004, J COGNITIVE NEUROSCI, V16, P503, DOI 10.1162/089892904323057245
   Schembri M., 2007, P 6 IEEE INT C DEV L, P282
   Schembri M., 2007, P 7 INT C EP ROB EPI, P141
   Schlesinger M., 2013, FRONT PSYCHOL COGN S, V4
   Schlesinger M, 2012, DEVELOPMENTAL SCI, V15, P739, DOI 10.1111/j.1467-7687.2012.01177.x
   SCHMIDHUBER J, 1991, IEEE IJCNN, P1458, DOI 10.1109/IJCNN.1991.170605
   Schmidhuber J., 1991, P INT C SIM AD BEH A, P222
   Schmidhuber J., 1991, INT J NEURAL SYST, V2, P135, DOI DOI 10.1142/S012906579100011X
   Schultz W, 1998, J NEUROPHYSIOL, V80, P1
   Schultz W, 2006, ANNU REV PSYCHOL, V57, P87, DOI 10.1146/annurev.psych.56.091103.070229
   Seepanomwan K., 2017, P 7 JOINT IEEE INT C, P178
   Simsek O., 2008, ADV NEURAL INFORM PR, P1497, DOI DOI 10.1145/1102351.1102454
   Singh S, 2005, ADV NEURAL INFORM PR, P1281
   Sperati V, 2014, FOUTH JOINT IEEE INTERNATIONAL CONFERENCES ON DEVELOPMENT AND LEARNING AND EPIGENETIC ROBOTICS (IEEE ICDL-EPIROB 2014), P461, DOI 10.1109/DEVLRN.2014.6983024
   Sutton R. S, 1998, REINFORCEMENT LEARNI
   Sutton RS, 1999, ARTIF INTELL, V112, P181, DOI 10.1016/S0004-3702(99)00052-1
   Taffoni F, 2014, EXP BRAIN RES, V232, P2167, DOI 10.1007/s00221-014-3907-z
   ULLMAN S, 1984, COGNITION, V18, P97, DOI 10.1016/0010-0277(84)90023-4
   Wang Q, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0030884
   Weng JY, 2001, SCIENCE, V291, P599, DOI 10.1126/science.291.5504.599
   White B. J., 2011, OXFORD HDB EYE MOVEM, P195, DOI DOI 10.1093/OXFORDHB/9780199539789.013.0011
   WHITE RW, 1959, PSYCHOL REV, V66, P297, DOI 10.1037/h0040934
NR 86
TC 0
Z9 0
U1 10
U2 10
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2379-8920
EI 2379-8939
J9 IEEE T COGN DEV SYST
JI IEEE Trans. Cogn. Dev. Syst.
PD JUN
PY 2018
VL 10
IS 2
SI SI
BP 326
EP 344
DI 10.1109/TCDS.2017.2772908
PG 19
WC Computer Science, Artificial Intelligence; Robotics; Neurosciences
SC Computer Science; Robotics; Neurosciences & Neurology
GA GJ3MC
UT WOS:000435198600018
DA 2019-02-18
ER

PT J
AU Hwang, J
   Tani, J
AF Hwang, Jungsik
   Tani, Jun
TI Seamless Integration and Coordination of Cognitive Skills in Humanoid
   Robots: A Deep Learning Approach
SO IEEE TRANSACTIONS ON COGNITIVE AND DEVELOPMENTAL SYSTEMS
LA English
DT Article
DE Deep learning; neurorobotics; sensorimotor learning
ID DEVELOPMENTAL ROBOTICS; NEURAL-NETWORKS; BEHAVIOR; INTENTIONS; INFANTS;
   SYSTEMS; OBJECTS; DESIGN; CORTEX; MODEL
AB This paper investigates how adequate coordination among the different cognitive processes of a humanoid robot can be developed through end-to-end learning of direct perception of visuomotor stream. We propose a deep dynamic neural network model built on a dynamic vision network, a motor generation network, and a higher-level network. The proposed model was designed to process and to integrate direct perception of dynamic visuomotor patterns in a hierarchical model characterized by different spatial and temporal constraints imposed on each level. We conducted synthetic robotic experiments in which a robot learned to read human's intention through observing the gestures and then to generate the corresponding goal-directed actions. Results verify that the proposed model is able to learn the tutored skills and to generalize them to novel situations. The model showed synergic coordination of perception, action, and decision making, and it integrated and coordinated a set of cognitive skills including visual perception, intention reading, attention switching, working memory, action preparation, and execution in a seamless manner. Analysis reveals that coherent internal representations emerged at each level of the hierarchy. Higher-level representation reflecting actional intention developed by means of continuous integration of the lower-level visuo-proprioceptive stream.
C1 [Hwang, Jungsik; Tani, Jun] Korea Adv Inst Sci & Technol, Sch Elect Engn, Daejeon 305701, South Korea.
   [Tani, Jun] Okinawa Inst Sci & Technol, Onna, Okinawa 9040495, Japan.
RP Tani, J (reprint author), Korea Adv Inst Sci & Technol, Sch Elect Engn, Daejeon 305701, South Korea.
EM jungsik.hwang@gmail.com; tani1216jp@gmail.com
RI Tani, Jun/H-3681-2012
FU National Research Foundation of Korea through the Korea Government
   (MSIP) [2014R1A2A2A01005491]
FX This work was supported by the National Research Foundation of Korea
   through the Korea Government (MSIP) under Grant 2014R1A2A2A01005491.
CR Asada M, 2001, ROBOT AUTON SYST, V37, P185, DOI 10.1016/S0921-8890(01)00157-9
   Bengio Y., 2007, P ADV NEUR INF PROC, V19, P153
   Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50
   Berthouze L, 2003, CONNECT SCI, V15, P147, DOI 10.1080/09540090310001658063
   Cangelosi A., 2015, DEV ROBOTICS BABIES
   Carpaneto J, 2011, NEUROSCIENCE, V188, P80, DOI 10.1016/j.neuroscience.2011.04.062
   Celikkanat H., 2013, WORKSH NEUR ROB IROS, P1
   Di Nuovo A, 2015, 5TH INTERNATIONAL CONFERENCE ON DEVELOPMENT AND LEARNING AND ON EPIGENETIC ROBOTICS (ICDL-EPIROB), P320, DOI 10.1109/DEVLRN.2015.7346165
   Dominey PF, 2011, NEW IDEAS PSYCHOL, V29, P260, DOI 10.1016/j.newideapsych.2009.07.006
   Dominey PF, 2003, BRAIN LANG, V86, P207, DOI 10.1016/S0093-934X(02)00529-1
   Droniou A, 2015, ROBOT AUTON SYST, V71, P83, DOI 10.1016/j.robot.2014.11.005
   Georgeon OL, 2013, BIOL INSPIR COGN ARC, V6, P46, DOI 10.1016/j.bica.2013.05.006
   Guerin F, 2013, IEEE T AUTON MENT DE, V5, P18, DOI 10.1109/TAMD.2012.2209879
   Hwang J, 2015, IEEE-RAS INT C HUMAN, P817
   Jeong S, 2012, COGN NEURODYNAMICS, V6, P43, DOI 10.1007/s11571-011-9176-7
   Jung M, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0131214
   Jung MJ, 2014, FOUTH JOINT IEEE INTERNATIONAL CONFERENCES ON DEVELOPMENT AND LEARNING AND EPIGENETIC ROBOTICS (IEEE ICDL-EPIROB 2014), P235, DOI 10.1109/DEVLRN.2014.6982987
   Krizhevsky A., 2012, ADV NEUR INFORM PROC, P1097, DOI DOI 10.1145/3065386
   LASKY RE, 1977, CHILD DEV, V48, P112, DOI 10.1111/j.1467-8624.1977.tb04249.x
   LeCun Yann A., 2012, Neural Networks: Tricks of the Trade. Second Edition: LNCS 7700, P9, DOI 10.1007/978-3-642-35289-8_3
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Lenz I, 2015, INT J ROBOT RES, V34, P705, DOI 10.1177/0278364914549607
   Levine S, 2016, J MACH LEARN RES, V17
   Lungarella M, 2003, CONNECT SCI, V15, P151, DOI 10.1080/09540090310001655110
   Lungarella M., 2003, LUND U COGNITIVE STU, P81
   McCarty ME, 2001, CHILD DEV, V72, P973, DOI 10.1111/1467-8624.00329
   McClelland JL, 2010, TRENDS COGN SCI, V14, P348, DOI 10.1016/j.tics.2010.06.002
   Meyer K, 2009, TRENDS NEUROSCI, V32, P376, DOI 10.1016/j.tins.2009.04.002
   Mushiake H, 2006, NEURON, V50, P631, DOI 10.1016/j.neuron.2006.03.045
   Nishimoto R, 2009, PSYCHOL RES-PSYCH FO, V73, P545, DOI 10.1007/s00426-009-0236-0
   Noda K, 2014, ROBOT AUTON SYST, V62, P721, DOI 10.1016/j.robot.2014.03.003
   Oztop E, 2004, EXP BRAIN RES, V158, P480, DOI 10.1007/s00221-004-1914-1
   Park G, 2015, 5TH INTERNATIONAL CONFERENCE ON DEVELOPMENT AND LEARNING AND ON EPIGENETIC ROBOTICS (ICDL-EPIROB), P176, DOI 10.1109/DEVLRN.2015.7346137
   Pinto L, 2016, IEEE INT CONF ROBOT, P3406, DOI 10.1109/ICRA.2016.7487517
   Rumelhart D.E., 1986, PARALLEL DISTRIBUTED, V1, P1
   Savastano Piero, 2012, Biomimetic and Biohybrid Systems. Proceedings First International Conference, Living Machines 2012, P250, DOI 10.1007/978-3-642-31525-1_22
   Savastano P, 2013, IEEE T AUTON MENT DE, V5, P326, DOI 10.1109/TAMD.2013.2264321
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   Sigaud O, 2016, IEEE T COGN DEV SYST, V8, P99, DOI 10.1109/TAMD.2015.2496248
   Sporns O., 2011, NETWORKS BRAIN
   Tani J, 2014, P IEEE, V102, P586, DOI 10.1109/JPROC.2014.2308604
   Taniguchi T, 2016, ADV ROBOTICS, V30, P770, DOI 10.1080/01691864.2016.1159981
   Tikhanoff V., 2008, P 8 WORKSH PERF METR, P57, DOI DOI 10.1145/1774674.1774684
   Tomasello M, 2005, BEHAV BRAIN SCI, V28, P675, DOI 10.1017/S0140525X05000129
   Tsagarakis NG, 2007, ADV ROBOTICS, V21, P1151, DOI 10.1163/156855307781389419
   Ugur E., 2012, 2012 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2012), P3260, DOI 10.1109/IROS.2012.6385639
   Ugur E, 2015, IEEE T AUTON MENT DE, V7, P119, DOI 10.1109/TAMD.2015.2426192
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Vargas-Irwin CE, 2015, J NEUROSCI, V35, P10888, DOI 10.1523/JNEUROSCI.1574-15.2015
   Vernon D, 2016, INTEL SYST REF LIBR, V105, P15, DOI 10.1007/978-3-319-31056-5_3
   Wahlstrom N, 2015, ARXIV150202251
   Yamashita Y, 2008, PLOS COMPUT BIOL, V4, DOI 10.1371/journal.pcbi.1000220
   Yu Z, 2015, ROBOT AUTON SYST, V71, P134, DOI 10.1016/j.robot.2015.01.001
NR 53
TC 1
Z9 1
U1 3
U2 3
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2379-8920
EI 2379-8939
J9 IEEE T COGN DEV SYST
JI IEEE Trans. Cogn. Dev. Syst.
PD JUN
PY 2018
VL 10
IS 2
SI SI
BP 345
EP 358
DI 10.1109/TCDS.2017.2714170
PG 14
WC Computer Science, Artificial Intelligence; Robotics; Neurosciences
SC Computer Science; Robotics; Neurosciences & Neurology
GA GJ3MC
UT WOS:000435198600019
DA 2019-02-18
ER

PT J
AU Duran, B
   Sandamirskaya, Y
AF Duran, Boris
   Sandamirskaya, Yulia
TI Learning Temporal Intervals in Neural Dynamics
SO IEEE TRANSACTIONS ON COGNITIVE AND DEVELOPMENTAL SYSTEMS
LA English
DT Article
DE Dynamic neural fields (DNFs); learning timing; memory for duration;
   neural dynamics; neuromorphic engineering; neurorobotics
ID DISTAL REWARD PROBLEM; FIELD-THEORY; TIME PERCEPTION; CORTICAL NETWORKS;
   WORKING-MEMORY; CEREBELLUM; REPRESENTATION; INFORMATION; MECHANISMS;
   MODEL
AB Storing and reproducing temporal intervals is an important component of perception, action generation, and learning. How temporal intervals can be represented in neuronal networks is thus an important research question both in study of biological organisms and artificial neuromorphic systems. Here, we introduce a neural-dynamic computing architecture for learning temporal durations of actions. The architecture uses a dynamic neural fields (DNFs) representation of the elapsed time and a memory trace dynamics to store the experienced action duration. Interconnected dynamical nodes signal beginning of an action, its successful accomplishment, or failure, and activate formation of the memory trace that corresponds to the action's duration. The accumulated memory trace influences the competition between the dynamical nodes in such a way that the failure node gains a competitive advantage earlier if the stored duration is shorter. The model uses neurally based DNF dynamics and is a process model of how temporal durations may be stored in neural systems, both biological and artificial ones. The focus of this paper is on the mechanism to store and use duration in artificial neuronal systems. The model is validated in closed-loop experiments with a simulated robot.
C1 [Duran, Boris] Univ Skovde, Informat Res Ctr, S-54101 Skovde, Sweden.
   [Sandamirskaya, Yulia] Univ Zurich, Inst Neuroinformat, CH-8057 Zurich, Switzerland.
   [Sandamirskaya, Yulia] Univ Zurich, Neurosci Ctr, CH-8057 Zurich, Switzerland.
RP Duran, B (reprint author), Univ Skovde, Informat Res Ctr, S-54101 Skovde, Sweden.
EM yulia.sandamirskaya@ini.uzh.ch
FU EU [270247, 707373]; UZH Forschungskredit [FK-16-106]
FX This work was supported in part by the EU FP7-ICT-2009-6 under Grant
   270247 "NeuralDynamics," in part by the EU H2020-MSCA-IF-2015 under
   Grant 707373 "ECogNet," and in part by the UZH Forschungskredit under
   Grant FK-16-106.
CR Allman MJ, 2012, BRAIN, V135, P656, DOI 10.1093/brain/awr210
   AMARI SI, 1977, BIOL CYBERN, V27, P77, DOI 10.1007/BF00337259
   Bailey MR, 2013, CURR BIOL, V23, pR243, DOI 10.1016/j.cub.2013.02.006
   Benjamin B, 2014, P IEEE, V102, P699, DOI 10.1109/JPROC.2014.2313565
   Bicho E, 2000, INT J ROBOT RES, V19, P424, DOI 10.1177/02783640022066950
   Bicho E, 1997, ISIE '97 - PROCEEDINGS OF THE IEEE INTERNATIONAL SYMPOSIUM ON INDUSTRIAL ELECTRONICS, VOLS 1-3, pSS13, DOI 10.1109/ISIE.1997.651728
   Billing E., 2015, ADAPT BEHAV, V9, P1
   Brody CD, 2003, CEREB CORTEX, V13, P1196, DOI 10.1093/cercor/bhg100
   Bueti D, 2014, TIMING TIME PERCEPTI, V2, P261, DOI [10.1163/22134468-00002023, DOI 10.1163/22134468-00002023]
   Buhusi CV, 2005, NAT REV NEUROSCI, V6, P755, DOI 10.1038/nrn1764
   BULLOCK D, 1994, NEURAL NETWORKS, V7, P1101, DOI 10.1016/S0893-6080(05)80161-3
   Buonomano DV, 2007, NAT CHEM BIOL, V3, P594, DOI 10.1038/nchembio1007-594
   Buonomano DV, 2010, TRENDS COGN SCI, V14, P520, DOI 10.1016/j.tics.2010.09.002
   Buonomano DV, 2009, NAT REV NEUROSCI, V10, P113, DOI 10.1038/nrn2558
   Buonomano DV, 2002, NEUROSCIENTIST, V8, P42, DOI 10.1177/107385840200800109
   Buonomano DV, 2000, J NEUROSCI, V20, P1129, DOI 10.1523/JNEUROSCI.20-03-01129.2000
   Duran Boris, 2012, Artificial Neural Networks and Machine Learning - ICANN 2012. Proceedings 22nd International Conference on Artificial Neural Networks, P25, DOI 10.1007/978-3-642-33269-2_4
   Duran B, 2012, IEEE-RAS INT C HUMAN, P357, DOI 10.1109/HUMANOIDS.2012.6651544
   Durstewitz D, 2003, J NEUROSCI, V23, P5342
   Eichenbaum H, 2014, NAT REV NEUROSCI, V15, P732, DOI 10.1038/nrn3827
   Erlhagen W, 2006, ROBOT AUTON SYST, V54, P353, DOI 10.1016/j.robot.2006.01.004
   Erlhagen W, 2002, PSYCHOL REV, V109, P545, DOI 10.1037//0033-295X.109.3.545
   Erlhagen W, 2006, J NEURAL ENG, V3, pR36, DOI 10.1088/1741-2560/3/3/R02
   Faubel C., 2006, P 5 IEEE INT C DEV L, P1
   Furber SB, 2013, IEEE T COMPUT, V62, P2454, DOI 10.1109/TC.2012.142
   Gers FA, 2003, J MACH LEARN RES, V3, P115, DOI 10.1162/153244303768966139
   Goel A, 2014, PHILOS T R SOC B, V369, DOI 10.1098/rstb.2012.0460
   Grossberg S, 1996, J COGNITIVE NEUROSCI, V8, P257, DOI 10.1162/jocn.1996.8.3.257
   GROSSBERG S, 1989, NEURAL NETWORKS, V2, P79, DOI 10.1016/0893-6080(89)90026-9
   GROSSBERG S, 1988, NEURAL NETWORKS, V1, P17, DOI 10.1016/0893-6080(88)90021-4
   Harrington DL, 1998, J NEUROSCI, V18, P1085
   Heron J, 2012, P ROY SOC B-BIOL SCI, V279, P690, DOI 10.1098/rspb.2011.1131
   Indiveri G, 2015, P IEEE, V103, P1379, DOI 10.1109/JPROC.2015.2444094
   Ivry RB, 1996, CURR OPIN NEUROBIOL, V6, P851, DOI 10.1016/S0959-4388(96)80037-7
   Ivry RB, 2004, CURR OPIN NEUROBIOL, V14, P225, DOI 10.1016/j.conb.2004.03.013
   Ivry RB, 2002, BRAIN COGNITION, V48, P117, DOI 10.1006/brcg.2001.1308
   Ivry RB, 2008, TRENDS COGN SCI, V12, P273, DOI 10.1016/j.tics.2008.04.002
   Izhikevich EM, 2007, CEREB CORTEX, V17, P2443, DOI 10.1093/cercor/bhl152
   Izhikevich EM, 2006, NEURAL COMPUT, V18, P245, DOI 10.1162/089976606775093882
   Jaeger H, 2007, NEURAL NETWORKS, V20, P287, DOI 10.1016/j.neunet.2007.04.001
   Jin DZZ, 2009, P NATL ACAD SCI USA, V106, P19156, DOI 10.1073/pnas.0909881106
   Karmarkar UR, 2007, NEURON, V53, P427, DOI 10.1016/j.neuron.2007.01.006
   Kazemlou S., 2012, P POW EN SOC GEN M 2, P1
   Keele SW, 2003, PSYCHOL REV, V110, P316, DOI 10.1037/0033-295X.110.2.316
   Laje R, 2011, FRONT INTEGR NEUROSC, V5, DOI 10.3389/fnint.2011.00061
   Large EW, 2002, COGNITIVE SCI, V26, P1
   Lebedev MA, 2008, J NEUROPHYSIOL, V99, P166, DOI 10.1152/jn.00734.2007
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Leon MI, 1998, NEURON, V21, P669, DOI 10.1016/S0896-6273(00)80584-X
   Mauk MD, 1997, LEARN MEMORY, V4, P130, DOI 10.1101/lm.4.1.130
   Meck WH, 2005, BRAIN COGNITION, V58, P1, DOI 10.1016/j.bandc.2004.09.004
   Medina JF, 2000, J NEUROSCI, V20, P5516, DOI 10.1523/JNEUROSCI.20-14-05516.2000
   Mita A, 2009, NAT NEUROSCI, V12, P502, DOI 10.1038/nn.2272
   Neftci E, 2013, P NATL ACAD SCI USA, V110, pE3468, DOI 10.1073/pnas.1212083110
   O'Reilly JX, 2008, J NEUROSCI, V28, P2252, DOI 10.1523/JNEUROSCI.2742-07.2008
   Qiao N, 2015, FRONT NEUROSCI-SWITZ, V9, DOI 10.3389/fnins.2015.00141
   Raymond JL, 1996, SCIENCE, V272, P1126, DOI 10.1126/science.272.5265.1126
   Richter M, 2012, IEEE INT C INT ROBOT, P2457, DOI 10.1109/IROS.2012.6386153
   Sandamirskaya Y, 2010, 2010 IEEE 9th International Conference on Development and Learning (ICDL 2010), P251, DOI 10.1109/DEVLRN.2010.5578834
   Sandamirskaya Y., 2011, IEEE INT C DEV LEARN, V2, P1
   Sandamirskaya Y, 2014, FRONT NEUROSCI-SWITZ, V7, DOI 10.3389/fnins.2013.00276
   Sandamirskaya Y, 2013, NEW IDEAS PSYCHOL, V31, P322, DOI 10.1016/j.newideapsych.2013.01.002
   Sandamirskaya Y, 2010, NEURAL NETWORKS, V23, P1164, DOI 10.1016/j.neunet.2010.07.012
   Schneider BA, 2012, PLOS BIOL, V10, DOI 10.1371/journal.pbio.1001413
   Schoner G, 2006, PSYCHOL REV, V113, P273, DOI 10.1037/0033-295X.113.2.273
   Schoner G, 2015, DYNAMIC THINKING PRI
   Schutte AR, 2003, CHILD DEV, V74, P1393, DOI 10.1111/1467-8624.00614
   Simmering VR, 2008, BRAIN RES, V1202, P68, DOI 10.1016/j.brainres.2007.06.081
   Soltoggio A, 2013, NEURAL COMPUT, V25, P940, DOI 10.1162/NECO_a_00419
   TANK DW, 1987, P NATL ACAD SCI USA, V84, P1896, DOI 10.1073/pnas.84.7.1896
   Thelen E, 2001, BEHAV BRAIN SCI, V24, P1, DOI 10.1017/S0140525X01003910
   Vitay J, 2014, FRONT NEUROROBOTICS, V8, P1, DOI 10.3389/fnbot.2014.00004
   Wilimzig C, 2006, NEURAL NETWORKS, V19, P1059, DOI 10.1016/j.neunet.2006.03.003
   WILSON HR, 1973, KYBERNETIK, V13, P55, DOI 10.1007/BF00288786
   Yamazaki T, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0033319
NR 75
TC 1
Z9 1
U1 1
U2 2
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2379-8920
EI 2379-8939
J9 IEEE T COGN DEV SYST
JI IEEE Trans. Cogn. Dev. Syst.
PD JUN
PY 2018
VL 10
IS 2
SI SI
BP 359
EP 372
DI 10.1109/TCDS.2017.2676839
PG 14
WC Computer Science, Artificial Intelligence; Robotics; Neurosciences
SC Computer Science; Robotics; Neurosciences & Neurology
GA GJ3MC
UT WOS:000435198600020
DA 2019-02-18
ER

PT J
AU Yin, PJ
   Qiao, H
   Wu, W
   Qi, L
   Li, YL
   Zhong, SL
   Zhang, B
AF Yin, Peijie
   Qiao, Hong
   Wu, Wei
   Qi, Lu
   Li, Yinlin
   Zhong, Shanlin
   Zhang, Bo
TI A Novel Biologically Inspired Visual Cognition Model: Automatic
   Extraction of Semantics, Formation of Integrated Concepts, and
   Reselection Features for Ambiguity
SO IEEE TRANSACTIONS ON COGNITIVE AND DEVELOPMENTAL SYSTEMS
LA English
DT Article
DE Biologically inspired model; object recognition; semantic learning;
   structural learning
ID NEURAL MECHANISMS; HUMAN BRAIN; AREA V4; ATTENTION; MEMORY; RECOGNITION;
   REPRESENTATION; KNOWLEDGE; SHAPE; SYSTEM
AB Techniques that integrate neuroscience and information science benefit both fields. Many related models have been proposed in computer vision; however, in general, the robustness and recognition precision are still key problems in object recognition models. In this paper, inspired by the process by which humans recognize objects and its biological mechanisms, a new integrated and dynamic framework is proposed that mimics the semantic extraction, concept formation and feature reselection found in human visual processing. The main contributions of the proposed model are as follows: 1) semantic feature extraction: local semantic features are learned from episodic features extracted from raw images using a deep neural network; 2) integrated concept formation: concepts are formed using the local semantic information and structural information is learned through a network; and 3) feature reselection: when ambiguity is detected during the recognition process, distinctive features based on the differences between the ambiguous candidates are reselected for recognition. Experimental results on four datasets show that-compared with other methods-the new proposed model is more robust and achieves higher precision for visual recognition, especially when the input samples are semantically ambiguous. Meanwhile, the introduced biological mechanisms further strengthen the interaction between neuroscience and information science.
C1 [Yin, Peijie; Zhang, Bo] Chinese Acad Sci, Acad Math & Syst Sci, Inst Appl Math, Beijing 100190, Peoples R China.
   [Yin, Peijie; Qiao, Hong; Zhong, Shanlin; Zhang, Bo] Univ Chinese Acad Sci, Beijing 100049, Peoples R China.
   [Qiao, Hong; Wu, Wei; Qi, Lu; Li, Yinlin; Zhong, Shanlin] Chinese Acad Sci, Inst Automat, State Key Lab Management & Control Complex Syst, Beijing 100190, Peoples R China.
   [Qiao, Hong] CAS Ctr Excellence Brain Sci & Intelligence Techn, Shanghai 200031, Peoples R China.
   [Wu, Wei] Beijing Key Lab Res & Applicat Robot Intelligence, Beijing 100190, Peoples R China.
   [Zhang, Bo] Chinese Acad Sci, Cloud Comp Ctr, Dongguan 523808, Peoples R China.
RP Qiao, H (reprint author), Chinese Acad Sci, Inst Automat, State Key Lab Management & Control Complex Syst, Beijing 100190, Peoples R China.
EM hong.qiao@ia.ac.cn
FU National Science Foundation of China [61210009]; Strategic Priority
   Research Program of the CAS [XDB02080003]; National Key Research and
   Development Plan of China [2016YFC0300801]; National Natural Science
   Foundation of China [61210009, 61627808, 91648205]; Development of
   Science and Technology of Guangdong Province Special Fund Project
   [2016B090910001]
FX This work was supported in part by the National Science Foundation of
   China under Grant 61210009, in part by the Strategic Priority Research
   Program of the CAS under Grant XDB02080003, in part by the National Key
   Research and Development Plan of China under Grant 2016YFC0300801, in
   part by the National Natural Science Foundation of China under Grant
   61210009, Grant 61627808, and Grant 91648205, and in part by the
   Development of Science and Technology of Guangdong Province Special Fund
   Project under Grant 2016B090910001.
CR Aksoy EE, 2011, INT J ROBOT RES, V30, P1229, DOI 10.1177/0278364911410459
   Benchenane K, 2010, NEURON, V66, P921, DOI 10.1016/j.neuron.2010.05.013
   Berg J, 2002, J PRAGMATICS, V34, P349, DOI 10.1016/S0378-2166(01)00044-3
   BIEDERMAN I, 1987, PSYCHOL REV, V94, P115, DOI 10.1037/0033-295X.94.2.115
   Binder JR, 2011, TRENDS COGN SCI, V15, P527, DOI 10.1016/j.tics.2011.10.001
   Borji A, 2014, IEEE T SYST MAN CY-S, V44, P523, DOI 10.1109/TSMC.2013.2279715
   Chikkerur S, 2010, VISION RES, V50, P2233, DOI 10.1016/j.visres.2010.05.013
   Coco MI, 2017, IEEE T COGN DEV SYST, V9, P223, DOI 10.1109/TCDS.2016.2545739
   Daelli V, 2010, BRAIN RES, V1322, P81, DOI 10.1016/j.brainres.2010.01.060
   DESIMONE R, 1995, ANNU REV NEUROSCI, V18, P193, DOI 10.1146/annurev.neuro.18.1.193
   Dura-Bernal S, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0048216
   Eiter T, 2008, ARTIF INTELL, V172, P1495, DOI 10.1016/j.artint.2008.04.002
   Golomb JD, 2008, J NEUROSCI, V28, P10654, DOI 10.1523/JNEUROSCI.2525-08.2008
   Goodfellow I. J., 2015, P INT C LEARN REPR I
   Green AE, 2008, NAT REV NEUROSCI, V9, P710, DOI 10.1038/nrn2461
   Guo CE, 2007, COMPUT VIS IMAGE UND, V106, P5, DOI 10.1016/j.cviu.2005.09.004
   Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018
   Hu XL, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0081813
   Irshad H, 2013, J PATHOL INFORM, V4, P12, DOI DOI 10.4103/2153-3539.109870
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Jhuang H., 2007, COMPUTER VISION, P1, DOI DOI 10.1109/ICCV.2007.4408988
   Khan B, 2016, ASSEMBLY AUTOM, V36, P152, DOI 10.1108/AA-11-2015-100
   Kintsch W., 1974, REPRESENTATION MEANI
   Krizhevsky A., 2009, THESIS
   Krizhevsky A., 2012, ADV NEUR INFORM PROC, P1097, DOI DOI 10.1145/3065386
   Kumaran D, 2009, NEURON, V63, P889, DOI 10.1016/j.neuron.2009.07.030
   Lake BM, 2015, SCIENCE, V350, P1332, DOI 10.1126/science.aab3050
   Lee H., 2009, P ANN INT C MACH LEA, P609, DOI DOI 10.1145/1553374.1553453
   Li YL, 2015, FRONT COMPUT NEUROSC, V9, DOI 10.3389/fncom.2015.00123
   Liu CL, 2015, ADV SOC SCI EDUC HUM, V28, P1
   Longobardi Giuseppe, 2001, NAT LANG SEMANT, V9, P335, DOI [10.1023/A:1014861111123, DOI 10.1023/A:1014861111123]
   MARR D, 1978, PROC R SOC SER B-BIO, V200, P269, DOI 10.1098/rspb.1978.0020
   McClelland JL, 2003, NAT REV NEUROSCI, V4, P310, DOI 10.1038/nrn1076
   Miau F, 2001, P ANN INT IEEE EMBS, V23, P789, DOI 10.1109/IEMBS.2001.1019059
   Mitchell J, 2010, COGNITIVE SCI, V34, P1388, DOI 10.1111/j.1551-6709.2010.01106.x
   Moscovitch M, 2005, J ANAT, V207, P35, DOI 10.1111/j.1469-7580.2005.00421.x
   Netzer Y., 2011, P NIPS WORKSH DEEP L, P1
   Nguyen A. T., 2015, P WORKSH SDNFLEX NET, P1
   Ognibene D, 2015, IEEE T AUTON MENT DE, V7, P3, DOI 10.1109/TAMD.2014.2341351
   Pasupathy A, 2001, J NEUROPHYSIOL, V86, P2505
   Pasupathy A, 2002, NAT NEUROSCI, V5, P1332, DOI 10.1038/nn972
   Patterson K, 2007, NAT REV NEUROSCI, V8, P976, DOI 10.1038/nrn2277
   Petersen SE, 2012, ANNU REV NEUROSCI, V35, P73, DOI 10.1146/annurev-neuro-062111-150525
   Qiao H, 2016, IEEE T CYBERNETICS, V46, P2335, DOI 10.1109/TCYB.2015.2476706
   Qiao H, 2016, ASSEMBLY AUTOM, V36, P97, DOI 10.1108/AA-11-2015-099
   Qiao H, 2015, IEEE T CYBERNETICS, V45, P2612, DOI 10.1109/TCYB.2014.2377196
   Qiao H, 2014, IEEE T CYBERNETICS, V44, P1485, DOI 10.1109/TCYB.2013.2287014
   Riesenhuber M, 1999, NAT NEUROSCI, V2, P1019
   Sere T., 2004, 239AL CBCL
   Stokes M, 2009, J NEUROSCI, V29, P1565, DOI 10.1523/JNEUROSCI.4657-08.2009
   Sweegers CCG, 2014, NEUROIMAGE, V87, P138, DOI 10.1016/j.neuroimage.2013.10.063
   Szegedy C., 2014, IEEE C COMP VIS PATT, P1
   Theriault C, 2013, IEEE T IMAGE PROCESS, V22, P764, DOI 10.1109/TIP.2012.2222900
   TULVING E, 1985, AM PSYCHOL, V40, P385, DOI 10.1037/0003-066X.40.4.385
   Tulving E, 2002, ANNU REV PSYCHOL, V53, P1, DOI 10.1146/annurev.psych.53.100901.135114
   van Kesteren MTR, 2010, P NATL ACAD SCI USA, V107, P7550, DOI 10.1073/pnas.0914892107
   Walther D, 2002, LECT NOTES COMPUT SC, V2525, P472
   Wang Z, 2016, ARXIV160104155
NR 58
TC 0
Z9 0
U1 7
U2 8
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2379-8920
EI 2379-8939
J9 IEEE T COGN DEV SYST
JI IEEE Trans. Cogn. Dev. Syst.
PD JUN
PY 2018
VL 10
IS 2
SI SI
BP 420
EP 431
DI 10.1109/TCDS.2017.2749978
PG 12
WC Computer Science, Artificial Intelligence; Robotics; Neurosciences
SC Computer Science; Robotics; Neurosciences & Neurology
GA GJ3MC
UT WOS:000435198600025
DA 2019-02-18
ER

PT J
AU Stramandinoli, F
   Tikhanoff, V
   Pattacini, U
   Nori, F
AF Stramandinoli, Francesca
   Tikhanoff, Vadim
   Pattacini, Ugo
   Nori, Francesco
TI Heteroscedastic Regression and Active Learning for Modeling Affordances
   in Humanoids
SO IEEE TRANSACTIONS ON COGNITIVE AND DEVELOPMENTAL SYSTEMS
LA English
DT Article
DE Active learning; affordances modeling; Bayesian networks (BNs);
   cognitive robotics; developmental learning
ID TOOL USE; REPRESENTATION; OBJECTS; ROBOT; MIND
AB We investigate the learning of object and tool affordances in the iCub robot. We adopt the setup proposed in a previous experiment, using a Bayesian network (BN) in place of a least square support vector machine (LSSVM). The collected data, consisting of continuous and discrete variables, are used for learning the structure of the BN. Hence, the model is leveraged to: 1) identify a regression function for the prediction of the effects of actions on objects, calculated as the mean of the observed values; and 2) provide information on the reliability of the predicted values through the estimation of the variance for subsets of local observations. The information on the input-dependent variance is used to guide the learning algorithm in order to improve the performance of the robot, and hence to reduce the variance from the predicted values. The replacement of the LSSVM with the BN model provides a general probabilistic framework for dependencies among random variables; we perform conditional probability queries that enable the robot to choose the actions to perform on objects and select the most appropriate tool to obtain desired effects. The capability to make inference enables the robot to gather a better understanding of the world.
C1 [Stramandinoli, Francesca; Tikhanoff, Vadim; Pattacini, Ugo; Nori, Francesco] Ist Italian Tecnol, iCub Facil Dept, I-16163 Genoa, Italy.
RP Stramandinoli, F (reprint author), Ist Italian Tecnol, iCub Facil Dept, I-16163 Genoa, Italy.
EM francesca.stramandinoli@iit.it; vadim.tikhanoff@iit.it;
   ugo.pattacini@iit.it; francesco.nori@iit.it
FU Marie Curie Intra European Fellowship RoboTAsk through the 7th European
   Community Framework Programme [624424]; FP7 ICT POETICON++ [288382]
FX This work was supported in part by the Marie Curie Intra European
   Fellowship RoboTAsk through the 7th European Community Framework
   Programme (FP7) under Grant 624424, and in part by the FP7 ICT
   POETICON++ under Project 288382.
CR [Anonymous], 2014, GPY GAUSSIAN PROCESS
   Beck B., 1980, ANIMAL TOOL BEHAV
   Bourgeois KS, 2005, INFANCY, V8, P233, DOI 10.1207/s15327078in0803_3
   BUSHNELL EW, 1993, CHILD DEV, V64, P1005, DOI 10.2307/1131323
   Chemero A, 2003, ECOL PSYCHOL, V15, P181, DOI 10.1207/S15326969ECO1502_5
   COOPER GF, 1992, MACH LEARN, V9, P309, DOI 10.1023/A:1022649401552
   Cruz F., 2016, P EUR S ART NEUR NET, P665
   Dehban A, 2016, IEEE INT CONF ROBOT, P4866, DOI 10.1109/ICRA.2016.7487691
   FISHER R. A, 1922, PHILOS T R SOC A, V222, P309, DOI DOI 10.1098/RSTA.1922.0009
   Fitzpatrick P, 2003, IEEE INT CONF ROBOT, P3140
   Gibson J. J, 1979, ECOLOGICAL APPROACH
   Gijsberts A, 2013, NEURAL NETWORKS, V41, P59, DOI 10.1016/j.neunet.2012.08.011
   Goncalves A, 2014, FOUTH JOINT IEEE INTERNATIONAL CONFERENCES ON DEVELOPMENT AND LEARNING AND EPIGENETIC ROBOTICS (IEEE ICDL-EPIROB 2014), P482, DOI 10.1109/DEVLRN.2014.6983027
   Guerin F, 2013, IEEE T AUTON MENT DE, V5, P18, DOI 10.1109/TAMD.2012.2209879
   Huang C, 1996, INT J APPROX REASON, V15, P225, DOI 10.1016/S0888-613X(96)00069-2
   Ivaldi S, 2014, IEEE T AUTON MENT DE, V6, P56, DOI 10.1109/TAMD.2013.2280614
   Jain R, 2013, ARTIF LIFE ROBOT, V18, P95, DOI 10.1007/s10015-013-0105-1
   Jamone L., IEEE T COGN DEVELOP
   Kjellstrom H, 2011, COMPUT VIS IMAGE UND, V115, P81, DOI 10.1016/j.cviu.2010.08.002
   Koller D., 2009, PROBABILISTIC GRAPHI
   Lockman JJ, 2000, CHILD DEV, V71, P137, DOI 10.1111/1467-8624.00127
   Metta G., 2006, International Journal of Advanced Robotic Systems, V3, P43
   Metta G, 2010, NEURAL NETWORKS, V23, P1125, DOI 10.1016/j.neunet.2010.08.010
   Montesano Luis, 2007, 2007 IEEE/RSJ International Conference on Intelligent Robots and Systems, P4102, DOI 10.1109/IROS.2007.4399511
   Montesano L, 2008, IEEE T ROBOT, V24, P15, DOI 10.1109/TRO.2007.914848
   Murphy K, 2001, COMPUTING SCI STAT, V33, P1024
   Osorio Pedro, 2010, 2010 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2010), P4432, DOI 10.1109/IROS.2010.5650297
   Rasmussen CE, 2005, ADAPT COMPUT MACH LE, P1
   Rat-Fischer L, 2012, J EXP CHILD PSYCHOL, V113, P440, DOI 10.1016/j.jecp.2012.06.001
   Rudolph Mathias, 2010, Proceedings of the 2010 International Conference on Emerging Security Technologies (EST 2010), P124, DOI 10.1109/EST.2010.9
   Sahin E, 2007, ADAPT BEHAV, V15, P447, DOI 10.1177/1059712307084689
   Settles Burr, 2010, U WISCONSIN MADISON, V52, P55
   Sinapov J, 2008, INT C DEVEL LEARN, P91, DOI 10.1109/DEVLRN.2008.4640811
   Song D, 2010, 2010 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2010), P1579, DOI 10.1109/IROS.2010.5649406
   St Amant R, 2008, ANIM BEHAV, V75, P1199, DOI 10.1016/j.anbehav.2007.09.028
   Steedman M, 2002, LINGUIST PHILOS, V25, P723, DOI 10.1023/A:1020820000972
   Stoffregen TA, 2003, ECOL PSYCHOL, V15, P115, DOI 10.1207/S15326969ECO1502_2
   Stoytchev A, 2005, IEEE INT CONF ROBOT, P3060
   Stramandinoli F, 2016, 2016 JOINT IEEE INTERNATIONAL CONFERENCE ON DEVELOPMENT AND LEARNING AND EPIGENETIC ROBOTICS (ICDL-EPIROB), P79, DOI 10.1109/DEVLRN.2016.7846794
   Stramandinoli F, 2015, 5TH INTERNATIONAL CONFERENCE ON DEVELOPMENT AND LEARNING AND ON EPIGENETIC ROBOTICS (ICDL-EPIROB), P298, DOI 10.1109/DEVLRN.2015.7346160
   Tenenbaum JB, 2011, SCIENCE, V331, P1279, DOI 10.1126/science.1192788
   Tikhanoff V, 2013, IEEE-RAS INT C HUMAN, P130, DOI 10.1109/HUMANOIDS.2013.7029967
   Turvey M. T., 1992, ECOL PSYCHOL, V4, P173, DOI DOI 10.1207/S15326969EC00403_
NR 43
TC 0
Z9 0
U1 1
U2 1
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2379-8920
EI 2379-8939
J9 IEEE T COGN DEV SYST
JI IEEE Trans. Cogn. Dev. Syst.
PD JUN
PY 2018
VL 10
IS 2
SI SI
BP 455
EP 468
DI 10.1109/TCDS.2017.2700207
PG 14
WC Computer Science, Artificial Intelligence; Robotics; Neurosciences
SC Computer Science; Robotics; Neurosciences & Neurology
GA GJ3MC
UT WOS:000435198600028
DA 2019-02-18
ER

PT J
AU Olteteanu, AM
   Falomir, Z
   Freksa, C
AF Olteteanu, Ana-Maria
   Falomir, Zoe
   Freksa, Christian
TI Artificial Cognitive Systems That Can Answer Human Creativity Tests: An
   Approach and Two Case Studies
SO IEEE TRANSACTIONS ON COGNITIVE AND DEVELOPMENTAL SYSTEMS
LA English
DT Article
DE Cognitive knowledge acquisition; cognitive processing; cognitive
   systems; cognitively-comparable evaluation; computational creativity;
   human creativity
ID REMOTE ASSOCIATES TEST; INSIGHT; THINKING; MODEL
AB Creative cognitive systems are rarely assessed with the same tools as human creativity. In this paper, an approach is proposed for building cognitive systems which can solve human creativity tests. The importance of using cognitively viable processes, cognitive knowledge acquisition and organization, and cognitively comparable evaluation when implementing creative problem-solving systems is emphasized. Two case studies of artificial cognitive systems evaluated with human creativity tests are reviewed. A general approach is put forward. The applicability of this general approach to other creativity tests and artificial cognitive systems, together with ways of performing cognitive knowledge acquisition for these systems are then explored.
C1 [Olteteanu, Ana-Maria; Falomir, Zoe; Freksa, Christian] Univ Bremen, Bremen Spatial Cognit Ctr, D-28359 Bremen, Germany.
RP Olteteanu, AM (reprint author), Univ Bremen, Bremen Spatial Cognit Ctr, D-28359 Bremen, Germany.
EM amoodu@informatik.uni-bremen.de
OI Olteteanu, Ana-Maria/0000-0002-0639-7956; Freksa,
   Christian/0000-0002-0330-0004; Falomir, Zoe/0000-0002-6398-8488
FU Deutsche Forschungsgemeinschaft; Universitat Bremen
FX The work of A.-M. Olteleanu was supported by the Deutsche
   Forschungsgemeinschaft for the Creative Cognitive Systems (CreaCogs:
   http://creacogcomp.com/) Project. The work of Z. Falomir was supported
   by the Universitat Bremen through the 04-Independent Projects for
   Postdocs action for the project Cognitive Qualitative Descriptions and
   Applications
CR Ansburg PI, 2000, CURR PSYCHOL, V19, P143, DOI 10.1007/s12144-000-1011-y
   BABA Y, 1982, JPN J PSYCHOL, V52, P330, DOI 10.4992/jjpsy.52.330
   Batchelder WH, 2012, J PROBL SOLVING, V5, P56, DOI 10.7771/1932-6246.1143
   Boden M., 2003, CREATIVE MIND MYTHS
   Bowden EM, 2003, BEHAV RES METH INS C, V35, P634, DOI 10.3758/BF03195543
   Chermahini SA, 2012, THINK SKILLS CREAT, V7, P177, DOI 10.1016/j.tsc.2012.02.003
   Colton S, 2008, P AAAI SPRING S CREA, P14
   Colton Simon, 2012, P 3 INT C COMP CREAT, P95
   Colton Simon, 2012, COMPUTERS CREATIVITY, P3
   Coltonm S., 2011, P 2 INT C COMP CREAT, P90
   Duncker K, 1945, PSYCHOL MONOGR, V58, P1
   Evans T., 1964, P SPRING JOINT COMP, P327
   Fauconnier G, 1998, COGNITIVE SCI, V22, P133, DOI 10.1016/S0364-0213(99)80038-X
   FORBUS KD, 1995, COGNITIVE SCI, V19, P141, DOI 10.1016/0364-0213(95)90016-0
   GENTNER D, 1983, COGNITIVE SCI, V7, P155, DOI 10.1207/s15516709cog0702_3
   Gilhooly KJ, 2007, BRIT J PSYCHOL, V98, P611, DOI 10.1348/096317907X173421
   Guilford JP, 1967, NATURE HUMAN INTELLI
   Halford G. S., 1994, ADV CON NEUR COMP TH, V2, P363
   HAMILTON MA, 1982, PERCEPT MOTOR SKILL, V55, P321, DOI 10.2466/pms.1982.55.1.321
   Helie S, 2010, PSYCHOL REV, V117, P994, DOI 10.1037/a0019532
   Hennessey B. A., 1999, ENCY CREATIVITY, VI, P347
   Hofstadter Douglas R, 1994, ADV CONNECTIONIST NE, V2, P29
   Hummel JE, 1997, PSYCHOL REV, V104, P427, DOI 10.1037/0033-295X.104.3.427
   JACOBS MK, 1981, B PSYCHONOMIC SOC, V17, P171
   Jordanous A, 2012, COGN COMPUT, V4, P246, DOI 10.1007/s12559-012-9156-1
   Joyner D. A., 2015, P 6 INT C COMP CREAT, P23
   Kihlstrom J. F., 1996, IMPLICIT COGNITION, P257
   Kim KH, 2006, CREATIVITY RES J, V18, P3, DOI 10.1207/s15326934crj1801_2
   Lenat D. B., 1976, STANCS76570 DTIC
   LEVIN I, 1978, MEGAMOT, V24, P87
   Maier N. R. F., 1931, J COMP PSYCHOL, V12, P181, DOI [DOI 10.1037/H0071361, 10.1037/h0071361]
   Mednick S. A., 1971, REMOTE ASS TEST EXAM
   Olteeanu A.-M., 2015, P 3 INT WORKSH ART I, V1510, P19
   Olteteanu A.-M., 2014, I COGN SCI
   Olteteanu AM, 2016, SYNTH LIBR, V376, P159, DOI 10.1007/978-3-319-26485-1_11
   Olteteanu AM, 2014, FRONT ARTIF INTEL AP, V269, P249, DOI 10.3233/978-1-61499-452-7-249
   Olteteanu AM, 2016, COGN SYST RES, V39, P15, DOI 10.1016/j.cogsys.2015.12.011
   Olteteanu AM, 2015, PATTERN RECOGN LETT, V67, P81, DOI 10.1016/j.patrec.2015.05.015
   Pease A., 2001, P ICCBR WORKSH APPR, P129
   Reck Miranda E., 2002, Music and Artificial Intelligence. Second International Conference, ICMAI 2002. Proceedings (Lecture Notes in Artificial Intelligence Vol.2445), P107
   Ritchie G., 2001, P AISB S YORK UK
   Ritchie G, 2007, MIND MACH, V17, P67, DOI 10.1007/s11023-007-9066-2
   Schorlemmer M., 2014, P 5 INT C COMP CREAT, P288
   Todd P. M., 2006, MUSICAL CREATIVITY M, VI, P376
   Ventura D., 2016, P 7 INT C COMP CREAT, P17
   Wallach MA, 1965, MODES THINKING YOUNG
   Wiggins G. A., 2001, CASE BASED REASONING, V1, P113
   Williams H., 2014, FRONTIERS PSYCHOL, V5
   WORTHEN BR, 1971, J EDUC MEAS, V8, P113, DOI 10.1111/j.1745-3984.1971.tb00914.x
NR 49
TC 0
Z9 0
U1 2
U2 4
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2379-8920
EI 2379-8939
J9 IEEE T COGN DEV SYST
JI IEEE Trans. Cogn. Dev. Syst.
PD JUN
PY 2018
VL 10
IS 2
SI SI
BP 469
EP 475
DI 10.1109/TCDS.2016.2629622
PG 7
WC Computer Science, Artificial Intelligence; Robotics; Neurosciences
SC Computer Science; Robotics; Neurosciences & Neurology
GA GJ3MC
UT WOS:000435198600029
DA 2019-02-18
ER

PT J
AU Costa, S
   Brunete, A
   Bae, BC
   Mavridis, N
AF Costa, Sandra
   Brunete, Alberto
   Bae, Byung-Chull
   Mavridis, Nikolaos
TI Emotional Storytelling Using Virtual and Robotic Agents
SO INTERNATIONAL JOURNAL OF HUMANOID ROBOTICS
LA English
DT Article
DE Storytelling; robot and virtual agents; emotional affective response;
   eye blink analysis; facial expression analysis; non-verbal
   communication; posture analysis
ID EXPRESSION; JUDGMENT; MOTION; HEAD
AB In order to create effective storytelling agents three fundamental questions must be answered: first, is a physically embodied agent preferable to a virtual agent or a voice-only narration? Second, does a human voice have an advantage over a synthesised voice? Third, how should the emotional trajectory of the different characters in a story be related to a storyteller's facial expressions during storytelling time, and how does this correlate with the apparent emotions on the faces of the listeners? The results of two specially designed studies indicate that the physically embodied robot produces more attention to the listener as compared to a virtual embodiment, that a human voice is preferable over the current state of the art of text-to-speech, and that there is a complex yet interesting relation between the emotion lines of the story, the facial expressions of the narrating agent, and the emotions of the listener, and that the empathising of the listener is evident through its facial expressions. This work constitutes an important step towards emotional storytelling robots that can observe their listeners and adapt their style in order to maximise their effectiveness.
C1 [Costa, Sandra] Univ Minho, Dept Ind Elect Engn, Minho, Portugal.
   [Brunete, Alberto] UPM, CSIC, CAR, Madrid, Spain.
   [Bae, Byung-Chull] Hongik Univ, Sch Games, Sejong, South Korea.
   [Mavridis, Nikolaos] IRML, Athens, Greece.
RP Brunete, A (reprint author), UPM, CSIC, CAR, Madrid, Spain.
EM scosta@dei.uminho.pt; alberto.brunete@upm.es; byuc@hongik.ac.kr;
   nmavridis@iit.demokritos.gr
FU Portuguese Foundation (FCT) [RIPD/ADA/109407/2009, SFRH/BD/71600/2010,
   FCOMP-01-0124-FEDER-022674]; Hongik University
FX To the IRSS2013 participants, to the Portuguese Foundation (FCT) for
   funding through the R&D project RIPD/ADA/109407/2009,
   SFRH/BD/71600/2010, and FCOMP-01-0124-FEDER-022674. This work was also
   supported in part by the Hongik University new faculty research support
   fund.
CR Bakeman R, 1997, OBSERVING INTERACTIO
   Bentivoglio AR, 1997, MOVEMENT DISORD, V12, P1028, DOI 10.1002/mds.870120629
   Bleackley P., 2010, P INT C KANS ENG EM
   BRADLEY MM, 1994, J BEHAV THER EXP PSY, V25, P49, DOI 10.1016/0005-7916(94)90063-9
   Busselle R, 2009, MEDIA PSYCHOL, V12, P321, DOI 10.1080/15213260903287259
   Busso C, 2007, IEEE T AUDIO SPEECH, V15, P1075, DOI 10.1109/TASL.2006.885910
   Cabibihan J. J., 2012, HUMAN RECOGNIZABLE R
   Carmichael L, 1937, J SOC PSYCHOL, V8, P115, DOI 10.1080/00224545.1937.9919994
   Charles F, 2007, LECT NOTES COMPUT SC, V4871, P210
   Christoforou C., 2010, P INT S ROB INT SENS
   Csikszentmihalyi M., 1990, FLOW PSYCHOL OPTIMAL
   Decety Jean, 2004, Behav Cogn Neurosci Rev, V3, P71, DOI 10.1177/1534582304267187
   Drummond K., 1993, RES LANG SOC INTERAC, V26, P157, DOI DOI 10.1207/S15327973RLSI2602_
   EKMAN P, 1967, PERCEPT MOTOR SKILL, V24, P711, DOI 10.2466/pms.1967.24.3.711
   Fast J., 1998, POCKET
   Gwo-Dong Chen, 2011, Edutainment Technologies. Educational Games and Virtual Reality/Augmented Reality Applications. Proceedings 6th International Conference on E-learning and Games, Edutainment 2011, P450, DOI 10.1007/978-3-642-23456-9_81
   Kennedy J, 2015, INT J SOC ROBOT, V7, P293, DOI 10.1007/s12369-014-0277-4
   Lee C.H. J., 2006, CHI 06, P1007
   LEVENSON RW, 1992, J PERS SOC PSYCHOL, V63, P234, DOI 10.1037//0022-3514.63.2.234
   Mancas M., 2016, HUMAN ATTENTION COMP
   Mancini M., 2008, P WORKSH FML AAMAS, V8
   Maus FE, 1997, J AESTHET ART CRITIC, V55, P293, DOI 10.2307/431799
   Mavridis N., 2007, THESIS
   Mavridis N., 18 IEEE INT S ROB HU, P681
   Mavridis N, 2012, AI SOC, V27, P517, DOI 10.1007/s00146-011-0370-2
   Meyer L., 1956, EMOTION MEANING MUSI
   MILLER GA, 1956, PSYCHOL REV, V63, P81, DOI 10.1037//0033-295X.101.2.343
   Munekata T., 2009, SEMANTIC SCHOLAR
   Mutlu B, 2006, IEEE-RAS INT C HUMAN, P518, DOI 10.1109/ICHR.2006.321322
   NOLDUS LPJJ, 1991, BEHAV RES METH INSTR, V23, P415, DOI 10.3758/BF03203406
   OATLEY K, 1995, POETICS, V23, P53, DOI 10.1016/0304-422X(94)P4296-S
   Pantic M, 2000, IEEE T PATTERN ANAL, V22, P1424, DOI 10.1109/34.895976
   Pease A., 2012, BODY LANGUAGE
   Plaisant Catherine, 2000, P 4 INT ACM C ASS TE, P50, DOI 10.1145/354324.354338
   Poggi I, 2005, TEXT SPEECH LANG TEC, V27, P3, DOI 10.1007/1-4020-3051-7_1
   Reilly J. S., 1992, SIGN LANGUAGE STUDIE, V75, P113, DOI DOI 10.1353/SLS.1992.0035
   Ribeiro C. R., 2009, ROBOTICS CHILD STORY
   Riek L., 2010, P 2 INT S NEW FRONT, V1
   RONEY RC, 1989, READ TEACH, V42, P520
   RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714
   Ryokai K, 2009, C & C 09: PROCEEDINGS OF THE 2009 ACM SIGCHI CONFERENCE ON CREATIVITY AND COGNITION, P19
   Samadani Ali-Akbar, 2011, 2011 RO-MAN: The 20th IEEE International Symposium on Robot and Human Interactive Communication, P93, DOI 10.1109/ROMAN.2011.6005276
   Scherer K. R., 2000, NEUROPSYCHOLOGY EMOT, V137, P137
   Shultz S, 2011, P NATL ACAD SCI USA, V108, P21270, DOI 10.1073/pnas.1109304108
   Silva A, 2003, LECT NOTES COMPUT SC, V2897, P146
   Silva A., 2001, Intelligent Virtual Agents. Third International Workshop, IVA 2001. Proceedings (Lecture Notes in Artificial Intelligence Vol.2190), P171
   Sugimoto M, 2011, IEEE T LEARN TECHNOL, V4, P249, DOI 10.1109/TLT.2011.13
   Tang D, 2015, EXPERT SYST APPL, V42, P4540, DOI 10.1016/j.eswa.2015.01.016
   Wallbott HG, 1998, EUR J SOC PSYCHOL, V28, P879, DOI 10.1002/(SICI)1099-0992(1998110)28:6<879::AID-EJSP901>3.0.CO;2-W
   Wong CJ, 2016, ELEVENTH ACM/IEEE INTERNATIONAL CONFERENCE ON HUMAN ROBOT INTERACTION (HRI'16), P535, DOI 10.1109/HRI.2016.7451843
   Ying KT, 2016, INT CONF USER SCI, P253, DOI 10.1109/IUSER.2016.7857970
   Zwaan RA, 1998, PSYCHOL BULL, V123, P162, DOI 10.1037//0033-2909.123.2.162
NR 52
TC 1
Z9 1
U1 0
U2 0
PU WORLD SCIENTIFIC PUBL CO PTE LTD
PI SINGAPORE
PA 5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE
SN 0219-8436
EI 1793-6942
J9 INT J HUM ROBOT
JI Int. J. Humanoid Robot.
PD JUN
PY 2018
VL 15
IS 3
AR 1850006
DI 10.1142/S0219843618500068
PG 31
WC Robotics
SC Robotics
GA GI7AU
UT WOS:000434655200005
DA 2019-02-18
ER

PT J
AU Arelekatti, VNM
   Winter, VAG
AF Arelekatti, V. N. Murthy
   Winter, Amos G., V
TI Design and Preliminary Field Validation of a Fully Passive Prosthetic
   Knee Mechanism for Users With Transfemoral Amputation in India
SO JOURNAL OF MECHANISMS AND ROBOTICS-TRANSACTIONS OF THE ASME
LA English
DT Article
DE bio inspired designs; dynamics; mechanism design; prosthetics
ID PSYCHOSOCIAL ADJUSTMENT; DEVELOPING-WORLD; KINEMATICS; AMPUTEES; WALKING
AB An estimated 230,000 above-knee amputees in India are currently in need of prosthetic devices, a majority of them facing severe socio-economic constraints. However, only a few passive prosthetic knee devices in the market have been designed for facilitation of normative gait kinematics and for meeting the specific daily life needs of above-knee amputees in the developing world. Based on the results of our past studies, this paper establishes a framework for designing a potentially low-cost, fully passive prosthetic knee device, which aims to facilitate able-bodied kinematics at a low metabolic cost. Based on a comprehensive set of functional requirements and biomechanical analysis from our past work, we present an early prototype mechanism for the prosthetic knee joint that is primarily focused on enabling able-bodied kinematics. The mechanism is implemented using two functional modules: an automatic early stance lock for stability and a differential friction damping system for late stance and swing control. For preliminary, qualitative validation of the knee mechanism, we carried out a field trial on four above-knee amputees in India, which showed satisfactory performance of the early stance lock. The prototype enabled smooth stance-to-swing transition by timely initiation of late stance flexion. Possible methods of incorporating an additional spring module for further refinement of the design are also discussed, which can enable flexion-extension during the early-stance phase of the gait cycle and potentially reduce the metabolic energy expenditure of the user further.
C1 [Arelekatti, V. N. Murthy; Winter, Amos G., V] MIT, Dept Mech Engn, Cambridge, MA 02139 USA.
RP Arelekatti, VNM (reprint author), MIT, Dept Mech Engn, Cambridge, MA 02139 USA.
EM murthya@mit.edu; awinter@mit.edu
FU Tata Center for Technology and Design at MIT
FX We would like to thank Yashraj S. Narang and Daniel S. Dorsch for their
   guidance and suggestions. We would also like to acknowledge Bhagwan
   Mahaveer Viklang Sahayata Samiti (BMVSS, a.k.a., the Jaipur Foot
   organization) for their partnership in our project to design a
   high-performance, low-cost prosthetic knee for the developing world.
   Funding for this research was provided by the Tata Center for Technology
   and Design at MIT.
CR Andrysek J, 2011, PROSTHET ORTHOT INT, V35, P163, DOI 10.1177/0309364611408495
   Andrysek J, 2010, PROSTHET ORTHOT INT, V34, P378, DOI 10.3109/03093646.2010.520060
   Arelekatti VNM, 2015, INT C REHAB ROBOT, P350, DOI 10.1109/ICORR.2015.7281224
   Baker R., 2013, MEASURING WALKING HD
   BMVSS, 2014, WHAT WE DO KNEE PROS
   Cummings D, 1996, PROSTHET ORTHOT INT, V20, P51
   Donelan JM, 2002, J EXP BIOL, V205, P3717
   Farber BS, 1995, J REHABIL RES DEV, V32, P337
   Furse A, 2011, J MED BIOL ENG, V31, P145, DOI 10.5405/jmbe.821
   Hamner SR, 2013, ANN BIOMED ENG, V41, P1851, DOI 10.1007/s10439-013-0792-8
   Horgan O, 2004, DISABIL REHABIL, V26, P837, DOI 10.1080/09638280410001708869
   Inman V. T., 1981, HUMAN WALKING
   Kuo AD, 2007, HUM MOVEMENT SCI, V26, P617, DOI 10.1016/j.humov.2007.04.003
   Martinez-Vilialpando EC, 2009, J REHABIL RES DEV, V46, P361, DOI 10.1682/JRRD.2008.09.0131
   MOHAN D, 1986, ORTHOTICS PROSTHET, V40, P16
   NARANG IC, 1984, PROSTHET ORTHOT INT, V8, P43
   Narang Y. S., 2013, THESIS
   Narang Y. S., 2014, DETC201435065 ASME
   Narang YS, 2016, J BIOMECH ENG-T ASME, V138, DOI 10.1115/1.4034168
   Narang YS, 2016, IEEE T NEUR SYS REH, V24, P754, DOI 10.1109/TNSRE.2015.2455054
   Ottobock, 2014, REIMB PROD
   Perry J, 2010, GAIT ANALYSIS: NORMAL AND PATHOLOGICAL FUNCTION, SECOND EDITION, P1
   RADCLIFFE CW, 1994, PROSTHET ORTHOT INT, V18, P159
   RYBARCZYK B, 1995, REHABIL PSYCHOL, V40, P95
   Sup F, 2008, INT J ROBOT RES, V27, P263, DOI 10.1177/0278364907084588
   Winter DA, 2009, BIOMECHANICS MOTOR C
   World Health Organization (WHO), 2005, GUID TRAIN PERS DEV
   Wyss D., 2012, THESIS
   Yinusa W, 2003, INT ORTHOP, V27, P121, DOI 10.1007/s00264-002-0421-x
   2011, WORLD REP DIS, P1
NR 30
TC 0
Z9 0
U1 5
U2 7
PU ASME
PI NEW YORK
PA TWO PARK AVE, NEW YORK, NY 10016-5990 USA
SN 1942-4302
EI 1942-4310
J9 J MECH ROBOT
JI J. Mech. Robot.
PD JUN
PY 2018
VL 10
IS 3
AR 031007
DI 10.1115/1.4039222
PG 8
WC Engineering, Mechanical; Robotics
SC Engineering; Robotics
GA GH5RN
UT WOS:000433491700007
DA 2019-02-18
ER

PT J
AU Bao, GJ
   Fang, H
   Chen, LF
   Wan, YH
   Xu, F
   Yang, QH
   Zhang, LB
AF Bao, Guanjun
   Fang, Hui
   Chen, Lingfeng
   Wan, Yuehua
   Xu, Fang
   Yang, Qinghua
   Zhang, Libin
TI Soft Robotics: Academic Insights and Perspectives Through Bibliometric
   Analysis
SO SOFT ROBOTICS
LA English
DT Review
DE soft robotics; artificial muscle; bioinspired robot; smart material;
   multidisciplinary; bibliometrics
ID ACTUATORS; FUTURE; SENSORS; HAND; SKIN; CHALLENGES; PROSPECTS; GUIDANCE;
   MUSCLES; TRENDS
AB Soft robotics is of growing interest in the robot community as well as in public media, and there is an increase in the quality and quantity of publications related to this topic. To formally elaborate this growth, we have used a bibliometric analysis to evaluate the publications in the field from 1990 to 2017 based on the Science Citation Index Expanded database. We present a detailed overview and discussion based on keywords, citation, h-index, year, journal, institution, country, author, and review articles. The results show that the United States takes the leading position in this research field, followed by China and Italy. Harvard University has the most publications, high average number of citations per publication and the highest h-index. IEEE Transactions on Robotics ranks first among the top 20 academic journals publishing articles related to this field, whereas Soft Robotics holds the top position in journals categorized with "ROBOTICS." Actuator, fabrication, control, material, sensing, simulation, bionics, stiffness, modeling, power, motion, and application are the hot topics of soft robotics. Smart materials, bionics, morphological computation, and embodiment control are expected to contribute to this field in the future. Application and commercialization appear to be the initial driving force and final goal for soft robots.
C1 [Bao, Guanjun; Chen, Lingfeng; Xu, Fang; Yang, Qinghua; Zhang, Libin] Zhejing Univ Technol, Coll Mech Engn, Hangzhou, Zhejiang, Peoples R China.
   [Fang, Hui; Wan, Yuehua] Zhejiang Univ Technol, Lib, 18 Changwang Rd, Hangzhou 310014, Zhejiang, Peoples R China.
RP Wan, YH (reprint author), Zhejiang Univ Technol, Lib, 18 Changwang Rd, Hangzhou 310014, Zhejiang, Peoples R China.
EM wanyuehua@zjut.edu.cn
RI Wan, Yuehua/G-2351-2011
OI Wan, Yuehua/0000-0003-3456-8748
FU National Natural Science Foundation of China [51775499]; NSFC-Zhejiang
   Joint Fund for the Integration of Industrialization and Informatization
   [U1509212]; Open Foundation of Intelligent Robots and Systems at the
   University of Beijing Institute of Technology, High-Tech Innovation
   Center [2016IRS03]
FX This work is financially supported by National Natural Science
   Foundation of China (Grant No. 51775499), NSFC-Zhejiang Joint Fund for
   the Integration of Industrialization and Informatization (Grant No.
   U1509212), and Open Foundation of Intelligent Robots and Systems at the
   University of Beijing Institute of Technology, High-Tech Innovation
   Center (Grant No. 2016IRS03).
CR Aguilar J, 2016, REP PROG PHYS, V79, DOI 10.1088/0034-4885/79/11/110001
   Albu-Schaffer A, 2005, IEEE RSJ INT C INT R, V4, P3295
   Amjadi M, 2016, ADV FUNCT MATER, V26, P1678, DOI 10.1002/adfm.201504755
   Bahramzadeh Y, 2014, SOFT ROBOT, V1, P38, DOI 10.1089/soro.2013.0006
   Bao GJ, 2017, INT J AGR BIOL ENG, V10, P114, DOI 10.3965/j.ijabe.20171002.2909
   Bauer S, 2014, ADV MATER, V26, P149, DOI 10.1002/adma.201303349
   Boblan I, 2004, LECT NOTES ARTIF INT, V3139, P160
   Calma A, 2016, SCIENTOMETRICS, V108, P959, DOI 10.1007/s11192-016-1998-y
   Camarillo DB, 2008, IEEE T ROBOT, V24, P1262, DOI 10.1109/TRO.2008.2002311
   Cao Yujun, 2012, Journal of Mechanical Engineering, V48, P25, DOI 10.3901/JME.2012.03.025
   Chen D, 2017, CHEM REV, V117, P11239, DOI 10.1021/acs.chemrev.7b00019
   Chen G, 2009, ROBOT AUTON SYST, V57, P712, DOI 10.1016/j.robot.2008.11.001
   Chen HQ, 2016, RENEW SUST ENERG REV, V58, P966, DOI 10.1016/j.rser.2015.12.239
   Chen HQ, 2014, SCIENTOMETRICS, V98, P1865, DOI 10.1007/s11192-013-1132-3
   Chen H, 2015, APPL ENERG, V155, P585, DOI 10.1016/j.apenergy.2015.06.055
   Chen JL, 2016, NEUROCOMPUTING, V174, P1087, DOI 10.1016/j.neucom.2015.09.105
   Chen Z, 2010, IEEE-ASME T MECH, V15, P448, DOI 10.1109/TMECH.2009.2027812
   Cho KJ, 2009, INT J PRECIS ENG MAN, V10, P171, DOI 10.1007/s12541-009-0064-6
   Cianchetti M, 2015, BIOINSPIR BIOMIM, V10, DOI 10.1088/1748-3190/10/3/035003
   Cundy TP, 2018, J ROBOT SURG, V12, P109, DOI 10.1007/s11701-017-0703-3
   De Greef A, 2009, PRECIS ENG, V33, P311, DOI 10.1016/j.precisioneng.2008.10.004
   De Volder M, 2010, J MICROMECH MICROENG, V20, DOI 10.1088/0960-1317/20/4/043001
   Elango N, 2015, INT J ADV MANUF TECH, V80, P1027, DOI 10.1007/s00170-015-7085-3
   Franceschet M, 2010, SCIENTOMETRICS, V83, P243, DOI 10.1007/s11192-009-0021-2
   Hannan MW, 2001, IEEE ASME INT C ADV, P14, DOI 10.1109/AIM.2001.936423
   Heradio R, 2016, COMPUT EDUC, V98, P14, DOI 10.1016/j.compedu.2016.03.010
   Hernandez-Garcia YI, 2016, J ASSOC INF SCI TECH, V67, P1245, DOI 10.1002/asi.23493
   Hughes J, 2016, FRONT ROBOT AI, V3, DOI 10.3389/frobt.2016.00069
   Iida F, 2011, PROCEDIA COMPUT SCI, V7, P99, DOI 10.1016/j.procs.2011.12.030
   Ilievski F, 2011, ANGEW CHEM INT EDIT, V50, P1890, DOI 10.1002/anie.201006464
   IMMEGA G, 1995, IEEE INT CONF ROBOT, P3149, DOI 10.1109/ROBOT.1995.525733
   Jones BA, 2006, IEEE T ROBOT, V22, P1087, DOI 10.1109/TRO.2006.886268
   Kim S, 2008, IEEE T ROBOT, V24, P65, DOI 10.1109/TRO.2007.909786
   Kim S, 2013, TRENDS BIOTECHNOL, V31, P23, DOI 10.1016/j.tibtech.2013.03.002
   Kim Y, 2013, NATURE, V500, P59, DOI 10.1038/nature12401
   Kornbluh R, 1998, IEEE INT CONF ROBOT, P2147, DOI 10.1109/ROBOT.1998.680638
   Krishna S, 2011, J APPL SCI, V11, P1
   Kruusamae K, 2015, ACTUATORS, V4, P17, DOI 10.3390/act4010017
   Laschi C, 2009, BIOINSPIR BIOMIM, V4, DOI 10.1088/1748-3182/4/1/015006
   Laschi C., 2014, FRONT BIOENG BIOTECH, V2, P3, DOI DOI 10.3389/FBI0E.2014.00003
   Laschi C, 2016, SCI ROBOT, V1, P3690
   Laschi C, 2016, SOFT ROBOTICS TRENDS
   Lee C, 2017, INT J CONTROL AUTOM, V15, P3, DOI 10.1007/s12555-016-0462-3
   [李铁风 Li Tiefeng], 2016, [力学学报, Chinese Journal of Theoretical and Applied Mechanics], V48, P756
   Majidi C, 2014, SOFT ROBOT, V1, P5, DOI 10.1089/soro.2013.0001
   Manti M, 2016, IEEE ROBOT AUTOM MAG, V23, P93, DOI 10.1109/MRA.2016.2582718
   McMahan W., 2005, 2005 IEEE/RSJ International Conference on Intelligent Robots and Systems, P2578
   Merigo JM, 2016, J BUS ECON MANAG, V17, P397, DOI 10.3846/16111699.2013.807868
   Mingers J, 2017, EUR J OPER RES, V257, P323, DOI 10.1016/j.ejor.2016.07.058
   Nakajima K, 2011, PROCEDIA COMPUT SCI, V7, P246, DOI 10.1016/j.procs.2011.09.045
   NICKEL VL, 1963, J BONE JOINT SURG AM, V45, P933, DOI 10.2106/00004623-196345050-00004
   Noritsugu T., 2001, J ROBOTICS MECHATRON, V13, P17
   Otero TF, 2012, ELECTROCHIM ACTA, V84, P112, DOI 10.1016/j.electacta.2012.03.097
   Ozkan M, 2000, NEURAL NETWORKS, V13, P533, DOI 10.1016/S0893-6080(00)00020-4
   Park SJ, 2016, SCIENCE, V353, P158, DOI 10.1126/science.aaf4292
   Pfeifer R, 2007, SCIENCE, V318, P1088, DOI 10.1126/science.1145803
   Pfeifer R, 2012, COMMUN ACM, V55, P76, DOI 10.1145/2366316.2366335
   Polygerinos P, 2017, ADV ENG MATER, V19, DOI 10.1002/adem.201700016
   Polygerinos P, 2015, ROBOT AUTON SYST, V73, P135, DOI 10.1016/j.robot.2014.08.014
   Robinson G, 1999, ICRA '99: IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS 1-4, PROCEEDINGS, P2849
   Robinson G, 1998, P ROBOTICA 98, P195
   Rus D, 2015, NATURE, V521, P467, DOI 10.1038/nature14543
   Schulz S, 2001, IEEE INT CONF ROBOT, P2437, DOI 10.1109/ROBOT.2001.932988
   Shepherd RF, 2011, P NATL ACAD SCI USA, V108, P20400, DOI 10.1073/pnas.1116564108
   Shimachi S, 1990, T JPN SOC MECH ENG-C, V56, P1440
   Suo ZG, 2010, ACTA MECH SOLIDA SIN, V23, P549
   Suzumori K, 1997, IEEE-ASME T MECH, V2, P281, DOI 10.1109/3516.653052
   Suzumori K., 1992, IEEE Control Systems Magazine, V12, P21, DOI 10.1109/37.120448
   SUZUMORI K, 1991, 1991 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS 1-3, P1622, DOI 10.1109/ROBOT.1991.131850
   Suzumori K, 1991, J JPN SOC MECH ENG, V94, P600
   Tahamtan I, 2016, SCIENTOMETRICS, V107, P1195, DOI 10.1007/s11192-016-1889-2
   Tan DP, 2016, INT J ADV MANUF TECH, V85, P1261, DOI 10.1007/s00170-015-8044-8
   Tan DP, 2013, IEEE T EDUC, V56, P268, DOI 10.1109/TE.2012.2212707
   Tee BCK, 2012, NAT NANOTECHNOL, V7, P825, DOI [10.1038/nnano.2012.192, 10.1038/NNANO.2012.192]
   Tondu B, 2000, IEEE CONTR SYST MAG, V20, P15, DOI 10.1109/37.833638
   Trimmer B, 2006, 7 INT S TECHN MIN PR, P1
   Trivedi Deepak, 2008, Applied Bionics and Biomechanics, V5, P99, DOI 10.1080/11762320802557865
   Verl A., 2015, SOFT ROBOTICS TRANSF, P141
   Wang LY, 2015, IEEE ROBOT AUTOM MAG, V22, P125, DOI 10.1109/MRA.2015.2448277
   [王田苗 Wang Tianmiao], 2017, [机械工程学报, Journal of Mechanical Engineering], V53, P1
   Wang Y, 2017, SCI ROBOT, V2, P1, DOI DOI 10.1016/J.JMAPR0.2017.02.001
   Yang GZ, 2016, SCI ROBOT, V1, DOI 10.1126/scirobotics.aal2099
   [张进华 Zhang Jinhua], 2017, [机械工程学报, Journal of Mechanical Engineering], V53, P19
   Zhang Libin, 2008, China Mechanical Engineering, V19, P2891
NR 84
TC 2
Z9 2
U1 32
U2 81
PU MARY ANN LIEBERT, INC
PI NEW ROCHELLE
PA 140 HUGUENOT STREET, 3RD FL, NEW ROCHELLE, NY 10801 USA
SN 2169-5172
EI 2169-5180
J9 SOFT ROBOT
JI Soft Robot.
PD JUN
PY 2018
VL 5
IS 3
BP 229
EP 241
DI 10.1089/soro.2017.0135
EA MAY
EY 2018
PG 13
WC Robotics
SC Robotics
GA GI6ZX
UT WOS:000432690500001
PM 29782219
OA Bronze
DA 2019-02-18
ER

PT J
AU Ajoudani, A
   Zanchettin, AM
   Ivaldi, S
   Albu-Schaffer, A
   Kosuge, K
   Khatib, O
AF Ajoudani, Arash
   Zanchettin, Andrea Maria
   Ivaldi, Serena
   Albu-Schaeffer, Alin
   Kosuge, Kazuhiro
   Khatib, Oussama
TI Progress and prospects of the human-robot collaboration
SO AUTONOMOUS ROBOTS
LA English
DT Article
DE Physical human robot collaboration; Progress and prospects; Human-robot
   interaction; Human-in-the-loop; Human-robot interfaces
ID END-POINT STIFFNESS; IMPEDANCE CONTROL; UNSTABLE DYNAMICS; COOPERATION;
   SYSTEM; MANIPULATION; STABILITY; FEEDBACK; MOVEMENT; FORCE
AB Recent technological advances in hardware design of the robotic platforms enabled the implementation of various control modalities for improved interactions with humans and unstructured environments. An important application area for the integration of robots with such advanced interaction capabilities is human-robot collaboration. This aspect represents high socio-economic impacts and maintains the sense of purpose of the involved people, as the robots do not completely replace the humans from the work process. The research community's recent surge of interest in this area has been devoted to the implementation of various methodologies to achieve intuitive and seamless human-robot-environment interactions by incorporating the collaborative partners' superior capabilities, e.g. human's cognitive and robot's physical power generation capacity. In fact, the main purpose of this paper is to review the state-of-the-art on intermediate human-robot interfaces (bi-directional), robot control modalities, system stability, benchmarking and relevant use cases, and to extend views on the required future developments in the realm of human-robot collaboration.
C1 [Ajoudani, Arash] Ist Italiano Tecnol, Human Robot Interfaces & Phys Interact Lab HRI2, Genoa, Italy.
   [Zanchettin, Andrea Maria] Politecn Milan, Dipartimento Elettron Informaz & Bioingn, Milan, Italy.
   [Ivaldi, Serena] INRIA Nancy Grand Est, Villers Les Nancy, France.
   [Ivaldi, Serena] Tech Univ Darmstadt, Intelligent Autonomous Syst Lab, Darmstadt, Germany.
   [Albu-Schaeffer, Alin] German Aerosp Ctr DLR, Inst Robot & Mech, Cologne, Germany.
   [Kosuge, Kazuhiro] Tohoku Univ, Syst Robot Lab, Sendai, Miyagi, Japan.
   [Khatib, Oussama] Stanford Univ, Stanford Robot Lab, Stanford, CA 94305 USA.
RP Ajoudani, A (reprint author), Ist Italiano Tecnol, Human Robot Interfaces & Phys Interact Lab HRI2, Genoa, Italy.
EM arash.ajoudani@iit.it; andreamaria.zanchettin@polimi.it;
   serena.ivaldi@inria.fr; Alin.Albu-Schaeffer@dlr.de;
   kosuge@m.tohoku.ac.jp; ok@robo.stanford.edu
FU EU [611832, 600716]; H2020 Project SoftPro [688857]; H2020 Project AnDy
   [731540]
FX The authors would like to thank and remember Fabrizio Flacco for his
   spirit, contributions, and enthusiasm for writing this review paper. We
   will keep his memories alive in our hearts. This work is supported in
   part by the EU FP7-ICT projects WALKMAN (No. 611832) and CoDyCo (No.
   600716); in part by the H2020 Projects SoftPro (No. 688857) and AnDy
   (No. 731540).
CR Adams J, 1996, EXPERT SYST APPL, V11, P89, DOI 10.1016/0957-4174(96)00036-X
   Agravante DJ, 2014, IEEE INT CONF ROBOT, P607, DOI 10.1109/ICRA.2014.6906917
   Ajoudani A., 2016, TRANSFERRING HUMAN I
   Ajoudani A, 2014, IEEE T HAPTICS, V7, P203, DOI 10.1109/TOH.2014.2309142
   Alami R., 2006, INT ROB SYST 2006 IE, P1, DOI DOI 10.1109/IROS.2006.6936985
   Albu-Schaffer A, 2007, IND ROBOT, V34, P376, DOI 10.1108/01439910710774386
   Albu-Schaffer A, 2007, INT J ROBOT RES, V26, P23, DOI 10.1177/0278364907073776
   AlJarrah OM, 1997, IEEE INT CONF ROBOT, P2326, DOI 10.1109/ROBOT.1997.619309
   Argall BD, 2010, ROBOT AUTON SYST, V58, P1159, DOI 10.1016/j.robot.2010.07.002
   Bascetta L, 2011, IEEE INT C INT ROBOT, P2971, DOI 10.1109/IROS.2011.6048287
   Bauer A, 2008, INT J HUM ROBOT, V5, P47, DOI 10.1142/S0219843608001303
   Bell CJ, 2008, J NEURAL ENG, V5, P214, DOI 10.1088/1741-2560/5/2/012
   Ben Amor H, 2009, LECT NOTES ARTIF INT, V5803, P492
   Berret B, 2011, IEEE INT C INT ROBOT, P4354, DOI 10.1109/IROS.2011.6048586
   Bestick AM, 2015, IEEE INT C INT ROBOT, P1037, DOI 10.1109/IROS.2015.7353498
   Bohme HJ, 2003, ROBOT AUTON SYST, V44, P83, DOI [10.1016/S0921-8890(03)00012-5, 10.1016/S0921-8890(02)00012-5]
   Buerger SP, 2006, 2006 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-12, P4570, DOI 10.1109/IROS.2006.282161
   Buerger SP, 2007, IEEE T ROBOT, V23, P232, DOI 10.1109/TRO.2007.892229
   Burdet E, 2001, NATURE, V414, P446, DOI 10.1038/35106566
   Burdet E, 2000, J BIOMECH, V33, P1705, DOI 10.1016/S0021-9290(00)00142-1
   Calinon S, 2010, IEEE ROBOT AUTOM MAG, V17, P44, DOI 10.1109/MRA.2010.936947
   Carlson T, 2012, IEEE T SYST MAN CY B, V42, P876, DOI 10.1109/TSMCB.2011.2181833
   Castellini C, 2014, FRONT NEUROROBOTICS, V8, P1, DOI 10.3389/fnbot.2014.00022
   Cherubini A, 2016, ROBOT CIM-INT MANUF, V40, P1, DOI 10.1016/j.rcim.2015.12.007
   Cherubini A, 2013, IEEE INT C INT ROBOT, P2202, DOI 10.1109/IROS.2013.6696664
   Chuy O, 2006, IEEE T SYST MAN CY C, V36, P725, DOI 10.1109/TSMCC.2006.879396
   COLGATE E, 1989, PROCEEDINGS - 1989 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOL 1-3, P404, DOI 10.1109/ROBOT.1989.100021
   COLGATE JE, 1988, INT J CONTROL, V48, P65, DOI 10.1080/00207178808906161
   Colome A, 2015, IEEE INT CONF ROBOT, P5649, DOI 10.1109/ICRA.2015.7139990
   Corrales J. A., 2008, P 3 ACM IEEE INT C H, P193, DOI DOI 10.1145/1349822.1349848
   De Santis A, 2008, MECH MACH THEORY, V43, P253, DOI 10.1016/j.mechmachtheory.2007.03.003
   De Santis A, 2007, LECT NOTES CONTR INF, V353, P51
   De Schutter J, 2007, INT J ROBOT RES, V26, P433, DOI [10.1177/027836490707809107, 10.1177/0278364907078091]
   de Vlugt E, 2003, J NEUROSCI METH, V129, P151, DOI [10.1016/S0165-0270(03)00203-6, 10.1016/S0165-0270(03)00203-0]
   Dimeas F, 2016, IEEE T HAPTICS, V9, P267, DOI 10.1109/TOH.2016.2518670
   Donner P, 2016, IEEE T ROBOT, V32, P744, DOI 10.1109/TRO.2016.2560898
   Dragan A., 2013, HUMAN ROBOT INTERACT
   Duchaine V, 2009, P IEEE INT C ROB AUT, P3383, DOI DOI 10.1109/ROBOT.2009.5152664
   Duchaine V, 2008, IEEE INT CONF ROBOT, P2189, DOI 10.1109/ROBOT.2008.4543531
   Duchaine V, 2007, WORLD HAPTICS 2007: SECOND JOINT EUROHAPTICS CONFERENCE AND SYMPOSIUM ON HAPTIC INTERFACES FOR VIRTUAL ENVIRONMENT AND TELEOPERATOR SYSTEMS, PROCEEDINGS, P446
   Dumora J, 2012, IEEE INT C INT ROBOT, P5137, DOI 10.1109/IROS.2012.6385721
   Ebert DM, 2002, 2002 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-3, PROCEEDINGS, P1826, DOI 10.1109/IRDS.2002.1044021
   Edsinger Aaron, 2007, 16th IEEE International Conference on Robot and Human Interactive Communication, P1167
   Eppinger S. D., 1987, Proceedings of the 1987 IEEE International Conference on Robotics and Automation (Cat. No.87CH2413-3), P904
   Erden MS, 2014, IEEE INT CONF ROBOT, P126, DOI 10.1109/ICRA.2014.6906599
   Evrard Paul, 2009, 2009 9th IEEE-RAS International Conference on Humanoid Robots (Humanoids 2009), P399, DOI 10.1109/ICHR.2009.5379513
   Evrard P, 2009, WORLD HAPTICS 2009: THIRD JOINT EUROHAPTICS CONFERENCE AND SYMPOSIUM ON HAPTIC INTERFACES FOR VIRTUAL ENVIRONMENT AND TELEOPERATOR SYSTEMS, PROCEEDINGS, P45, DOI 10.1109/WHC.2009.4810879
   Farina D, 2014, IEEE T NEUR SYS REH, V22, P797, DOI 10.1109/TNSRE.2014.2305111
   Farry KA, 1996, IEEE T ROBOTIC AUTOM, V12, P775, DOI 10.1109/70.538982
   Feil-Seifer D, 2007, INTERACT STUD, V8, P423
   Fernandez V, 2001, IEEE INT CONF ROBOT, P2668, DOI 10.1109/ROBOT.2001.933025
   Ficuciello F, 2014, IEEE INT C INT ROBOT, P2120, DOI 10.1109/IROS.2014.6942847
   Fleischer C, 2008, IEEE T ROBOT, V24, P872, DOI 10.1109/TRO.2008.926860
   Fong T, 2003, ROBOT AUTON SYST, V42, P143, DOI 10.1016/S0921-8890(02)00372-X
   Franklin DW, 2008, J NEUROSCI, V28, P11165, DOI 10.1523/JNEUROSCI.3099-08.2008
   Franklin DW, 2007, J NEUROSCI, V27, P7705, DOI 10.1523/JNEUROSCI.0968-07.2007
   Franklin DW, 2003, J NEUROPHYSIOL, V90, P3270, DOI 10.1152/jn.01112.2002
   Freedy A, 2007, CTS 2007: PROCEEDINGS OF THE 2007 INTERNATIONAL SYMPOSIUM ON COLLABORATIVE TECHNOLOGIES AND SYSTEMS, P106, DOI 10.1109/CTS.2007.4621745
   Fumagalli M, 2012, AUTON ROBOT, V33, P381, DOI 10.1007/s10514-012-9291-2
   Gams A, 2014, IEEE T ROBOT, V30, P816, DOI 10.1109/TRO.2014.2304775
   Gijsberts A, 2014, FRONT NEUROROBOTICS, V8, P1, DOI 10.3389/fnbot.2014.00008
   Glassmire J, 2004, 12TH INTERNATIONAL SYMPOSIUM ON HAPTIC INTERFACES FOR VIRTUAL ENVIRONMENT AND TELEOPERATOR SYSTEMS, PROCEEDINGS, P114, DOI 10.1109/HAPTIC.2004.1287185
   Godfrey S B, 2013, IEEE Int Conf Rehabil Robot, V2013, P6650377, DOI 10.1109/ICORR.2013.6650377
   GORDON AM, 1993, J NEUROPHYSIOL, V69, P1789
   Green S. A., 2009, INT J INTELL SYST, V8, P130
   Green SA, 2008, INT J ADV ROBOT SYST, V5, P1, DOI 10.5772/5664
   Gribovskaya E, 2011, IEEE INT CONF ROBOT
   Haddadin S, 2009, INT J ROBOT RES, V28, P1507, DOI 10.1177/0278364909343970
   Hawkins KP, 2013, IEEE-RAS INT C HUMAN, P499, DOI 10.1109/HUMANOIDS.2013.7030020
   Hegel F, 2008, 2008 17TH IEEE INTERNATIONAL SYMPOSIUM ON ROBOT AND HUMAN INTERACTIVE COMMUNICATION, VOLS 1 AND 2, P574, DOI 10.1109/ROMAN.2008.4600728
   HOGAN N, 1985, J DYN SYST-T ASME, V107, P8, DOI 10.1115/1.3140713
   Horiguchi Y, 2000, IEEE SYS MAN CYBERN, P876, DOI 10.1109/ICSMC.2000.885960
   Hwang J, 2013, APPL ERGON, V44, P459, DOI 10.1016/j.apergo.2012.10.010
   Ikemoto S, 2012, IEEE ROBOT AUTOM MAG, V19, P24, DOI 10.1109/MRA.2011.2181676
   IKEURA R, 1995, IEEE INT CONF ROBOT, P3097, DOI 10.1109/ROBOT.1995.525725
   Ivaldi S., 2012, PALADYN, V3, P75
   Ivaldi S, 2017, INT J SOC ROBOT, V9, P63, DOI 10.1007/s12369-016-0357-8
   Ivaldi S, 2014, FRONT NEUROROBOTICS, V8, P1, DOI 10.3389/fnbot.2014.00005
   Jarrasse N, 2008, IEEE INT CONF ROBOT, P2134, DOI 10.1109/ROBOT.2008.4543522
   Jarrasse N, 2014, ADAPT BEHAV, V22, P70, DOI 10.1177/1059712313481044
   Jiang N, 2009, IEEE T BIO-MED ENG, V56, P1070, DOI 10.1109/TBME.2008.2007967
   Johansson RS, 1998, NOVART FDN SYMP, V218, P45
   Kahn P. H., 2006, P 15 IEEE INT S ROB, P364, DOI DOI 10.1109/ROMAN.2006.314461
   Kaneko K, 2008, 2008 IEEE/RSJ INTERNATIONAL CONFERENCE ON ROBOTS AND INTELLIGENT SYSTEMS, VOLS 1-3, CONFERENCE PROCEEDINGS, P2471, DOI 10.1109/IROS.2008.4650604
   Khansari-Zadeh S., 2014, RSS
   Khansari-Zadeh SM, 2011, IEEE T ROBOT, V27, P943, DOI 10.1109/TRO.2011.2159412
   Khatib O, 2009, J PHYSIOL-PARIS, V103, P211, DOI 10.1016/j.jphysparis.2009.08.004
   Kilner JM, 2003, CURR BIOL, V13, P522, DOI 10.1016/S0960-9822(03)00165-9
   Kim S, 2006, 2006 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-12, P3486, DOI 10.1109/IROS.2006.282591
   Kim W, 2017, INT C REHAB ROBOT, P828, DOI 10.1109/ICORR.2017.8009351
   Kimura H., 1999, Proceedings 1999 IEEE/RSJ International Conference on Intelligent Robots and Systems. Human and Environment Friendly Robots with High Intelligence and Emotional Quotients (Cat. No.99CH36289), P701, DOI 10.1109/IROS.1999.812762
   Klingspor V, 1997, APPL ARTIF INTELL, V11, P719
   Kosuge K, 1997, RO-MAN '97 SENDAI: 6TH IEEE INTERNATIONAL WORKSHOP ON ROBOT AND HUMAN COMMUNICATION, PROCEEDINGS, P142, DOI 10.1109/ROMAN.1997.646971
   Kosuge K, 1998, IEEE INT CONF ROBOT, P1841, DOI 10.1109/ROBOT.1998.677435
   Kronander K, 2014, IEEE T HAPTICS, V7, P367, DOI 10.1109/TOH.2013.54
   Kruger J, 2009, CIRP ANN-MANUF TECHN, V58, P628, DOI 10.1016/j.cirp.2009.09.009
   Kruse D, 2015, IEEE INT CONF ROBOT, P3782, DOI 10.1109/ICRA.2015.7139725
   Kulic D, 2007, IEEE T ROBOT, V23, P991, DOI 10.1109/TRO.2007.904899
   Lacevic B, 2011, J DYN SYST-T ASME, V133, DOI 10.1115/1.4003260
   Lackey S., 2011, P HUM FACT ERG SOC A, V55, P461, DOI DOI 10.1177/1071181311551095
   Lallee S, 2012, IEEE T AUTON MENT DE, V4, P239, DOI 10.1109/TAMD.2012.2199754
   Lamy X, 2009, 2009 IEEE International Conference on Robotics and Automation (ICRA), P265, DOI 10.1109/ROBOT.2009.5152294
   Lawitzky M, 2012, IEEE INT C INT ROBOT, P3646, DOI 10.1109/IROS.2012.6386040
   Lecours A, 2012, IEEE INT CONF ROBOT, P3903, DOI 10.1109/ICRA.2012.6224586
   Lee D, 2011, AUTON ROBOT, V31, P115, DOI 10.1007/s10514-011-9234-3
   Lee SY, 2007, AUTON ROBOT, V22, P305, DOI 10.1007/s10514-006-9722-z
   Levratti A, 2016, IEEE ASME INT C ADV, P733, DOI 10.1109/AIM.2016.7576855
   Li Z., 2005, P WORKSH MOD PEOPL H, V77
   Maeda Y, 2001, IEEE INT CONF ROBOT, P3477, DOI 10.1109/ROBOT.2001.933156
   Magnanimo V, 2014, IEEE ROMAN, P726, DOI 10.1109/ROMAN.2014.6926339
   Magrini E, 2014, IEEE INT C INT ROBOT, P2126, DOI 10.1109/IROS.2014.6942848
   Maurice P, 2017, INT J IND ERGONOM, V57, P88, DOI 10.1016/j.ergon.2016.11.011
   Medina J. R., 2012, 2012 RO-MAN: The 21st IEEE International Symposium on Robot and Human Interactive Communication, P1097, DOI 10.1109/ROMAN.2012.6343895
   Mittendorfer P, 2015, ADV ROBOTICS, V29, P51, DOI 10.1080/01691864.2014.952493
   Mortl A, 2012, INT J ROBOT RES, V31, P1656, DOI 10.1177/0278364912455366
   Mojtahedi K, 2017, FRONT NEUROROBOTICS, V11, DOI 10.3389/fnbot.2017.00021
   Morasso P., 2007, VIRTUAL REHABILITATI, P70
   Morel G, 1998, IEEE INT CONF ROBOT, P1743, DOI 10.1109/ROBOT.1998.677418
   Murphy RR, 2004, IEEE T SYST MAN CY C, V34, P138, DOI 10.1109/TSMCC.2004.826267
   Nagai Y, 2009, IEEE T AUTON MENT DE, V1, P44, DOI 10.1109/TAMD.2009.2021090
   NAPIER JR, 1956, J BONE JOINT SURG BR, V38, P902
   NEWMAN WS, 1992, J DYN SYST-T ASME, V114, P563, DOI 10.1115/1.2897725
   NOHAMA P, 1995, ARTIF ORGANS, V19, P225, DOI 10.1111/j.1525-1594.1995.tb02318.x
   Ogata T, 2003, IROS 2003: PROCEEDINGS OF THE 2003 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-4, P162
   Ott C, 2006, IEEE-RAS INT C HUMAN, P276, DOI 10.1109/ICHR.2006.321397
   OZTOP E, 2005, INT J HUM ROBOT, V2, P537, DOI DOI 10.1142/S0219843605000582
   Palunko I, 2014, IEEE INT C INT ROBOT, P885, DOI 10.1109/IROS.2014.6942664
   Pecchinenda A, 1996, COGNITION EMOTION, V10, P481, DOI 10.1080/026999396380123
   Perzanowski D, 1998, JOINT CONFERENCE ON THE SCIENCE AND TECHNOLOGY OF INTELLIGENT SYSTEMS, P247, DOI 10.1109/ISIC.1998.713669
   Peternel L., 2016, 2016 IEEE RAS INT C
   Peternel L., 2016, 2016 IEEE RSJ INT C
   Peternel L, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0148942
   Peternel L, 2014, AUTON ROBOT, V36, P123, DOI 10.1007/s10514-013-9361-0
   Peternel L, 2013, ADV ROBOTICS, V27, P1003, DOI 10.1080/01691864.2013.808305
   Petit M, 2013, IEEE T AUTON MENT DE, V5, P3, DOI 10.1109/TAMD.2012.2209880
   Piovesan D, 2013, IEEE T NEUR SYS REH, V21, P454, DOI 10.1109/TNSRE.2012.2226915
   Plagemann C, 2010, IEEE INT CONF ROBOT, P3108, DOI 10.1109/ROBOT.2010.5509559
   Radford NA, 2015, J FIELD ROBOT, V32, P397, DOI 10.1002/rob.21560
   Ragaglia M, 2016, ROBOT CIM-INT MANUF, V39, P9, DOI 10.1016/j.rcim.2015.11.002
   Rani P, 2006, PATTERN ANAL APPL, V9, P58, DOI 10.1007/s10044-006-0025-y
   Rani P, 2004, ROBOTICA, V22, P85, DOI 10.1017/S0263574703005319
   Reed K. B, 2012, SERIES TOUCH HAPTIC
   Reed KB, 2008, IEEE T HAPTICS, V1, P108, DOI 10.1109/ToH.2008.13
   Rosen J, 2001, IEEE T SYST MAN CY A, V31, P210, DOI 10.1109/3468.925661
   Rozo L., 2013, P AAAI C ART INT BEL, P1422
   Rozo L, 2016, IEEE T ROBOT, V32, P513, DOI 10.1109/TRO.2016.2540623
   Rozo L, 2015, IEEE INT C INT ROBOT, P1024, DOI 10.1109/IROS.2015.7353496
   Rozo L, 2014, IEEE ROMAN, P619, DOI 10.1109/ROMAN.2014.6926321
   Sakita K., 2004, 2004 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) (IEEE Cat. No.04CH37566), P846
   Sebanz N, 2006, TRENDS COGN SCI, V10, P70, DOI 10.1016/j.tics.2005.12.009
   SHADMEHR R, 1994, J NEUROSCI, V14, P3208
   SHANNON GF, 1976, MED BIOL ENG, V14, P289, DOI 10.1007/BF02478123
   Shimizu H., 1994, 3 IEEE INT WORKSH RO, P118, DOI DOI 10.1109/R0MAN.1994.365945
   Squeri V, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0011189
   Srinivasa S., 2012, ROBOTICS SCI SYSTEMS
   Strazzulla I, 2017, IEEE T NEUR SYS REH, V25, P227, DOI 10.1109/TNSRE.2016.2554884
   Stulp F, 2015, IEEE INT C INT ROBOT, P1249, DOI 10.1109/IROS.2015.7353529
   Tamei T, 2011, ADV ROBOTICS, V25, P563, DOI 10.1163/016918611X558252
   Tan JTC, 2009, 2009 IEEE-RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, P29, DOI 10.1109/IROS.2009.5354155
   Tegin J, 2005, IND ROBOT, V32, P64, DOI 10.1108/01439910510573318
   Todorov E, 2002, NAT NEUROSCI, V5, P1226, DOI 10.1038/nn963
   Tomasello M, 2009, WHY WE COOPERATE, P1
   Tsagarakis NG, 2017, J FIELD ROBOT, V34, P1225, DOI 10.1002/rob.21702
   Tsumugiwa T, 2002, 2002 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-3, PROCEEDINGS, P1075, DOI 10.1109/IRDS.2002.1043874
   Ugur E, 2015, ROBOTICA, V33, P1163, DOI 10.1017/S0263574714002148
   Ulrich I, 2001, IEEE T SYST MAN CY A, V31, P131, DOI 10.1109/3468.911370
   Vanderborght B, 2013, ROBOT AUTON SYST, V61, P1601, DOI 10.1016/j.robot.2013.06.009
   Vogel J, 2011, IEEE INT C INT ROBOT, P672, DOI 10.1109/IROS.2011.6048345
   Wakita K, 2013, IEEE-ASME T MECH, V18, P285, DOI 10.1109/TMECH.2011.2169980
   WANG GZ, 1995, 1995 IEEE INTERNATIONAL CONFERENCE ON SYSTEMS, MAN AND CYBERNETICS, VOLS 1-5, P501, DOI 10.1109/ICSMC.1995.537810
   Wang Z., 2005, FUTURE, V10, P20
   Wojtara T, 2009, AUTOMATICA, V45, P333, DOI 10.1016/j.automatica.2008.08.021
   Yang C., 2016, IEEE INT C INT ROB S
   Yang CG, 2011, IEEE T ROBOT, V27, P918, DOI 10.1109/TRO.2011.2158251
   Zanchettin AM, 2015, IEEE INT CONF ROBOT, P2748, DOI 10.1109/ICRA.2015.7139572
   Zanchettin AM, 2013, IEEE ROBOT AUTOM MAG, V20, P131, DOI 10.1109/MRA.2013.2283650
   Zanchettin AM, 2013, APPL ERGON, V44, P982, DOI 10.1016/j.apergo.2013.03.028
NR 177
TC 6
Z9 6
U1 19
U2 30
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 0929-5593
EI 1573-7527
J9 AUTON ROBOT
JI Auton. Robot.
PD JUN
PY 2018
VL 42
IS 5
SI SI
BP 957
EP 975
DI 10.1007/s10514-017-9677-2
PG 19
WC Computer Science, Artificial Intelligence; Robotics
SC Computer Science; Robotics
GA GF1CL
UT WOS:000431669800002
DA 2019-02-18
ER

PT J
AU Liu, P
   Glas, DF
   Kanda, T
   Ishiguro, H
AF Liu, Phoebe
   Glas, Dylan F.
   Kanda, Takayuki
   Ishiguro, Hiroshi
TI Learning proactive behavior for interactive social robots
SO AUTONOMOUS ROBOTS
LA English
DT Article
DE Human-robot interaction; Data-driven learning; Learning by imitation;
   Social robotics; Service robots; Proactive behaviors
ID DESIGN
AB Learning human-robot interaction logic from example interaction data has the potential to leverage "big data" to reduce the effort and time spent on designing interaction logic or crafting interaction content. Previous work has demonstrated techniques by which a robot can learn motion and speech behaviors from non-annotated human-human interaction data, but these techniques only enable a robot to respond to human-initiated inputs, and do not enable the robot to proactively initiate interaction. In this work, we propose a method for learning both human-initiated and robot-initiated behavior for a social robot from human-human example interactions, which we demonstrate for a shopkeeper interacting with a customer in a camera shop scenario. This was achieved by extending an existing technique by (1) introducing a concept of a customer yield action, (2) incorporating interaction history, represented by sequences of discretized actions, as inputs for training and generating robot behavior, and (3) using an "attention mechanism" in our learning system for training robot behaviors, that learns which parts of the interaction history are more important for generating robot behaviors. The proposed method trains a robot to generate multimodal actions, consisting of speech and locomotion behaviors. We compared this study with the previous technique in two ways. Cross-validation on the training data showed higher social appropriateness of predicted behaviors using the proposed technique, and a user study of live interaction with a robot showed that participants perceived the proposed technique to produce behaviors that were more proactive, socially-appropriate, and better in overall quality.
C1 [Liu, Phoebe; Glas, Dylan F.] ERATO Ishiguro Symbiot Human Robot Interact Proje, 2-2-2 Hikaridai, Keihanna Sci City, Kyoto, Japan.
   [Kanda, Takayuki] ATR IRC, 2-2-2 Hikaridai, Keihanna Sci City, Kyoto, Japan.
   [Ishiguro, Hiroshi] Osaka Univ, ERATO Ishiguro Symbiot Human Robot Interact Proje, 1-3 Machikaneyama, Toyonaka, Osaka, Japan.
RP Liu, P (reprint author), ERATO Ishiguro Symbiot Human Robot Interact Proje, 2-2-2 Hikaridai, Keihanna Sci City, Kyoto, Japan.
EM phoebe@atr.jp; dylan@atr.jp; kanda@atr.jp; ishiguro@sys.es.osaka-u.ac.jp
OI Kanda, Takayuki/0000-0002-9546-5825
FU JST ERATO Ishiguro Symbiotic Human-Robot Interaction Project
   [JPMJER1401]; JSPS KAKENHI [25240042]
FX This work was supported in part by the JST ERATO Ishiguro Symbiotic
   Human-Robot Interaction Project, Grant Number JPMJER1401, and in part by
   JSPS KAKENHI Grant Number 25240042.
CR Admoni Henny, 2014, P 16 INT C MULT INT, P196
   Awais M, 2012, IEEE INT C INT ROBOT, P4098, DOI 10.1109/IROS.2012.6385880
   Bahdanau D., 2014, ARXIV14090473
   Bauer A, 2009, INT J SOC ROBOT, V1, P127, DOI 10.1007/s12369-009-0011-9
   Breazeal C, 2013, J HUM-ROBOT INTERACT, V2, P82, DOI 10.5898/JHRI.2.1.Breazeal
   Brscic D, 2013, IEEE T HUM-MACH SYST, V43, P522, DOI 10.1109/THMS.2013.2283945
   Chao C., 2011, J HUMAN ROBOT INTERA, V1, P1
   Chao Shi, 2010, 2010 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2010), P5302, DOI 10.1109/IROS.2010.5650128
   Cheng Jianpeng, 2016, ARXIV160106733
   Chernova S, 2011, P IEEE INT S ROB HUM, P21, DOI DOI 10.1109/ROMAN.2011.6005284
   COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964
   DUNCAN S, 1972, J PERS SOC PSYCHOL, V23, P283, DOI 10.1037/h0033031
   Duncan S, 1974, LANG SOC, V3, P161, DOI DOI 10.1017/S0047404500004322
   Fox D, 1997, IEEE ROBOT AUTOM MAG, V4, P23, DOI 10.1109/100.580977
   Glas DF, 2015, IEEE INT CONF ROBOT, P712, DOI 10.1109/ICRA.2015.7139257
   Gu E, 2006, LECT NOTES ARTIF INT, V4133, P193
   Gueguen L., 2001, Computational Biology. First International Conference on Biology, Informatics, and Mathematics, JOBIM 2000. Selected Papers (Lecture Notes in Computer Science Vol.2066), P32
   Hall E. T., 1966, HIDDEN DIMENSION
   Hayashi K., 2007, 2007 2nd Annual Conference on Human-Robot Interaction (HRI), P137
   Hermann K. M., 2015, ADV NEURAL INFORM PR, P1693
   Huang C.-M., 2015, P ROB SCI SYST
   HULME C, 1991, J MEM LANG, V30, P685, DOI 10.1016/0749-596X(91)90032-F
   Ioffe Sergey, 2015, ARXIV150203167
   Jayawardena C, 2016, IEEE SYST J, V10, P1056, DOI 10.1109/JSYST.2014.2337882
   Kawai H., 2004, 5 ISCA WORKSH SPEECH
   Keizer S, 2014, ACM T INTERACT INTEL, V4, DOI 10.1145/2600021
   Kitade T, 2013, ACMIEEE INT CONF HUM, P57, DOI 10.1109/HRI.2013.6483502
   Landauer TK, 1998, DISCOURSE PROCESS, V25, P259, DOI 10.1080/01638539809545028
   Liu P, 2016, IEEE T ROBOT, V32, P988, DOI 10.1109/TRO.2016.2588880
   Michalowski MP, 2006, 9TH IEEE INTERNATIONAL WORKSHOP ON ADVANCED MOTION CONTROL, VOLS 1 AND 2, PROCEEDINGS, P762, DOI 10.1109/AMC.2006.1631755
   Michaud F, 1998, MACH LEARN, V31, P141, DOI 10.1023/A:1007496725428
   Mikolov T, 2010, NTFRSPEECH, V2, P3
   Mohammad Y, 2012, 2012 12TH INTERNATIONAL CONFERENCE ON CONTROL, AUTOMATION AND SYSTEMS (ICCAS), P726
   Mutlu B, 2009, P 4 ACM IEEE INT C H
   Nickel K, 2007, IMAGE VISION COMPUT, V25, P1875, DOI 10.1016/j.imavis.2005.12.020
   Orkin J., 2007, J GAME DEV, V3, P39
   Orkin J., 2009, P 8 INT C AUT AG MUL, V1, P385
   Pandey AK, 2013, INT J SOC ROBOT, V5, P215, DOI 10.1007/s12369-013-0181-3
   Raffel C., 2015, ARXIV151208756
   Raux A., 2008, P 9 SIGDIAL WORKSH D, P1
   Rich C, 2010, ACMIEEE INT CONF HUM, P375, DOI 10.1109/HRI.2010.5453163
   Robins B., 2009, 2 INT C ADV COMP HUM, P205, DOI DOI 10.1109/ACHI.2009.32
   Rozo L, 2016, FRONT ROBOT AI, V3, DOI 10.3389/frobt.2016.00030
   Satake S., 2009, 2009 4th ACM/IEEE International Conference on Human-Robot Interaction (HRI), P109
   Satake S, 2015, IEEE INT C INT ROBOT, P1832, DOI 10.1109/IROS.2015.7353616
   Schmid A., 2007, P IEEE INT WORKSH RO, P726, DOI DOI 10.1109/ROMAN.2007.4415181
   Schrempf OC, 2005, 2005 IEEE International Workshop on Robot and Human Interactive Communication (RO-MAN), P555
   Shi C., 2011, P ROB SCI SYST
   Shiomi M, 2009, 2009 IEEE-RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, P2846, DOI 10.1109/IROS.2009.5354242
   Sugiyama O, 2007, 2007 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-9, P1447
   Sukhbaatar S., 2015, ADV NEURAL INFORM PR, P2440
   Thomaz AL, 2011, AI MAG, V32, P53, DOI 10.1609/aimag.v32i4.2379
   Tonis R, 2014, J HUM-ROBOT INTERACT, V3, P25, DOI 10.5898/JHRI.3.2.Toris
   Triebel R, 2016, SPRINGER TRAC ADV RO, V113, P607, DOI 10.1007/978-3-319-27702-8_40
   Viejo G, 2015, FRONT BEHAV NEUROSCI, V9, DOI 10.3389/fnbeh.2015.00225
   Yamaoka F., 2008, P 3 ACM IEEE INT C H, P137
   Young JE, 2014, ACM T INTERACT INTEL, V3, DOI 10.1145/2499671
   Young JE, 2013, HUM-COMPUT INTERACT, V28, P379, DOI 10.1080/07370024.2012.697046
NR 58
TC 0
Z9 0
U1 7
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 0929-5593
EI 1573-7527
J9 AUTON ROBOT
JI Auton. Robot.
PD JUN
PY 2018
VL 42
IS 5
SI SI
BP 1067
EP 1085
DI 10.1007/s10514-017-9671-8
PG 19
WC Computer Science, Artificial Intelligence; Robotics
SC Computer Science; Robotics
GA GF1CL
UT WOS:000431669800009
DA 2019-02-18
ER

PT J
AU Garcia, DH
   Adams, S
   Rast, A
   Wennekers, T
   Furber, S
   Cangelosi, A
AF Garcia, Daniel Hernandez
   Adams, Samantha
   Rast, Alex
   Wennekers, Thomas
   Furber, Steve
   Cangelosi, Angelo
TI Visual attention and object naming in humanoid robots using a
   bio-inspired spiking neural network
SO ROBOTICS AND AUTONOMOUS SYSTEMS
LA English
DT Article
DE Neurorobotics; Object naming; Visual attention; Biological inspired
   models; Spiking neural networks
ID COMPUTATIONAL MODEL; LANGUAGE; REPRESENTATION; RECOGNITION; PERCEPTION;
   EMERGENCE; CIRCUITS; INSIGHTS; BRAINS
AB Recent advances in behavioural and computational neuroscience, cognitive robotics, and in the hardware implementation of large-scale neural networks, provide the opportunity for an accelerated understanding of brain functions and for the design of interactive robotic systems based on brain-inspired control systems. This is especially the case in the domain of action and language learning, given the significant scientific and technological developments in this field. In this work we describe how a neuroanatomically grounded spiking neural network for visual attention has been extended with a word learning capability and integrated with the iCub humanoid robot to demonstrate attention-led object naming. Experiments were carried out with both a simulated and a real iCub robot platform with successful results. The iCub robot is capable of associating a label to an object with a 'preferred' orientation when visual and word stimuli are presented concurrently in the scene, as well as attending to said object, thus naming it. After learning is complete, the name of the object can be recalled successfully when only the visual input is present, even when the object has been moved from its original position or when other objects are present as distractors. (C) 2018 The Authors. Published by Elsevier B.V.
C1 [Garcia, Daniel Hernandez; Adams, Samantha; Wennekers, Thomas; Cangelosi, Angelo] Plymouth Univ, Ctr Robot & Neural Syst, Plymouth, Devon, England.
   [Rast, Alex; Furber, Steve] Univ Manchester, Sch Comp Sci, Manchester, Lancs, England.
RP Garcia, DH (reprint author), Plymouth Univ, Ctr Robot & Neural Syst, Plymouth, Devon, England.
EM daniel.hernandez@plymouth.ac.uk
OI Hernandez Garcia, Daniel/0000-0001-9296-9692; Furber,
   Stephen/0000-0002-6524-3367; Wennekers, Thomas/0000-0002-2917-8895
FU EPSRC (the UK Engineering and Physical Sciences Research Council)
   [EP/J004561/1, EP/J00457X/1]
FX This work was supported by EPSRC (the UK Engineering and Physical
   Sciences Research Council) under grants EP/J004561/1 and EP/J00457X/1
   (BABEL).
CR Abbott LF, 2000, NAT NEUROSCI, V3, P1178, DOI 10.1038/81453
   Adams SV, 2014, LECT NOTES COMPUT SC, V8836, P563, DOI 10.1007/978-3-319-12643-2_68
   Araki T, 2012, IEEE INT C INT ROBOT, P1623, DOI 10.1109/IROS.2012.6385812
   Arbib M. A., 2008, SPRINGER HDB ROBOTIC, P1453, DOI [10.1007/978-3-540-30301-5_63, DOI 10.1007/978-3-540-30301-5_63]
   Arbib MA, 2010, BRAIN LANG, V112, P12, DOI 10.1016/j.bandl.2009.10.001
   Attamimi M, 2016, ADV ROBOTICS, V30, P806, DOI 10.1080/01691864.2016.1172507
   Barros P, 2015, NEURAL NETWORKS, V72, P140, DOI 10.1016/j.neunet.2015.09.009
   Barsalou LW, 2008, ANNU REV PSYCHOL, V59, P617, DOI 10.1146/annurev.psych.59.103006.093639
   Beyeler M, 2015, NEURAL NETWORKS, V72, P75, DOI 10.1016/j.neunet.2015.09.005
   Brohan K, 2010, LECT NOTES COMPUT SC, V6353, P180
   Broz F, 2014, TOP COGN SCI, V6, P534, DOI 10.1111/tops.12099
   Caligiore D, 2013, PSYCHOL RES-PSYCH FO, V77, P7, DOI 10.1007/s00426-012-0424-1
   Cangelosi A., 2014, DEV ROBOTICS BABIES
   Cangelosi A, 2010, PHYS LIFE REV, V7, P139, DOI 10.1016/j.plrev.2010.02.001
   Chan V, 2007, IEEE T CIRCUITS-I, V54, P48, DOI 10.1109/TCSI.2006.887977
   Christiansen MH, 2001, TRENDS COGN SCI, V5, P82, DOI 10.1016/S1364-6613(00)01600-4
   Coath M, 2014, FRONT NEUROSCI-SWITZ, V7, DOI 10.3389/fnins.2013.00278
   Coradeschi S, 2013, KUNSTL INTELL, V27, P129, DOI 10.1007/s13218-013-0247-2
   Cox BR, 2009, IEEE ROBOT AUTOM MAG, V16, P72, DOI 10.1109/MRA.2009.933628
   Davison A. P., 2008, FRONT NEUROINFORM, V2
   de Azambuja R, 2016, IEEE IJCNN, P1134, DOI 10.1109/IJCNN.2016.7727325
   Dominey PF, 2009, CORTEX, V45, P1012, DOI 10.1016/j.cortex.2009.03.007
   Foerster F., 2017, IEEE T COGN DEV SYST
   Furber SB, 2013, IEEE T COMPUT, V62, P2454, DOI 10.1109/TC.2012.142
   Galluppi F, 2012, LECT NOTES COMPUT SC, V7664, P226, DOI 10.1007/978-3-642-34481-7_28
   Gamez D, 2012, BIOINSPIR BIOMIM, V7, DOI 10.1088/1748-3182/7/2/025008
   Garagnani M, 2008, EUR J NEUROSCI, V27, P492, DOI 10.1111/j.1460-9568.2008.06015.x
   Garagnani M, 2017, FRONT COMPUT NEUROSC, V10, DOI 10.3389/fncom.2016.00145
   Garagnani M, 2016, EUR J NEUROSCI, V43, P721, DOI 10.1111/ejn.13145
   Garagnani M, 2013, BRAIN LANG, V127, P75, DOI 10.1016/j.bandl.2013.02.001
   Gaskell MG, 1995, COGNITIVE SCI, V19, P407
   Gerstner W., 2002, SPIKING NEURON MODEL
   Goodman DFM, 2009, FRONT NEUROSCI-SWITZ, V3, P192, DOI 10.3389/neuro.01.026.2009
   Guenther FH, 2006, BRAIN LANG, V96, P280, DOI 10.1016/j.bandl.2005.06.001
   Hebb D. O, 1949, ORG BEHAV NEUROPSYCH
   Hubel D., 1995, SCI AM LIB SERIES
   Joanisse MF, 1999, P NATL ACAD SCI USA, V96, P7592, DOI 10.1073/pnas.96.13.7592
   Kaas JH, 2000, P NATL ACAD SCI USA, V97, P11793, DOI 10.1073/pnas.97.22.11793
   Kaas JH, 1999, CURR OPIN NEUROBIOL, V9, P164, DOI 10.1016/S0959-4388(99)80022-1
   Kaplan F, 2008, FRONT NEUROSCI-SWITZ, V2, P22, DOI 10.3389/neuro.01.023.2008
   Karnath HO, 2001, NAT REV NEUROSCI, V2, P568, DOI 10.1038/35086057
   Kasabov N, 2015, INFORM SCIENCES, V294, P565, DOI 10.1016/j.ins.2014.06.028
   Koickal TJ, 2011, IEEE INT SYMP CIRC S, P2465
   Krichmar J. L., 2011, NEUROMORPHIC BRAIN B
   Krichmar JL, 2015, NEURAL NETWORKS, V72, P1, DOI 10.1016/j.neunet.2015.11.004
   Kuniyoshi Y, 1998, NEURAL NETWORKS, V11, P1259, DOI 10.1016/S0893-6080(98)00085-9
   Lebedev MA, 2004, PLOS BIOL, V2, P1919, DOI 10.1371/journal.pbio.0020365
   Long S, 2014, 2014 IEEE INTERNATIONAL CONFERENCE ON IC DESIGN & TECHNOLOGY (ICICDT)
   Lyon C., 2010, AAAI FALL S
   Lyon C, 2016, INT J ADV ROBOT SYST, V13, DOI 10.5772/63462
   Lyon C, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0038236
   Maass W, 1997, NEURAL NETWORKS, V10, P1659, DOI 10.1016/S0893-6080(97)00011-7
   Morse AF, 2010, COGNITION IN FLUX, P1362
   Morse AF, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0116012
   Nakamura T, 2011, ADV ROBOTICS, V25, P2189, DOI 10.1163/016918611X595035
   Noudoost B, 2010, CURR OPIN NEUROBIOL, V20, P183, DOI 10.1016/j.conb.2010.02.003
   Park G, 2015, NEURAL NETWORKS, V72, P109, DOI 10.1016/j.neunet.2015.09.004
   Pattacini U., 2011, THESIS
   Paugam-Moisy H., 2012, HDB NATURAL COMPUTIN, P335, DOI [10.1007/978-3-540-92910-9_10, DOI 10.1007/978-3-540-92910-9_10]
   Peniak M., 2013, 2013 IEEE 3 JOINT IN, P1, DOI DOI 10.1109/DEVLRN.2013.6652565
   Pezzulo G, 2013, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00612
   Platt ML, 1999, NATURE, V400, P233, DOI 10.1038/22268
   Plaut DC, 2000, LANG COGNITIVE PROC, V15, P445, DOI 10.1080/01690960050119661
   Ponulak F, 2011, ACTA NEUROBIOL EXP, V71, P409
   Pulvermuller F, 2014, BIOL CYBERN, V108, P573, DOI 10.1007/s00422-014-0603-9
   Pulvermuller F, 1999, BEHAV BRAIN SCI, V22, P253, DOI 10.1017/S0140525X9900182X
   Pulvermuller F, 2005, NAT REV NEUROSCI, V6, P576, DOI 10.1038/nrn1706
   Pulvermuller F, 2010, NAT REV NEUROSCI, V11, P351, DOI 10.1038/nrn2811
   Rast A. D., 2010, THE 2010 INTERNATION, P1, DOI 10.1109/IJCNN.2010.5596364
   Riesenhuber M, 1999, NAT NEUROSCI, V2, P1019
   Rucci M, 2007, ADV ROBOTICS, V21, P1115, DOI 10.1163/156855307781389428
   Saunders J., 2010, 2 INT S NEW FRONT HU
   Saunders J., 2012, 2012 IEEE INT C DEV, DOI [10.1109/DevLrn.2012.6400588, DOI 10.1109/DEVLRN.2012.6400588]
   Saunders J, 2011, ADV INTERACT STUD, V2, P211
   Seepanomwan K, 2015, NEURAL NETWORKS, V72, P31, DOI 10.1016/j.neunet.2015.09.010
   Smith E, 2005, NEURAL COMPUT, V17, P19, DOI 10.1162/0899766052530839
   Song S, 2001, NEURON, V32, P339, DOI 10.1016/S0896-6273(01)00451-2
   Song S, 2000, NAT NEUROSCI, V3, P919
   Steels L, 2005, BEHAV BRAIN SCI, V28, P469
   Steels L, 2003, TRENDS COGN SCI, V7, P308, DOI 10.1016/S1364-6613(03)00129-3
   Steels L, 2001, IEEE INTELL SYST, V16, P16, DOI 10.1109/5254.956077
   Steels L, 2008, SYMBOLS EMBODIMENT D
   Ungerleider LG, 2008, CEREB CORTEX, V18, P477, DOI 10.1093/cercor/bhm061
   Vanarse A, 2016, FRONT NEUROSCI-SWITZ, V10, DOI 10.3389/fnins.2016.00115
   Walter F, 2015, NEURAL NETWORKS, V72, P152, DOI 10.1016/j.neunet.2015.07.004
   Westermann G, 2004, BRAIN LANG, V89, P393, DOI 10.1016/S0093-934X(03)00345-6
   Yu C, 2012, COGNITION, V125, P244, DOI 10.1016/j.cognition.2012.06.016
   Zhang A., SPEECH RECOGNITION
   Zhong JP, 2014, FRONT BEHAV NEUROSCI, V8, DOI 10.3389/fnbeh.2014.00022
NR 89
TC 0
Z9 0
U1 9
U2 19
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0921-8890
EI 1872-793X
J9 ROBOT AUTON SYST
JI Robot. Auton. Syst.
PD JUN
PY 2018
VL 104
BP 56
EP 71
DI 10.1016/j.robot.2018.02.010
PG 16
WC Automation & Control Systems; Computer Science, Artificial Intelligence;
   Robotics
SC Automation & Control Systems; Computer Science; Robotics
GA GE0GK
UT WOS:000430891900005
DA 2019-02-18
ER

PT J
AU Fagard, J
   Esseily, R
   Jacquey, L
   O'Regan, K
   Somogyi, E
AF Fagard, Jaqueline
   Esseily, Rana
   Jacquey, Lisa
   O'Regan, Kevin
   Somogyi, Eszter
TI Fetal Origin of Sensorimotor Behavior
SO FRONTIERS IN NEUROROBOTICS
LA English
DT Article
DE fetus; precursor; sensorimotor development; motor babbling; mechanisms
ID 4-DIMENSIONAL 4D ULTRASONOGRAPHY; QUANTITATIVE ASPECTS; NEURAL CIRCUITS;
   HUMAN FETUSES; MOVEMENTS; INFANTS; HAND; NEWBORNS; NEONATE; OBJECTS
AB The aim of this article is to track the fetal origin of infants' sensorimotor behavior. We consider development as the self-organizing emergence of complex forms from spontaneously generated activity, governed by the innate capacity to detect and memorize the consequences of spontaneous activity (contingencies), and constrained by the sensory and motor maturation of the body. In support of this view, we show how observations on fetuses and also several fetal experiments suggest that the fetus's first motor activity allows it to feel the space around it and to feel its body and the consequences of its movements on its body. This primitive motor babbling gives way progressively to sensorimotor behavior which already possesses most of the characteristics of infants' later behavior: repetition of actions leading to sensations, intentionality, some motor control and oriented reactions to sensory stimulation. In this way the fetus can start developing a body map and acquiring knowledge of its limited physical and social environment.
C1 [Fagard, Jaqueline; Jacquey, Lisa; O'Regan, Kevin; Somogyi, Eszter] Univ Paris 05, CNRS, Lab Psychol Percept, UMR 8242, Paris, France.
   [Esseily, Rana] Univ Paris Ouest Nanterre, LECD, EA 3456, Nanterre, France.
   [Somogyi, Eszter] Univ Portsmouth, Dept Psychol, Portsmouth, Hants, England.
RP Fagard, J (reprint author), Univ Paris 05, CNRS, Lab Psychol Percept, UMR 8242, Paris, France.
EM jacqueline.fagard@parisdescartes.fr
FU ERC Advanced project "FEEL'' [323674]; FET open project Goal Robots; 
   [ANR-13-BSH2-0007-01]
FX This article was partially financed by ANR-13-BSH2-0007-01, by ERC
   Advanced project "FEEL'' No. 323674 and by FET open project Goal Robots.
CR Blumberg MS, 2013, CURR BIOL, V23, pR532, DOI 10.1016/j.cub.2013.04.075
   BOWER TGR, 1970, NATURE, V228, P679, DOI 10.1038/228679a0
   Bruner J. S., 1976, PLAY ITS ROLE DEV EV, P277
   Byrge L, 2014, TRENDS COGN SCI, V18, P395, DOI 10.1016/j.tics.2014.04.010
   Caligiore D., 2008, COGSYS2008 INT C COG
   de Graaf-Peters VB, 2006, EARLY HUM DEV, V82, P257, DOI 10.1016/j.earlhumdev.2005.10.013
   DeCasper AJ, 2009, HEARING RES, V255, P135, DOI 10.1016/j.heares.2009.06.012
   Del Giudice M, 2011, DEV PSYCHOBIOL, V53, P214, DOI 10.1002/dev.20506
   DEVRIES JIP, 1985, EARLY HUM DEV, V12, P99, DOI 10.1016/0378-3782(85)90174-4
   Durier V, 2015, SCI REP-UK, V5, DOI 10.1038/srep09177
   Fagard J, 2005, INFANT BEHAV DEV, V28, P305, DOI 10.1016/j.infbeh.2005.05.005
   Fagard J, 1998, CLIN DEV MED, P123
   Fagard J, 1996, BRIT J DEV PSYCHOL, V14, P65, DOI 10.1111/j.2044-835X.1996.tb00694.x
   Farroni T, 2004, INFANCY, V5, P39, DOI 10.1207/s15327078in0501_2
   Feller MB, 1999, NEURON, V22, P653, DOI 10.1016/S0896-6273(00)80724-2
   Fernald A., 1993, PARENT CHILD PLAY DE, P259
   Ferrari GA, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.00354
   FETTERS L, 1987, J MOTOR BEHAV, V19, P147
   GOTTLIEB G, 1991, DEV PSYCHOL, V27, P35, DOI 10.1037//0012-1649.27.1.35
   GRENIER A, 1981, ARCH FR PEDIATR, V38, P557
   Hadders-Algra M, 2007, NEUROSCI BIOBEHAV R, V31, P1181, DOI 10.1016/j.neubiorev.2007.04.009
   Hoicka E, 2008, COGNITIVE DEV, V23, P180, DOI 10.1016/j.cogdev.2007.06.001
   HOOKER D, 1952, PRENATAL ORIGIN BEHA
   Kimmerle M, 2010, DEV PSYCHOBIOL, V52, P168, DOI 10.1002/dev.20428
   Kirkby LA, 2013, NEURON, V80, P1129, DOI 10.1016/j.neuron.2013.10.030
   Kisilevsky BS, 1998, DEV REV, V18, P1, DOI 10.1006/drev.1998.0452
   KONCZAK J, 1995, EXP BRAIN RES, V106, P156
   Kuno A, 2001, J ULTRAS MED, V20, P1271
   Kurjak A, 2002, J PERINAT MED, V30, P57, DOI 10.1515/JPM.2002.008
   Kurjak A, 2004, J PERINAT MED, V32, P346, DOI 10.1515/JPM.2004.065
   Kurjak A, 2008, J MATERN-FETAL NEO M, V21, P675, DOI 10.1080/14767050802212166
   LECANUET JP, 1992, Q J EXP PSYCHOL-B, V44B, P279
   LECANUET JP, 1989, SEMIN PERINATOL, V13, P421
   Luechinger AB, 2008, PEDIATR RES, V63, P191, DOI 10.1203/PDR.0b013e31815ed03e
   MALINGER G, 1993, AM J ROENTGENOL, V161, P1041, DOI 10.2214/ajr.161.5.8273605
   Marx V, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0129118
   MCCALL RB, 1974, MONOGR SOC RES CHILD, V39, P1, DOI 10.2307/1166007
   Milh M, 2007, CEREB CORTEX, V17, P1582, DOI 10.1093/cercor/bhl069
   Mireault G. C., 2016, SPRINGERBRIEFS PSYCH, DOI [10.1007/978-3-319-38963-9, DOI 10.1007/978-3-319-38963-9]
   Muenssinger J, 2013, DEVELOPMENTAL SCI, V16, P287, DOI 10.1111/desc.12025
   Muller GB, 2003, EVOL DEV, V5, P56, DOI 10.1046/j.1525-142X.2003.03009.x
   Myowa-Yamakoshi M, 2006, INFANCY, V10, P289, DOI 10.1207/s15327078in1003_5
   NATALE R, 1985, AM J OBSTET GYNECOL, V151, P256, DOI 10.1016/0002-9378(85)90022-5
   Nomikou I, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.01656
   PALMER CF, 1989, DEV PSYCHOL, V25, P885, DOI 10.1037/0012-1649.25.6.885
   Piontelli A, 2010, DEVELOPMENT OF NORMAL FETAL MOVEMENTS: THE FIRST 25 WEEKS OF GESTATION, P1, DOI 10.1007/978-88-470-1402-2
   PRECHTL HFR, 1990, EARLY HUM DEV, V23, P151, DOI 10.1016/0378-3782(90)90011-7
   Reddy V, 2001, ENFANCE, V53, P247, DOI DOI 10.3917/ENF.533.0247
   Reid VM, 2017, CURR BIOL, V27, P2052, DOI 10.1016/j.cub.2017.06.036
   Reissland N, 2014, DEV PSYCHOBIOL, V56, P955, DOI 10.1002/dev.21172
   Reissland Nadja, 2016, Pilot Feasibility Stud, V2, P14, DOI 10.1186/s40814-016-0053-3
   ROODENBURG PJ, 1991, EARLY HUM DEV, V25, P19, DOI 10.1016/0378-3782(91)90203-F
   ROVEE CK, 1969, J EXP CHILD PSYCHOL, V8, P33, DOI 10.1016/0022-0965(69)90025-3
   RUFF HA, 1984, DEV PSYCHOL, V20, P9, DOI 10.1037//0012-1649.20.1.9
   SCHAAL B, 1992, Q J EXP PSYCHOL-B, V44B, P245
   Schum N, 2011, J EXP CHILD PSYCHOL, V109, P218, DOI 10.1016/j.jecp.2011.01.007
   Sgandurra G, 2012, INFANT BEHAV DEV, V35, P205, DOI 10.1016/j.infbeh.2012.01.003
   Somogyi E, 2018, BRIT J DEV PSYCHOL, V36, P384, DOI 10.1111/bjdp.12224
   Sparling JW, 1999, PHYS THER, V79, P24
   THELEN E, 1993, CHILD DEV, V64, P1058, DOI 10.2307/1131327
   Thomas BL, 2015, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.01526
   Trevarthen C., 1984, APPROACHES EMOTION, P129
   Trevarthen C., 1984, ADV PSYCHOL, V17, P223
   VALMAN HB, 1980, BRIT MED J, V280, P233, DOI 10.1136/bmj.280.6209.233
   van der Meer A L, 1997, Eur J Paediatr Neurol, V1, P103
   VONHOFSTEN C, 1989, WENNER-GR C, V55, P129
   VONHOFSTEN C, 1988, J EXP PSYCHOL HUMAN, V14, P610, DOI 10.1037//0096-1523.14.4.610
   VONHOFSTEN C, 1982, DEV PSYCHOL, V18, P450, DOI 10.1037//0012-1649.18.3.450
   Wallace PS, 2003, NEUROPSYCHOLOGIA, V41, P1912, DOI 10.1016/S0028-3932(03)00128-3
   Watanabe H, 2006, INFANT BEHAV DEV, V29, P402, DOI 10.1016/j.infbeh.2006.02.001
   WHITE BL, 1964, CHILD DEV, V35, P349, DOI 10.2307/1126701
   Yamaguchi Y, 2010, PRES VES P, P145
   Zoia S, 2007, EXP BRAIN RES, V176, P217, DOI 10.1007/s00221-006-0607-3
NR 73
TC 1
Z9 1
U1 2
U2 2
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1662-5218
J9 FRONT NEUROROBOTICS
JI Front. Neurorobotics
PD MAY 23
PY 2018
VL 12
AR 23
DI 10.3389/fnbot.2018.00023
PG 7
WC Computer Science, Artificial Intelligence; Robotics; Neurosciences
SC Computer Science; Robotics; Neurosciences & Neurology
GA GG6VV
UT WOS:000432837600001
PM 29875649
OA DOAJ Gold
DA 2019-02-18
ER

PT J
AU Zhang, XZ
   Zhang, JF
   Zhong, JP
AF Zhang, Xinzheng
   Zhang, Jianfen
   Zhong, Junpei
TI Toward navigation ability for autonomous mobile robots with learning
   from demonstration paradigm: A view of hierarchical temporal memory
SO INTERNATIONAL JOURNAL OF ADVANCED ROBOTIC SYSTEMS
LA English
DT Article
DE Cortical learning algorithm; hierarchical temporal memory; learning from
   demonstration; navigation; sparse distributed representation
ID ENVIRONMENT; PERCEPTION; IMITATION; TERRAIN
AB Learning from demonstration, as an important component of imitation learning, is a paradigm for robot to learn new tasks. Considering the application of learning from demonstration in the navigation issue, the robot can also acquire the navigation task via the human teacher's demonstration. Based on research of the human brain neocortex, in this article, we present a learning from demonstration navigation paradigm from the perspective of hierarchical temporal memory theory. As a type of end-to-end learning form, the demonstrated relationship between perception data and motion commands will be learned and predicted by using hierarchical temporal memory. This framework first perceives images to obtain the corresponding categories information; then the categories incorporated with depth and motion command data are encoded as a sequence of sparse distributed representation vectors. The sequential vectors are treated as the inputs to train the navigation hierarchical temporal memory. After the training, the navigation hierarchical temporal memory stores the transitions of the perceived images, depth, and motion data so that future motion commands can be predicted. The performance of the proposed navigation strategy is evaluated via the real experiments and the public data sets.
C1 [Zhang, Xinzheng; Zhang, Jianfen] Jinan Univ, Sch Elect & Informat Engn, 207 Qianshan Rd, Zhuhai 519070, Guangdong, Peoples R China.
   [Zhong, Junpei] Natl Inst Adv Ind Sci & Technol, Tokyo, Japan.
RP Zhang, JF (reprint author), Jinan Univ, Sch Elect & Informat Engn, 207 Qianshan Rd, Zhuhai 519070, Guangdong, Peoples R China.
EM eejfzhang@gmail.com
FU National Natural Science Foundation of China [61203338]
FX The author(s) disclosed receipt of the following financial support for
   the research, authorship, and/or publication of this article: This work
   was supported by the National Natural Science Foundation of China under
   grant number 61203338.
CR Ahmad S, 2016, 1607 ARXIV
   Ahmad S, 2014, SENSORIMOTOR INFEREN
   Argall BD, 2009, ROBOT AUTON SYST, V57, P469, DOI 10.1016/j.robot.2008.10.024
   Bagnell JA, 2010, IEEE ROBOT AUTOM MAG, V17, P74, DOI 10.1109/MRA.2010.936946
   Billard A., 2008, SPRINGER HDB ROBOTIC, P1371, DOI DOI 10.1007/978-3-540-30301-5_60
   Billing E, 2015, BIOL INSPIR COGN ARC, V12, P43, DOI 10.1016/j.bica.2015.03.002
   Billing EA, 2016, FRONT ROBOT AI, V3, DOI 10.3389/frobt.2016.00009
   Blakemore SJ, 2001, NAT REV NEUROSCI, V2, P561, DOI 10.1038/35086023
   Choi S, 2016, IEEE INT CONF ROBOT, P470, DOI 10.1109/ICRA.2016.7487168
   De Rengerve A, 2010, LUND U COGNITIVE STU, V149, P105
   Du Y, 2015, PROC CVPR IEEE, P1110, DOI 10.1109/CVPR.2015.7298714
   Hawkins J., 2004, INTELLIGENCE
   Hawkins J., 2016, BIOL MACHINE INTELLI
   Kawewong A, 2011, ROBOT AUTON SYST, V59, P727, DOI 10.1016/j.robot.2011.05.007
   Knoblich G, 2001, PSYCHOL SCI, V12, P467, DOI 10.1111/1467-9280.00387
   Konidaris G, 2012, INT J ROBOT RES, V31, P360, DOI 10.1177/0278364911428653
   Kurzweil Ray, 2013, CREATE MIND SECRET H
   Monroe AE, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0119841
   Nehaniv CL, 2001, CYBERNET SYST, V32, P11, DOI 10.1080/019697201300001803
   Perez-Higueras N, 2016, LECT NOTES ARTIF INT, V9979, P1, DOI 10.1007/978-3-319-47437-3_1
   Rinkus GJ, 2014, FRONT COMPUT NEUROSC, V8, DOI 10.3389/fncom.2014.00160
   Rozado D, 2012, NEUROCOMPUTING, V79, P75, DOI 10.1016/j.neucom.2011.10.005
   Schaal S, 1999, TRENDS COGN SCI, V3, P233, DOI 10.1016/S1364-6613(99)01327-3
   Silver D, 2010, INT J ROBOT RES, V29, P1565, DOI 10.1177/0278364910369715
   Suleman KMU, 2014, IEEE T AUTON MENT DE, V6, P244, DOI 10.1109/TAMD.2014.2359912
   Yea-Shuan Huang, 2013, IAENG International Journal of Computer Science, V40, P87
   Yu CC, 2014, J INF SCI ENG, V30, P637
   ZHANG XJ, 2012, IEEE INT C ROB BIOM, P476
NR 28
TC 0
Z9 0
U1 11
U2 11
PU SAGE PUBLICATIONS INC
PI THOUSAND OAKS
PA 2455 TELLER RD, THOUSAND OAKS, CA 91320 USA
SN 1729-8814
J9 INT J ADV ROBOT SYST
JI Int. J. Adv. Robot. Syst.
PD MAY 23
PY 2018
VL 15
IS 3
AR 1729881418777939
DI 10.1177/1729881418777939
PG 14
WC Robotics
SC Robotics
GA GG8TG
UT WOS:000432971000001
OA DOAJ Gold
DA 2019-02-18
ER

PT J
AU Ossmy, O
   Hoch, JE
   MacAlpine, P
   Hasan, S
   Stone, P
   Adolph, KE
AF Ossmy, Ori
   Hoch, Justine E.
   MacAlpine, Patrick
   Hasan, Shohan
   Stone, Peter
   Adolph, Karen E.
TI Variety Wins: Soccer-Playing Robots and Infant Walking
SO FRONTIERS IN NEUROROBOTICS
LA English
DT Article
DE infant walking; locomotion; bipedal robotics; robot soccer; natural gait
ID INDEPENDENT WALKING; SCHEMA THEORY; PRACTICE HYPOTHESIS; OVERGROUND
   WALKING; CEREBRAL-PALSY; VARIABILITY; TODDLERS; LOCOMOTION;
   COORDINATION; DYNAMICS
AB Although both infancy and artificial intelligence (Al) researchers are interested in developing systems that produce adaptive, functional behavior, the two disciplines rarely capitalize on their complementary expertise Here, we used soccer-playing robots to test a central question about the development of infant walking During natural activity, infants' locomotor paths are immensely varied They walk along curved, multi-directional paths with frequent starts and stops Is the variability observed in spontaneous infant walking a "feature" or a "bug?" In other words, is variability beneficial for functional walking performance? To address this question, we trained soccer-playing robots on walking paths generated by infants during free play and tested them in simulated games of "RoboCup " In Tournament 1, we compared the functional performance of a simulated robot soccer team trained on infants' natural paths with teams trained on less varied, geometric paths-straight lines, circles, and squares Across 1,000 head-to-head simulated soccer matches, the infant-trained team consistently beat all teams trained with less varied walking paths In Tournament 2, we compared teams trained on different clusters of infant walking paths The team trained with the most varied combination of path shape, step direction, number of steps, and number of starts and stops outperformed teams trained with less varied paths This evidence indicates that variety is a crucial feature supporting functional walking performance More generally, we propose that robotics provides a fruitful avenue for testing hypotheses about infant development, reciprocally, observations of infant behavior may inform research on artificial intelligence.
C1 [Ossmy, Ori; Hoch, Justine E.; Hasan, Shohan; Adolph, Karen E.] NYU, Dept Psychol, 6 Washington Pl, New York, NY 10003 USA.
   [MacAlpine, Patrick; Stone, Peter] Univ Texas Austin, Dept Comp Sci, Austin, TX 78712 USA.
RP Ossmy, O (reprint author), NYU, Dept Psychol, 6 Washington Pl, New York, NY 10003 USA.
EM oo8@nyu.edu
FU NICHD [R37HD033486]; NSF [CNS-1305287, IIS-1637736, IIS-1651089,
   IIS-1724157]; Intel; Raytheon; Lockheed Martin
FX A portion of this work took place at New York University, and was
   supported by NICHD grant # R37HD033486 to KA. A portion of this work
   took place in the Learning Agents Research Group (LARG) at UT Austin,
   and was supported by NSF (CNS-1305287, IIS-1637736, IIS-1651089,
   IIS-1724157), Intel, Raytheon, and Lockheed Martin awards to PS. PS
   serves on the Board of Directors of Cogitai, Inc. Human subjects
   participation was approved by the NYU IRB-FY2016-825. The terms of this
   arrangement have been reviewed and approved by the University of Texas
   at Austin in accordance with its policy on objectivity in research. We
   are grateful to Do Kyeong Lee, Orit Herzberg-Keller, Carli Heiman,
   Joshua Schneider, Rose Egan, and Sinclaire O'Grady for their help with
   data coding and processing.
CR Adolph K. E., 2015, HDB CHILD PSYCHOL DE, V2, P114, DOI DOI 10.1002/9781118963418.CHILDPSY204
   Adolph KE, 2008, CURR DIR PSYCHOL SCI, V17, P213, DOI 10.1111/j.1467-8721.2008.00577.x
   Adolph KE, 2017, WIRES COGN SCI, V8, DOI 10.1002/wcs.1430
   Adolph KE, 2012, PSYCHOL SCI, V23, P1387, DOI 10.1177/0956797612446346
   Adolph KE, 2010, NEURAL NETWORKS, V23, P1033, DOI 10.1016/j.neunet.2010.08.012
   Adolph KE, 2000, J EXP PSYCHOL HUMAN, V26, P1148, DOI 10.1037/0096-1523.26.3.1148
   Adolph KE, 2003, CHILD DEV, V74, P475, DOI 10.1111/1467-8624.7402011
   BERNSTEIN NA, 1996, RES ECOL PS, P3
   Bisi MC, 2015, GAIT POSTURE, V41, P574, DOI 10.1016/j.gaitpost.2014.11.017
   Boedecker J., 2008, AUTON ROBOT, V3, P174
   Bonneuil N, 2012, INFANT BEHAV DEV, V35, P380, DOI 10.1016/j.infbeh.2012.05.001
   Bril B, 2015, EXP BRAIN RES, V233, P2903, DOI 10.1007/s00221-015-4378-6
   Burkhard HD, 2002, IEEE ROBOT AUTOM MAG, V9, P31, DOI 10.1109/MRA.2002.1019488
   Cangelosi A., 2015, DEV ROBOTICS BABIES
   CATALANO JF, 1984, PERCEPT MOTOR SKILL, V58, P851, DOI 10.2466/pms.1984.58.3.851
   Chang CL, 2006, INFANT BEHAV DEV, V29, P175, DOI 10.1016/j.infbeh.2005.10.001
   Cherng RJ, 2007, AM J PHYS MED REHAB, V86, P548, DOI 10.1097/PHM.0b013e31806dc302
   CLARK JE, 1988, DEV PSYCHOBIOL, V21, P445, DOI 10.1002/dev.420210504
   Davids K., 2006, MOVEMENT SYSTEM VARI
   Farchy A., 2013, P 2013 INT C AUT AG, P39
   Gibson J. J, 1979, ECOLOGICAL APPROACH
   Gill SV, 2009, DEVELOPMENTAL SCI, V12, P888, DOI 10.1111/j.1467-7687.2009.00828.x
   GOMEZ G, 2004, P 4 INT WORKSH EP RO, P1
   Hallemans A, 2006, GAIT POSTURE, V24, P270, DOI 10.1016/j.gaitpost.2005.10.003
   Hoch J., 2017, M SOC RES CHILD DEV
   Ivanenko YP, 2004, J EXP BIOL, V207, P3797, DOI 10.1242/jeb.01214
   Ivanenko YP, 2007, EXERC SPORT SCI REV, V35, P67
   Kitano H., 1997, Proceedings of the First International Conference on Autonomous Agents, P340, DOI 10.1145/267658.267738
   Kretch KS, 2017, DEVELOPMENTAL SCI, V20, DOI 10.1111/desc.12421
   Lee D. K., 2017, DEVELOPMENTAL SCI, DOI [10.1111/desc.12615, DOI 10.1111/DESC.12615.]
   MacAlpine P., 2012, DESIGN OPTIMIZATION, V1
   MacAlpine P., 2016, UT AUSTIN VILLA ROBO
   MacAlpine P., 2012, P 11 INT C AUT AG MU, V1, P129
   MacAlpine P, 2018, ARTIF INTELL, V254, P21, DOI 10.1016/j.artint.2017.09.001
   MOXLEY SE, 1979, J MOTOR BEHAV, V11, P65
   Newell KM, 1986, MOTOR DEV CHILDREN A, P341, DOI DOI 10.1007/978-94-009-4460-2_19
   Ranganathan R, 2013, EXERC SPORT SCI REV, V41, P64, DOI 10.1097/JES.0b013e318259beb5
   Reisman DS, 2009, NEUROREHAB NEURAL RE, V23, P735, DOI 10.1177/1545968309332880
   SCHMIDT RA, 1975, PSYCHOL REV, V82, P225, DOI 10.1037/h0076770
   Schmidt RA, 2003, RES Q EXERCISE SPORT, V74, P366, DOI 10.1080/02701367.2003.10609106
   SPATH H, 1985, CLUSTER DISSECTION A
   Ulrich DA, 2008, PHYS THER, V88, P114, DOI 10.2522/ptj.20070139
   Urieli D., 2011, P 10 INT C AUT AG MU
   VANROSSUM JHA, 1990, HUM MOVEMENT SCI, V9, P387, DOI 10.1016/0167-9457(90)90010-B
   Visser U, 2007, AI MAG, V28, P115
   Willoughby KL, 2010, ARCH PHYS MED REHAB, V91, P333, DOI 10.1016/j.apmr.2009.10.029
   Xu Y., 2013, SIMSPARK OPEN SOURCE
   Zhu SZ, 2010, KNOWL-BASED SYST, V23, P883, DOI 10.1016/j.knosys.2010.06.003
NR 48
TC 2
Z9 2
U1 1
U2 5
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1662-5218
J9 FRONT NEUROROBOTICS
JI Front. Neurorobotics
PD MAY 9
PY 2018
VL 12
AR e19
DI 10.3389/fnbot.2018.00019
PG 12
WC Computer Science, Artificial Intelligence; Robotics; Neurosciences
SC Computer Science; Robotics; Neurosciences & Neurology
GA GF2PG
UT WOS:000431781500001
PM 29867427
OA DOAJ Gold
DA 2019-02-18
ER

PT J
AU Wang, KY
   Yin, PC
   Yang, HP
   Wang, L
AF Wang, Keyi
   Yin, Pengcheng
   Yang, Haipeng
   Wang, Lan
TI Motion planning of rigid chain for rigid-flexible coupled robot
SO INTERNATIONAL JOURNAL OF ADVANCED ROBOTIC SYSTEMS
LA English
DT Article
DE Rigid-flexible; gait; rehabilitation robot; motion planning; wire
   tension
ID GAIT REHABILITATION; DESIGN; EXPERIENCE
AB This work is motivated by the possibility that hemiplegic patients might achieve complete functional recovery of lower limb joints, muscles, and nerves by stretching and bending the lower limbs using rehabilitation training. A model of a rigid- flexible coupled lower limb rehabilitation robot is established and mechanically analyzed to satisfy both the control of various movement loci with flexion and extension and the requirements of rehabilitation training. According to the Denavit-Hartenberg method and the influence coefficient method, a kinematic model is established. Moreover, a static equilibrium equation is presented, and two motion planning methods for rigid branched chain movement are put forward. Fluctuation parameters are proposed to estimate the tension of every wire. A planning strategy of different rigid branched chains is analyzed during mechanical simulation using MATLAB [version 2013a]/SinnMechanics along a specific trajectory. The law of wires and rigid branched chains is achieved. The wires' working performance of a parallel robot can be improved by introducing a rigid branched chain. During the dynamic simulation of the mechanism, other wires' tension changes are analyzed by setting the wire's tension (100 N) of a coupled branched chain. The wire's tension performance in the system is evaluated by its fluctuation performance. Finally, it is validated that the strategy of angle bisection is the best. The results prove that the rigid-flexible parallel rehabilitation robot can realize gait rehabilitation training of lower limbs, which leads to the servo control research of this robot.
C1 [Wang, Keyi; Yin, Pengcheng; Yang, Haipeng; Wang, Lan] Harbin Engn Univ, 145 Nantong St, Harbin 150001, Heilongjiang, Peoples R China.
RP Wang, KY (reprint author), Harbin Engn Univ, 145 Nantong St, Harbin 150001, Heilongjiang, Peoples R China.
EM wangkeyi@hrbeu.edu.cn
FU National Natural Science Foundation of China [51405095]; Postdoctoral
   Scientific Research Fund of Heilongjiang [LBH-Q15030]; Fundamental
   Research Funds for the Central Universities [HEUCF170701]
FX The author(s) disclosed receipt of the following financial support for
   the research, authorship, and/or publication of this article: This
   project is supported by the National Natural Science Foundation of China
   (51405095), Postdoctoral Scientific Research Fund of Heilongjiang
   (LBH-Q15030), and Fundamental Research Funds for the Central
   Universities (HEUCF170701).
CR Barbazza L, 2017, IEEE ROBOT AUTOM LET, V2, P896, DOI 10.1109/LRA.2017.2651941
   Burgar CG, 2000, J REHABIL RES DEV, V37, P663
   Colombo G, 2000, J REHABIL RES DEV, V37, P693
   Cui X, 2017, IEEE-ASME T MECH, V22, P161, DOI 10.1109/TMECH.2016.2618888
   Emken JL, 2006, IEEE T ROBOT, V22, P185, DOI 10.1109/TRO.2005.861481
   Hesse S, 2006, J REHABIL RES DEV, V43, P671, DOI 10.1682/JRRD.2005.02.0052
   Homma K, 2004, IEEE RSJ INT C INT R, P1668
   Hussein Sami, 2009, 2009 IEEE International Conference on Rehabilitation Robotics: Reaching Users & the Community (ICORR), P845, DOI 10.1109/ICORR.2009.5209488
   Mao Y, 2012, IEEE T ROBOT, V28, P922, DOI 10.1109/TRO.2012.2189496
   Reinkensmeyer DJ, 2006, J REHABIL RES DEV, V43, P657, DOI 10.1682/JRRD.2005.04.0073
   Simon AM, 2007, J BIOMECH, V40, P1286, DOI 10.1016/j.jbiomech.2006.05.021
   Veneman JF, 2007, IEEE T NEUR SYS REH, V15, P379, DOI 10.1109/TNSRE.2007.903919
   Wang KY, 2013, INT J ROBOT AUTOM, V28, P311, DOI 10.2316/Journal.206.2013.4.206-3621
   [王克义 Wang Keyi], 2009, [中国机械工程, China Mechanical Engineering], V20, P253
   Yang CJ, 2007, A61H100200601I ZHEJ
   Yang GL, 2005, IEEE ASME INT C ADV, P444
   Yu Wei-zheng, 2010, Journal of Shanghai University, V16, P130, DOI 10.3969/j.issn.1007-2861.2010.02.005
   Zhang LX, 2009, J CENT SOUTH UNIV T, V16, P971, DOI 10.1007/s11771-009-0161-9
NR 18
TC 0
Z9 0
U1 9
U2 11
PU SAGE PUBLICATIONS INC
PI THOUSAND OAKS
PA 2455 TELLER RD, THOUSAND OAKS, CA 91320 USA
SN 1729-8814
J9 INT J ADV ROBOT SYST
JI Int. J. Adv. Robot. Syst.
PD MAY 3
PY 2018
VL 15
IS 3
AR 1729881418772815
DI 10.1177/1729881418772815
PG 10
WC Robotics
SC Robotics
GA GF6LG
UT WOS:000432077900001
OA DOAJ Gold
DA 2019-02-18
ER

PT J
AU Scalise, R
   Li, S
   Admoni, H
   Rosenthal, S
   Srinivasa, SS
AF Scalise, Rosario
   Li, Shen
   Admoni, Henny
   Rosenthal, Stephanie
   Srinivasa, Siddhartha S.
TI Natural language instructions for human-robot collaborative manipulation
SO INTERNATIONAL JOURNAL OF ROBOTICS RESEARCH
LA English
DT Article; Data Paper
DE Natural language; instructions; human-robot collaboration; manipulation;
   ambiguity; perspective; spatial reference
ID AGREEMENT
AB This paper presents a dataset of natural language instructions for object reference in manipulation scenarios. It comprises 1582 individual written instructions, which were collected via online crowdsourcing. This dataset is particularly useful for researchers who work in natural language processing, human-robot interaction, and robotic manipulation. In addition to serving as a rich corpus of domain-specific language, it provides a benchmark of image-instruction pairs to be used in system evaluations and uncovers inherent challenges in tabletop object specification. Example code is provided for easy access via Python.
C1 [Scalise, Rosario; Li, Shen; Admoni, Henny; Rosenthal, Stephanie; Srinivasa, Siddhartha S.] Carnegie Mellon Univ, Personal Robot Lab, Robot Inst, Pittsburgh, PA 15213 USA.
RP Scalise, R (reprint author), Carnegie Mellon Univ, Robot Inst, Pittsburgh, PA 15213 USA.
EM rscalise@alumni.cmu.edu
FU Department of Defense [FA8721-05-C-0003]; Carnegie Mellon University;
   DARPA SIMPLEX program through ARO [67904LSDRP]; National Institute of
   Health R01 [R01EB019335]; National Science Foundation CPS [1544797];
   Office of Naval Research; Richard K. Mellon Foundation
FX This work was supported by the Department of Defense (grant number
   FA8721-05-C-0003) with Carnegie Mellon University for the operation of
   the Software Engineering Institute, a federally funded research and
   development center. This material has been approved for public release
   and unlimited distribution. Please see Copyright notice for non-US
   Government use and distribution. Carnegie Mellon is registered in the US
   Patent and Trademark Office by Carnegie Mellon University. DM-0003432.;
   This work was also supported by the DARPA SIMPLEX program through ARO
   (grant number 67904LSDRP), the National Institute of Health R01 (grant
   number R01EB019335), the National Science Foundation CPS (grant number
   1544797), the Office of Naval Research, and the Richard K. Mellon
   Foundation.
CR ANDERSON AH, 1991, LANG SPEECH, V34, P351, DOI 10.1177/002383099103400404
   Bard EG, 2008, P 30 ANN C COGN SCI, P2404
   Berenson Dmitry, 2008, 2008 8th IEEE-RAS International Conference on Humanoid Robots (Humanoids 2008), P189, DOI 10.1109/ICHR.2008.4755944
   Bisk Y, 2016, P 15 ANN C N AM CHAP, P751
   Boularias A, 2015, IEEE INT CONF ROBOT, P1976, DOI 10.1109/ICRA.2015.7139457
   COHEN J, 1968, PSYCHOL BULL, V70, P213, DOI 10.1037/h0026256
   Di Eugenio B, 2000, INT J HUM-COMPUT ST, V53, P1017, DOI 10.1006/ijhc.2000.0428
   Gatt A., 2007, P 11 EUR WORKSH NAT, P49
   Gorniak P, 2004, J ARTIF INTELL RES, V21, P429, DOI 10.1613/jair.1327
   Howard TM, 2014, IEEE INT CONF ROBOT, P6652, DOI 10.1109/ICRA.2014.6907841
   Jordan PW, 2000, THESIS
   Judd DB, 1943, J OPT SOC AM, V33, P294, DOI 10.1364/JOSA.33.000294
   Keysar B, 2000, PSYCHOL SCI, V11, P32, DOI 10.1111/1467-9280.00211
   Krahmer E, 2012, COMPUT LINGUIST, V38, P173, DOI 10.1162/COLI_a_00088
   LI S, 2016, P IEEE INT S ROB HUM, P44
   MacMahon M, 2006, P COGNITIVE SCI SOC, V28, P1759
   Matuszek C., 2013, EXPT ROBOTICS, V88, P403
   Oh J, 2015, P AAAI C ART INT, P1371
   Paul R, 2016, P ROB SCI SYST 12 AN
   Scheutz M., 2006, P 1 ACM INT C HUM RO, P226, DOI [DOI 10.1145/1121241.1121281, 10.1145/1121241.1121281]
   Skubic M, 2012, P 26 AAAI C ART INT
   Tellex S., 2011, P 25 AAAI C ART INT, P1507
   Viethen J, 2006, P 4 INT C NAT LANG G, P63
   Viethen J., 2008, P 5 INT NAT LANG GEN, P59, DOI DOI 10.3115/1708322.1708334
   Viethen J, 2010, P INT C LANG RES EV
NR 25
TC 0
Z9 0
U1 10
U2 10
PU SAGE PUBLICATIONS LTD
PI LONDON
PA 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND
SN 0278-3649
EI 1741-3176
J9 INT J ROBOT RES
JI Int. J. Robot. Res.
PD MAY
PY 2018
VL 37
IS 6
BP 558
EP 565
DI 10.1177/0278364918760992
PG 8
WC Robotics
SC Robotics
GA GI5FV
UT WOS:000434397300002
DA 2019-02-18
ER

PT J
AU Morales, Y
   Watanabe, A
   Ferreri, F
   Even, J
   Shinozawa, K
   Hagita, N
AF Morales, Yoichi
   Watanabe, Atsushi
   Ferreri, Florent
   Even, Jani
   Shinozawa, Kazuhiro
   Hagita, Norihiro
TI Passenger discomfort map for autonomous navigation in a robotic
   wheelchair
SO ROBOTICS AND AUTONOMOUS SYSTEMS
LA English
DT Article
DE HRI; Human factors; Human comfort; Autonomous navigation
ID COMFORT
AB This work presents a navigational approach that takes into consideration the perception of comfort by a human passenger. Comfort is the state of being at ease and free from stress; thus, comfortable navigation is a ride that, in addition to being safe, is perceived by the passenger as being free from anxiety and stress. This study considers how to compute passenger comfortable paths. To compute such paths, passenger discomfort is studied in locations with good visibility and those with no visibility. In locations with good visibility, passenger preference to ride in the road is studied. For locations with non-visible areas, the relationship between passenger visibility and discomfort is studied. Autonomous-navigation experiments are performed to build a map of human discomfort that is used to compute global paths. A path planner is proposed that minimizes a three-variable cost function: location discomfort cost, area visibility cost, and path length cost. Planner parameters are calibrated toward a composite trajectory histogram built with data taken from participant self-driving trajectories. Finally, autonomous navigation experiments with 30 participants show that the proposed approach is rated as more comfortable than the state-of-the-art shortest planner approach. (C) 2018 Elsevier B.V. All rights reserved.
C1 [Morales, Yoichi; Watanabe, Atsushi; Ferreri, Florent; Even, Jani; Shinozawa, Kazuhiro; Hagita, Norihiro] Adv Telecommun Res Inst, Intelligent Robot & Commun Labs, 2-2-2 Hikaridai Seika Cho,Box 619-0228, Kyoto, Japan.
RP Morales, Y (reprint author), Adv Telecommun Res Inst, Intelligent Robot & Commun Labs, 2-2-2 Hikaridai Seika Cho,Box 619-0228, Kyoto, Japan.
EM yoichims@ieee.org
FU Ministry of Internal Affairs and Communications; JSPS KAKENHI
   [JP16K21719, JP26118006]
FX This research was supported by the Ministry of Internal Affairs and
   Communications with a contract entitled "Novel and innovative R&D making
   use of brain structures". The authors would like to thank Nagasrikanth
   Kallakuri and Philip Chan for their help in performing the experiments.
   Part of this work was supported by JSPS KAKENHI Grants Number JP16K21719
   and JP26118006.
CR Argyros A., J INTELL ROBOT SYST, V34
   Beeson P, 2005, IEEE INT CONF ROBOT, P4373
   Cabine G.o.J., 2010, TRAFF SAF JAP 2010
   Carlson T, 2008, IEEE INT CONF ROBOT, P3926, DOI 10.1109/ROBOT.2008.4543814
   Dakulovic M, 2013, IEEE INT C INT ROBOT, P2644, DOI 10.1109/IROS.2013.6696729
   de Looze MP, 2003, ERGONOMICS, V46, P985, DOI 10.1080/0014013031000121977
   Demeester E., 2012, INT S ROB
   Demeester E, 2006, 2006 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-12, P5775, DOI 10.1109/IROS.2006.282386
   Durrant-Whyte H., 2006, IEEE ROBOTICS AUTOMA, V2, P2006, DOI DOI 10.1109/MRA.2006.1638022
   Elbanhawi M, 2015, IEEE INTEL TRANSP SY, V7, P4, DOI 10.1109/MITS.2015.2405571
   Fernandez-Carmona M, 2009, 2009 IEEE International Conference on Rehabilitation Robotics: Reaching Users & the Community (ICORR), P737, DOI 10.1109/ICORR.2009.5209573
   Fox D, 1997, IEEE ROBOT AUTOM MAG, V4, P23, DOI 10.1109/100.580977
   Gross HM, 2009, 2009 IEEE-RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, P2005, DOI 10.1109/IROS.2009.5354497
   Gulati S., 2008, P IEEE INT C ROB AUT
   Gulati S, 2009, 2009 IEEE-RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, P4253, DOI 10.1109/IROS.2009.5354172
   Hata K., CONCEPT OMOIYARI ALT, V15
   Hornung A, 2013, AUTON ROBOT, V34, P189, DOI 10.1007/s10514-012-9321-0
   Iida S., 1991, Proceedings IROS '91. IEEE/RSJ International Workshop on Intelligent Robots and Systems '91. Intelligence for Mechanical Systems (Cat. No.91TH0375-6), P212, DOI 10.1109/IROS.1991.174452
   Iturrate I, 2009, IEEE T ROBOT, V25, P614, DOI 10.1109/TRO.2009.2020347
   Kanemura A., 2013, INT ROB SYST IROS 20
   Kirby Rachel, 2009, RO-MAN 2009 - The 18th IEEE International Symposium on Robot and Human Interactive Communication, P607, DOI 10.1109/ROMAN.2009.5326271
   Kobayashi Y, 2009, 2009 IEEE-RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, P2013, DOI 10.1109/IROS.2009.5353933
   Koenig S, 2002, EIGHTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-02)/FOURTEENTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE (IAAI-02), PROCEEDINGS, P476
   KOLCABA KY, 1992, ADV NURS SCI, V15, P1
   Kruse T, 2013, ROBOT AUTON SYST, V61, P1726, DOI 10.1016/j.robot.2013.05.007
   Kuo-Chen Huang, 2010, Proceedings of the SICE 2010 - 49th Annual Conference of the Society of Instrument and Control Engineers of Japan, P1892
   Lam CP, 2011, IEEE T ROBOT, V27, P99, DOI 10.1109/TRO.2010.2076851
   LAWRENCE TL, 1985, INT J HEALTH SERV, V15, P677, DOI 10.2190/Y409-DEYJ-8YG1-W2Y8
   Lee JD, 2008, HUM FACTORS, V50, P404, DOI 10.1518/001872008X288547
   Lu DV, 2014, IEEE INT C INT ROBOT, P709, DOI 10.1109/IROS.2014.6942636
   Millan JD, 2009, IEEE ENG MED BIO, P3361, DOI 10.1109/IEMBS.2009.5332828
   Morales Y, 2015, IEEE INT CONF ROBOT, P6153, DOI 10.1109/ICRA.2015.7140063
   Morales Y, 2015, INT J SOC ROBOT, V7, P165, DOI 10.1007/s12369-014-0265-8
   Morales Y, 2014, IEEE INT CONF ROBOT, P2197, DOI 10.1109/ICRA.2014.6907162
   Morse J., HLTH SA GESONDHEID, V2
   MORSE JM, 1994, J ADV NURS, V20, P189, DOI 10.1046/j.1365-2648.1994.20010189.x
   Nakane J., 2003, PERSPECTIVES, V28, P17
   Ormuz Krunoslav, 2004, P 2 INT ERG C, V2, P77
   Pandey AK, 2009, P NAT SEM E LEARN NA, P1
   Pandey AK, 2010, IEEE INT C INT ROBOT, P5855, DOI 10.1109/IROS.2010.5649688
   Park JJ, 2012, IEEE INT C INT ROBOT, P4945, DOI 10.1109/IROS.2012.6386195
   Qinan Li, 2011, IEEE International Conference on Robotics and Automation, P4278
   Quigley M., 2009, ICRA WORKSH OP SOURC
   Scandolo Leonardo, 2011, 2011 IEEE International Conference on Robotics and Automation, P809
   Shimizu H, 2000, ETHOS, V28, P224, DOI 10.1525/eth.2000.28.2.224
   Sisbot EA, 2007, IEEE T ROBOT, V23, P874, DOI 10.1109/TRO.2007.904911
   Soh H, 2013, IEEE INT C INT ROBOT, P3230, DOI 10.1109/IROS.2013.6696815
   Strandemar K., 2005, OBJECTIVE MEASURES R
   Svenstrup M, 2010, IEEE INT C INT ROBOT, P4293, DOI 10.1109/IROS.2010.5651531
   Thrun S, 2000, INT J ROBOT RES, V19, P972, DOI 10.1177/02783640022067922
   Tranberg Hansen Soren, 2009, RO-MAN 2009 - The 18th IEEE International Symposium on Robot and Human Interactive Communication, P927, DOI 10.1109/ROMAN.2009.5326212
   Urmson C, 2008, J FIELD ROBOT, V25, P425, DOI 10.1002/rob.20255
   Vander Poorten EB, 2012, IEEE INT CONF ROBOT, P3706, DOI 10.1109/ICRA.2012.6225349
   Wastlund E., 2010, P 2010 S EYE TRACK R, P133
   Watanabe A, 2015, IEEE INT C INT ROBOT, P5763
   Zanlungo F., 2012, PEDESTRIAN EVACUATIO, P289
   Ziebart BD, 2009, 2009 IEEE-RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, P3931, DOI 10.1109/IROS.2009.5354147
NR 57
TC 0
Z9 0
U1 4
U2 11
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0921-8890
EI 1872-793X
J9 ROBOT AUTON SYST
JI Robot. Auton. Syst.
PD MAY
PY 2018
VL 103
BP 13
EP 26
DI 10.1016/j.robot.2018.02.002
PG 14
WC Automation & Control Systems; Computer Science, Artificial Intelligence;
   Robotics
SC Automation & Control Systems; Computer Science; Robotics
GA GD8LO
UT WOS:000430764100002
DA 2019-02-18
ER

PT J
AU Suzuki, Y
   Geyer, H
AF Suzuki, Yasuyuki
   Geyer, Hartmut
TI A simple bipedal model for studying control of gait termination
SO BIOINSPIRATION & BIOMIMETICS
LA English
DT Article
DE gait termination; spring mass model; stable manifold
ID INTERMITTENT CONTROL; ANKLE STIFFNESS; HUMAN WALKING; STABILITY;
   DYNAMICS; HUMANS
AB We study the control of human gait termination with a simple bipedal locomotion model. Several control strategies have been proposed for gait termination. However, the relative importance of these strategies has not been evaluated in models of human gait. Here we extend the bipedal spring mass walking model in a least parameter fashion and study three explicit control strategies for gait termination, including the shortening of the final step, braking at the ankle, and extending the knee. Applying the strategies separately, we find that only braking at the ankle reduces the propulsive force enough to transition into quiet standing. In combination with the other two strategies, we observe that the range of control parameters suitable for gait termination increases, especially when the ankle control is applied intermittently by taking advantage of passive stabilizing dynamics. We further show the resulting model behavior is compatible with several experimental observations about the human center of mass dynamics and leg forces during gait termination, and discuss model improvements to correct mismatches. The proposed model may serve as a starting point for more advanced models that can provide a deeper understanding of human control strategies during gait termination.
C1 [Suzuki, Yasuyuki; Geyer, Hartmut] Carnegie Mellon Univ, Inst Robot, Pittsburgh, PA 15213 USA.
   [Suzuki, Yasuyuki] Osaka Univ, Grad Sch Engn Sci, Osaka, Japan.
RP Suzuki, Y (reprint author), Carnegie Mellon Univ, Inst Robot, Pittsburgh, PA 15213 USA.; Suzuki, Y (reprint author), Osaka Univ, Grad Sch Engn Sci, Osaka, Japan.
EM suzuki@bpe.es.osaka-u.ac.jp
FU JSPS [17K13016]; JSPS Overseas Research Fellowships
FX This work was supported in part by JSPS grants-in-aid 17K13016 and JSPS
   Overseas Research Fellowships.
CR Asai Y, 2009, PLOS ONE, V4, DOI 10.1371/journal.pone.0006169
   Bishop MD, 2002, NEUROSCI LETT, V323, P1, DOI 10.1016/S0304-3940(01)02525-3
   Bottaro A, 2008, HUM MOVEMENT SCI, V27, P473, DOI 10.1016/j.humov.2007.11.005
   Casadio M, 2005, GAIT POSTURE, V21, P410, DOI 10.1016/j.gaitpost.2004.05.005
   Crenna P, 2001, J PHYSIOL-LONDON, V537, P1059
   DeDonato M, 2015, J FIELD ROBOT, V32, P275, DOI 10.1002/rob.21567
   Englsberger J, 2011, IEEE INT C INT ROBOT, P4420, DOI 10.1109/IROS.2011.6048045
   Geyer H, 2006, P R SOC B, V273, P2861, DOI 10.1098/rspb.2006.3637
   Hase K, 1998, J NEUROPHYSIOL, V80, P255
   Hof AL, 2008, HUM MOVEMENT SCI, V27, P112, DOI 10.1016/j.humov.2007.08.003
   JAEGER RJ, 1992, J BIOMECH, V25, P1233, DOI 10.1016/0021-9290(92)90080-K
   JIAN YC, 1993, GAIT POSTURE, V1, P9, DOI DOI 10.1016/0966-6362(93)90038-3
   Kagawa T, 2010, HUM MOVEMENT SCI, V29, P964, DOI 10.1016/j.humov.2010.03.007
   KAJITA S, 1995, IEEE INT CONF ROBOT, P2885, DOI 10.1109/ROBOT.1995.525693
   Kim S, 2011, J BIOMECH, V44, P1253, DOI 10.1016/j.jbiomech.2011.02.072
   Lipfert SW, 2012, J THEOR BIOL, V292, P11, DOI 10.1016/j.jtbi.2011.09.021
   Loram ID, 2002, J PHYSIOL-LONDON, V545, P1041, DOI 10.1113/jphysiol.2002.025049
   Lynch J, 2007, J BIOMECH, V40, pS500
   Nomura T, 2013, MATH BIOSCI, V245, P86, DOI 10.1016/j.mbs.2013.02.002
   Pratt J, 2006, IEEE-RAS INT C HUMAN, P200, DOI 10.1109/ICHR.2006.321385
   Qiao M, 2016, J BIOMECH, V49, P66, DOI 10.1016/j.jbiomech.2015.11.022
   Ridge ST, 2016, HUM MOVEMENT SCI, V49, P178, DOI 10.1016/j.humov.2016.07.001
   Rummel J, 2010, BIOINSPIR BIOMIM, V5, DOI 10.1088/1748-3182/5/4/046004
   Shahhazi M, 2014, IFAC P VOLUMES, V47, P2171
   Suzuki Y, 2012, J THEOR BIOL, V310, P55, DOI 10.1016/j.jtbi.2012.06.019
   Tirosh O, 2004, GAIT POSTURE, V19, P243, DOI 10.1016/S0966-6362(03)00063-8
   van Keeken HG, 2013, MED ENG PHYS, V35, P583, DOI 10.1016/j.medengphy.2012.07.002
   Vanitchatchavan P, 2009, IEEE SYS MAN CYBERN, P3169, DOI 10.1109/ICSMC.2009.5346162
   Vejdani HR, 2015, IEEE INT CONF ROBOT, P5101, DOI 10.1109/ICRA.2015.7139909
   Whittington BR, 2009, J BIOMECH ENG-T ASME, V131, DOI 10.1115/1.3005147
NR 30
TC 0
Z9 0
U1 4
U2 19
PU IOP PUBLISHING LTD
PI BRISTOL
PA TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND
SN 1748-3182
EI 1748-3190
J9 BIOINSPIR BIOMIM
JI Bioinspir. Biomim.
PD MAY
PY 2018
VL 13
IS 3
AR 036005
DI 10.1088/1748-3190/aaae8e
PG 10
WC Engineering, Multidisciplinary; Materials Science, Biomaterials;
   Robotics
SC Engineering; Materials Science; Robotics
GA GA9EK
UT WOS:000428643900001
PM 29582777
DA 2019-02-18
ER

PT J
AU Hofree, G
   Ruvolo, P
   Reinert, A
   Bartlett, MS
   Winkielman, P
AF Hofree, Galit
   Ruvolo, Paul
   Reinert, Audrey
   Bartlett, Marian S.
   Winkielman, Piotr
TI Behind the Robot's Smiles and Frowns: In Social Context, People Do Not
   Mirror Android's Expressions But React to Their Informational Value
SO FRONTIERS IN NEUROROBOTICS
LA English
DT Article
DE facial expressions; emotions; human-robot-interaction; android; affect;
   electromyography; embodiment
ID FACIAL REACTIONS; IMITATION; EMOTION; MIMICRY; HUMANS; COMPETITION;
   MODULATION; RESPONSES; SCIENCE; FACES
AB Facial actions are key elements of non-verbal behavior. Perceivers' reactions to others' facial expressions often represent a match or mirroring (e.g., they smile to a smile). However, the information conveyed by an expression depends on context. Thus, when shown by an opponent, a smile conveys bad news and evokes frowning. The availability of anthropomorphic agents capable of facial actions raises the question of how people respond to such agents in social context. We explored this issue in a study where participants played a strategic game with or against a facially expressive android. Electromyography (EMG) recorded participants' reactions over zygomaticus muscle (smiling) and corrugator muscle (frowning). We found that participants' facial responses to android's expressions reflect their informational value, rather than a direct match. Overall, participants smiled more, and frowned less, when winning than losing. Critically, participants' responses to the game outcome were similar regardless of whether it was conveyed via the android's smile or frown. Furthermore, the outcome had greater impact on people's facial reactions when it was conveyed through android's face than a computer screen. These findings demonstrate that facial actions of artificial agents impact human facial responding. They also suggest a sophistication in human-robot communication that highlights the signaling value of facial expressions.
C1 [Hofree, Galit; Winkielman, Piotr] San Diego State Univ, Dept Psychol, San Diego, CA 92182 USA.
   [Ruvolo, Paul] Franklin W Olin Coll Engn, Dept Engn, Needham, MA USA.
   [Reinert, Audrey] Purdue Univ, Dept Ind Engn, W Lafayette, IN 47907 USA.
   [Bartlett, Marian S.] Univ Calif San Diego, Inst Neural Computat, San Diego, CA 92103 USA.
   [Winkielman, Piotr] SWPS Univ Social Sci & Humanities, Dept Psychol, Warsaw, Poland.
RP Winkielman, P (reprint author), San Diego State Univ, Dept Psychol, San Diego, CA 92182 USA.; Winkielman, P (reprint author), SWPS Univ Social Sci & Humanities, Dept Psychol, Warsaw, Poland.
EM pwinkiel@ucsd.edu
OI Winkielman, Piotr/0000-0003-2330-1802; Reinert,
   Audrey/0000-0001-8951-702X
FU Academic Senate Grant from UCSD; NSF [BCS-1232676]
FX This work was supported by Academic Senate Grant from UCSD to PW and NSF
   Grant BCS-1232676 to MSB and PW.
CR Beasley RA, 2012, J ROBOT, DOI 10.1155/2012/401613
   Bornemann B, 2012, INT J PSYCHOPHYSIOL, V85, P116, DOI 10.1016/j.ijpsycho.2011.04.007
   Bourgeois P, 2008, BIOL PSYCHOL, V77, P343, DOI 10.1016/j.biopsycho.2007.11.008
   Breazeal C, 2003, INT J HUM-COMPUT ST, V59, P119, DOI 10.1016/S1071-5819(03)00018-1
   Carr EW, 2017, J EXP PSYCHOL HUMAN, V43, P651, DOI 10.1037/xhp0000304
   Carr EW, 2014, J EXP PSYCHOL GEN, V143, P997, DOI 10.1037/a0034972
   Carr L, 2003, P NATL ACAD SCI USA, V100, P5497, DOI 10.1073/pnas.0935845100
   Cheetham M, 2011, FRONT HUM NEUROSCI, V5, DOI 10.3389/fnhum.2011.00126
   Cook R, 2012, P ROY SOC B-BIOL SCI, V279, P780, DOI 10.1098/rspb.2011.1024
   Darwin C., 1872, EXPRESSION EMOTIONS
   de Melo CM, 2014, J PERS SOC PSYCHOL, V106, P73, DOI 10.1037/a0034251
   Dimberg U, 2000, PSYCHOL SCI, V11, P86, DOI 10.1111/1467-9280.00221
   DIMBERG U, 1982, PSYCHOPHYSIOLOGY, V19, P643, DOI 10.1111/j.1469-8986.1982.tb02516.x
   EKMAN P, 1979, ANNU REV PSYCHOL, V30, P527, DOI 10.1146/annurev.ps.30.020179.002523
   Ekman P., 1978, FACIAL ACTION CODING
   Gratch J., 2013, EMOTION NATURE ARTIF, P181
   Gray K, 2012, COGNITION, V125, P125, DOI 10.1016/j.cognition.2012.06.007
   Hess U, 2017, PSYCHOPHYSIOLOGY, V54, P12, DOI 10.1111/psyp.12676
   Hess U, 2013, PERS SOC PSYCHOL REV, V17, P142, DOI 10.1177/1088868312472607
   Hofree G., 2012, P IEEE INT C DEV LEA, P1
   Hofree G, 2015, FRONT HUM NEUROSCI, V9, DOI [10.3339/fnhum.2015.00364, 10.3389/fnhum.2015.00364]
   Hofree G, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0099934
   Horstmann G, 2003, EMOTION, V3, P150, DOI 10.1037/1528-3542.3.2.150
   Ishiguro H, 2006, CONNECT SCI, V18, P319, DOI 10.1080/09540090600873953
   Jin J, 2014, J NEURAL ENG, V11, DOI 10.1088/1741-2560/11/3/036004
   Jin J, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0049688
   Keltner D, 1999, COGNITION EMOTION, V13, P505, DOI 10.1080/026999399379168
   Lakens D, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00863
   LANZETTA JT, 1989, J PERS SOC PSYCHOL, V56, P543, DOI 10.1037//0022-3514.56.4.543
   Leighton J, 2010, J EXP SOC PSYCHOL, V46, P905, DOI 10.1016/j.jesp.2010.07.001
   Likowski KU, 2008, J EXP SOC PSYCHOL, V44, P1065, DOI 10.1016/j.jesp.2007.10.007
   MacDorman KF, 2006, INTERACT STUD, V7, P297, DOI 10.1075/is.7.3.03mac
   McDonnell R., 2012, ACM T GRAPHIC, V31, P1, DOI DOI 10.1145/2185520.2185587
   McIntosh D. N., 2006, POLISH PSYCHOL B, V37, P31, DOI DOI 10.3389/FPSYG.2016.00458
   Moody EJ, 2007, EMOTION, V7, P447, DOI 10.1037/1528-3542.7.2.447
   Mori M., 1970, ENERGY, V7, P33, DOI DOI 10.1109/MRA.2012.2192811
   Mukamel R, 2010, CURR BIOL, V20, P750, DOI 10.1016/j.cub.2010.02.045
   MURPHY ST, 1993, J PERS SOC PSYCHOL, V64, P723, DOI 10.1037//0022-3514.64.5.723
   Neumann R, 2014, BIOL PSYCHOL, V96, P144, DOI 10.1016/j.biopsycho.2013.12.009
   Niedenthal PM, 2012, ANNU REV PSYCHOL, V63, P259, DOI 10.1146/annurev.psych.121208.131605
   Niedenthal PM, 2010, BEHAV BRAIN SCI, V33, P417, DOI 10.1017/S0140525X10000865
   Russell JA, 2003, ANNU REV PSYCHOL, V54, P329, DOI 10.1146/annurev.psych.54.101601.145102
   Sanchez-Vives MV, 2005, NAT REV NEUROSCI, V6, P332, DOI 10.1038/nrn1651
   Saygin AP, 2012, SOC COGN AFFECT NEUR, V7, P413, DOI 10.1093/scan/nsr025
   Seibt B, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.01122
   Siakaluk PD, 2008, COGNITION, V106, P433, DOI 10.1016/j.cognition.2006.12.011
   Tamir M, 2004, PERS SOC PSYCHOL B, V30, P237, DOI 10.1177/0146167203259934
   Tanaka F, 2007, P NATL ACAD SCI USA, V104, P17954, DOI 10.1073/pnas.0707769104
   Tassinary LG, 2000, HDB PSYCHOPHYSIOLOGY, V2, P163
   Weyers P, 2009, PSYCHOPHYSIOLOGY, V46, P328, DOI 10.1111/j.1469-8986.2008.00771.x
   Winkielman P, 2005, PERS SOC PSYCHOL B, V31, P121, DOI 10.1177/0146167204271309
   Winkielman P., 2015, APA HDB PERSONALITY, P151, DOI [10.1037/14341-004, DOI 10.1037/14341-004]
   Winkielman P, 2018, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.02261
   Wu T., 2009, P IEEE 8 INT C DEV L, P1, DOI [DOI 10.1109/DEVLRN.2009.5175536, 10.1109/DEVLRN.2009.5175536]
NR 54
TC 0
Z9 0
U1 6
U2 11
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1662-5218
J9 FRONT NEUROROBOTICS
JI Front. Neurorobotics
PD APR 24
PY 2018
VL 12
AR 14
DI 10.3389/fnbot.2018.00014
PG 11
WC Computer Science, Artificial Intelligence; Robotics; Neurosciences
SC Computer Science; Robotics; Neurosciences & Neurology
GA GD8GN
UT WOS:000430751000001
PM 29740307
OA DOAJ Gold, Green Published
DA 2019-02-18
ER

PT J
AU Ballardini, G
   Carlini, G
   Giannoni, P
   Scheidt, RA
   Nisky, I
   Casadio, M
AF Ballardini, Giulia
   Carlini, Giorgio
   Giannoni, Psiche
   Scheidt, Robert A.
   Nisky, Ilana
   Casadio, Maura
TI Tactile-STAR: A Novel Tactile STimulator And Recorder System for
   Evaluating and Improving Tactile Perception
SO FRONTIERS IN NEUROROBOTICS
LA English
DT Article
DE tactile stimulation; somatosensory function; skin stretch; skin brush;
   stroke; neurological disease; haptics
ID SKIN DEFORMATION FEEDBACK; ROBOT-ASSISTED THERAPY; LIMB POSITION SENSE;
   STROKE REHABILITATION; STIFFNESS PERCEPTION; BODY SHAPE; RECOVERY;
   FORCE; SUBSTITUTION; HAND
AB Many neurological diseases impair the motor and somatosensory systems. While several different technologies are used in clinical practice to assess and improve motor functions, somatosensation is evaluated subjectively with qualitative clinical scales. Treatment of somatosensory deficits has received limited attention. To bridge the gap between the assessment and training of motor vs. somatosensory abilities, we designed, developed, and tested a novel, low-cost, two-component (bimanual) mechatronic system targeting tactile somatosensation: the Tactile-STAR-a tactile stimulator and recorder. The stimulator is an actuated pantograph structure driven by two servomotors, with an end-effector covered by a rubber material that can apply two different types of skin stimulation: brush and stretch. The stimulator has a modular design, and can be used to test the tactile perception in different parts of the body such as the hand, arm, leg, big toe, etc. The recorder is a passive pantograph that can measure hand motion using two potentiometers. The recorder can serve multiple purposes: participants can move its handle to match the direction and amplitude of the tactile stimulator, or they can use it as a master manipulator to control the tactile stimulator as a slave. Our ultimate goal is to assess and affect tactile acuity and somatosensory deficits. To demonstrate the feasibility of our novel system, we tested the Tactile-STAR with 16 healthy individuals and with three stroke survivors using the skin-brush stimulation. We verified that the system enables the mapping of tactile perception on the hand in both populations. We also tested the extent to which 30 min of training in healthy individuals led to an improvement of tactile perception. The results provide a first demonstration of the ability of this new system to characterize tactile perception in healthy individuals, as well as a quantification of the magnitude and pattern of tactile impairment in a small cohort of stroke survivors. The finding that short-term training with Tactile-STAR can improve the acuity of tactile perception in healthy individuals suggests that Tactile-STAR may have utility as a therapeutic intervention for somatosensory deficits.
C1 [Ballardini, Giulia; Carlini, Giorgio; Giannoni, Psiche; Casadio, Maura] Univ Genoa, Dept Informat Bioengn Robot & Syst Engn, Genoa, Italy.
   [Scheidt, Robert A.] Marquette Univ, Milwaukee, WI 53233 USA.
   [Scheidt, Robert A.] Med Coll Wisconsin, Milwaukee, WI 53226 USA.
   [Scheidt, Robert A.] Northwestern Univ, Feinberg Sch Med, Chicago, IL 60611 USA.
   [Scheidt, Robert A.] Natl Sci Fdn, Div Civil Mech & Mfg Innovat, Alexandria, VA USA.
   [Nisky, Ilana] Ben Gurion Univ Negev, Dept Biomed Engn, Beer Sheva, Israel.
   [Nisky, Ilana] Ben Gurion Univ Negev, Zlotowski Ctr Neurosci, Beer Sheva, Israel.
RP Casadio, M (reprint author), Univ Genoa, Dept Informat Bioengn Robot & Syst Engn, Genoa, Italy.
EM maura.casadio@unige.it
OI Nisky, Ilana/0000-0003-4128-9771
FU Marie Curie Integration Grant (REMAKE) [FP7-PEOPLE-2012-CIG-334201];
   Italian Multiple Sclerosis Foundation; National Institute of
   Neurological Disorders and Stroke; Eunice Kennedy Shriver National
   Institute of Child Health and Human Development of the National
   Institutes of Health [R15HD093086]; National Science Foundation under an
   Individual Research and Development plan; United States-Israel
   Binational Science Foundation [2016850]; Israeli Science Foundation
   [823/15]; Helmsley Charitable Trust through the Agricultural, Biological
   and Cognitive Robotics Initiative of Ben-Gurion University of the Negev,
   Israel
FX This study was supported in part by a Marie Curie Integration Grant
   (REMAKE, FP7-PEOPLE-2012-CIG-334201), the Italian Multiple Sclerosis
   Foundation, the National Institute of Neurological Disorders and Stroke,
   and the Eunice Kennedy Shriver National Institute of Child Health and
   Human Development of the National Institutes of Health under Award
   Number R15HD093086; the National Science Foundation under an Individual
   Research and Development plan; the United States-Israel Binational
   Science Foundation (Grant No. 2016850); by the Israeli Science
   Foundation (Grant No. 823/15); and by the Helmsley Charitable Trust
   through the Agricultural, Biological and Cognitive Robotics Initiative
   of Ben-Gurion University of the Negev, Israel. Any opinions, findings,
   conclusions, or recommendations expressed in this material are those of
   the authors and do not necessarily reflect the views of the Israel
   Science Foundation, the National Science Foundation, the National
   Institutes of Health, the United States-Israel Binational Science
   Foundation, or the Helmsley Charitable Trust.
CR Akhtar A, 2014, LECT NOTES COMPUT SC, V8619, P120, DOI 10.1007/978-3-662-44196-1_16
   Aman JE, 2015, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.01075
   BARK K, 2008, IEEE COMPUTER SOCIET
   Bark K, 2009, WORLD HAPTICS 2009: THIRD JOINT EUROHAPTICS CONFERENCE AND SYMPOSIUM ON HAPTIC INTERFACES FOR VIRTUAL ENVIRONMENT AND TELEOPERATOR SYSTEMS, PROCEEDINGS, P464, DOI 10.1109/WHC.2009.4810850
   Basteris A, 2014, J NEUROENG REHABIL, V11, DOI 10.1186/1743-0003-11-111
   BATTAGLIA E, 2017, J IEEE, P7
   BOHANNON RW, 1987, PHYS THER, V67, P206, DOI 10.1093/ptj/67.2.206
   Campion G, 2005, 2005 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-4, P723, DOI 10.1109/IROS.2005.1545066
   Carey LM, 1996, ARCH PHYS MED REHAB, V77, P1271, DOI 10.1016/S0003-9993(96)90192-6
   CAREY LM, 1993, ARCH PHYS MED REHAB, V74, P602, DOI 10.1016/0003-9993(93)90158-7
   Chinello F, 2016, IEEE HAPTICS SYM, P14, DOI 10.1109/HAPTICS.2016.7463149
   Chisholm AE, 2016, NEUROREHAB NEURAL RE, V30, P199, DOI 10.1177/1545968315591703
   Craig JC, 2000, CURR DIR PSYCHOL SCI, V9, P29, DOI 10.1111/1467-8721.00054
   Culbertson H., 2018, ANNU REV, V1, P1, DOI 10.1146/annurev-control-060117-105043
   Cuppone A. V., 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0164511
   De Santis D, 2015, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.01037
   Demain S, 2013, DISABIL REHABIL-ASSI, V8, P181, DOI 10.3109/17483107.2012.697532
   Domingo A, 2014, J NEUROENG REHABIL, V11, DOI 10.1186/1743-0003-11-167
   Drewing K., 2005, ACM T APPL PERCEPT, V2, P118
   Dukelow SP, 2012, J NEUROENG REHABIL, V9, DOI 10.1186/1743-0003-9-72
   Dukelow SP, 2010, NEUROREHAB NEURAL RE, V24, P178, DOI 10.1177/1545968309345267
   FEIGENSON JS, 1977, STROKE, V8, P657, DOI 10.1161/01.STR.8.6.657
   Gleeson BT, 2010, IEEE T HAPTICS, V3, P297, DOI [10.1109/TOH.2010.8, 10.1109/ToH.2010.8]
   Gleeson BT, 2009, WORLD HAPTICS 2009: THIRD JOINT EUROHAPTICS CONFERENCE AND SYMPOSIUM ON HAPTIC INTERFACES FOR VIRTUAL ENVIRONMENT AND TELEOPERATOR SYSTEMS, PROCEEDINGS, P172, DOI 10.1109/WHC.2009.4810804
   Gordon C. C., 1989, TECHNICAL REPORT NO
   GORDON J, 1994, EXP BRAIN RES, V99, P112, DOI 10.1007/BF00241416
   Guinan AL, 2013, 2013 WORLD HAPTICS CONFERENCE (WHC), P13, DOI 10.1109/WHC.2013.6548377
   Gurari N., 2014, MULTISENSORY SOFTNES, P189
   Harrar V, 2014, J EXP PSYCHOL HUMAN, V40, P15, DOI 10.1037/a0033200
   Harris JA, 2001, J NEUROSCI, V21, P1056
   Irving B., 1968, RES MEDICA, VVI, P25
   Johansson RS, 2009, NAT REV NEUROSCI, V10, P345, DOI 10.1038/nrn2621
   JOHANSSON RS, 1980, BRAIN RES, V184, P343, DOI 10.1016/0006-8993(80)90803-3
   Jones L. A., 2006, PRESS, DOI 10.1093/acprof:oso/9780195173154.001.0001
   JONES LA, 1993, EXP BRAIN RES, V94, P343
   Kandel E. R., 2000, P IEEE INF VIS S HOT, P4
   Klamroth-Marganska V, 2014, LANCET NEUROL, V13, P159, DOI 10.1016/S1474-4422(13)70305-3
   Kording KP, 2004, NATURE, V427, P244, DOI 10.1038/nature02169
   Krueger AR, 2017, J NEUROENG REHABIL, V14, DOI 10.1186/s12984-017-0248-8
   Kuczynski AM, 2016, NEUROREHAB NEURAL RE, V30, P762, DOI 10.1177/1545968315624781
   Kuniyasu Y., 2012, PROCEEDINGS OF THE 3, P1, DOI 10.1145/2160125.2160141
   KUSOFFSKY A, 1982, SCAND J REHABIL MED, V14, P27
   Kwakkel G, 2008, NEUROREHAB NEURAL RE, V22, P111, DOI 10.1177/1545968307305457
   Lambert GA, 2009, J NEUROSCI METH, V177, P420, DOI 10.1016/j.jneumeth.2008.10.033
   Leib R, 2016, J NEUROSCI, V36, P10545, DOI 10.1523/JNEUROSCI.1178-16.2016
   Levesque V., 2005, ACM T APPL PERCEPT, V2, P132, DOI DOI 10.1145/1060581.1060587
   Longo MR, 2011, J EXP PSYCHOL HUMAN, V37, P720, DOI 10.1037/a0021921
   Luk J., 2006, P SIGCHI C HUM FACT, P171, DOI 10.1145/1124772
   Maggioni S, 2016, J NEUROENG REHABIL, V13, DOI 10.1186/s12984-016-0180-3
   Marini F., 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0161155
   Marini Francesca, 2017, J Neuroeng Rehabil, V14, P3, DOI 10.1186/s12984-016-0215-9
   MEHRHOLZ J, 2012, COCHRANE DB SYST REV
   Memeo M, 2016, LECT NOTES COMPUT SC, V9775, P438, DOI 10.1007/978-3-319-42324-1_43
   MORASSO P, 2015, FRONT HUM NEUROSCI, V2015, P83
   Norouzi-Gheidari N, 2012, J REHABIL RES DEV, V49, P479, DOI 10.1682/JRRD.2010.10.0210
   Pacchierotti C, 2017, IEEE T HAPTICS, V10, P580, DOI 10.1109/TOH.2017.2689006
   Pare M, 2002, EXP BRAIN RES, V142, P342, DOI 10.1007/s00221-001-0939-y
   Peurala SH, 2002, CLIN REHABIL, V16, P709, DOI 10.1191/0269215502cr543oa
   Prange GB, 2006, J REHABIL RES DEV, V43, P171, DOI 10.1682/JRRD.2005.04.0076
   Prattichizzo D, 2012, IEEE T HAPTICS, V5, P289, DOI [10.1109/ToH.2012.15, 10.1109/TOH.2012.15]
   Proske U, 2012, PHYSIOL REV, V92, P1651, DOI 10.1152/physrev.00048.2011
   Proske U, 2009, J PHYSIOL-LONDON, V587, P4139, DOI 10.1113/jphysiol.2009.175372
   Provancher WR, 2009, IEEE T HAPTICS, V2, P212, DOI [10.1109/TOH.2009.34, 10.1109/ToH.2009.34]
   Quek ZF, 2015, IEEE INT CONF ROBOT, P264, DOI 10.1109/ICRA.2015.7139010
   Quek ZF, 2015, IEEE T HAPTICS, V8, P209, DOI 10.1109/TOH.2015.2398448
   Quek ZF, 2014, IEEE T HUM-MACH SYST, V44, P731, DOI 10.1109/THMS.2014.2348865
   Quek ZF, 2014, IEEE HAPTICS SYM, P27, DOI 10.1109/HAPTICS.2014.6775429
   Ruch TC, 1938, ARCH NEURO PSYCHIATR, V39, P919, DOI 10.1001/archneurpsyc.1938.02270050045003
   Schorr SB, 2015, IEEE T HUM-MACH SYST, V45, P714, DOI 10.1109/THMS.2015.2463090
   Schorr SB, 2013, IEEE INT CONF ROBOT, P2341, DOI 10.1109/ICRA.2013.6630894
   SCHORR SB, 2017, IEEE TRANS HAPTICS
   Scott SH, 2011, J REHABIL RES DEV, V48, P335, DOI 10.1682/JRRD.2010.04.0057
   Semrau JA, 2013, STROKE, V44, P3414, DOI 10.1161/STROKEAHA.113.002058
   SHERRICK CE, 1990, J ACOUST SOC AM, V88, P169, DOI 10.1121/1.399937
   Simo LS, 2011, IEEE ENG MED BIO, P8227, DOI 10.1109/IEMBS.2011.6092029
   Sketch SM, 2015, IEEE INT CONF ROBOT, P272, DOI 10.1109/ICRA.2015.7139011
   SMITH DL, 1983, AGE AGEING, V12, P63, DOI 10.1093/ageing/12.1.63
   Stevens JC, 1996, SOMATOSENS MOT RES, V13, P153, DOI 10.3109/08990229609051403
   SZETO AYJ, 1982, IEEE T BIO-MED ENG, V29, P300, DOI 10.1109/TBME.1982.324948
   VANBOVEN RW, 1994, BRAIN, V117, P149, DOI 10.1093/brain/117.1.149
   VANBUSKIRK C, 1955, NEUROLOGY, V5, P407
   Vidoni ED, 2010, NEUROBIOL LEARN MEM, V93, P532, DOI 10.1016/j.nlm.2010.01.011
   Von Frey M., 1896, UNTERSUCHUNGEN UBER, V23
   Wilson E. T., 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0011851
   Winter JA, 2005, J PHYSIOL-LONDON, V568, P1035, DOI 10.1113/jphysiol.2005.092619
   Winward C. E., 1999, CLIN REHABIL, V2155, P48, DOI 10.1191/026921599701532126
   WOOLF CJ, 1983, NATURE, V306, P686, DOI 10.1038/306686a0
   YEKUTIEL M, 1993, J NEUROL NEUROSUR PS, V56, P241, DOI 10.1136/jnnp.56.3.241
   YEKUTIEL M, 1994, DEV MED CHILD NEUROL, V36, P619
   ZEMAN BD, 1989, J NEUROL NEUROSUR PS, V52, P242, DOI 10.1136/jnnp.52.2.242
NR 90
TC 0
Z9 0
U1 4
U2 8
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1662-5218
J9 FRONT NEUROROBOTICS
JI Front. Neurorobotics
PD APR 6
PY 2018
VL 12
AR 12
DI 10.3389/fnbot.2018.00012
PG 17
WC Computer Science, Artificial Intelligence; Robotics; Neurosciences
SC Computer Science; Robotics; Neurosciences & Neurology
GA GB9AE
UT WOS:000429365600001
PM 29681809
OA DOAJ Gold, Green Published
DA 2019-02-18
ER

PT J
AU Chadwell, A
   Kenney, L
   Thies, S
   Galpin, A
   Head, J
AF Chadwell, Alix
   Kenney, Laurence
   Thies, Sibylle
   Galpin, Adam
   Head, John
TI The Reality of myoelectric Prostheses: Understanding What Makes These
   Devices Difficult for Some User to Control (vol 10, 7, 2016)
SO FRONTIERS IN NEUROROBOTICS
LA English
DT Correction
ID AMPUTATION
C1 [Chadwell, Alix; Kenney, Laurence; Thies, Sibylle; Galpin, Adam; Head, John] Univ Salford, Ctr Hlth Sci Res, Salford, Lancs, England.
RP Kenney, L (reprint author), Univ Salford, Ctr Hlth Sci Res, Salford, Lancs, England.
EM l.p.j.kenney@salford.ac.uk
CR Actigraph Corp, 2015, ACTIGRAPH WHIT PAP W
   Bailey RR, 2015, NEUROREHAB NEURAL RE, V29, P969, DOI 10.1177/1545968315583720
   Brown BB, 2008, J PHYS ACT HEALTH, V5, P882, DOI 10.1123/jpah.5.6.882
   Chadwell A, 2016, FRONT NEUROROBOTICS, V10, DOI 10.3389/fnbot.2016.00007
   Gallagher P, 2000, REHABIL PSYCHOL, V45, P130, DOI 10.1037//0090-5550.45.2.130
   Metcalf C, 2007, MUSCULOSKELET CARE, V5, P160, DOI 10.1002/msc.108
   Noorkoiv M, 2014, J NEUROENG REHABIL, V11, DOI 10.1186/1743-0003-11-144
   Raichle KA, 2008, J REHABIL RES DEV, V45, P961, DOI 10.1682/JRRD.2007.09.0151
   ROESCHLEIN RA, 1989, PROSTHET ORTHOT INT, V13, P14
   Sherman RA, 1999, J REHABIL RES DEV, V36, P100
NR 10
TC 0
Z9 0
U1 1
U2 1
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1662-5218
J9 FRONT NEUROROBOTICS
JI Front. Neurorobotics
PD APR 3
PY 2018
VL 12
AR 15
DI 10.3389/fnbot.2018.00015
PG 2
WC Computer Science, Artificial Intelligence; Robotics; Neurosciences
SC Computer Science; Robotics; Neurosciences & Neurology
GA GB4SD
UT WOS:000429050100001
PM 29643774
OA DOAJ Gold, Green Published
DA 2019-02-18
ER

PT J
AU Petric, F
   Miklic, D
   Kovacic, Z
AF Petric, Frano
   Miklic, Damjan
   Kovacic, Zdenko
TI POMDP-Based Coding of Child-Robot Interaction within a Robot-Assisted
   ASD Diagnostic Protocol
SO INTERNATIONAL JOURNAL OF HUMANOID ROBOTICS
LA English
DT Article
DE Robotics; POMDP; autism spectrum disorder; diagnostics
ID AUTISM SPECTRUM DISORDER; JOINT ATTENTION; TASKS; ADULTS
AB The existing procedures for autism spectrum disorder (ASD) diagnosis are often time consuming and tiresome both for highly-trained human evaluators and children, which may be alleviated by using humanoid robots in the diagnostic process. Hence, this paper proposes a framework for robot-assisted ASD evaluation based on partially observable Markov decision process (POMDP) modeling, specifically POMDPs with mixed observability (MOMDPs). POMDP is broadly used for modeling optimal sequential decision making tasks under uncertainty. Spurred by the widely accepted autism diagnostic observation schedule (ADOS), we emulate ADOS through four tasks, whose models incorporate observations of multiple social cues such as eye contact, gestures and utterances. Relying only on those observations, the robot provides an assessment of the child's ASD-relevant functioning level (which is partially observable) within a particular task and provides human evaluators with readable information by partitioning its belief space. Finally, we evaluate the proposed MOMDP task models and demonstrate that chaining the tasks provides fine-grained outcome quantification, which could also increase the appeal of robot-assisted diagnostic protocols in the future.
C1 [Petric, Frano; Miklic, Damjan; Kovacic, Zdenko] Univ Zagreb, Fac Elect Engn & Comp, Unska 3, Zagreb 10000, Croatia.
RP Petric, F (reprint author), Univ Zagreb, Fac Elect Engn & Comp, Unska 3, Zagreb 10000, Croatia.
EM frano.petric@fer.hr; damjan.miklic@fer.hr; zdenko.kovacic@fer.hr
FU Croatian Science Foundation under the project Autism Diagnostic
   Observation with Robot Evaluator [93743-2014]
FX This work has been fully supported by Croatian Science Foundation under
   the project Autism Diagnostic Observation with Robot Evaluator (No.
   93743-2014). We would like to thank Dr. Domagoj Tolic, who provided
   insight into POMDPs that greatly assisted the work described in this
   paper. We also thank Dr. Maja Cepanec, Dr. Jasmina Stosic and Dr. Sanja
   Simlesa for their invaluable insight into expected children behaviors
   and help with the clinical trials.
CR American Psychiatric Association, 2013, DIAGN STAT MAN MENT
   Baio J., 2014, MMWR, V63
   Cabibihan JJ, 2013, INT J SOC ROBOT, V5, P593, DOI 10.1007/s12369-013-0202-2
   Caccavale R, 2014, IEEE ROMAN, P844, DOI 10.1109/ROMAN.2014.6926358
   Carpenter M, 1998, MONOGR SOC RES CHILD, V63, pV
   Cassandra A. R., 2013, POMDP SOLVE
   Charman T, 1997, DEV PSYCHOL, V33, P781, DOI 10.1037//0012-1649.33.5.781
   Dawson G, 2004, DEV PSYCHOL, V40, P271, DOI 10.1037/0012-1649.40.2.271
   Hauck M, 1995, J AUTISM DEV DISORD, V25, P579, DOI 10.1007/BF02178189
   Hoey J, 2005, 19TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI-05), P1332
   Iacovides Joanna, 2011, International Journal of Virtual and Personal Learning Environments, V2, P1, DOI 10.4018/jvple.2011040101
   Jones W, 2008, ARCH GEN PSYCHIAT, V65, P946, DOI 10.1001/archpsyc.65.8.946
   Klin A, 2000, J AUTISM DEV DISORD, V30, P163, DOI 10.1023/A:1005415823867
   Kurniawati H., 2008, P ROB SCI SYST 4 ZUR
   Lam CP, 2014, IEEE DECIS CONTR P, P6031, DOI 10.1109/CDC.2014.7040333
   Lee J.-G., 2017, INT J HUM ROBOT, V14
   Liu CC, 2008, IEEE T ROBOT, V24, P883, DOI 10.1109/TRO.2008.2001362
   Lord C., 2002, AUTISM DIAGNOSTIC OB
   Ong SCW, 2010, INT J ROBOT RES, V29, P1053, DOI 10.1177/0278364910369861
   Petric F, 2014, IEEE GLOB HUMANIT C, P510, DOI 10.1109/GHTC.2014.6970331
   Petric F, 2015, LECT NOTES ARTIF INT, V9245, P82, DOI 10.1007/978-3-319-22876-1_8
   Poupart Pascal, 2005, THESIS
   Rafferty AN, 2011, LECT NOTES ARTIF INT, V6738, P280, DOI 10.1007/978-3-642-21869-9_37
   Ricks D. J., 2010, 2010 IEEE INT C ROB
   Rosenthal S., 2011, 2011 RO-MAN: The 20th IEEE International Symposium on Robot and Human Interactive Communication, P53, DOI 10.1109/ROMAN.2011.6005272
   Rutter M., 2003, AUTISM DIAGNOSTIC IN
   Scassellati B, 2007, SPRINGER TRAC ADV RO, V28, P552
   Scassellati B, 2012, ANNU REV BIOMED ENG, V14, P275, DOI 10.1146/annurev-bioeng-071811-150036
   Schodde Thorten, 2017, 2017 12th ACM/IEEE International Conference on Human-Robot Interaction (HRI), P128, DOI 10.1145/2909824.3020222
   STONE WL, 1990, J AUTISM DEV DISORD, V20, P437, DOI 10.1007/BF02216051
   Taha Tarek, 2011, IEEE International Conference on Robotics and Automation, P544
   Wang ML, 2013, IEEE INT C INT ROBOT, P5285, DOI 10.1109/IROS.2013.6697121
   Zwaigenbaum L, 2005, INT J DEV NEUROSCI, V23, P143, DOI 10.1016/j.ijdevneu.2004.05.001
NR 33
TC 0
Z9 0
U1 4
U2 4
PU WORLD SCIENTIFIC PUBL CO PTE LTD
PI SINGAPORE
PA 5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE
SN 0219-8436
EI 1793-6942
J9 INT J HUM ROBOT
JI Int. J. Humanoid Robot.
PD APR
PY 2018
VL 15
IS 2
SI SI
AR 1850011
DI 10.1142/S0219843618500111
PG 23
WC Robotics
SC Robotics
GA GI7AL
UT WOS:000434654300006
DA 2019-02-18
ER

PT J
AU Sunderhauf, N
   Brock, O
   Scheirer, W
   Hadsell, R
   Fox, D
   Leitner, J
   Upcroft, B
   Abbeel, P
   Burgard, W
   Milford, M
   Corke, P
AF Suenderhauf, Niko
   Brock, Oliver
   Scheirer, Walter
   Hadsell, Raia
   Fox, Dieter
   Leitner, Juergen
   Upcroft, Ben
   Abbeel, Pieter
   Burgard, Wolfram
   Milford, Michael
   Corke, Peter
TI The limits and potentials of deep learning for robotics
SO INTERNATIONAL JOURNAL OF ROBOTICS RESEARCH
LA English
DT Article; Proceedings Paper
CT Workshop on Are the Skeptics Right Limits and Potentials of Deep
   Learning in Robotics at the 12th Conference on Robotics - Science and
   Systems (RSS)
CY JUN 18-22, 2016
CL Univ Michigan, Ann Arbor, MI
HO Univ Michigan
DE Robotics; deep learning; machine learning; robotic vision
ID NEURAL-NETWORKS; OBJECT; SIMULATION
AB The application of deep learning in robotics leads to very specific problems and research questions that are typically not addressed by the computer vision and machine learning communities. In this paper we discuss a number of robotics-specific learning, reasoning, and embodiment challenges for deep learning. We explain the need for better evaluation metrics, highlight the importance and unique challenges for deep robotic learning in simulation, and explore the spectrum between purely data-driven and model-driven approaches. We hope this paper provides a motivating overview of important research directions to overcome the current limitations, and helps to fulfill the promising potentials of deep learning in robotics.
C1 [Suenderhauf, Niko; Leitner, Juergen; Milford, Michael; Corke, Peter] Queensland Univ Technol, Australian Ctr Robot Vis, Brisbane, Qld, Australia.
   [Brock, Oliver] Tech Univ Berlin, Robot & Biol Lab, Berlin, Germany.
   [Scheirer, Walter] Univ Notre Dame, Dept Comp Sci & Engn, Notre Dame, IN 46556 USA.
   [Hadsell, Raia] DeepMind, London, England.
   [Fox, Dieter] Univ Washington, Paul G Allen Sch Comp Sci & Engn, Seattle, WA 98195 USA.
   [Upcroft, Ben] Oxbotica Ltd, Oxford, England.
   [Abbeel, Pieter] Univ Calif Berkeley, Dept Elect Engn & Comp Sci, Berkeley, CA USA.
   [Burgard, Wolfram] Univ Freiburg, Dept Comp Sci, Freiburg, Germany.
RP Sunderhauf, N (reprint author), Queensland Univ Technol, 2 George St, Brisbane, Qld 4000, Australia.
EM niko.suenderhauf@roboticvision.org
OI Milford, Michael/0000-0002-5162-1793
FU Australian Research Council Centre of Excellence for Robotic Vision
   [CE140100016]; DFG [329426068]; IARPA [D16PC00002]; Australian Research
   Council [FT140101229]
FX This work was supported by the Australian Research Council Centre of
   Excellence for Robotic Vision (project number CE140100016). Oliver Brock
   was supported by the DFG (grant number 329426068). Walter Scheirer
   acknowledges the funding provided by IARPA (contract number D16PC00002).
   Michael Milford was partially supported by an Australian Research
   Council Future Fellowship (FT140101229).
CR Agrawal P., 2016, ADV NEURAL INFORM PR
   Angelova A, 2017, COMP VIS PATT REC CV
   Nguyen A, 2015, PROC CVPR IEEE, P427, DOI 10.1109/CVPR.2015.7298640
   Anthony Samuel English, 2016, SLATE
   Atanasov N, 2014, IEEE T ROBOT, V30, P1078, DOI 10.1109/TRO.2014.2320795
   Baillargeon R., 2011, WILEY BLACKWELL HDB, P11
   Baillargeon R, 2012, LANG LEARN DEV, V8, P4, DOI 10.1080/15475441.2012.630610
   Barrett S., 2010, 9 INT C AUT AG MULT
   Battaglia P, 2016, ADV NEURAL INFORM PR, P4502
   Battaglia PW, 2013, P NATL ACAD SCI USA, V110, P18327, DOI 10.1073/pnas.1306572110
   Bendale A, 2016, PROC CVPR IEEE, P1563, DOI 10.1109/CVPR.2016.173
   Bendale A, 2015, PROC CVPR IEEE, P1893, DOI 10.1109/CVPR.2015.7298799
   Bertinetto L, 2016, ADV NEURAL INFORM PR, P523
   Bircher A, 2016, IEEE INT CONF ROBOT, P1462, DOI 10.1109/ICRA.2016.7487281
   Blanz V, 1999, PERCEPTION, V28, P575, DOI 10.1068/p2897
   Byravan A, 2017, P IEEE INT C ROB AUT
   Byravan A, 2018, P IEEE INT C ROB AUT
   C Finn IG, 2016, ADV NEURAL INFORM PR
   Cadena C, IEEE T ROBOTICS, V32, P1309
   Choy CB, 2016, LECT NOTES COMPUT SC, V9912, P628, DOI 10.1007/978-3-319-46484-8_38
   Cohn DA, 1996, J ARTIF INTELL RES, V4, P129, DOI 10.1613/jair.295
   Cox DD, 2014, CURR BIOL, V24, pR921, DOI 10.1016/j.cub.2014.08.026
   Csurka Gabriela, 2017, ARXIV170205374
   Dayoub F, 2017, CVPR WORKSH DEEP LEA
   Doumanoglou A, 2016, PROC CVPR IEEE, P3583, DOI 10.1109/CVPR.2016.390
   Embretson SE, 2000, ITEM RESPONSE THEORY
   Finn C, 2017, ARXIV170303400
   Gal Y., 2016, INT C MACH LEARN, P1050
   Gal Y., 2017, ARXIV170302910
   Ganin Y, 2015, ABS150507818 CORR
   Garg R, 2016, LECT NOTES COMPUT SC, V9912, P740, DOI 10.1007/978-3-319-46484-8_45
   Godard C, 2017, COMPUTER VISION PATT
   Goldstein EB, 2016, SENSATION PERCEPTION
   Goodfellow I. J., 2013, ARXIV13126211
   Goodfellow I. J., 2014, ARXIV14126572
   Greff K, 2017, ADV NEURAL INFORM PR, P6694
   Gu S, 2016, ICML 2016
   Guo C., 2017, ARXIV170604599
   Haarnoja T, 2016, ABS160507148 CORR
   Hane C., 2017, ARXIV170400710
   Hariharan B., 2016, ARXIV160602819
   He K., 2017, IEEE INT C COMP VIS
   Heess N, 2015, ADV NEURAL INFORM PR, V28, P2944
   Hendrycks D, 2017, INT C MACH LEARN ICM
   Hespos S, 2009, COGNITIVE SCI, V33, P1483, DOI 10.1111/j.1551-6709.2009.01051.x
   Hinton G, 2015, ABS150302531
   Hofer S, 2016, DEEP LEARN WORKSH C
   James S, 2016, ARXIV E PRINTS
   Jonschkowski R, 2015, ABS151106429 CORR
   Jonschkowski R., 2017, ARXIV170509805
   Jonschkowski R., 2016, WORKSH DEEP LEARN AC
   Jonschkowski R, 2015, AUTON ROBOT, V39, P407, DOI 10.1007/s10514-015-9459-7
   Kaess M, 2012, INT J ROBOT RES, V31, P216, DOI 10.1177/0278364911430419
   Kendall Alex, 2017, ARXIV170304977
   Kersten D, 2004, ANNU REV PSYCHOL, V55, P271, DOI 10.1146/annurev.psych.55.090902.142005
   Kingma D.P., 2014, ADV NEURAL INFORM PR, P3581
   Kuindersma S, 2016, AUTON ROBOT, V40, P429, DOI 10.1007/s10514-015-9479-3
   Kummerle Rainer, 2011, IEEE International Conference on Robotics and Automation, P3607
   Kunze L, 2015, ARTIF INTELL, V247, P352
   Lake BM, 2015, SCIENCE, V350, P1332, DOI 10.1126/science.aab3050
   Lakshminarayanan B., 2017, ADV NEURAL INFORM PR, P6393
   Levine S, 2015, J MACHINE LEARNING R, V17, P1334
   Levine S., 2014, ADV NEURAL INFORM PR, P1071
   Lillicrap T. P., 2015, ABS150902971 CORR
   Lin DH, 2013, IEEE I CONF COMP VIS, P1417, DOI 10.1109/ICCV.2013.179
   Liu FY, 2016, IEEE T PATTERN ANAL, V38, P2024, DOI 10.1109/TPAMI.2015.2505283
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Lohr S., 2016, NY TIMES
   Lomonaco V, 2017, ARXIV170503550
   Long M., 2015, INT C MACH LEARN, V37, P97
   Lopez-Paz D, 2016, ABS151103643 CORR
   MACKAY DJC, 1992, NEURAL COMPUT, V4, P448, DOI 10.1162/neco.1992.4.3.448
   Malmir M, 2017, COMPUT VIS IMAGE UND, V156, P128, DOI 10.1016/j.cviu.2016.10.011
   MCCLOSKEY M, 1983, SCI AM, V248, P122, DOI 10.1038/scientificamerican0483-122
   Mensink T, 2012, LECT NOTES COMPUT SC, V7573, P488, DOI 10.1007/978-3-642-33709-3_35
   Miller D, 2017, INT C ROB AUT ICRA
   Mnih V., 2016, INT C MACH LEARN ICM
   Neal Radford M, 1995, THESIS
   Oliva A, 2007, TRENDS COGN SCI, V11, P520, DOI 10.1016/j.tics.2007.09.009
   Papandreou G, 2015, IEEE I CONF COMP VIS, P1742, DOI 10.1109/ICCV.2015.203
   Patel VM, 2015, IEEE SIGNAL PROC MAG, V32, P53, DOI 10.1109/MSP.2014.2347059
   Peng XC, 2015, IEEE I CONF COMP VIS, P1278, DOI 10.1109/ICCV.2015.151
   Piaget J, 2013, CONSTRUCTION REALITY
   Pillai S, 2015, ROBOTICS SCI SYSTEMS
   Posner I, 2016, NEUR INF PROC SYST N
   Povinelli DJ, 2000, FOLK PHYS APES CHIMP
   Rasmus A., 2015, ADV NEURAL INFORM PR, P3546
   Rebuffi S. - A., 2017, IEEE C COMP VIS PATT
   Redmon J., 2016, IEEE C COMP VIS PATT, P2
   Rezende D, 2016, P MACHINE LEARNING R, P1521
   RichardWebster B, 2016, ABS161106448 CORR
   Rock I., 1983, LOGIC PERCEPTION
   Rumsfeld D, 2002, DOD NEWS BRIEFING AD
   Rusu Andrei A., 2016, ARXIV160604671
   Sadeghi F., 2016, ARXIV161104201, P12
   Salas-Moreno RF, 2013, PROC CVPR IEEE, P1352, DOI 10.1109/CVPR.2013.178
   Santoro A., 2016, P 33 INT C MACH LEAR, V48, P1842
   Scheirer WJ, 2014, IEEE T PATTERN ANAL, V36, P2317, DOI 10.1109/TPAMI.2014.2321392
   Scheirer WJ, 2014, IEEE T PATTERN ANAL, V36, P1679, DOI 10.1109/TPAMI.2013.2297711
   Scheirer WJ, 2013, IEEE T PATTERN ANAL, V35, P1757, DOI 10.1109/TPAMI.2012.256
   Schierwagen A, 2012, NAT COMPUT, V11, P141, DOI 10.1007/s11047-012-9306-0
   Schmidt T, 2015, P IEEE INT C ROB AUT
   Schulman J., 2016, P INT C LEARN REPR I
   Schulman J., 2015, P 32 INT C MACH LEAR
   Shi L, 2009, P NEUR INF PROC SYST
   Simon H., 1996, SCI ARTIFICIAL
   Su H, 2015, IEEE I CONF COMP VIS, P2686, DOI 10.1109/ICCV.2015.308
   Sunderhauf N, 2017, ROB SCI SYST RSS WOR
   Sunderhauf N, 2016, ROB SCI SYST RSS WOR
   Sunderhauf N, 2017, INT C INT ROB SYST I
   Sunderhauf N, 2016, IEEE INT CONF ROBOT, P5729, DOI 10.1109/ICRA.2016.7487796
   Szegedy C, ABS13126199 CORR
   Tamar A, 2016, ABS160202867 CORR
   Thrun S., 2005, PROBABILISTIC ROBOTI
   Tobin J, 2017, IEEE INT C INT ROBOT, P23, DOI 10.1109/IROS.2017.8202133
   Todorov E, 2012, INT C INT ROB SYST I
   Torralba A, 2011, PROC CVPR IEEE, P1521, DOI 10.1109/CVPR.2011.5995347
   Tzeng E, 2015, ABS151107111 CORR
   Tzeng E, 2015, IEEE I CONF COMP VIS, P4068, DOI 10.1109/ICCV.2015.463
   Tzeng Eric, 2014, ABS14123474 CORR
   Vinyals O, 2016, ADV NEURAL INFORM PR, P3630
   Von Helmholtz H, 1867, HDB PHYSL OPTIK, V9
   Wang YX, 2016, LECT NOTES COMPUT SC, V9910, P616, DOI 10.1007/978-3-319-46466-4_37
   Watter M., 2015, ADV NEURAL INFORM PR, P2728
   Wilson RC, 2009, P NEUR INF PROC SYST
   Wu J., 2015, ADV NEURAL INF PROCE, P127, DOI DOI 10.1007/978-3-319-26532-2_15
   Yan X., 2016, ADV NEURAL INFORM PR, P1696
   Yildirim I, 2017, ARXIV170708212
   Zeng MY, 2015, IEEE COMPUT SOC CONF
   Zhang C, 2016, ABS161103530 CORR
   Zhang F, 2015, AUSTR C ROB AUT
   Zhang H., 2016, J CHEM, V2016, P1, DOI DOI 10.1016/J.FSIGEN.2016.01.005
   Zhang Yang, 2017, IEEE INT C COMP VIS
   Zhu R, 2017, IEEE I CONF COMP VIS, P57, DOI 10.1109/ICCV.2017.16
   Zhu Y, 2016, ABS160905143 CORR
NR 135
TC 1
Z9 1
U1 11
U2 21
PU SAGE PUBLICATIONS LTD
PI LONDON
PA 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND
SN 0278-3649
EI 1741-3176
J9 INT J ROBOT RES
JI Int. J. Robot. Res.
PD APR
PY 2018
VL 37
IS 4-5
SI SI
BP 405
EP 420
DI 10.1177/0278364918770733
PG 16
WC Robotics
SC Robotics
GA GF7FY
UT WOS:000432134700002
DA 2019-02-18
ER

PT J
AU Pour, AG
   Taheri, A
   Alemi, M
   Meghdari, A
AF Pour, Ali Ghorbandaei
   Taheri, Alireza
   Alemi, Minoo
   Meghdari, Ali
TI Human-Robot Facial Expression Reciprocal Interaction Platform: Case
   Studies on Children with Autism
SO INTERNATIONAL JOURNAL OF SOCIAL ROBOTICS
LA English
DT Article
DE Human-robot interaction (HRI); Reciprocal interaction; Facial
   expressions; Autism; Fuzzy finite state machine; Imitation
ID EMOTION RECOGNITION; IMITATION; IMPACT; GAMES
AB Reciprocal interaction and facial expression are some of the most interesting topics in the fields of social and cognitive robotics. On the other hand, children with autism show a particular interest toward robots, and facial expression recognition can improve these children's social interaction abilities in real life. In this research, a robotic platform has been developed for reciprocal interaction consisting of two main phases, namely as Non-structured and Structured interaction modes. In the Non-structured interaction mode, a vision system recognizes the facial expressions of the user through a fuzzy clustering method. The interaction decision-making unit is combined with a fuzzy finite state machine to improve the quality of human-robot interaction by utilizing the results obtained from the facial expression analysis. In the Structured interaction mode, a set of imitation scenarios with eight different posed facial behaviors were designed for the robot. As a pilot study, the effect and acceptability of our platform have been investigated on autistic children between 3 and 7 years old and the preliminary acceptance rate of 78% is observed in our experimental conditions. The scenarios start with simple facial expressions and get more complicated as they continue. The same vision system and fuzzy clustering method of the Non-structured interaction mode are used for automatic evaluation of a participant's gestures. Lastly, the automatic assessment of imitation quality was compared with the manual video coding results. The Pearson's r on these equivalent grades were computed as r = 0.89 which shows a sufficient agreement on the automatic and manual scores.
C1 [Pour, Ali Ghorbandaei; Taheri, Alireza; Alemi, Minoo; Meghdari, Ali] Sharif Univ Technol, CEDRA, Social & Cognit Robot Lab, Tehran, Iran.
   [Alemi, Minoo] Islamic Azad Univ, West Tehran Branch, Fac Humanities, Tehran, Iran.
RP Meghdari, A (reprint author), Sharif Univ Technol, CEDRA, Social & Cognit Robot Lab, Tehran, Iran.
EM ali.ghr@gmail.com; taheri@mech.sharif.edu; alemi@sharif.edu;
   meghdari@sharif.edu
FU "Cognitive Sciences and Technology Council" (CSTC) of Iran [95p22]
FX This study was funded by the "Cognitive Sciences and Technology Council"
   (CSTC) of Iran (Grant Number: 95p22)
CR Abdat F, 2011, UKSIM EURO SYMP COMP, P196, DOI 10.1109/EMS.2011.20
   Alemi M, 2015, INT J SOC ROBOT, V7, P523, DOI 10.1007/s12369-015-0286-y
   Alemi M, 2016, INT J SOC ROBOT, V8, P743, DOI 10.1007/s12369-015-0294-y
   Aly A, 2015, IEEE INT C INT ROBOT, P2986, DOI 10.1109/IROS.2015.7353789
   [Anonymous], 2016, KINECT WINDOWS SDK
   Baron-Cohen S, 2001, PRISME, V34, P74
   BARONCOHEN S, 1985, COGNITION, V21, P37, DOI 10.1016/0010-0277(85)90022-8
   BEZDEK JC, 1984, COMPUT GEOSCI, V10, P191, DOI 10.1016/0098-3004(84)90020-7
   Brown L, 2014, IEEE ROMAN, P471, DOI 10.1109/ROMAN.2014.6926297
   Chakraborty A, 2009, IEEE T SYST MAN CY A, V39, P726, DOI 10.1109/TSMCA.2009.2014645
   Chumkamon S, 2014, 11 INT C EL ENG EL C, P1
   Cid F, 2013, IEEE INT C INT ROBOT, P2188, DOI 10.1109/IROS.2013.6696662
   Dahmane M, 2014, IEEE T MULTIMEDIA, V16, P1574, DOI 10.1109/TMM.2014.2321113
   Dawson G, 2005, DEV NEUROPSYCHOL, V27, P403, DOI 10.1207/s15326942dn2703_6
   de Carvalho Santos V., 2012, 2012 Brazilian Robotics Symposium and Latin American Robotics Symposium (SBR-LARS 2012), P251, DOI 10.1109/SBR-LARS.2012.48
   Dong-Soo Kwon, 2007, 16th IEEE International Conference on Robot and Human Interactive Communication, P351
   Duquette A, 2008, AUTON ROBOT, V24, P147, DOI 10.1007/s10514-007-9056-5
   Ekman P., 1978, FACIAL ACTION CODING
   Elahi MT, 2017, LECT NOTES ARTIF INT, V10652, P728, DOI 10.1007/978-3-319-70022-9_72
   Feil-Seifer D, 2008, 2008 17TH IEEE INTERNATIONAL SYMPOSIUM ON ROBOT AND HUMAN INTERACTIVE COMMUNICATION, VOLS 1 AND 2, P328, DOI 10.1109/ROMAN.2008.4600687
   Giannopulu I, 2014, P 2 INT C HUM AG INT, P9
   Halder A, 2013, IEEE T SYST MAN CY-S, V43, P587, DOI 10.1109/TSMCA.2012.2207107
   Hanson D, 2012, P 5 ACM INT C PERV T
   HAVILAND JM, 1987, DEV PSYCHOL, V23, P97, DOI 10.1037/0012-1649.23.1.97
   Holthaus Patrick, 2013, 2013 IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN), P370, DOI 10.1109/ROMAN.2013.6628502
   Hopkins IM, 2011, J AUTISM DEV DISORD, V41, P1543, DOI 10.1007/s10803-011-1179-z
   Ingersoll B, 2010, J AUTISM DEV DISORD, V40, P590, DOI [10.1007/s10803-009-0907-0, 10.1007/s10803-010-0966-2]
   Kotsia I, 2007, IEEE T IMAGE PROCESS, V16, P172, DOI 10.1109/TIP.2006.884954
   Li YQ, 2015, PATTERN RECOGN, V48, P3417, DOI 10.1016/j.patcog.2015.04.022
   Li YQ, 2013, IEEE T IMAGE PROCESS, V22, P2559, DOI 10.1109/TIP.2013.2253477
   Mavadati S., 2015, THESIS
   Mavridis N, 2015, ROBOT AUTON SYST, V63, P22, DOI 10.1016/j.robot.2014.09.031
   Meghdari A, 2016, 2016 4TH RSI INTERNATIONAL CONFERENCE ON ROBOTICS AND MECHATRONICS (ICROM), P524, DOI 10.1109/ICRoM.2016.7886797
   Meghdari A, 2016, LECT NOTES ARTIF INT, V9979, P351, DOI 10.1007/978-3-319-47437-3_34
   Minitab INC, 2000, MINITAB STAT SOFTW M
   Noh JY, 1998, TECHNICAL REPORT, P99
   Pantic M, 2007, LECT NOTES COMPUTER, V4451
   Popescu M., 2015, P IEEE INT C FUZZ SY, P1
   Pouretemad H, 2011, ASSESSMENT TREATMENT
   Salvador MJ, 2015, IEEE INT CONF ROBOT, P6128, DOI 10.1109/ICRA.2015.7140059
   Scassellati B, 2012, ANNU REV BIOMED ENG, V14, P275, DOI 10.1146/annurev-bioeng-071811-150036
   Taheri A, 2017, INT J SOC ROBOT
   Taheri A, 2017, INT J SCI IRAN T G
   Taheri A, 2016, LECT NOTES ARTIF INT, V9979, P541, DOI 10.1007/978-3-319-47437-3_53
   Taheri A, 2015, LECT NOTES ARTIF INT, V9388, P623, DOI 10.1007/978-3-319-25554-5_62
   Tamura T, 2004, J GERONTOL A-BIOL, V59, P83
   Tanaka JW, 2010, J CHILD PSYCHOL PSYC, V51, P944, DOI 10.1111/j.1469-7610.2010.02258.x
   Tardif C, 2007, J AUTISM DEV DISORD, V37, P1469, DOI 10.1007/s10803-006-0223-x
   Tonks J, 2007, BRAIN INJURY, V21, P623, DOI 10.1080/02699050701426865
   Valstar MF, 2008, TIMING IS EVERYTHING
   Wainer J, 2014, IEEE T AUTON MENT DE, V6, P183, DOI 10.1109/TAMD.2014.2303116
   Xiao Y, 2014, PRESENCE-TELEOP VIRT, V23, P133, DOI 10.1162/PRES_a_00176
   Yan Juan, 1994, USING FUZZY LOGIC IN, V1
   Zacharatos H, 2014, IEEE COMPUT GRAPH, V34, P35, DOI 10.1109/MCG.2014.106
NR 54
TC 2
Z9 2
U1 4
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1875-4791
EI 1875-4805
J9 INT J SOC ROBOT
JI Int. J. Soc. Robot.
PD APR
PY 2018
VL 10
IS 2
SI SI
BP 179
EP 198
DI 10.1007/s12369-017-0461-4
PG 20
WC Robotics
SC Robotics
GA GA8YY
UT WOS:000428628900002
DA 2019-02-18
ER

PT J
AU Menne, IM
   Schwab, F
AF Menne, Isabelle M.
   Schwab, Frank
TI Faces of Emotion: Investigating Emotional Facial Expressions Towards a
   Robot
SO INTERNATIONAL JOURNAL OF SOCIAL ROBOTICS
LA English
DT Article
DE Facial expression; Facial Action Coding System; Emotion; Emotional
   response; Empathy; Human-robot interaction
ID NEGATIVE AFFECT; BEHAVIOR; CONSEQUENCES; SCALES; PAIN
AB Emotions have always been an intriguing topic in everyday life as well as in science. As robots are starting to move from industry halls to our private homes, emotions have become a vital theme for the field of human-robot interaction. Since Darwin, research suggests facial expressions are associated with emotions. Facial expressions could provide an ideal tool for a natural, social human-robot interaction. Despite a growing body of research on the implementation of emotions in robots (mostly based on facial expressions), systematic research on users' emotions and facial expressions towards robots remains largely neglected (cf. Arkin and Moshkina in Calvo R, D'Mello S, Gratch J, Kappas A (eds) The Oxford handbook of affective computing. Oxford University Press, New York, pp 483-493, 2015 on challenges in effective testing in affective human-robot interaction). We experimentally investigated the multilevel phenomenon of emotions by using a multi-method approach. Since self-reports of emotions are prone to biases such as social desirability, we supplemented it by an objective behavioral measurement. By using the Facial Action Coding System we analyzed the facial expressions of 62 participants who watched the entertainment robot dinosaur Pleo either in a friendly interaction or being tortured. Participants differed in the type and frequency of Action Units displayed as well as in their self-reported feelings depending on the type of treatment they had watched (friendly or torture). In line with a previous study by Rosenthal-von der Putten et al. (Int J Soc Robot 5(1):17-34, 2013. https://doi.org/10.1007/s12369-012-0173-8), participants reported feeling more positive after the friendly video and more negative after the torture video. In the torture condition, participants furthermore showed a wide range of different Action Units primarily associated with negative emotions. For example, the Action Unit 4 ("Brow Lowerer") that is common in negative emotions such as anger and sadness was displayed more frequently in the torture condition than in the friendly condition. The Action Unit 12 ("Lip Corner Puller") however, an Action Unit commonly associated with joy, was present in both conditions and thus not necessarily predictive of positive emotions. The findings indicate the importance for a thorough investigation of the variables of emotional facial expressions. In investigating the Action Units participants display due to an emotional situation, we aim to provide information on spontaneous facial expressions towards a robot that could also serve as guidance for automatic approaches.
C1 [Menne, Isabelle M.] Univ Wurzburg, Dept Media Psychol, Wurzburg, Germany.
   [Schwab, Frank] Univ Wurzburg, Media Psychol, Wurzburg, Germany.
RP Menne, IM (reprint author), Univ Wurzburg, Dept Media Psychol, Wurzburg, Germany.
EM isabelle.menne@uni-wuerzburg.de
CR AMBADY N, 1992, PSYCHOL BULL, V111, P256, DOI 10.1037/0033-2909.111.2.256
   Arkin RC, 2015, OXFORD HDB AFFECTIVE, P483
   Austin EJ, 1998, PERS INDIV DIFFER, V24, P421, DOI 10.1016/S0191-8869(97)00175-X
   Bartneck C., 2005, P INT 2005 WORKSH AG
   Bartneck C, 2002, THESIS
   Bartneck C, 2008, INTERACT STUD, V9, P415, DOI 10.1075/is.9.3.04bar
   Becker-Asano C, 2011, 2011 IEEE WORKSH AFF
   Bethel CL, 2010, INT J SOC ROBOT, V2, P347, DOI 10.1007/s12369-010-0064-9
   Brave S, 2005, INT J HUM-COMPUT ST, V62, P161, DOI 10.1016/j.ijhcs.2004.11.002
   Breazeal C, 2003, INT J HUM-COMPUT ST, V59, P119, DOI 10.1016/S1071-5819(03)00018-1
   Breazeal C, 2002, INT J ROBOT RES, V21, P883, DOI 10.1177/0278364902021010096
   Canamero LD, 2002, SOCIALLY INTELLIGENT, P69
   Carroll JM, 1997, J PERS SOC PSYCHOL, V72, P164, DOI 10.1037/0022-3514.72.1.164
   Costa S, 2013, LECT NOTES ARTIF INT, V8239, P542, DOI 10.1007/978-3-319-02675-6_54
   CRAIG KD, 1991, PAIN, V46, P161, DOI 10.1016/0304-3959(91)90071-5
   Cramer H, 2010, ACMIEEE INT CONF HUM, P141, DOI 10.1109/HRI.2010.5453224
   DAVIS MH, 1983, J PERS SOC PSYCHOL, V44, P113, DOI 10.1037//0022-3514.44.1.113
   Del Giudice M, 2007, DEV PSYCHOL, V43, P796, DOI 10.1037/0012-1649.43.3.796
   Dimberg U, 1998, SCAND J PSYCHOL, V39, P39, DOI 10.1111/1467-9450.00054
   DIMBERG U, 1982, PSYCHOPHYSIOLOGY, V19, P643, DOI 10.1111/j.1469-8986.1982.tb02516.x
   EKMAN P, 1980, J PERS SOC PSYCHOL, V39, P1125, DOI 10.1037/h0077722
   EKMAN P, 1993, AM PSYCHOL, V48, P384, DOI 10.1037/0003-066X.48.4.384
   EKMAN P, 1982, J NONVERBAL BEHAV, V6, P238, DOI 10.1007/BF00987191
   Ekman P., 2005, WHAT FACE REVEALS
   Ekman P, 2002, FACIAL ACTION CODING
   Ekman P, 2003, UNMASKING FACE GUIDE
   Ekman P., 2002, FACS INVESTIGATORS G
   Ekman P, 1969, SEMIOTICA
   Endo N, 2008, 2008 IEEE INT C ROB
   Fan XT, 2006, FIELD METHOD, V18, P223, DOI 10.1177/152822X06289161
   Fasel B, 2003, PATTERN RECOGN, V36, P259, DOI 10.1016/S0031-3203(02)00052-3
   Friesen W., 1983, EMFACS 7 EMOTI UNPUB
   GROSS JJ, 1995, COGNITION EMOTION, V9, P87, DOI 10.1080/02699939508408966
   Haxby JV, 2000, TRENDS COGN SCI, V4, P223, DOI 10.1016/S1364-6613(00)01482-0
   Heerink M, 2010, VIRTUAL REAL-LONDON, V14, P77, DOI 10.1007/s10055-009-0142-1
   Hegel F, 2010, P 19 IEEE INT S ROB, P120, DOI DOI 10.1109/ROMAN.2010.5598691
   Kahn PH, 2012, DEV PSYCHOL, V48, P303, DOI 10.1037/a0027033
   Kappas A, 1998, PSYCHOPHYSIOLOGY, V35, pS44
   Kappas A, 2013, HANDB COMMUN SCI, V2, P131
   Larsen JT, 2003, PSYCHOPHYSIOLOGY, V40, P776, DOI 10.1111/1469-8986.00078
   LAZARUS RS, 1991, AM PSYCHOL, V46, P819, DOI 10.1037/0003-066X.46.8.819
   Lien JJJ, 2000, ROBOT AUTON SYST, V31, P131, DOI 10.1016/S0921-8890(99)00103-7
   Martinez B., 2016, ADV FACE DETECTION F, P63, DOI DOI 10.1007/978-3-319-25958-1_4
   Menne IM, 2016, LECT NOTES ARTIF INT, V9979, P372, DOI 10.1007/978-3-319-47437-3_36
   Mirnig N, 2015, INT J SOC ROBOT, V7, P63, DOI 10.1007/s12369-014-0261-z
   Ohman A, 2002, CURR DIR PSYCHOL SCI, V11, P62, DOI 10.1111/1467-8721.00169
   PRKACHIN KM, 1992, PAIN, V51, P297, DOI 10.1016/0304-3959(92)90213-U
   Reed LI, 2012, EVOL HUM BEHAV, V33, P200, DOI 10.1016/j.evolhumbehav.2011.09.003
   Reeves B., 1996, PEOPLE TREAT COMPUTE
   Ribeiro T, 2012, P 7 ANN ACM IEEE INT
   Riether N., 2013, THESIS
   Rosenthal-von der Putten AM, 2014, COMPUT HUM BEHAV, V33, P201, DOI 10.1016/j.chb.2014.01.004
   Rosenthal-von der Putten AM, 2013, INT J SOC ROBOT, V5, P17, DOI 10.1007/s12369-012-0173-8
   Russell J. A., 1997, PSYCHOL FACIAL EXPRE
   Sato W, 2007, COGNITION, V104, P1, DOI 10.1016/j.cognition.2006.05.001
   Scherer K. R., 2001, APPRAISAL PROCESSES
   Takahashi Y, 2008, 2008 INT C CONTR AUT
   Unz D. C., 2008, J MEDIA PSYCHOL, V20, P141, DOI DOI 10.1027/1864-1105.20.4.141
   WATSON D, 1988, J PERS SOC PSYCHOL, V54, P1063, DOI 10.1037//0022-3514.54.6.1063
   Wilcox Rand R, 2011, INTRO ROBUST ESTIMAT
   Woods S, 2006, 9 IEEE INT WORKSH AD
NR 61
TC 1
Z9 1
U1 9
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1875-4791
EI 1875-4805
J9 INT J SOC ROBOT
JI Int. J. Soc. Robot.
PD APR
PY 2018
VL 10
IS 2
SI SI
BP 199
EP 209
DI 10.1007/s12369-017-0447-2
PG 11
WC Robotics
SC Robotics
GA GA8YY
UT WOS:000428628900003
DA 2019-02-18
ER

PT J
AU Ojha, S
   Williams, MA
   Johnston, B
AF Ojha, Suman
   Williams, Mary-Anne
   Johnston, Benjamin
TI The Essence of Ethical Reasoning in Robot-Emotion Processing
SO INTERNATIONAL JOURNAL OF SOCIAL ROBOTICS
LA English
DT Article
DE Social robots; Computational emotion model; Believability; Ethical
   reasoning; Socially acceptable emotions; EEGS
ID DECISION-MAKING; MACHINE ETHICS; MODEL; AGENT
AB As social robots become more and more intelligent and autonomous in operation, it is extremely important to ensure that such robots act in socially acceptable manner. More specifically, if such an autonomous robot is capable of generating and expressing emotions of its own, it should also have an ability to reason if it is ethical to exhibit a particular emotional state in response to a surrounding event. Most existing computational models of emotion for social robots have focused on achieving a certain level of believability of the emotions expressed. We argue that believability of a robot's emotions, although crucially necessary, is not a sufficient quality to elicit socially acceptable emotions. Thus, we stress on the need of higher level of cognition in emotion processing mechanism which empowers social robots with an ability to decide if it is socially appropriate to express a particular emotion in a given context or it is better to inhibit such an experience. In this paper, we present the detailed mathematical explanation of the ethical reasoning mechanism in our computational model, EEGS, that helps a social robot to reach to the most socially acceptable emotional state when more than one emotions are elicited by an event. Experimental results show that ethical reasoning in EEGS helps in the generation of believable as well as socially acceptable emotions.
C1 [Ojha, Suman; Williams, Mary-Anne; Johnston, Benjamin] Univ Technol Sydney, CAI, Sydney, NSW, Australia.
RP Ojha, S (reprint author), Univ Technol Sydney, CAI, Sydney, NSW, Australia.
EM Suman.Ojha@student.uts.edu.au; Mary-Anne.Williams@uts.edu.au;
   Benjamin.Johnston@uts.edu.au
OI Ojha, Suman/0000-0003-4856-8335
FU University of Technology Sydney
FX This research was funded by the Research Scholarship provided by the
   University of Technology Sydney. There is no external funding associated
   with this research.
CR Alexander L., 2007, STANFORD ENCY PHILOS
   Allen C, 2000, J EXP THEOR ARTIF IN, V12, P251, DOI 10.1080/09528130050111428
   Allen C, 2006, IEEE INTELL SYST, V21, P12, DOI 10.1109/MIS.2006.83
   Anderson M, 2007, AI MAG, V28, P15
   Bartneck C., 2003, P 2003 INT C DES PLE, P55, DOI [10.1145/782896.782911, DOI 10.1145/782896.782911]
   Becker-Asano C., 2008, WASABI AFFECT SIMULA, V319
   Breazeal C, 2003, INT J HUM-COMPUT ST, V59, P119, DOI 10.1016/S1071-5819(03)00018-1
   CALLAHAN S, 1988, HASTINGS CENT REP, V18, P9, DOI 10.2307/3562196
   Dias Joao, 2014, Emotion Modeling. Towards Pragmatic Computational Models of Affective Processes. LNCS 8750, P44, DOI 10.1007/978-3-319-12973-0_3
   El-Nasr MS, 2000, AUTON AGENT MULTI-AG, V3, P219, DOI 10.1023/A:1010030809960
   Gaudine A, 2001, J BUS ETHICS, V31, P175, DOI 10.1023/A:1010711413444
   Gebhard P., 2005, P 4 INT JOINT C AUT, P29, DOI DOI 10.1145/1082473.1082478
   Gratch J., 2004, J COGNITIVE SYSTEMS, V5, P269, DOI DOI 10.1016/J.C0GSYS.2004.02.002
   Hooker J, 1996, 3 KINDS ETHICS
   ISEN AM, 1983, SOC COGNITION, V2, P18, DOI 10.1521/soco.1983.2.1.18
   Kopp S., 2003, KI KUNSTLICHE INTELL, V17, P11
   Lambie JA, 2002, PSYCHOL REV, V109, P219, DOI 10.1037//0033-295X.109.2.219
   Le Blanc AD, 1999, US Patent, Patent No. [5,977,968, 5977968]
   Marinier RP, 2007, P COGN SCI SOC, V29
   Marreiros G, 2010, IEEE INTELL SYST, V25, P31, DOI 10.1109/MIS.2010.46
   Marsella S., 2010, BLUEPRINT AFFECTIVE, P21
   Marsella SC, 2009, COGN SYST RES, V10, P70, DOI 10.1016/j.cogsys.2008.03.005
   Ojha S, 2017, ANN C ADV COGN SYST
   Ojha S., 2017, ANN M COGN SCI SOC
   Ojha S, 2016, LECT NOTES ARTIF INT, V9979, P233, DOI 10.1007/978-3-319-47437-3_23
   Ortony A., 1990, COGNITIVE STRUCTURE
   Padgham L, 1997, INT WORKSH INT AG SY
   Plutchik R., 1997, CIRCUMPLEX MODELS PE
   Quinton Anthony, 1973, UTILITARIAN ETHICS
   Reilly WN, 2006, S AG CONSTR EM
   Reilly WS, 1996, TECH REP
   Scherer Klaus R., 2001, APPRAISAL PROCESSES, V92, P57
   White J, 2015, RETHINKING MACHINE E
NR 33
TC 0
Z9 0
U1 8
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1875-4791
EI 1875-4805
J9 INT J SOC ROBOT
JI Int. J. Soc. Robot.
PD APR
PY 2018
VL 10
IS 2
SI SI
BP 211
EP 223
DI 10.1007/s12369-017-0459-y
PG 13
WC Robotics
SC Robotics
GA GA8YY
UT WOS:000428628900004
DA 2019-02-18
ER

PT J
AU Rossi, S
   Staffa, M
   Tamburro, A
AF Rossi, Silvia
   Staffa, Mariacarla
   Tamburro, Anna
TI Socially Assistive Robot for Providing Recommendations: Comparing a
   Humanoid Robot with a Mobile Application
SO INTERNATIONAL JOURNAL OF SOCIAL ROBOTICS
LA English
DT Article
DE Socially assistive robotics; Interfaces for recommendations; Non-verbal
   cues; Mobile applications
ID SYSTEMS; TRUST; MODEL
AB Socially assistive robotics has gained a valuable role in assisting, influencing and motivating the human behavior in many Human-Machine Interaction contexts. This finding suggested the use of social robots as recommendation interfaces. Despite many other types of recommending technologies exist (e.g., virtual agents, apps on cell phones, etc.), experimental studies convey that human beings result to be more engaged and influenced by the interaction with robots with respect to these other technologies. In particular, this has been shown by comparing social robots with virtual agents; a poor literature copes with the comparison between social robots and applications on mobile phones. To this extent, in this work, we address the comparison between these latest two technologies in the context of movie recommendation, where the two considered interfaces are programmed to provide the same contents, but through different communication channels. We provide the results of two experimental studies with the aim of evaluating the quality of the interaction from both the point of view of the application (by considering the users' acceptance rate of the recommendations) and of the users (by analyzing the users' evaluations) while interacting with the two interfaces. The main result arising from this study is that the social robot is preferred by users although, apparently, it does not change the acceptance rate of the proposed movies.
C1 [Rossi, Silvia; Tamburro, Anna] Univ Naples Federico II, Dept Phys, Naples, Italy.
   [Staffa, Mariacarla] Univ Naples Federico II, Dept Elect Engn & Informat Technol, Naples, Italy.
RP Rossi, S (reprint author), Univ Naples Federico II, Dept Phys, Naples, Italy.
EM silvia.rossi@unina.it
OI Rossi, Silvia/0000-0002-3379-1756
FU MIUR (Italian Ministry of Education, Universities, and Research) within
   the PRIN research project "UPA4SAR - User-centered Profiling and
   Adaptation for Socially Assistive Robotics" [2015KB-L78T]
FX This study was has been partially supported by MIUR (Italian Ministry of
   Education, Universities, and Research) within the PRIN 2015 research
   project "UPA4SAR - User-centered Profiling and Adaptation for Socially
   Assistive Robotics" (Grant no. 2015KB-L78T).
CR Alemi M, 2015, INT J SOC ROBOT, V7, P523, DOI 10.1007/s12369-015-0286-y
   Bader N., 2017, P 22 INT C INT US IN, P35
   Bainbridge WA, 2008, 2008 17TH IEEE INTERNATIONAL SYMPOSIUM ON ROBOT AND HUMAN INTERACTIVE COMMUNICATION, VOLS 1 AND 2, P701, DOI 10.1109/ROMAN.2008.4600749
   Bartneck C., 2010, J BEHAV ROBOTICS, V1, P109, DOI DOI 10.2478/S13230-010-0011-3
   Boone RT, 2003, J NONVERBAL BEHAV
   Cavallo F, 2012, GERONTECHNOLOGY, V11
   Cervone F, 2015, P 16 WORKSH OBJ AG C, P32
   Dautenhahn K, 2004, PRAGMAT COGN, V12, P1, DOI DOI 10.1075/PC.12.1.03DAU
   de Melo CM, 2009, P 9 INT C INT VIRT A
   Feil-Seifer D, 2005, INT C REHAB ROBOT, P465
   Ham Jaap, 2011, Social Robotics. Proceedings Third International Conference (ICSR 2011), P71, DOI 10.1007/978-3-642-25504-5_8
   Iengo S, 2014, IEEE INT CONF ROBOT, P4863, DOI 10.1109/ICRA.2014.6907571
   John OP, 2008, HDB PERSONALITY THEO, P114, DOI DOI 10.1037/0021-9010.87.3.530
   Johnson DO, 2014, INT J SOC ROBOT, V6, P195, DOI 10.1007/s12369-013-0217-8
   Junchao Xu, 2013, 2013 IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN), P533, DOI 10.1109/ROMAN.2013.6628534
   Kidd C. D., 2004, 2004 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) (IEEE Cat. No.04CH37566), P3559
   Konstan JA, 2012, USER MODEL USER-ADAP, V22, P101, DOI 10.1007/s11257-011-9112-x
   Lim A, 2012, DESIRE MODEL CROSS M, V74, P4
   Mataric MJ, 2017, SCI ROBOT, V2
   MCCRAE RR, 1987, J PERS SOC PSYCHOL, V52, P81, DOI 10.1037/0022-3514.52.1.81
   Merritt SM, 2008, HUM FACTORS, V50, P194, DOI 10.1518/001872008X288574
   Murphy-Hill E., 2014, RECOMMENDATION SYSTE, P223
   Posner J, 2005, DEV PSYCHOPATHOL, V17, P715, DOI 10.1017/S0954579405050340
   Powers A., 2007, 2007 2nd Annual Conference on Human-Robot Interaction (HRI), P145
   Qiu LY, 2009, J MANAGE INFORM SYST, V25, P145, DOI 10.2753/MIS0742-1222250405
   Rossi Silvia, 2016, ICAART 2016. 8th International Conference on Agents and Artificial Intelligence. Proceedings, P38
   Rossi S, 2017, PATTERN RECOGN LETT, V99, P3, DOI [10.1016/j.patrec.2017.06.002, 10.1016/patrec.2017.06.002]
   Rossi S, 2015, 2015 24TH IEEE INTERNATIONAL SYMPOSIUM ON ROBOT AND HUMAN INTERACTIVE COMMUNICATION (RO-MAN), P791, DOI 10.1109/ROMAN.2015.7333652
   Salichs MA, 2016, INT J SOC ROBOT, V8, P85, DOI 10.1007/s12369-015-0319-6
   Shinozawa K, 2005, INT J HUM-COMPUT ST, V62, P267, DOI 10.1016/j.ijhcs.2004.11.003
   Shiomi M, 2013, INT J SOC ROBOT, V5, P251, DOI 10.1007/s12369-013-0180-4
   Sichao Song, 2017, 2017 12th ACM/IEEE International Conference on Human-Robot Interaction (HRI), P2, DOI 10.1145/2909824.3020239
   Staffa M., 2014, 22 EUR S ART NEUR NE, P511
   Staffa M, 2016, LECT NOTES ARTIF INT, V9979, P200, DOI 10.1007/978-3-319-47437-3_20
   Tapus A., 2008, INTELLIGENT SERVICE, V1, P169, DOI DOI 10.1007/S11370-008-0017-4
   Tkalcic M, 2015, PERSONALITY RECOMMEN, P715
   Wang YD, 2005, COMPUT HUM BEHAV, V21, P105, DOI 10.1016/j.chb.2003.11.008
   Yoo KH, 2011, RECOMMENDER SYSTEMS HANDBOOK, P455, DOI 10.1007/978-0-387-85820-3_14
NR 38
TC 0
Z9 0
U1 3
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1875-4791
EI 1875-4805
J9 INT J SOC ROBOT
JI Int. J. Soc. Robot.
PD APR
PY 2018
VL 10
IS 2
SI SI
BP 265
EP 278
DI 10.1007/s12369-018-0469-4
PG 14
WC Robotics
SC Robotics
GA GA8YY
UT WOS:000428628900008
DA 2019-02-18
ER

PT J
AU Obaid, M
   Baykal, GE
   Yantac, AE
   Barendregt, W
AF Obaid, Mohammad
   Baykal, Gokce Elif
   Yantac, Asim Evren
   Barendregt, Wolmet
TI Developing a Prototyping Method for Involving Children in the Design of
   Classroom Robots
SO INTERNATIONAL JOURNAL OF SOCIAL ROBOTICS
LA English
DT Article
DE Classroom robots; Prototyping; Design; Toolkit; Children
ID EXAMPLES
AB Including children in the design of technologies that will have an impact on their daily lives is one of the pillars of user-centered design. Educational robots are an example of such a technology where children's involvement is important. However, the form in which this involvement should take place is still unclear. Children do not have a lot of experience with educational robots yet, while they do have some ideas of what robot could be like from popular media, such as BayMax from the Big Hero 6 movie. In this paper we describe two pilot studies to inform the development of an elicitation method focusing on form factors; a first study in which we have asked children between 8 and 15 years old to design their own classroom robot using a toolkit, the Robo2Box, and a second study where we have compared the use of the Robo2Box toolkit and clay as elicitation methods. We present the results of the two studies, and discuss the implications of the outcomes to inform further development of the Robo2Box for prototyping classroom robots by children.
C1 [Obaid, Mohammad] Uppsala Univ, Dept Informat Technol, Uppsala, Sweden.
   [Baykal, Gokce Elif] Koc Univ, Design Technol & Soc Program, Istanbul, Turkey.
   [Yantac, Asim Evren] Koc Univ, KUAR, Media & Visual Arts Dept, Istanbul, Turkey.
   [Barendregt, Wolmet] Univ Gothenburg, Dept Appl IT, Gothenburg, Sweden.
RP Obaid, M (reprint author), Uppsala Univ, Dept Informat Technol, Uppsala, Sweden.
EM mohammad.obaid@it.uu.se; gbaykal13@ku.edu.tr; eyantac@ku.edu.tr;
   wolmet.barendregt@ait.gu.se
OI Barendregt, Wolmet/0000-0003-0730-7286
FU Swedish Research Council [2015-04378]; COIN Project - Swedish Foundation
   for Strategic Research [RIT15-0133]
FX The work was partly supported by the Swedish Research Council (Grant no.
   2015-04378) and the COIN Project (RIT15-0133) funded by the Swedish
   Foundation for Strategic Research.
CR Barker BS, 2007, J RES TECHNOL EDUC, V39, P229, DOI 10.1080/15391523.2007.10782481
   Sandoval EB, 2012, ACMIEEE INT CONF HUM, P107
   Bumby K, 1999, P CT99 3 INT COGN TE, P391
   Chu SL, 2014, P 2014 C INT DES CHI, P329
   Druin A, 2002, BEHAV INFORM TECHNOL, V21, P1, DOI [10.1080/01449290110108659, 10.1080/014492901101008659]
   Garzotto F., 2008, P 7 INT C INT DES CH, P186, DOI DOI 10.1145/1463689.1463755
   Goodrich Michael A, 2007, Foundations and Trends in Human-Computer Interaction, V1, P203, DOI 10.1561/1100000005
   Lee HR, 2014, ACMIEEE INT CONF HUM, P17, DOI 10.1145/2559636.2559676
   Marsh RL, 1996, MEM COGNITION, V24, P669, DOI 10.3758/BF03201091
   Mubin O., 2013, TECHNOLOGY ED LEARNI, V1, P209, DOI DOI 10.2316/J0URNAL.209.2013.1.209-0015
   Obaid M, 2015, LECT NOTES ARTIF INT, V9388, P502, DOI 10.1007/978-3-319-25554-5_50
   Rogers C., 2004, J STEM ED, V5, P17
   Scaife M, 1998, DESIGN CHILDRENS TEC, P27
   Sciutti A, 2014, IEEE ROMAN, P567, DOI 10.1109/ROMAN.2014.6926313
   Shin N, 2007, P 16 IEEE INT S ROB, P1040
   SMITH SM, 1993, MEM COGNITION, V21, P837, DOI 10.3758/BF03202751
   Vaajakallio K., 2009, P INT DES CHILDR IDC, P246
   Van Mechelen M, 2015, P 14 INT C INT DES C, P219, DOI DOI 10.1145/2771839.2771862
   Benitti FBV, 2012, COMPUT EDUC, V58, P978, DOI 10.1016/j.compedu.2011.10.006
   Woods S, 2005, 2005 IEEE International Workshop on Robot and Human Interactive Communication (RO-MAN), P384
   Woods S, 2006, INTERACT COMPUT, V18, P1390, DOI 10.1016/j.intcom.2006.05.001
   Zhu K, 2013, P SIGCHI C HUM FACT, P661
NR 22
TC 1
Z9 1
U1 3
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1875-4791
EI 1875-4805
J9 INT J SOC ROBOT
JI Int. J. Soc. Robot.
PD APR
PY 2018
VL 10
IS 2
SI SI
BP 279
EP 291
DI 10.1007/s12369-017-0450-7
PG 13
WC Robotics
SC Robotics
GA GA8YY
UT WOS:000428628900009
OA Other Gold
DA 2019-02-18
ER

PT J
AU Olson, DL
   Johansson, B
   De Carvalho, RA
AF Olson, David L.
   Johansson, Bjorn
   De Carvalho, Rogerio Atem
TI Open source ERP business model framework
SO ROBOTICS AND COMPUTER-INTEGRATED MANUFACTURING
LA English
DT Article
DE Business models; Enterprise resource planning (ERP); Evaluation; Open
   source
ID OPEN SOURCE SOFTWARE; ENTERPRISE; COMPETITION; TECHNOLOGY; SYSTEMS;
   IMPACT
AB ERP systems became popular with large organizations in the 1990s. in the 21st Century, these products were expanded by addition of supply chain management (SCM) and customer relationship management (CRM), as well as access through the Web, creating the ERP II concept. Efforts to increase the market led vendors to Serve not only large organizations, but also focus more on small-to-medium sized enterprises (SMEs).
   Open source software has become a player in the field of enterprise resource planning (ERP) systems. While it is still unclear to what extent it has diffused among organizations, it is clear that opportunities exist. New ways of delivering ERP software, such as software as a service (SaaS) have appeared. Some smaller vendors utilized a free distribution system (Free/Open Source ERP, FOS-ERP) for their source code, relying on various business models for corporate success. There also have been attempts to generate FOS-ERP components found on sites such as SourceForge.com that are not only distributed freely, but also were developed through community participation much as Linux has been developed. Some ERP vendors use community developed components for various purposes to support their proprietorial software. Thus one dimension of ERP systems is based Upon who directs the development process. Proprietorial ERP refers to systems with closely held intellectual property rights, such as the leading market products by SAP and Oracle as well as many smaller proprietorial competitors. FOS-ERP can be community based, or sponsored by some organization.
   In this paper we present a framework that aims at analyzing FOS-ERP business models. Goals include discussing the differences between FOS-ERP and their proprietary equivalents (P-ERP) in terms of business models, selection, customization, and evolution. We Will discuss challenges and opportunities that they offer to adopters and vendors. (C) 2015 Elsevier Ltd. All rights reserved.
C1 [Olson, David L.] Univ Nebraska, CBA 209, Lincoln, NE 68588 USA.
   [Johansson, Bjorn] Lund Univ, Dept Informat, Sch Econ & Management, Lund, Sweden.
   [De Carvalho, Rogerio Atem] Fed Ctr Technol Educ Campos, R Dr Siqueira 273, BR-28030130 Campos, RJ, Brazil.
RP Olson, DL (reprint author), Univ Nebraska, CBA 209, Lincoln, NE 68588 USA.
EM Dolson3@unl.edu; bjorn.johansson@ics.lu.se; ratem@iff.edu.br
CR de Carvalho RA, 2006, INT FED INFO PROC, P667
   Babcock C., 2009, INFORMATIONWEEK, V18
   Baharum Z, 2009, 2009 THIRD ASIA INTERNATIONAL CONFERENCE ON MODELLING & SIMULATION, VOLS 1 AND 2, P419, DOI 10.1109/AMS.2009.96
   Benkler Y, 2006, WEALTH NETWORKS SOCI
   Bonaccorsi A, 2006, MANAGE SCI, V52, P1085, DOI 10.1287/mnsc.1060.0547
   Cereola SJ, 2012, BEHAV INFORM TECHNOL, V31, P889, DOI 10.1080/0144929X.2010.528029
   Conry-Murray Andrew, 2009, InformationWEEK, P23
   Davenport TH, 1998, HARVARD BUS REV, V76, P121
   Dorner C, 2009, IEEE SOFTWARE, V26, P45, DOI 10.1109/MS.2009.127
   Dreiling A., 2005, P 38 ANN HAW INT C S
   Economides N, 2006, MANAGE SCI, V52, P1057, DOI 10.1287/mnsc.1060.0549
   Fleisher CS, 2008, EUR J MARKETING, V42, P852, DOI 10.1108/03090560810877196
   Grewal R, 2006, MANAGE SCI, V52, P1043, DOI 10.1287/mnsc.1060.0550
   Jaisingh J, 2008, J MANAGE INFORM SYST, V25, P241, DOI 10.2753/MIS0742-1222250307
   Johansson B, 2008, J ENTERP INF MANAG, V21, P649, DOI 10.1108/17410390810911230
   Johansson B, 2009, INT FED INFO PROC, V299, P143
   Kane D, 2009, J INVEST, V18, P92, DOI 10.3905/JOI.2009.18.1.092
   Karimi J, 2007, J MANAGE INFORM SYST, V24, P101, DOI 10.2753/MIS0742-1222240103
   Kazman R, 2009, COMMUN ACM, V52, P76, DOI 10.1145/1538788.1538808
   Kim H.M., 2008, FRAMEWORK EVALUATING
   Lee D, 2008, PROD OPER MANAG, V17, P12, DOI 10.3401/poms.1070.0005
   Lee SM, 2009, ENTERP INF SYST-UK, V3, P201, DOI 10.1080/17517570902777624
   Leina Z., 2008, DEV IMPLEMENTATION E
   Osterwalder A, 2005, COMMUN ASSOC INF SYS, V16
   Paulson JW, 2004, IEEE T SOFTWARE ENG, V30, P246, DOI 10.1109/TSE.2004.1274044
   Poba-Nzaou P, 2011, J INF TECHNOL, V26, P170, DOI 10.1057/jit.2010.34
   Raymond E. S., 1999, CATHEDRAL BAZAAR MUS
   RedHat, 2009, THE PERF STORM
   Santosus M., 2006, EWEEK
   Sen R, 2007, J MANAGE INFORM SYST, V24, P233, DOI 10.2753/MIS0742-1222240107
   Serrano N, 2006, IEEE SOFTWARE, V23, P94, DOI 10.1109/MS.2006.78
   Smets-Solanes J.-P., 2003, IT Professional, V5, P38, DOI 10.1109/MITP.2003.1216231
   Stoilov T., 2008, P INT C COMP SYST TE
   Watson RT, 2008, COMMUN ACM, V51, P41, DOI 10.1145/1330311.1330321
   Watts CA, 2008, INT J OPER PROD MAN, V28, P1219, DOI 10.1108/01443570810919378
   Weber S, 2005, SUCCESS OPEN SOURCE
   West J., 2005, P 38 ANN HAW INT C S
NR 37
TC 0
Z9 0
U1 8
U2 97
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0736-5845
EI 1879-2537
J9 ROBOT CIM-INT MANUF
JI Robot. Comput.-Integr. Manuf.
PD APR
PY 2018
VL 50
BP 30
EP 36
DI 10.1016/j.rcim.2015.09.007
PG 7
WC Computer Science, Interdisciplinary Applications; Engineering,
   Manufacturing; Robotics
SC Computer Science; Engineering; Robotics
GA FR9VG
UT WOS:000419420600003
DA 2019-02-18
ER

PT J
AU Borenstein, J
   Wagner, AR
   Howard, A
AF Borenstein, Jason
   Wagner, Alan R.
   Howard, Ayanna
TI Overtrust of Pediatric Health-Care Robots A Preliminary Survey of Parent
   Perspectives
SO IEEE ROBOTICS & AUTOMATION MAGAZINE
LA English
DT Article
ID AUTOMATION BIAS; CHILDREN; BURDEN
C1 [Borenstein, Jason] Georgia Inst Technol, Sch Publ Policy, Ctr Eth & Technol, Atlanta, GA 30332 USA.
   [Borenstein, Jason] Georgia Inst Technol, Off Grad Studies, Ctr Eth & Technol, Atlanta, GA 30332 USA.
   [Wagner, Alan R.] Penn State Univ, Rock Eth Inst, State College, University Pk, PA 16802 USA.
   [Howard, Ayanna] Georgia Inst Technol, Sch Interact Comp, Inst Robot & Intelligent Machines, Atlanta, GA 30332 USA.
RP Borenstein, J (reprint author), Georgia Inst Technol, Sch Publ Policy, Ctr Eth & Technol, Atlanta, GA 30332 USA.; Borenstein, J (reprint author), Georgia Inst Technol, Off Grad Studies, Ctr Eth & Technol, Atlanta, GA 30332 USA.
EM borenstein@gatech.edu; alan.r.wagner@psu.edu; ah260@gatech.edu
FU Linda J. and Mark C. Smith Endowed Chair in Bioengineering at the
   Georgia Institute of Technology
FX Partial support for this research was provided by the Linda J. and Mark
   C. Smith Endowed Chair in Bioengineering at the Georgia Institute of
   Technology. The authors would like to acknowledge the contributions of
   Yvette Pearson, Ph.D., Old Dominion University; Rebecca D. Pentz, Ph.
   D., Emory University; and Carol Thurman, Ph.D., Georgia Institute of
   Technology, each of whom reviewed a draft version of the survey.
CR Borenstein J, 2017, ROBOT ETHICS 2 0
   Brutsch K., 2010, J NEUROENG REHABILIT, V7
   Centers for Disease Control and Prevention, 2016, CER PALS CP DAT STAT
   Children's Healthcare of Atlanta, 2017, SURV IM
   Christensen HI, 2013, ROADMAP US ROBOTICS
   Cioi D., 2011, P IEEE INT C REH ROB
   Coxworth B., 2015, REWALK ROBOTICS ANNO
   Cyberdyne, 2017, WHATS HAL WORLDS 1 C
   Cyberdyne, 2017, HAL FIT
   Dunn ME, 2001, COMMUNITY MENT HLT J, V37, P39, DOI 10.1023/A:1026592305436
   Eveleth Rose, 2015, ATLANTIC
   Goddard K, 2012, J AM MED INFORM ASSN, V19, P121, DOI 10.1136/amiajnl-2011-000089
   Hartwig M., 2014, MODERN HAND ARM REHA
   Howard A., 2013, 26 INT FLOR ART INT
   Howard A., 2018, ENCY MED ROBOTICS, V4
   Kahn P. H., 2004, 47CHI EXT ABSTR HUM, P1499
   Lee JD, 2004, HUM FACTORS, V46, P50, DOI 10.1518/hfes.46.1.50.30392
   Maes B, 2003, J INTELL DISABIL RES, V47, P447, DOI 10.1046/j.1365-2788.2003.00513.x
   Martin R., 2010, GIZMAG
   Mirelman A, 2010, GAIT POSTURE, V31, P433, DOI 10.1016/j.gaitpost.2010.01.016
   Parasuraman R, 1997, HUM FACTORS, V39, P230, DOI 10.1518/001872097778543886
   Povyakalo AA, 2013, MED DECIS MAKING, V33, P98, DOI 10.1177/0272989X12465490
   ReWalk, 2017, WHAT IS REWALK
   Robinette P., 2017, AUTONOMY ARTIFICIAL
   Sharkey N, 2010, INTERACT STUD, V11, P161, DOI 10.1075/is.11.2.o1sha
   Simonsen Jesper, 2012, ROUTLEDGE INT HDB PA
   Skitka LJ, 1999, INT J HUM-COMPUT ST, V51, P991, DOI 10.1006/ijhc.1999.0252
   Smith PJ, 1997, IEEE T SYST MAN CY A, V27, P360, DOI 10.1109/3468.568744
   Spanish National Research Council, 2016, WORLDS 1 CHILD EX PI
   Townsend V., 2014, P ASME INT MECH ENG, V14, DOI [10.1115/IMECE2014-38492, DOI 10.1115/IMECE2014-38492]
   Wade SL, 1998, PEDIATRICS, V102, P110, DOI 10.1542/peds.102.1.110
   Yamagishi T., 2001, TRUST SOC, V2, P121
   Yamagishi Toshio, 1999, ASIAN J SOC PSYCHOL, V2, P145, DOI DOI 10.1111/1467-839X.00030
NR 33
TC 2
Z9 2
U1 1
U2 1
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1070-9932
EI 1558-223X
J9 IEEE ROBOT AUTOM MAG
JI IEEE Robot. Autom. Mag.
PD MAR
PY 2018
VL 25
IS 1
BP 46
EP 54
DI 10.1109/MRA.2017.2778743
PG 9
WC Automation & Control Systems; Robotics
SC Automation & Control Systems; Robotics
GA FZ2QW
UT WOS:000427426900010
DA 2019-02-18
ER

PT J
AU Ghalamzan, EAM
   Ragaglia, M
AF Ghalamzan, Amir M. E.
   Ragaglia, Matteo
TI Robot learning from demonstrations: Emulation learning in environments
   with moving obstacles
SO ROBOTICS AND AUTONOMOUS SYSTEMS
LA English
DT Article
DE Robot learning from demonstration; Dynamic environment; Moving obstacles
ID MOVEMENT PRIMITIVES; IMITATION; PRINCIPLES; AVOIDANCE; ROUTE; MODEL;
   TASK
AB In this paper, we present an approach to the problem of Robot Learning from Demonstration (RLfD) in a dynamic environment, i.e. an environment whose state changes throughout the course of performing a task. RLfD mostly has been successfully exploited only in non-varying environments to reduce the programming time and cost, e.g. fixed manufacturing workspaces. Non-conventional production lines necessitate Human-Robot Collaboration (HRC) implying robots and humans must work in shared workspaces. In such conditions, the robot needs to avoid colliding with the objects that are moved by humans in the workspace. Therefore, not only is the robot: (i) required to learn a task model from demonstrations; but also, (ii) must learn a control policy to avoid a stationary obstacle. Furthermore, (iii) it needs to build a control policy from demonstration to avoid moving obstacles. Here, we present an incremental approach to RLfD addressing all these three problems. We demonstrate the effectiveness of the proposed RLfD approach, by a series of pick-and-place experiments by an ABB YuMi robot. The experimental results show that a person can work in a workspace shared with a robot where the robot successfully avoids colliding with him. (C) 2018 Elsevier B.V. All rights reserved.
C1 [Ghalamzan, Amir M. E.] Univ Birmingham, Birmingham B15 2TT, W Midlands, England.
   [Ragaglia, Matteo] Yanmar R&D Europe, Viale Galileo 3-A, I-50125 Florence, Italy.
RP Ghalamzan, EAM (reprint author), Univ Birmingham, Birmingham B15 2TT, W Midlands, England.
EM a.ghalamzanesfahani@bham.ac.uk
OI Ragaglia, Matteo/0000-0002-7216-3664
CR Abbeel P., 2004, P 21 INT C MACH LEAR, P1
   Argall BD, 2009, ROBOT AUTON SYST, V57, P469, DOI 10.1016/j.robot.2008.10.024
   Billard A., 2008, SURVEY ROBOT PROGRAM
   Billard AG, 2016, SPRINGER HANDBOOK OF ROBOTICS, P1995
   Byravan A, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1874
   Calinon S., 2009, ROBOT PROGRAMMING DE
   Calinon S, 2010, IEEE INT C INT ROBOT, P249, DOI 10.1109/IROS.2010.5648931
   Fajen BR, 2003, J EXP PSYCHOL HUMAN, V29, P343, DOI 10.1037/0096-1523.29.2.343
   Flanagan JR, 2003, CURR BIOL, V13, P146, DOI 10.1016/S0960-9822(03)00007-1
   Gams A, 2015, IEEE-RAS INT C HUMAN, P304, DOI 10.1109/HUMANOIDS.2015.7363559
   Ghalamzan EAM, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P907, DOI 10.1109/IROS.2016.7759158
   Ghalamzan AM, 2015, IEEE INT CONF ROBOT, P5616, DOI 10.1109/ICRA.2015.7139985
   Gu S., 2016, ARXIV161000633
   Guenter F, 2007, ADV ROBOTICS, V21, P1521
   Hoffmann H., 2009, P IEEE INT C ROB AUT, P2587, DOI DOI 10.1109/ROBOT.2009.5152423
   Kalakrishnan M., 2011, 2011 IEEE International Conference on Robotics and Automation (ICRA 2011), P4569, DOI 10.1109/ICRA.2011.5980280
   Karaman S., 2010, ROBOTICS SCI SYSTEMS, V104
   Kober J, 2012, AUTON ROBOT, V33, P361, DOI 10.1007/s10514-012-9290-3
   Kormushev P, 2010, IEEE INT C INT ROBOT, P3232, DOI 10.1109/IROS.2010.5649089
   Krug R, 2015, J INTELL ROBOT SYST, V77, P17, DOI 10.1007/s10846-014-0100-3
   Levine S, 2016, J MACH LEARN RES, V17
   Maeda G., 2017, INT J ROBOTICS RES
   Miller R. B, 1968, P AFIPS FALL JOINT C, V33, P267, DOI DOI 10.1145/1476589.1476628
   Ng A. Y., 2000, P 17 INT C MACH LEAR, P663, DOI DOI 10.2460/AJVR.67.2.323
   Park DH, 2008, IEEE-RAS INT C HUMAN, P91, DOI 10.1109/ICHR.2008.4755937
   Pastor Peter, 2009, P IEEE INT C ROB AUT, P763, DOI DOI 10.1109/ROBOT.2009.5152385
   Powell Michael J. D., 1994, ADV OPTIMIZATION NUM, P51, DOI DOI 10.1007/978-94-015-8330-5_4
   Rai A., 2016, ARXIV161003557
   Rai A, 2014, IEEE-RAS INT C HUMAN, P512, DOI 10.1109/HUMANOIDS.2014.7041410
   Ratliff ND, 2009, P IEEE INT C ROB AUT, P489, DOI DOI 10.1109/ROBOT.2009.5152817
   Schaal S, 1999, TRENDS COGN SCI, V3, P233, DOI 10.1016/S1364-6613(99)01327-3
   Schmidt M., 2010, THESIS
   Tanner W. R., 1981, IND ROBOTS FUNDAMENT
   Tanwani AK, 2016, IEEE ROBOT AUTOM LET, V1, P235, DOI 10.1109/LRA.2016.2517825
   Thompson DE, 2004, DEV PSYCHOL, V40, P882, DOI 10.1037/0012-1649.40.5.882
   Thoroughman KA, 2000, NATURE, V407, P742
   Todorov E, 2004, NAT NEUROSCI, V7, P907, DOI 10.1038/nn1309
   Wheeler DS, 2002, 2ND INTERNATIONAL CONFERENCE ON DEVELOPMENT AND LEARNING, PROCEEDINGS, P197, DOI 10.1109/DEVLRN.2002.1011865
   WHITEN A, 1992, ADV STUD BEHAV, V21, P239, DOI 10.1016/S0065-3454(08)60146-1
   Whiten A, 2009, PHILOS T R SOC B, V364, P2417, DOI 10.1098/rstb.2009.0069
   Wolpert DM, 2011, NAT REV NEUROSCI, V12, P739, DOI 10.1038/nrn3112
   Ziebart B.D., 2008, AAAI, P1433
NR 42
TC 1
Z9 1
U1 4
U2 13
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0921-8890
EI 1872-793X
J9 ROBOT AUTON SYST
JI Robot. Auton. Syst.
PD MAR
PY 2018
VL 101
BP 45
EP 56
DI 10.1016/j.robot.2017.12.001
PG 12
WC Automation & Control Systems; Computer Science, Artificial Intelligence;
   Robotics
SC Automation & Control Systems; Computer Science; Robotics
GA GA0MT
UT WOS:000428009100004
DA 2019-02-18
ER

PT J
AU Jamone, L
   Ugur, E
   Cangelosi, A
   Fadiga, L
   Bernardino, A
   Piater, J
   Santos-Victor, J
AF Jamone, Lorenzo
   Ugur, Emre
   Cangelosi, Angelo
   Fadiga, Luciano
   Bernardino, Alexandre
   Piater, Justus
   Santos-Victor, Jose
TI Affordances in Psychology, Neuroscience, and Robotics: A Survey
SO IEEE TRANSACTIONS ON COGNITIVE AND DEVELOPMENTAL SYSTEMS
LA English
DT Article
DE Affordances; cognitive system and development; ecological perception;
   embodied cognition; learning skills; robots with development
ID OBJECT-ACTION-COMPLEXES; PRIMATE VISUAL-CORTEX; PREMOTOR CORTEX; AREA
   F5; PERCEIVING AFFORDANCES; MACAQUE MONKEY; FUNCTIONAL-ORGANIZATION;
   COMPUTATIONAL MODEL; LEARNED AFFORDANCES; SCALED INFORMATION
AB The concept of affordances appeared in psychology during the late 60s as an alternative perspective on the visual perception of the environment. It was revolutionary in the intuition that the way living beings perceive the world is deeply influenced by the actions they are able to perform. Then, across the last 40 years, it has influenced many applied fields, e.g., design, human-computer interaction, computer vision, and robotics. In this paper, we offer a multidisciplinary perspective on the notion of affordances. We first discuss the main definitions and formalizations of the affordance theory, then we report the most significant evidence in psychology and neuroscience that support it, and finally we review the most relevant applications of this concept in robotics.
C1 [Jamone, Lorenzo; Bernardino, Alexandre; Santos-Victor, Jose] Inst Super Tecn, Inst Sistemas & Robot, P-1049001 Lisbon, Portugal.
   [Ugur, Emre] Bogazici Univ, TR-34342 Istanbul, Turkey.
   [Ugur, Emre; Piater, Justus] Univ Innsbruck, A-6020 Innsbruck, Austria.
   [Cangelosi, Angelo] Univ Plymouth, Plymouth PL4 8AA, Devon, England.
   [Fadiga, Luciano] Ist Italiano Tecnol, I-16163 Genoa, Italy.
   [Fadiga, Luciano] Univ Ferrara, Physiol, I-44121 Ferrara, Italy.
RP Jamone, L (reprint author), Inst Super Tecn, Inst Sistemas & Robot, P-1049001 Lisbon, Portugal.
EM ljamone@isr.tecnico.ulisboa.pt; emre.ugur@boun.edu.tr;
   a.cangelosi@plymouth.ac.uk; luciano.fadig@iit.it;
   alex@isr.tecnico.ulisboa.pt; justus.piater@uibk.ac.at;
   jasv@isr.tecnico.ulisboa.pt
OI Cangelosi, Angelo/0000-0002-4709-2243; Jamone,
   Lorenzo/0000-0002-1521-6168
FU EU Project POETICON++ [FP7-ICT-288382]; EU Project LIMOMAN
   [PIEF-GA-2013-628315]; EU Project SQUIRREL [FP7-ICT-270273]
FX This work was supported in part by the EU Projects POETICON++ under
   Grant FP7-ICT-288382, in part by the LIMOMAN under Grant
   PIEF-GA-2013-628315, and in part by the SQUIRREL under Grant
   FP7-ICT-270273.
CR Adolph K. E., 2015, INT ENCY SOCIAL BEHA, V10, P127, DOI DOI 10.1016/B978-0-08-097086-8.23096-1
   ALOIMONOS J, 1987, INT J COMPUT VISION, V1, P333
   Ambrosini E, 2013, EXP BRAIN RES, V229, P197, DOI 10.1007/s00221-013-3607-0
   Antunes A, 2016, IEEE INT CONF ROBOT, P5449, DOI 10.1109/ICRA.2016.7487757
   ARBIB MA, 1985, HUM NEUROBIOL, V4, P63
   Arie H, 2009, NEW MATH NAT COMPUT, V5, P307, DOI 10.1142/S1793005709001283
   Arkin R. C, 1998, BEHAV BASED ROBOTICS
   Atil I., 2010, P 10 INT C EP ROB, P11
   BAJCSY R, 1988, P IEEE, V76, P996
   Bartoli E, 2014, NEUROPSYCHOLOGIA, V61, P335, DOI 10.1016/j.neuropsychologia.2014.06.025
   Bates E., 2014, EMERGENCE SYMBOLS CO
   Berlyne D. E, 1960, CONFLICT AROUSAL CUR
   Bermudez J. L, 2014, COGNITIVE SCI INTRO
   Bernshtein N.A, 1967, COORDINATION REGULAT
   Bicchi A., 2000, Proceedings 2000 ICRA. Millennium Conference. IEEE International Conference on Robotics and Automation. Symposia Proceedings (Cat. No.00CH37065), P348, DOI 10.1109/ROBOT.2000.844081
   Bohg J, 2014, IEEE T ROBOT, V30, P289, DOI 10.1109/TRO.2013.2289018
   Bourgeois KS, 2005, INFANCY, V8, P233, DOI 10.1207/s15327078in0803_3
   Brand RJ, 2002, DEVELOPMENTAL SCI, V5, P72, DOI 10.1111/1467-7687.00211
   Bremner J. G., 1988, INFANCY
   Brochier T, 2007, CURR OPIN NEUROBIOL, V17, P637, DOI 10.1016/j.conb.2007.12.002
   Brooks R. A., 1990, Robotics and Autonomous Systems, V6, P3, DOI 10.1016/S0921-8890(05)80025-9
   Bub DN, 2010, J EXP PSYCHOL HUMAN, V36, P341, DOI 10.1037/a0017606
   Buccino G, 2009, NEUROPSYCHOLOGIA, V47, P3074, DOI 10.1016/j.neuropsychologia.2009.07.003
   BUSHNELL EW, 1993, CHILD DEV, V64, P1005, DOI 10.2307/1131323
   Caiani SZ, 2014, PHENOMENOL COGN SCI, V13, P275, DOI 10.1007/s11097-013-9295-1
   Cakmak M., 2007, P 7 INT C EP ROB EPI
   Caligiore D, 2013, PSYCHOL RES-PSYCH FO, V77, P7, DOI 10.1007/s00426-012-0424-1
   Caligiore D, 2010, PSYCHOL REV, V117, P1188, DOI 10.1037/a0020887
   Cangelosi A., 2015, DEV ROBOTICS BABIES
   Cangelosi A, 2010, IEEE T AUTON MENT DE, V2, P167, DOI 10.1109/TAMD.2010.2053034
   Cardellicchio P, 2013, SOC COGN AFFECT NEUR, V8, P455, DOI 10.1093/scan/nss017
   Cardellicchio P, 2011, NEUROPSYCHOLOGIA, V49, P1369, DOI 10.1016/j.neuropsychologia.2011.01.021
   Carpenter M., 1998, MONOGR SOC RES CHILD, V63, P1, DOI DOI 10.2307/1166214
   Casby M. W., 2003, COMMUNICATION DISORD, V24, P163, DOI DOI 10.1177/15257401030240040201
   Celikkanat H, 2015, IEEE T AUTON MENT DE, V7, P92, DOI 10.1109/TAMD.2015.2418678
   Chang WC, 2014, INT C ADV MECH SYST, P469, DOI [10.1109/DEVLRN.2014.6983025, 10.1109/ICAMechS.2014.6911591]
   Chemero A, 2003, ECOL PSYCHOL, V15, P181, DOI 10.1207/S15326969ECO1502_5
   Chemero A, 2000, ECOL PSYCHOL, V12, P37, DOI 10.1207/S15326969ECO1201_3
   Chemero A, 2007, ADAPT BEHAV, V15, P473, DOI 10.1177/1059712307085098
   Cisek P, 2010, ANNU REV NEUROSCI, V33, P269, DOI 10.1146/annurev.neuro.051508.135409
   Clark A., 1997, BEING THERE PUTTING
   COLLETT T, 1977, NATURE, V267, P349, DOI 10.1038/267349a0
   Cornus S, 1999, ECOL PSYCHOL, V11, P249, DOI 10.1207/s15326969eco1104_1
   Cos-Aguilera I., 2004, P 5 WORKSH PHYS AG G
   Cos-Aguilera I., 2003, P 5 INT C COGN MOD I, P57
   Costantini M, 2010, EXP BRAIN RES, V207, P95, DOI 10.1007/s00221-010-2435-8
   Culham JC, 2006, CURR OPIN NEUROBIOL, V16, P205, DOI 10.1016/j.conb.2006.03.005
   Dag N, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P3089, DOI 10.1109/ICPR.2010.1146
   Damast AM, 1996, CHILD DEV, V67, P1752, DOI 10.1111/j.1467-8624.1996.tb01825.x
   de Souza R, 2015, ROBOT AUTON SYST, V74, P108, DOI 10.1016/j.robot.2015.07.006
   Dehban A, 2016, IEEE INT CONF ROBOT, P4866, DOI 10.1109/ICRA.2016.7487691
   Demiris Y., 2005, P 5 INT WORKSH EP RO, V123, P31
   Detry R, 2009, 2009 IEEE 8 INT C DE, P1
   Detry R, 2010, IEEE INT CONF ROBOT, P2287, DOI 10.1109/ROBOT.2010.5509126
   DIPELLEGRINO G, 1992, EXP BRAIN RES, V91, P176, DOI 10.1007/BF00230027
   Dogar Mehmet R, 2007, 2007 IEEE/RSJ International Conference on Intelligent Robots and Systems, P729, DOI 10.1109/IROS.2007.4399469
   Dogar MR, 2008, IEEE INT CONF ROBOT, P3802, DOI 10.1109/ROBOT.2008.4543794
   Duchon AP, 1998, ADAPT BEHAV, V6, P473, DOI 10.1177/105971239800600306
   Dum RP, 2005, J NEUROSCI, V25, P1375, DOI 10.1523/JNEUROSCI.3902-04.2005
   Ellis R, 2007, J EXP PSYCHOL HUMAN, V33, P670, DOI 10.1037/0096-1523.33.3.670
   Elsner B, 2003, CONSCIOUS COGN, V12, P732, DOI 10.1016/S1053-8100(03)00073-4
   Elsner B, 2001, J EXP PSYCHOL HUMAN, V27, P229, DOI 10.1037/0096-1523.27.1.229
   Erdemir E, 2008, 2008 IEEE/RSJ INTERNATIONAL CONFERENCE ON ROBOTS AND INTELLIGENT SYSTEMS, VOLS 1-3, CONFERENCE PROCEEDINGS, P2016, DOI 10.1109/IROS.2008.4650745
   Fagard J, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00491
   Fichtl S., PALADYN J BEHAV ROBO, V3, P188
   Fiorentino MR, 1981, BASIS SENSORIMOTOR D
   Fitzpatrick P, 2003, IEEE INT CONF ROBOT, P3140
   Fitzpatrick P, 2003, PHILOS T R SOC A, V361, P2165, DOI 10.1098/rsta.2003.1251
   Fogassi L, 1996, J NEUROPHYSIOL, V76, P141
   Franca M, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0049025
   Franklin S, 2014, IEEE T AUTON MENT DE, V6, P19, DOI 10.1109/TAMD.2013.2277589
   Friedman N, 1999, IJCAI-99: PROCEEDINGS OF THE SIXTEENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 & 2, P1300
   Fritz G, 2006, LECT NOTES COMPUT SC, V4095, P52
   Gallese V, 1996, BRAIN, V119, P593, DOI 10.1093/brain/119.2.593
   Gallese V, 2003, PHILOS T ROY SOC B, V358, P1231, DOI 10.1098/rstb.2003.1315
   Geib C., 2006, P IEEE HUM WORKSH CO
   Gibson E. J., 1970, SCIENCE, V168, P958
   Gibson E. J., 1994, ODYSSEY LEARNING PER
   Gibson E. l., 1975, PSYCHOL READING
   Gibson EJ, 2003, ECOL PSYCHOL, V15, P283, DOI 10.1207/s15326969eco1504_3
   GIBSON EJ, 1987, J EXP PSYCHOL HUMAN, V13, P533, DOI 10.1037/0096-1523.13.4.533
   GIBSON EJ, 1988, ANNU REV PSYCHOL, V39, P1, DOI 10.1146/annurev.ps.39.020188.000245
   Gibson EJ, 2000, ECOL PSYCHOL, V12, P295, DOI 10.1207/S15326969ECO1204_04
   GIBSON EJ, 1994, PSYCHOL SCI, V5, P69, DOI 10.1111/j.1467-9280.1994.tb00633.x
   Gibson J. J, 1979, ECOLOGICAL APPROACH
   Gibson J. J., 1977, PERCEIVING ACTING KN, P67
   Gibson JJ, 1938, AM J PSYCHOL, V51, P453, DOI 10.2307/1416145
   Gibson JJ., 1966, SENSES CONSIDERED PE
   Goncalves A, 2014, FOUTH JOINT IEEE INTERNATIONAL CONFERENCES ON DEVELOPMENT AND LEARNING AND EPIGENETIC ROBOTICS (IEEE ICDL-EPIROB 2014), P482, DOI 10.1109/DEVLRN.2014.6983027
   Goncalves A, 2014, 2014 IEEE INTERNATIONAL CONFERENCE ON AUTONOMOUS ROBOT SYSTEMS AND COMPETITIONS (ICARSC), P128, DOI 10.1109/ICARSC.2014.6849774
   GOODALE MA, 1992, TRENDS NEUROSCI, V15, P20, DOI 10.1016/0166-2236(92)90344-8
   Goodale M, 2008, COGN NEUROPSYCHOL, V25, P891, DOI 10.1080/02643290801961984
   Goslin J, 2012, PSYCHOL SCI, V23, P152, DOI 10.1177/0956797611429578
   Grezes J, 2003, EUR J NEUROSCI, V17, P2735, DOI 10.1046/j.1460-9568.2003.02695.x
   Griffith S, 2012, IEEE T AUTON MENT DE, V4, P54, DOI 10.1109/TAMD.2011.2157504
   Griffiths S., 2009, P 8 IEEE INT C DEV L, V37, P1
   Guerin F, 2013, IEEE T AUTON MENT DE, V5, P18, DOI 10.1109/TAMD.2012.2209879
   Hart S., 2005, P NAT C ART INT, P1280
   Hart S, 2011, IEEE T AUTON MENT DE, V3, P216, DOI 10.1109/TAMD.2010.2103311
   Heft H, 2003, ECOL PSYCHOL, V15, P149, DOI 10.1207/S15326969ECO1502_4
   Hermans T, 2013, IEEE-RAS INT C HUMAN, P435, DOI 10.1109/HUMANOIDS.2013.7030011
   Hickok G, 2009, J COGNITIVE NEUROSCI, V21, P1229, DOI 10.1162/jocn.2009.21189
   Hoffmann M, 2014, ROBOT AUTON SYST, V62, P1790, DOI 10.1016/j.robot.2014.07.006
   Hoffmann Matej, 2012, From Animals to Animats 12. Proceedings of the 12th International Conference on Simulation of Adaptive Behavior, SAB 2012, P54, DOI 10.1007/978-3-642-33093-3_6
   Hogman V, 2013, IEEE INT C INT ROBOT, P2799, DOI 10.1109/IROS.2013.6696752
   Horton TE, 2012, AVANT, V3, P70
   Huang CT, 2005, J EXP CHILD PSYCHOL, V92, P276, DOI 10.1016/j.jecp.2005.06.003
   Humphreys G, 2001, PSYCHOLOGIST, V14, P408
   Ikuzawa M., 2000, DEV DIAGNOSTIC TESTS
   INGLE D, 1977, VISION RES, V17, P1009, DOI 10.1016/0042-6989(77)90003-7
   Ishak S, 2014, J EXP CHILD PSYCHOL, V117, P92, DOI 10.1016/j.jecp.2013.09.003
   Ivaldi S, 2012, IEEE-RAS INT C HUMAN, P248, DOI 10.1109/HUMANOIDS.2012.6651528
   Jain R, 2013, ARTIF LIFE ROBOT, V18, P95, DOI 10.1007/s10015-013-0105-1
   James DK, 2010, INFANT CHILD DEV, V19, P45, DOI 10.1002/icd.653
   Jones KS, 2003, ECOL PSYCHOL, V15, P107, DOI 10.1207/S15326969ECO1502_1
   Kaiser P, 2015, IEEE-RAS INT C HUMAN, P920, DOI 10.1109/HUMANOIDS.2015.7363471
   Kalkan S, 2014, INTERACT STUD, V15, P1, DOI 10.1075/is.15.1.01kal
   Kim D, 2006, IEEE INT CONF ROBOT, P518, DOI 10.1109/ROBOT.2006.1641763
   Kinsella-Shaw Jeffrey M., 1992, Ecological Psychology, V4, P223, DOI 10.1207/s15326969eco0404_2
   Kintsch W., 1998, COMPREHENSION PARADI
   Kjellstrom H, 2011, COMPUT VIS IMAGE UND, V115, P81, DOI 10.1016/j.cviu.2010.08.002
   Koflka K., 1935, PRINCIPLES GESTALT P
   KOHLER W, 1925, MENTALITY APES
   Kontschieder P, 2011, IEEE I CONF COMP VIS, P2190, DOI 10.1109/ICCV.2011.6126496
   Kopicki M., 2011, 2011 IEEE International Conference on Robotics and Automation (ICRA 2011), P5722, DOI 10.1109/ICRA.2011.5980295
   Koppula HS, 2013, INT J ROBOT RES, V32, P951, DOI 10.1177/0278364913478446
   Kraft D, 2008, INT J HUM ROBOT, V5, P247, DOI 10.1142/S021984360800139X
   Kroemer O, 2012, IEEE INT CONF ROBOT, P2605, DOI 10.1109/ICRA.2012.6224957
   Krotkov E. P., 1995, P INT JOINT C ART IN, P88
   Kruger N., 2009, TECH REP
   Kruger N, 2013, IEEE T PATTERN ANAL, V35, P1847, DOI 10.1109/TPAMI.2012.272
   Kruger N, 2011, ROBOT AUTON SYST, V59, P740, DOI 10.1016/j.robot.2011.05.009
   Lafferty J., 2001, CONDITIONAL RANDOM F, V2001, P282
   Lang T, 2010, J ARTIF INTELL RES, V39, P1, DOI 10.1613/jair.3093
   Lee H., 2007, ADV NEURAL INF PROCE, P801
   LETTVIN JY, 1959, P IRE, V47, P1940, DOI 10.1109/JRPROC.1959.287207
   Lezine I, 1973, Res Publ Assoc Res Nerv Ment Dis, V51, P221
   LOCK A, 1979, J COMP PHYSIOL, V131, P179, DOI 10.1007/BF00619078
   Lockman JJ, 2000, CHILD DEV, V71, P137, DOI 10.1111/1467-8624.00127
   Lopes Manuel, 2007, 2007 IEEE/RSJ International Conference on Intelligent Robots and Systems, P1015, DOI 10.1109/IROS.2007.4399517
   MacDorman K. F., 2000, Proceedings 2000 ICRA. Millennium Conference. IEEE International Conference on Robotics and Automation. Symposia Proceedings (Cat. No.00CH37065), P3253, DOI 10.1109/ROBOT.2000.845164
   Mar T, 2015, IEEE INT CONF ROBOT, P3200, DOI 10.1109/ICRA.2015.7139640
   MARK LS, 1987, J EXP PSYCHOL HUMAN, V13, P361, DOI 10.1037//0096-1523.13.3.361
   Marr D., 1982, VISION COMPUTATIONAL
   May Stefan, 2007, 2007 IEEE/RSJ International Conference on Intelligent Robots and Systems, P3385, DOI 10.1109/IROS.2007.4399118
   Maye Alexander, 2012, From Animals to Animats 12. Proceedings of the 12th International Conference on Simulation of Adaptive Behavior, SAB 2012, P106, DOI 10.1007/978-3-642-33093-3_11
   Maye A, 2013, ADAPT BEHAV, V21, P423, DOI 10.1177/1059712313497975
   MCCABE V, 1982, ETHOL SOCIOBIOL, V3, P79, DOI 10.1016/0162-3095(82)90003-6
   McGrenere J, 2000, PROC GRAPH INTERF, P179
   Metta G, 2003, ADAPT BEHAV, V11, P109, DOI 10.1177/10597123030112004
   Metta G, 2010, NEURAL NETWORKS, V23, P1125, DOI 10.1016/j.neunet.2010.08.010
   Michaels CF, 2003, ECOL PSYCHOL, V15, P135, DOI 10.1207/S15326969ECO1502_3
   Miller AT, 2004, IEEE ROBOT AUTOM MAG, V11, P110, DOI 10.1109/MRA.2004.1371616
   Miller AT, 2003, IEEE INT CONF ROBOT, P1824, DOI 10.1109/ROBOT.2003.1241860
   Milner A. D., 1995, VISUAL BRAIN ACTION, V27
   MILNER AD, 1991, BRAIN, V114, P405, DOI 10.1093/brain/114.1.405
   Modayil J, 2008, ROBOT AUTON SYST, V56, P879, DOI 10.1016/j.robot.2008.08.004
   Moldovan B, 2013, IEEE INT CONF ROBOT, P1290, DOI 10.1109/ICRA.2013.6630737
   Moldovan B, 2012, IEEE INT CONF ROBOT, P4373, DOI 10.1109/ICRA.2012.6225042
   Montesano Luis, 2007, 2007 IEEE/RSJ International Conference on Intelligent Robots and Systems, P4102, DOI 10.1109/IROS.2007.4399511
   Montesano L., 2007, 2007 IEEE 6 INT C DE, P270
   Montesano L, 2008, IEEE T ROBOT, V24, P15, DOI 10.1109/TRO.2007.914848
   Montesano L, 2012, ROBOT AUTON SYST, V60, P452, DOI 10.1016/j.robot.2011.07.013
   Morales A, 2006, ROBOT AUTON SYST, V54, P496, DOI 10.1016/j.robot.2006.01.002
   Mugan J, 2012, IEEE T AUTON MENT DE, V4, P70, DOI 10.1109/TAMD.2011.2160943
   Murata A, 1997, J NEUROPHYSIOL, V78, P2226
   Murata A, 2000, J NEUROPHYSIOL, V83, P2580
   Murata S., 2015, IEEE T NEURAL NETWOR, P1
   Murphy RR, 1999, IEEE T SYST MAN CY A, V29, P105, DOI 10.1109/3468.736365
   Myers A, 2015, IEEE INT CONF ROBOT, P1374, DOI 10.1109/ICRA.2015.7139369
   Nagai Y., 2009, P 8 IEEE INT C DEV L, P1
   NEISSER U, 1994, EUR J COGN PSYCHOL, V6, P225, DOI 10.1080/09541449408520146
   Neisser U., 1976, COGNITION REALITY PR
   Neville J, 2004, FOURTH IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P170, DOI 10.1109/ICDM.2004.10101
   NEVILLE J, 2003, KDD 03, P625
   Nguyen S., 2012, PALADYN, V3, P136, DOI DOI 10.2478/S13230-013-0110-Z
   Norman D. A., 1999, Interactions, V6, P38, DOI 10.1145/301153.301168
   Norman D.A., 1988, PSYCHOL EVERYDAY THI
   Norman J, 2002, BEHAV BRAIN SCI, V25, P121
   Norman J, 2001, ECOL PSYCHOL, V13, P135, DOI 10.1207/S15326969ECO1302_6
   Nowak LG, 1997, CEREBR CORT, V12, P205
   O'Regan JK, 2001, BEHAV BRAIN SCI, V24, P939, DOI 10.1017/S0140525X01000115
   Osorio Pedro, 2010, 2010 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2010), P4432, DOI 10.1109/IROS.2010.5650297
   Oudejans RRD, 1996, ECOL PSYCHOL, V8, P259, DOI 10.1207/s15326969eco0803_4
   Oudeyer PY, 2007, IEEE T EVOLUT COMPUT, V11, P265, DOI 10.1109/TEVC.2006.890271
   Oztop E, 2006, NEUROCOMPUTING, V69, P1354, DOI 10.1016/j.neucom.2005.12.106
   Pastra K, 2012, PHILOS T R SOC B, V367, P103, DOI 10.1098/rstb.2011.0123
   Pasula HM, 2007, J ARTIF INTELL RES, V29, P309, DOI 10.1613/jair.2113
   Patla AE, 1996, NEUROREPORT, V8, P165, DOI 10.1097/00001756-199612200-00033
   Paulus M, 2011, CHILD DEV, V82, P1047, DOI 10.1111/j.1467-8624.2011.01610.x
   Pearl J., 1988, PROBABILISTIC REASON
   Pelleg D, 2000, ICML, P727, DOI DOI 10.1007/3-540-44491-2_3
   Petrick R., 2008, P 6 INT COGN ROB WOR, P32
   Piaget J., 1966, PSYCHOL CHILD
   Piaget J, 1952, ORIGINS INTELLIGENCE
   PICK HL, 1992, DEV PSYCHOL, V28, P787, DOI 10.1037/0012-1649.28.5.787
   Pisokas J, 2005, LECT NOTES COMPUT SC, V3394, P216
   Pitti A, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0069474
   Prattichizzo D., 2008, SPRINGER HDB ROBOTIC, P671
   Provasi J, 2001, INFANT BEHAV DEV, V24, P195, DOI 10.1016/S0163-6383(01)00072-8
   Raos V, 2006, J NEUROPHYSIOL, V95, P709, DOI 10.1152/jn.00463.2005
   Richardson M, 2006, MACH LEARN, V62, P107, DOI 10.1007/s10994-006-5833-1
   Ridge B, 2015, PROCEEDINGS OF THE 17TH INTERNATIONAL CONFERENCE ON ADVANCED ROBOTICS (ICAR), P635, DOI 10.1109/ICAR.2015.7251523
   Ridge B, 2010, IEEE INT CONF ROBOT, P5047, DOI 10.1109/ROBOT.2010.5509544
   Rizzolatti G, 1997, SCIENCE, V277, P190, DOI 10.1126/science.277.5323.190
   Rizzolatti G, 2001, NEURON, V31, P889, DOI 10.1016/S0896-6273(01)00423-8
   Rizzolatti G, 2001, NAT REV NEUROSCI, V2, P661, DOI 10.1038/35090060
   Rizzolatti G, 1998, NOVART FDN SYMP, V218, P81
   RIZZOLATTI G, 1988, EXP BRAIN RES, V71, P491, DOI 10.1007/BF00248742
   Rizzolatti G, 2003, EXP BRAIN RES, V153, P146, DOI 10.1007/s00221-003-1588-0
   Rochat P., 2009, THE INFANTS WORLD
   ROSENBAUM DA, 1991, HUMAN MOTOR CONTROL
   ROSENBLATT D, 1977, BIOL PLAY, P33
   Rozzi S, 2008, EUR J NEUROSCI, V28, P1569, DOI 10.1111/j.1460-9568.2008.06395.x
   Sahin E, 2007, ADAPT BEHAV, V15, P447, DOI 10.1177/1059712307084689
   Salvi G, 2012, IEEE T SYST MAN CY B, V42, P660, DOI 10.1109/TSMCB.2011.2172420
   SANTROCK JW, 2008, TOPICAL APPROACH LIF, P172
   Saxena A, 2008, INT J ROBOT RES, V27, P157, DOI 10.1177/0278364907087172
   Sinapov J., 2007, ICDL, P19
   Soska KC, 2010, DEV PSYCHOL, V46, P129, DOI 10.1037/a0014618
   Steedman M, 2002, LINGUIST PHILOS, V25, P723, DOI 10.1023/A:1020820000972
   Stoffregen TA, 2003, ECOL PSYCHOL, V15, P115, DOI 10.1207/S15326969ECO1502_2
   Stoytchev A, 2005, IEEE INT CONF ROBOT, P3060
   Stoytchev A, 2008, LECT NOTES ARTIF INT, V4760, P140, DOI 10.1007/978-3-540-77915-5_10
   Stoytchev S, 2005, P AAAI S DEV ROB STA, P17
   Sun J, 2010, INT J ROBOT RES, V29, P174, DOI 10.1177/0278364909356602
   Sun R, 2007, J EXP THEOR ARTIF IN, V19, P159, DOI 10.1080/0952813070119560
   SUTTON C, 2004, P INT C MACH LEARN
   Szokolszky A, 2003, ECOL PSYCHOL, V15, P271, DOI 10.1207/s15326969eco1504_2
   Takeshita H, 2001, Anim Cogn, V4, P335, DOI 10.1007/s100710100089
   Taskar B., 2004, P 21 INT C MACH LEAR, P102
   Tikhanoff V, 2013, IEEE-RAS INT C HUMAN, P130, DOI 10.1109/HUMANOIDS.2013.7029967
   Tomasello M, 1999, CULTURAL ORIGINS HUM
   Tomasello Michael, 1996, P319, DOI 10.1016/B978-012273965-1/50016-9
   Treue S, 2001, TRENDS NEUROSCI, V24, P295, DOI 10.1016/S0166-2236(00)01814-2
   Tucker M, 1998, J EXP PSYCHOL HUMAN, V24, P830, DOI 10.1037/0096-1523.24.3.830
   Turvey M. T., 1992, ECOL PSYCHOL, V4, P173, DOI DOI 10.1207/S15326969EC00403_
   Ugur E., 2012, 2012 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2012), P3260, DOI 10.1109/IROS.2012.6385639
   Ugur Emre, 2011, 2011 IEEE International Conference on Robotics and Automation, P4312
   Ugur Emre, 2009, 2009 24th International Symposium on Computer and Information Sciences (ISCIS), P415, DOI 10.1109/ISCIS.2009.5291803
   Ugur E., 2007, DEV LEARN 2007 ICDL, P13
   Ugur E., 2009, P 9 INT C EP ROB EPI, P177
   Ugur E, 2007, IEEE INT CONF ROBOT, P1721, DOI 10.1109/ROBOT.2007.363571
   Ugur E, 2015, IEEE-RAS INT C HUMAN, P1007, DOI 10.1109/HUMANOIDS.2015.7363477
   Ugur E, 2015, IEEE INT CONF ROBOT, P2627, DOI 10.1109/ICRA.2015.7139553
   Ugur E, 2015, IEEE T AUTON MENT DE, V7, P119, DOI 10.1109/TAMD.2015.2426192
   Ugur E, 2015, ROBOTICA, V33, P1163, DOI 10.1017/S0263574714002148
   Ugur E, 2014, FOUTH JOINT IEEE INTERNATIONAL CONFERENCES ON DEVELOPMENT AND LEARNING AND EPIGENETIC ROBOTICS (IEEE ICDL-EPIROB 2014), P476, DOI 10.1109/DEVLRN.2014.6983026
   Ugur E, 2014, FOUTH JOINT IEEE INTERNATIONAL CONFERENCES ON DEVELOPMENT AND LEARNING AND EPIGENETIC ROBOTICS (IEEE ICDL-EPIROB 2014), P489, DOI 10.1109/DEVLRN.2014.6983028
   Ugur E, 2011, ROBOT AUTON SYST, V59, P580, DOI 10.1016/j.robot.2011.04.005
   Ugur E, 2010, ADAPT BEHAV, V18, P258, DOI 10.1177/1059712310370625
   UNGERER JA, 1981, CHILD DEV, V52, P186, DOI 10.2307/1129229
   Ungerleider L. G., 1982, ANAL VISUAL BEHAV, P549
   van Elk M, 2008, NEUROIMAGE, V43, P808, DOI 10.1016/j.neuroimage.2008.07.057
   Varadarajan K.M., 2013, LNCS, V7724, P512
   Varadarajan KM, 2012, IEEE INT C INT ROBOT, P1343, DOI 10.1109/IROS.2012.6386232
   Varela F. J., 1991, EMBODIED MIND COGNIT
   Vatakis A, 2016, SCI DATA, V3, DOI 10.1038/sdata.2015.78
   VERA AH, 1993, COGNITIVE SCI, V17, P7, DOI 10.1207/s15516709cog1701_2
   Vernon D, 2010, COGN SYST MONOGR, V11, P1
   Vingerhoets G, 2009, BRAIN COGNITION, V69, P481, DOI 10.1016/j.bandc.2008.10.003
   von Hofsten C, 2004, TRENDS COGN SCI, V8, P266, DOI 10.1016/j.tics.2004.04.002
   VONHOFSTEN C, 1982, DEV PSYCHOL, V18, P450, DOI 10.1037//0012-1649.18.3.450
   Want SC, 2002, DEVELOPMENTAL SCI, V5, P1, DOI 10.1111/1467-7687.00194
   WARREN WH, 1984, J EXP PSYCHOL HUMAN, V10, P683, DOI 10.1037/0096-1523.10.5.683
   WARREN WH, 1987, J EXP PSYCHOL HUMAN, V13, P371, DOI 10.1037/0096-1523.13.3.371
   WHITE RW, 1959, PSYCHOL REV, V66, P297, DOI 10.1037/h0040934
   WILLATTS P, 1984, INFANT BEHAV DEV, V7, P125, DOI 10.1016/S0163-6383(84)80053-3
   Willatts P, 1999, DEV PSYCHOL, V35, P651, DOI 10.1037/0012-1649.35.3.651
   Witt JK, 2011, CURR DIR PSYCHOL SCI, V20, P201, DOI 10.1177/0963721411408770
   Worgotter F, 2009, ROBOT AUTON SYST, V57, P420, DOI 10.1016/j.robot.2008.06.011
   Worgotter F, 2015, IEEE T AUTON MENT DE, V7, P140, DOI 10.1109/TAMD.2015.2427233
   Wood A. B., 2005, 2005 IEEE Systems and Information Engineering Design Symposium (IEEE Cat. No. 05EX1024), P75, DOI 10.1109/SIEDS.2005.193241
   Yuruten O, 2013, ADAPT BEHAV, V21, P437, DOI 10.1177/1059712313497976
   Zhu YK, 2014, LECT NOTES COMPUT SC, V8690, P408, DOI 10.1007/978-3-319-10605-2_27
NR 275
TC 3
Z9 3
U1 15
U2 22
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2379-8920
EI 2379-8939
J9 IEEE T COGN DEV SYST
JI IEEE Trans. Cogn. Dev. Syst.
PD MAR
PY 2018
VL 10
IS 1
BP 4
EP 25
DI 10.1109/TCDS.2016.2594134
PG 22
WC Computer Science, Artificial Intelligence; Robotics; Neurosciences
SC Computer Science; Robotics; Neurosciences & Neurology
GA FZ3FA
UT WOS:000427470800002
OA Green Published
DA 2019-02-18
ER

PT J
AU Sarathy, V
   Scheutz, M
AF Sarathy, Vasanth
   Scheutz, Matthias
TI A Logic-Based Computational Framework for Inferring Cognitive
   Affordances
SO IEEE TRANSACTIONS ON COGNITIVE AND DEVELOPMENTAL SYSTEMS
LA English
DT Article
DE Affordances; autonomous mental development; cognitive system and
   development; cognitive robotics; embodied intelligence; robots with
   development and learning skills; visual attention; visual perception
ID ROBOT; ATTENTION; SYSTEM
AB The concept of "affordance" refers to the relationship between human perceivers and aspects of their environment. Being able to infer affordances is central to commonsense reasoning, tool use and creative problem solving in artificial agents. Existing approaches to inferring affordances have focused on functional aspects, relying on either static ontologies or statistical formalisms to extract relationships between physical features of objects, actions, and the corresponding effects of their interaction. These approaches do not provide flexibility with which to reason about affordances in the open world, where affordances are influenced by changing context, social norms, historical precedence, and uncertainty. We develop a computational framework comprising a probabilistic rules-based logical representation coupled with a computational architecture (cognitive affordances logically expressed) to reason about affordances in a more general manner than described in the existing literature. Our computational architecture allows robotic agents to make deductive and abductive inferences about functional and social affordances, collectively and dynamically, thereby allowing the agent to adapt to changing conditions. We demonstrate our approach with experiments, and show that an agent can successfully reason through situations that involve a tight interplay between various social and functional norms.
C1 [Sarathy, Vasanth; Scheutz, Matthias] Tufts Univ, Dept Comp Sci, Medford, MA 02155 USA.
RP Sarathy, V (reprint author), Tufts Univ, Dept Comp Sci, Medford, MA 02155 USA.
EM vasanth.sarathy@tufts.edu
CR Abel D., 2005, AFFORDANCE AWARE PLA
   Aleotti J, 2014, INT J SOC ROBOT, V6, P653, DOI 10.1007/s12369-014-0241-3
   Barsalou L., 2005, REPRESENTING FUNCTIO, P131
   Bicici E., 2003, TECH REP
   Boularias A., 2015, P 29 AAAI C ART INT, P1336
   Cantrell R, 2012, ACMIEEE INT CONF HUM, P471
   CHAN WP, 2015, IEEE INT C INT ROBOT, P1
   Chemero A, 2003, ECOL PSYCHOL, V15, P181, DOI 10.1207/S15326969ECO1502_5
   Fellrath J, 2015, NEUROPSYCHOLOGIA, V73, P70, DOI 10.1016/j.neuropsychologia.2015.05.003
   Garrido-Vasquez P, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00059
   Gibson J. J., 1979, ECOLOGICAL APPROACH, V39
   Glasauer S, 2010, 2010 IEEE RO-MAN, P252, DOI 10.1109/ROMAN.2010.5598638
   Kim J., 2004, ADV GRASP PLANNING H, P34
   Macchi L., 2014, MIND SOC, V13, P97
   Mastrogiovanni F., 2011, INT J MACHINE CONSCI, V3, P91
   Mastrogiovanni F, 2012, BIOL INSPIR COGN ARC, V2, P77, DOI 10.1016/j.bica.2012.07.006
   Moldovan B, 2012, IEEE INT CONF ROBOT, P4373, DOI 10.1109/ICRA.2012.6225042
   Montesano Luis, 2007, 2007 IEEE/RSJ International Conference on Intelligent Robots and Systems, P4102, DOI 10.1109/IROS.2007.4399511
   Montesano L., 2009, 2009 IEEE 8 INT C DE, P1
   Navalpakkam V, 2005, VISION RES, V45, P205, DOI 10.1016/j.visres.2004.07.042
   Norman D. A., 1988, PSYCHOL EVERYDAY THI, P1, DOI 10.2307/1423268
   Nunez RC, 2013, 2013 16TH INTERNATIONAL CONFERENCE ON INFORMATION FUSION (FUSION), P1934
   Olteteanu A. - M., 2014, P 1 WORKSH AFF AFF V
   Pas A. Ten, 2014, EXPT ROBOTICS
   Potapova E, 2014, IEEE-RAS INT C HUMAN, P252, DOI 10.1109/HUMANOIDS.2014.7041368
   Reed E., 1996, ENCOUNTERING WORLD E, V34
   Roberts KL, 2011, Q J EXP PSYCHOL, V64, P669, DOI 10.1080/17470218.2010.520086
   Sahin E, 2007, ADAPT BEHAV, V15, P447, DOI 10.1177/1059712307084689
   Sarathy V., 2015, P IROS WORKSH LEARN
   Scarantino A, 2003, PHILOS SCI, V70, P949, DOI 10.1086/377380
   Scheutz M, 2007, AUTON ROBOT, V22, P411, DOI 10.1007/s10514-006-9018-3
   Schmidt RC, 2007, ECOL PSYCHOL, V19, P137
   Shafer G, 1976, MATH THEORY EVIDENCE
   Shapira L, 2008, VISUAL COMPUT, V24, P249, DOI 10.1007/s00371-007-0197-5
   Shibata S, 1995, RO-MAN'95 TOKYO: 4TH IEEE INTERNATIONAL WORKSHOP ON ROBOT AND HUMAN COMMUNICATION, PROCEEDINGS, P53, DOI 10.1109/ROMAN.1995.531934
   Shu T., 2016, P INT JOINT C ART IN, P3454
   Steedman M., 2002, ANN M COGN SCI SOC, P834
   Stoffregen TA, 2003, ECOL PSYCHOL, V15, P115, DOI 10.1207/S15326969ECO1502_2
   Strabala K, 2013, J HUM-ROBOT INTERACT, V2, P112, DOI 10.5898/JHRI.2.1.Strabala
   Tang YQ, 2012, FRONT ARTIF INTEL AP, V245, P462, DOI 10.3233/978-1-61499-111-3-462
   Tunnermann J., 2014, P 1 WORKSH AFF AFF V
   Turvey M. T., 1992, ECOL PSYCHOL, V4, P173, DOI DOI 10.1207/S15326969EC00403_
   Ugur E., 2012, 2012 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2012), P3260, DOI 10.1109/IROS.2012.6385639
   Ugur Emre, 2011, 2011 11th IEEE-RAS International Conference on Humanoid Robots (Humanoids 2011), P480, DOI 10.1109/Humanoids.2011.6100890
   Ugur E, 2015, ROBOTICA, V33, P1163, DOI 10.1017/S0263574714002148
   Varadarajan Karthik Mahesh, 2011, Computer Vision Systems. Proceedings 8th International Conference (ICVS 2011), P173, DOI 10.1007/978-3-642-23968-7_18
   Varadarajan KM, 2015, PROCEEDINGS OF THE 2015 6TH INTERNATIONAL CONFERENCE ON AUTOMATION, ROBOTICS AND APPLICATIONS (ICARA), P42, DOI 10.1109/ICARA.2015.7081123
   Wickramaratna K., 2009, P FLOR ART INT RES S
   Williams T., 2015, AAAI, P1387
   YAGER RR, 1987, INFORM SCIENCES, V41, P93, DOI 10.1016/0020-0255(87)90007-7
   Yarbus A. L., 1967, EYE MOVEMENTS VISION, V6
   Zadeh LA, 1979, VALIDITY DEMPSTERS R
NR 52
TC 0
Z9 0
U1 2
U2 8
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2379-8920
EI 2379-8939
J9 IEEE T COGN DEV SYST
JI IEEE Trans. Cogn. Dev. Syst.
PD MAR
PY 2018
VL 10
IS 1
BP 26
EP 43
DI 10.1109/TCDS.2016.2615326
PG 18
WC Computer Science, Artificial Intelligence; Robotics; Neurosciences
SC Computer Science; Robotics; Neurosciences & Neurology
GA FZ3FA
UT WOS:000427470800003
DA 2019-02-18
ER

PT J
AU Fichtl, S
   Kraft, D
   Kruger, N
   Guerin, F
AF Fichtl, Severin
   Kraft, Dirk
   Kruger, Norbert
   Guerin, Frank
TI Bootstrapping Relational Affordances of Object Pairs Using Transfer
SO IEEE TRANSACTIONS ON COGNITIVE AND DEVELOPMENTAL SYSTEMS
LA English
DT Article
DE Artificial intelligence; autonomous mental development; intelligent
   systems
ID DEVELOPMENTAL ROBOTICS; TOOL USE; MODELS
AB Robots acting in everyday environments need a good knowledge of how a manipulation action can affect pairs of objects in a relationship, such as "inside" or "behind" or "on top." These relationships afford certain means-end actions such as pulling a container to retrieve the contents, or pulling a tool to retrieve a desired object. We investigate how these relational affordances could be learned by a robot from its own action experience. A major challenge in this approach is to reduce the number of training samples needed to achieve accuracy, and hence we investigate an approach which can leverage past knowledge to accelerate current learning (which we call bootstrapping). We learn random forest-based affordance predictors from visual inputs and demonstrate two approaches to knowledge transfer for bootstrapping. In the first approach [direct bootstrapping (DB)], the state-space for a new affordance predictor is augmented with the output of previously learned affordances. In the second approach [category-based bootstrapping (CB)], we form categories that capture underlying commonalities of a pair of existing affordances and augment the state-space with this category classifier's output. In addition, we introduce a novel heuristic, which suggests how a large set of potential affordance categories can be pruned to leave only those categories which are most promising for bootstrapping future affordances. Our results show that both bootstrapping approaches outperform learning without bootstrapping. We also show that there is no significant difference in performance between DB and CB.
C1 [Fichtl, Severin] Univ Aberdeen, Aberdeen AB24 3UE, Scotland.
   [Fichtl, Severin] Univ Southern Denmark, DK-5230 Odense, Denmark.
   [Kraft, Dirk; Kruger, Norbert] Univ Southern Denmark, Maersk McKinney Moller Inst, DK-5230 Odense, Denmark.
   [Guerin, Frank] Univ Aberdeen, Comp Sci, Aberdeen, Scotland.
RP Fichtl, S (reprint author), Univ Aberdeen, Aberdeen AB24 3UE, Scotland.
EM fichtl@mmmi.sdu.dk; kraft@mmmi.sdu.dk; norbert@mmmi.sdu.dk;
   f.guerin@abdn.ac.uk
OI Kruger, Norbert/0000-0002-3931-116X; Kraft, Dirk/0000-0002-6125-8481
FU U.K. EPSRC DTG at Aberdeen [EP/J5000343/1]; EU Cognitive Systems Project
   XPERIENCE at SDU [FP7-ICT-270273]
FX This work was supported in part by the U.K. EPSRC DTG EP/J5000343/1 at
   Aberdeen, and in part by the EU Cognitive Systems Project XPERIENCE at
   SDU under Grant FP7-ICT-270273.
CR Aksoy EE, 2010, IEEE INT CONF ROBOT, P398, DOI 10.1109/ROBOT.2010.5509319
   Barsalou LW, 2009, PHILOS T R SOC B, V364, P1281, DOI 10.1098/rstb.2008.0319
   Bellman R. E., 1961, ADAPTIVE CONTROL PRO
   Breiman L., 1984, CLASSIFICATION REGRE
   Breiman L, 2004, RANDOM FORESTS
   Chaput H. H., 2004, THESIS
   Choi W., 2011, P IEEE C COMP VIS PA, P33
   Clark A., 1993, Mind and Language, V8, P487, DOI 10.1111/j.1468-0017.1993.tb00299.x
   Do M, 2014, IEEE INT CONF ROBOT, P1858, DOI 10.1109/ICRA.2014.6907103
   DRESCHER G, 1991, MADE UP MINDS CONSTR
   Fichtl S., 2012, PALADYN, V3, P188
   Fichtl S., 2015, P IEEE RSJ INT C INT, P1
   Fichtl S, 2014, IEEE INT CONF ROBOT, P501, DOI 10.1109/ICRA.2014.6906902
   Grabner H, 2011, PROC CVPR IEEE, P1529, DOI 10.1109/CVPR.2011.5995327
   Griffith S, 2012, IEEE T AUTON MENT DE, V4, P54, DOI 10.1109/TAMD.2011.2157504
   Guerin F, 2013, IEEE T AUTON MENT DE, V5, P18, DOI 10.1109/TAMD.2012.2209879
   Hart S, 2011, IEEE T AUTON MENT DE, V3, P216, DOI 10.1109/TAMD.2010.2103311
   Joergensen J. A., 2010, P 41 INT S ROB ISR 6, P1
   Khoshelham K, 2012, SENSORS-BASEL, V12, P1437, DOI 10.3390/s120201437
   Konidaris G. D., 2014, P 28 C ART INT, P1932
   Konidaris George, 2016, IJCAI (U S), V2016, P1648
   Konidaris G, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P3619
   Koppula HS, 2013, INT J ROBOT RES, V32, P951, DOI 10.1177/0278364913478446
   Lazaric A, 2012, ADAPT LEARN OPTIM, V12, P143
   Lee MH, 2007, ADAPT BEHAV, V15, P241, DOI 10.1177/1059712307082085
   Lockman JJ, 2000, CHILD DEV, V71, P137, DOI 10.1111/1467-8624.00127
   MANDLER JM, 1992, PSYCHOL REV, V99, P587, DOI 10.1037//0033-295X.99.4.587
   Moldovan B, 2012, IEEE INT CONF ROBOT, P4373, DOI 10.1109/ICRA.2012.6225042
   Moore Roger K., 2013, Your Virtual Butler. The Making-of: LNCS 7407, P119, DOI 10.1007/978-3-642-37346-6_10
   Mugan J, 2012, IEEE T AUTON MENT DE, V4, P70, DOI 10.1109/TAMD.2011.2160943
   Mustafa W, 2013, IEEE INT CONF ROBOT, P4230, DOI 10.1109/ICRA.2013.6631175
   Nguyen CV, 2012, SECOND JOINT 3DIM/3DPVT CONFERENCE: 3D IMAGING, MODELING, PROCESSING, VISUALIZATION & TRANSMISSION (3DIMPVT 2012), P524, DOI 10.1109/3DIMPVT.2012.84
   Olesen SM, 2015, J REAL-TIME IMAGE PR, V10, P105, DOI 10.1007/s11554-012-0261-x
   Oudeyer P.-Y., 2013, INTRINSICALLY MOTIVA, P303
   Oudeyer PY, 2007, IEEE T EVOLUT COMPUT, V11, P265, DOI 10.1109/TEVC.2006.890271
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Panda S, 2013, IEEE INT C INT ROBOT, P809, DOI 10.1109/IROS.2013.6696444
   Pasula HM, 2007, J ARTIF INTELL RES, V29, P309, DOI 10.1613/jair.2113
   Piaget J., 1937, CONSTRUCTION REALITY
   Piaget J, 1936, ORIGINS INTELLIGENCE
   Rosman B, 2011, INT J ROBOT RES, V30, P1328, DOI 10.1177/0278364911408155
   Schoeler M, 2015, PROC CVPR IEEE, P5207, DOI 10.1109/CVPR.2015.7299157
   Stoytchev A, 2009, IEEE T AUTON MENT DE, V1, P122, DOI 10.1109/TAMD.2009.2029989
   Ugur E, 2014, FOUTH JOINT IEEE INTERNATIONAL CONFERENCES ON DEVELOPMENT AND LEARNING AND EPIGENETIC ROBOTICS (IEEE ICDL-EPIROB 2014), P476, DOI 10.1109/DEVLRN.2014.6983026
   Ugur E, 2014, FOUTH JOINT IEEE INTERNATIONAL CONFERENCES ON DEVELOPMENT AND LEARNING AND EPIGENETIC ROBOTICS (IEEE ICDL-EPIROB 2014), P489, DOI 10.1109/DEVLRN.2014.6983028
   Varadarajan K. M., 2011, 2011 15th International Conference on Advanced Robotics, P21, DOI 10.1109/ICAR.2011.6088647
   Willatts P, 1999, DEV PSYCHOL, V35, P651, DOI 10.1037/0012-1649.35.3.651
   Willatts P, 1990, CHILDRENS STRATEGIES, P23
   Worgotter F, 2015, IEEE T AUTON MENT DE, V7, P140, DOI 10.1109/TAMD.2015.2427233
   Yeh WC, 2006, AM J PSYCHOL, V119, P349, DOI 10.2307/20445349
   Zimmerman T, 2003, AI MAG, V24, P73
NR 51
TC 0
Z9 0
U1 2
U2 3
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2379-8920
EI 2379-8939
J9 IEEE T COGN DEV SYST
JI IEEE Trans. Cogn. Dev. Syst.
PD MAR
PY 2018
VL 10
IS 1
BP 56
EP 71
DI 10.1109/TCDS.2016.2616496
PG 16
WC Computer Science, Artificial Intelligence; Robotics; Neurosciences
SC Computer Science; Robotics; Neurosciences & Neurology
GA FZ3FA
UT WOS:000427470800005
DA 2019-02-18
ER

PT J
AU Braud, R
   Pitti, A
   Gaussier, P
AF Braud, Raphael
   Pitti, Alexandre
   Gaussier, Philippe
TI A Modular Dynamic Sensorimotor Model for Affordances Learning, Sequences
   Planning, and Tool-Use
SO IEEE TRANSACTIONS ON COGNITIVE AND DEVELOPMENTAL SYSTEMS
LA English
DT Article
DE Affordance; ideomotor principle; robotics; sensorimotor laws; sequences;
   tool-use
ID INTERNAL-MODELS; MOTOR CONTROL; ARTIFICIAL-INTELLIGENCE; EMBODIED
   COGNITION; MIRROR-NEURONS; INVERSE MODELS; BODY SCHEMA; BEHAVIOR;
   SIMULATION; COMPLEX
AB This paper proposes a computational model for learning robot control and sequence planning based on the ideomotor principle. This model encodes covariation laws between sensors and motors in a modular fashion and exploits these primitive skills to build complex action sequences, potentially involving tool-use. Implemented for a robotic arm, the model starts with raw unlabeled sensor and motor vectors and autonomously assigns functions to neutral objects in the environment. Our experimental evaluation highlights the emergent properties of such a modular system and we discuss their consequences from ideomotor and sensorimotor-theoretic perspectives.
C1 [Braud, Raphael; Pitti, Alexandre; Gaussier, Philippe] Univ Cergy Pontoise, CNRS, UMR 8051, Lab ETIS,ENSEA, F-95302 Pontoise, France.
RP Braud, R (reprint author), Univ Cergy Pontoise, CNRS, UMR 8051, Lab ETIS,ENSEA, F-95302 Pontoise, France.
EM raphael.braud@gmail.com
FU ROBOTEX Project
FX This work was supported by ROBOTEX Project.
CR Arbib MA, 2011, ANNU REV ANTHROPOL, V40, P257, DOI 10.1146/annurev-anthro-081309-145722
   Baillieul J., 1984, Proceedings of the 23rd IEEE Conference on Decision and Control (Cat. No. 84CH2093-3), P768
   Baranes A, 2013, ROBOT AUTON SYST, V61, P49, DOI 10.1016/j.robot.2012.05.008
   Barsalou Lawrence W, 2007, Cogn Process, V8, P79, DOI 10.1007/s10339-007-0163-1
   Barsalou LW, 2009, PHILOS T R SOC B, V364, P1281, DOI 10.1098/rstb.2008.0319
   Barsalou LW, 1999, BEHAV BRAIN SCI, V22, P577
   Billing E, 2015, ADAPT BEHAV, V23, P243, DOI 10.1177/1059712315601188
   Bonini L, 2011, J NEUROSCI, V31, P5876, DOI 10.1523/JNEUROSCI.5186-10.2011
   Botvinick MM, 2008, TRENDS COGN SCI, V12, P201, DOI 10.1016/j.tics.2008.02.009
   Braud R, 2015, 5TH INTERNATIONAL CONFERENCE ON DEVELOPMENT AND LEARNING AND ON EPIGENETIC ROBOTICS (ICDL-EPIROB), P267, DOI 10.1109/DEVLRN.2015.7346154
   Braud R, 2014, LECT NOTES ARTIF INT, V8575, P154, DOI 10.1007/978-3-319-08864-8_15
   Bub DN, 2008, COGNITION, V106, P27, DOI 10.1016/j.cognition.2006.12.010
   BULLOCK D, 1993, J COGNITIVE NEUROSCI, V5, P408, DOI 10.1162/jocn.1993.5.4.408
   Butz MV, 2003, LECT NOTES ARTIF INT, V2684, P86
   Cangelosi A, 2010, IEEE T AUTON MENT DE, V2, P167, DOI 10.1109/TAMD.2010.2053034
   Chaput H. H., 2004, CONSTRUCTIVIST LEARN
   Cisek P, 2007, PHILOS T R SOC B, V362, P1585, DOI 10.1098/rstb.2007.2054
   Cisek P, 2010, ANNU REV NEUROSCI, V33, P269, DOI 10.1146/annurev.neuro.051508.135409
   Cooper R, 2000, COGN NEUROPSYCHOL, V17, P297, DOI 10.1080/026432900380427
   Craigherol L, 2007, PROG BRAIN RES, V164, P39, DOI 10.1016/S0079-6123(07)64003-5
   Creem-Regehr SH, 2005, COGNITIVE BRAIN RES, V22, P457, DOI 10.1016/j.cogbrainres.2004.10.006
   D'Souza A, 2001, IROS 2001: PROCEEDINGS OF THE 2001 IEEE/RJS INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-4, P298, DOI 10.1109/IROS.2001.973374
   de Rengerve A, 2015, BIOL CYBERN, V109, P255, DOI 10.1007/s00422-014-0640-4
   Decety J, 2006, BRAIN RES, V1079, P4, DOI 10.1016/j.brainres.2005.12.115
   Dehaene S, 1997, P NATL ACAD SCI USA, V94, P13293, DOI 10.1073/pnas.94.24.13293
   DENNETT DC, 1978, AM PHILOS QUART, V15, P249
   Ellis R, 2000, BRIT J PSYCHOL, V91, P451, DOI 10.1348/000712600161934
   Flanagan JR, 2003, CURR BIOL, V13, P146, DOI 10.1016/S0960-9822(03)00007-1
   Fogassi L, 2005, SCIENCE, V308, P662, DOI 10.1126/science.1106138
   Gaussier P, 1995, ROBOT AUTON SYST, V16, P291, DOI 10.1016/0921-8890(95)00052-6
   Gibson J. J, 1979, ECOLOGICAL APPROACH
   GROSSBERG S, 1986, PATTERN RECOGN, V1, P187, DOI DOI 10.1037/0033-295X.93.1.46
   Grush R, 2004, BEHAV BRAIN SCI, V27, P377
   Guerin F, 2013, IEEE T AUTON MENT DE, V5, P18, DOI 10.1109/TAMD.2012.2209879
   Guerin F, 2011, KNOWL ENG REV, V26, P209, DOI 10.1017/S0269888911000038
   Hart S, 2011, IEEE T AUTON MENT DE, V3, P216, DOI 10.1109/TAMD.2010.2103311
   Hesslow G, 2002, TRENDS COGN SCI, V6, P242, DOI 10.1016/S1364-6613(02)01913-7
   Hoffmann M, 2010, IEEE T AUTON MENT DE, V2, P304, DOI 10.1109/TAMD.2010.2086454
   Hommel B, 2001, BEHAV BRAIN SCI, V24, P849, DOI 10.1017/S0140525X01000103
   James W., 1890, PRINCIPLES PSYCHOL, V8
   Jamone L., 2012, PALADYN J BEHAV ROBO, V3, P113
   Johnson SH, 2000, COGNITION, V74, P33, DOI 10.1016/S0010-0277(99)00063-3
   Johnson-Frey SH, 2004, TRENDS COGN SCI, V8, P71, DOI 10.1016/j.tics.2003.12.002
   Kaplan F, 2005, INT C DEVEL LEARN, P129
   Kawato M, 1999, CURR OPIN NEUROBIOL, V9, P718, DOI 10.1016/S0959-4388(99)00028-8
   Kruger N, 2011, ROBOT AUTON SYST, V59, P740, DOI 10.1016/j.robot.2011.05.009
   Lashley Karl S., 1951, PROBLEM SERIAL ORDER
   Law J., 2014, FRONT NEUROROBOTICS, V8, P260
   Lockman JJ, 2000, CHILD DEV, V71, P137, DOI 10.1111/1467-8624.00127
   Mahe S, 2015, NEURAL NETWORKS, V62, P102, DOI 10.1016/j.neunet.2014.08.009
   Maravita A, 2004, TRENDS COGN SCI, V8, P79, DOI 10.1016/j.tics.2003.12.008
   McCarty ME, 1999, DEV PSYCHOL, V35, P1091, DOI 10.1037/0012-1649.35.4.1091
   Miller GA, 1960, PLANS STRUCTURE BEHA
   Moller R, 2008, COGNITIVE SCI, V32, P504, DOI 10.1080/03640210802035241
   MUSSAIVALDI FA, 1991, INT J ROBOT RES, V10, P481, DOI 10.1177/027836499101000504
   Nabeshima C, 2006, ADV ROBOTICS, V20, P1105, DOI 10.1163/156855306778522550
   Nagai Y., 2015, P IROS WORKSH SENS C, P51
   Nicolescu M. N., 2002, Proceedings of the First International Joint Conference on Autonomous Agents and Multiagent Systems, P227
   O'Regan JK, 2001, BEHAV BRAIN SCI, V24, P939, DOI 10.1017/S0140525X01000115
   Ogino M., 2012, P IEEE INT C DEV LEA, P1
   Olsson LA, 2006, CONNECT SCI, V18, P121, DOI 10.1080/09540090600768542
   Oudeyer PY, 2007, IEEE T EVOLUT COMPUT, V11, P265, DOI 10.1109/TEVC.2006.890271
   Perotto FS, 2013, CONSTR FOUND, V9, P46
   Pezzulo G, 2013, NEW IDEAS PSYCHOL, V31, P270, DOI 10.1016/j.newideapsych.2013.01.004
   Pezzulo G, 2009, PSYCHOL RES-PSYCH FO, V73, P559, DOI 10.1007/s00426-009-0237-z
   Pierce D, 1997, ARTIF INTELL, V92, P169, DOI 10.1016/S0004-3702(96)00051-3
   PRINCE C, 2005, P 5 INT WORKSH EP RO, P63
   Prinz W., 1990, RELATIONSHIPS PERCEP, P167, DOI DOI 10.1007/978-3-642-75348-0_7
   Rat-Fischer L, 2012, J EXP CHILD PSYCHOL, V113, P440, DOI 10.1016/j.jecp.2012.06.001
   Rizzolatti G, 2004, ANNU REV NEUROSCI, V27, P169, DOI 10.1146/annurev.neuro.27.070203.144230
   Rolf M, 2010, Proceedings of the 2010 International Conference on Emerging Security Technologies (EST 2010), P171, DOI 10.1109/EST.2010.20
   Rolf M, 2015, 5TH INTERNATIONAL CONFERENCE ON DEVELOPMENT AND LEARNING AND ON EPIGENETIC ROBOTICS (ICDL-EPIROB), P332, DOI 10.1109/DEVLRN.2015.7346167
   Sandamirskaya Y, 2010, 2010 IEEE 9th International Conference on Development and Learning (ICDL 2010), P251, DOI 10.1109/DEVLRN.2010.5578834
   Schaal S, 1998, NEURAL COMPUT, V10, P2047, DOI 10.1162/089976698300016963
   Schoner G, 2008, CAMB HANDB PSYCHOL, P101
   Smith L, 2005, ARTIF LIFE, V11, P13, DOI 10.1162/1064546053278973
   Smith LB, 2003, TRENDS COGN SCI, V7, P343, DOI 10.1016/S1364-6613(03)00156-6
   Srinivasa N, 2012, NEURAL NETWORKS, V35, P54, DOI 10.1016/j.neunet.2012.07.010
   Srinivasa N, 2008, NEURAL NETWORKS, V21, P1380, DOI 10.1016/j.neunet.2008.07.007
   Steele J, 2012, PHILOS T R SOC B, V367, P4, DOI 10.1098/rstb.2011.0295
   Stout D, 2007, NEUROPSYCHOLOGIA, V45, P1091, DOI 10.1016/j.neuropsychologia.2006.09.014
   Stout D, 2009, CAMB ARCHAEOL J, V19, P85, DOI 10.1017/S0959774309000055
   Stoytchev A, 2005, IEEE INT CONF ROBOT, P3060
   Stronger D, 2006, CONNECT SCI, V18, P97, DOI 10.1080/09540090600768690
   Tani J, 2003, LECT NOTES ARTIF INT, V2684, P167
   Thill S, 2013, NEUROSCI BIOBEHAV R, V37, P491, DOI 10.1016/j.neubiorev.2013.01.012
   Ugur E, 2011, ROBOT AUTON SYST, V59, P580, DOI 10.1016/j.robot.2011.04.005
   Weng JY, 2001, SCIENCE, V291, P599, DOI 10.1126/science.291.5504.599
   Willatts P, 1999, DEV PSYCHOL, V35, P651, DOI 10.1037/0012-1649.35.3.651
   Wolpert DM, 2000, NAT NEUROSCI, V3, P1212, DOI 10.1038/81497
   Wolpert DM, 1998, NEURAL NETWORKS, V11, P1317, DOI 10.1016/S0893-6080(98)00066-5
   Wolpert DM, 2003, PHILOS T R SOC B, V358, P593, DOI 10.1098/rstb.2002.1238
   Wolpert DM, 1998, TRENDS COGN SCI, V2, P338, DOI 10.1016/S1364-6613(98)01221-2
NR 93
TC 1
Z9 1
U1 0
U2 1
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2379-8920
EI 2379-8939
J9 IEEE T COGN DEV SYST
JI IEEE Trans. Cogn. Dev. Syst.
PD MAR
PY 2018
VL 10
IS 1
BP 72
EP 87
DI 10.1109/TCDS.2016.26474391
PG 16
WC Computer Science, Artificial Intelligence; Robotics; Neurosciences
SC Computer Science; Robotics; Neurosciences & Neurology
GA FZ3FA
UT WOS:000427470800006
DA 2019-02-18
ER

PT J
AU Van de Perre, G
   Cao, HL
   De Beir, A
   Esteban, PG
   Lefeber, D
   Vanderborght, B
AF Van de Perre, Greet
   Cao, Hoang-Long
   De Beir, Albert
   Esteban, Pablo Gomez
   Lefeber, Dirk
   Vanderborght, Bram
TI Generic method for generating blended gestures and affective functional
   behaviors for social robots
SO AUTONOMOUS ROBOTS
LA English
DT Article
DE Generic gesture system; Pointing; Gestures; Upper body postures;
   Affective gesture
ID BODY MOVEMENT; POINT-LIGHT; IMITATION; EMOTION; PERCEPTION; EXPRESSION;
   MOTION
AB Gesturing is an important modality in human-robot interaction. Up to date, gestures are often implemented for a specific robot configuration and therefore not easily transferable to other robots. To cope with this issue, we presented a generic method to calculate gestures for social robots. The method was designed to work in two modes to allow the calculation of different types of gestures. In this paper, we present the new developments of the method. We discuss how the two working modes can be combined to generate blended emotional expressions and deictic gestures. In certain situations, it is desirable to express an emotional condition through an ongoing functional behavior. Therefore, we implemented the possibility of modulating a pointing or reaching gesture into an affective gesture by influencing the motion speed and amplitude of the posture. The new implementations were validated on virtual models with different configurations, including those of the robots NAO and Justin.
C1 [Van de Perre, Greet; Cao, Hoang-Long; De Beir, Albert; Esteban, Pablo Gomez; Lefeber, Dirk; Vanderborght, Bram] Vrije Univ Brussel, Robot & Multibody Mech Res Grp, Brussels, Belgium.
   [Van de Perre, Greet; Cao, Hoang-Long; De Beir, Albert; Esteban, Pablo Gomez; Lefeber, Dirk; Vanderborght, Bram] Flanders Make, Brussels, Belgium.
RP Van de Perre, G (reprint author), Vrije Univ Brussel, Robot & Multibody Mech Res Grp, Brussels, Belgium.; Van de Perre, G (reprint author), Flanders Make, Brussels, Belgium.
EM Greet.Van.de.Perre@vub.ac.be
OI Cao, Hoang-Long/0000-0003-2851-5527; Gomez Esteban,
   Pablo/0000-0002-1721-9338
FU Fund for Scientific Research (FWO) Flanders; EU-Project DREAM [611391]
FX The first author is funded by the Fund for Scientific Research (FWO)
   Flanders. This work is partially funded by the EU-Project DREAM
   (611391). Robotics and Multibody Mechanics Research Group is partner of
   the Agile and Human Centered Production and Robotic Systems Research
   Priority of Flanders Make. The authors would like to thank DLR for
   sharing the virtual model of Justin.
CR Alissandrakis A, 2002, IEEE T SYST MAN CY A, V32, P482, DOI 10.1109/TSMCA.2002.804820
   Amaya K, 1996, PROC GRAPH INTERF, P222
   Andry P, 2001, IEEE T SYST MAN CY A, V31, P431, DOI 10.1109/3468.952717
   Ascher U, 1998, COMPUTER METHODS ORD
   Atkinson AP, 2004, PERCEPTION, V33, P717, DOI 10.1068/p5096
   Azad P, 2007, IEEE INT CONF ROBOT, P2558, DOI 10.1109/ROBOT.2007.363850
   Balit E, 2016, ELEVENTH ACM/IEEE INTERNATIONAL CONFERENCE ON HUMAN ROBOT INTERACTION (HRI'16), P417, DOI 10.1109/HRI.2016.7451784
   Belpaeme T, 2012, J HUM-ROBOT INTERACT, V1, P33, DOI 10.5898/JHRI.1.2.Belpaeme
   Breazeal C, 2005, 2005 IEEE/RSJ International Conference on Intelligent Robots and Systems, Vols 1-4, P383, DOI 10.1109/IROS.2005.1545011
   Castellano G, 2007, LECT NOTES COMPUT SC, V4738, P71
   Coulson M, 2004, J NONVERBAL BEHAV, V28, P117, DOI 10.1023/B:JONB.0000023655.25550.be
   Crane E, 2007, LECT NOTES COMPUT SC, V4738, P95
   Dautenhahn K., 2002, CORRES PROBLEM
   DEMEIJER M, 1989, J NONVERBAL BEHAV, V13, P247, DOI 10.1007/BF00990296
   Dittrich WH, 1996, PERCEPTION, V25, P727, DOI 10.1068/p250727
   Do Martin, 2008, 2008 8th IEEE-RAS International Conference on Humanoid Robots (Humanoids 2008), P545, DOI 10.1109/ICHR.2008.4756029
   Hild M., 2012, LANGUAGE GROUNDING R, P25
   Hirukawa H, 2004, ROBOT AUTON SYST, V48, P165, DOI 10.1016/j.robot.2004.07.007
   Ido J, 2006, 2006 IEEE/RSJ International Conference on Intelligent Robots and Systems, Vols 1-12, P1316, DOI 10.1109/IROS.2006.281896
   Itoh K., 2004, 2004 First IEEE Technical Exhibition Based Conference on Robotics and Automation (IEEE Cat. No.04EX878), P35
   James WT, 1932, J GEN PSYCHOL, V7, P405, DOI 10.1080/00221309.1932.9918475
   Junchao Xu, 2013, 2013 IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN), P533, DOI 10.1109/ROMAN.2013.6628534
   JUNG ES, 1995, INT J IND ERGONOM, V16, P95, DOI 10.1016/0169-8141(94)00088-K
   KADABA MP, 1990, J ORTHOP RES, V8, P383, DOI 10.1002/jor.1100080310
   Koga Y., 1994, Computer Graphics Proceedings. Annual Conference Series 1994. SIGGRAPH 94 Conference Proceedings, P395
   Li GD, 2006, CONF CYBERN INTELL S, P110
   Lin YH, 2009, LECT NOTES ARTIF INT, V5773, P308
   Matsui D., 2005, 2005 IEEE/RSJ International Conference on Intelligent Robots and Systems, P3301
   MONTEPARE JM, 1987, J NONVERBAL BEHAV, V11, P33, DOI 10.1007/BF00999605
   Muhlig M, 2012, AUTON ROBOT, V32, P97, DOI 10.1007/s10514-011-9261-0
   Park E, 2011, HUMAN COMPUTER INTER, V6, P91
   Pelachaud C, 2009, SPEECH COMMUN, V51, P630, DOI 10.1016/j.specom.2008.04.009
   Pollick FE, 2001, COGNITION, V82, pB51, DOI 10.1016/S0010-0277(01)00147-0
   Posner J, 2005, DEV PSYCHOPATHOL, V17, P715, DOI 10.1017/S0954579405050340
   Quoc Anh Le, 2011, 2011 11th IEEE-RAS International Conference on Humanoid Robots (Humanoids 2011), P134, DOI 10.1109/Humanoids.2011.6100857
   Salem M., 2010, P ICRA 2010 WORKSH I
   Salem M, 2013, INT J SOC ROBOT, V5, P313, DOI 10.1007/s12369-013-0196-9
   Salem M, 2009, COGN SYST MONOGR, V6, P173
   Scheutz M, 2007, AUTON ROBOT, V22, P411, DOI 10.1007/s10514-006-9018-3
   Siciliano B, 2009, ADV TXB CONTR SIG PR, P1
   SOECHTING JF, 1989, J NEUROPHYSIOL, V62, P595
   Stanton C., 2012, P AUSTR C ROB AUT
   Sugiyama Osamu, 2007, 2007 IEEE/RSJ International Conference on Intelligent Robots and Systems, P1441
   Tapus A, 2012, INTERACT STUD, V13, P315, DOI 10.1075/is.13.3.01tap
   Terlemez O, 2014, IEEE-RAS INT C HUMAN, P894, DOI 10.1109/HUMANOIDS.2014.7041470
   Van de Perre G, 2016, ROBOT AUTON SYST, V83, P32, DOI 10.1016/j.robot.2016.06.006
   Van de Perre G, 2015, ADV ROBOTICS, V29, P597, DOI 10.1080/01691864.2015.1031697
   Wallbott HG, 1998, EUR J SOC PSYCHOL, V28, P879, DOI 10.1002/(SICI)1099-0992(1998110)28:6<879::AID-EJSP901>3.0.CO;2-W
   Xu JC, 2013, INT CONF AFFECT, P558, DOI 10.1109/ACII.2013.98
   Zecca Massimiliano, 2009, RO-MAN 2009 - The 18th IEEE International Symposium on Robot and Human Interactive Communication, P381, DOI 10.1109/ROMAN.2009.5326184
NR 50
TC 0
Z9 0
U1 2
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 0929-5593
EI 1573-7527
J9 AUTON ROBOT
JI Auton. Robot.
PD MAR
PY 2018
VL 42
IS 3
BP 569
EP 580
DI 10.1007/s10514-017-9650-0
PG 12
WC Computer Science, Artificial Intelligence; Robotics
SC Computer Science; Robotics
GA FW2DY
UT WOS:000425113800004
DA 2019-02-18
ER

PT J
AU Rojas, M
   Ponce, P
   Molina, A
AF Rojas, Mario
   Ponce, Pedro
   Molina, Arturo
TI A fuzzy logic navigation controller implemented in hardware for an
   electric wheelchair
SO INTERNATIONAL JOURNAL OF ADVANCED ROBOTIC SYSTEMS
LA English
DT Article
DE Artificial intelligence; assistive technology; collision avoidance;
   fuzzy logic; FPGA; smart wheelchairs; ultrasonic sensors
ID SMART WHEELCHAIR; INTELLIGENT WHEELCHAIR; SYSTEM; ENVIRONMENTS;
   DISABILITIES; AVOIDANCE; COMMANDS; DESIGN
AB In this article, we present an obstacle avoidance controller implemented in a field programmable gate array for an electric wheelchair. It is based on a traditional approach with ultrasonic sensors and fuzzy logic. Various tests were conducted to characterize the prototype and to evaluate the controller performance. The results showed that the system is able to acquire data from sensors and make decisions 46.16 times per second. The sensors' coverage extends 3 m to the front, rear, left, and right sides of the wheelchair; moreover, the sensors detect 0.95-cm diameter objects at 40 cm. The power consumption was evaluated, and it was found that the hardware architecture reduces the battery life by only 0.87%. Furthermore, the controller helped to navigate in confined areas, avoiding obstacles with cautious movements and decreasing the likelihood of collision. The proposed methodology uses data from eight sonars distributed around the wheelchair to make navigation decisions, besides the hardware-based architecture guarantees real-time control and on-time response.
C1 [Rojas, Mario; Ponce, Pedro; Molina, Arturo] Tecnol Monterrey, Natl Dept Res, 222 Del Tlalpan, Mexico City 14380, DF, Mexico.
RP Rojas, M (reprint author), Tecnol Monterrey, Natl Dept Res, Campus Ciudad Mexico,Calle Del Puente 222, Tlalpan 14380, DF, Mexico.
EM ramjorh@gmail.com
CR 546345 C., 2014, J CHEM, V2014, P10, DOI DOI 10.1155/2014/425497
   Baklouti E, 2017, ROBOT AUTON SYST, V89, P9, DOI 10.1016/j.robot.2016.09.001
   Bayar V, 2014, 2014 IEEE INTERNATIONAL SYMPOSIUM ON INNOVATIONS IN INTELLIGENT SYSTEMS AND APPLICATIONS (INISTA 2014), P162, DOI 10.1109/INISTA.2014.6873613
   BORENSTEIN J, 1991, IEEE T ROBOTIC AUTOM, V7, P278, DOI 10.1109/70.88137
   Boucher P, 2013, J NEUROENG REHABIL, V10, DOI 10.1186/1743-0003-10-58
   Bourhis G, 2001, IEEE ROBOT AUTOM MAG, V8, P20, DOI 10.1109/100.924353
   Bryner R, 2004, CISC VIS NETW IND GL
   Cavanini L., 2014, IEEE ASME INT C MECH, P1, DOI DOI 10.1109/MESA.2014.6935628
   Desai S., 2017, 2017 INT C NASC TECH, P1, DOI DOI 10.1109/ICNTE.2017.7947914
   Eid MA, 2016, IEEE ACCESS, V4, P558, DOI 10.1109/ACCESS.2016.2520093
   Fehr L, 2000, J REHABIL RES DEV, V37, P353
   Gomi T., 1998, Assistive technology and artificial intelligence. Applications in robotics, user interfaces and natural language processing, P150
   Hadj-Abdelkader MA, 2012, APPL BIONICS BIOMECH, V9, P181, DOI 10.3233/ABB-2012-0067
   HONG TS, 2012, CONTROLS CONCEPTS TH, P21, DOI DOI 10.5772/36358
   How TV, 2013, J NEUROENG REHABIL, V10, DOI 10.1186/1743-0003-10-90
   Hsu PE, 2012, INT J ADV ROBOT SYST, V9, DOI 10.5772/54819
   Ito T, 2013, INT J ADV ROBOT SYST, V10, DOI 10.5772/56450
   Kuo CH, 2007, IEEE INT C SYST MAN, P2939, DOI 10. 1109/ICSMC. 2007. 4414123. Fuzzy/behaviour/low cost
   Leaman J, 2017, IEEE T HUM-MACH SYST, V47, P486, DOI 10.1109/THMS.2017.2706727
   Leishman F, 2010, ROBOT AUTON SYST, V58, P1149, DOI 10.1016/j.robot.2010.06.007
   Levine S P, 1999, IEEE Trans Rehabil Eng, V7, P443, DOI 10.1109/86.808948
   Li ZJ, 2017, IEEE-ASME T MECH, V22, P185, DOI 10.1109/TMECH.2016.2606642
   LoPresti EF, 2011, J REHABIL RES DEV, V48, P529, DOI 10.1682/JRRD.2010.01.0008
   Luis Conde Bento GP, 2002, P 5 PORT C AUT CONTR, P341
   Braga RAM, 2011, J REHABIL RES DEV, V48, P1061, DOI 10.1682/JRRD.2010.08.0139
   Mazo M., 1995, Autonomous Robots, V2, P203, DOI 10.1007/BF00710857
   Melendez A, 2013, INT J ADV ROBOT SYST, V10, DOI 10.5772/55561
   Montesano L, 2010, IEEE T NEUR SYS REH, V18, P193, DOI 10.1109/TNSRE.2009.2039592
   Nguyen JS, 2013, IEEE ENG MED BIO, P4597, DOI 10.1109/EMBC.2013.6610571
   Nisbet PD, 2002, PROCEEDINGS OF THE 2002 IEEE INTERNATIONAL CONFERENCE ON CONTROL APPLICATIONS, VOLS 1 & 2, P760
   Omrane H, 2016, COMPUT INTEL NEUROSC, DOI 10.1155/2016/9548482
   Pires G, 2002, J INTELL ROBOT SYST, V34, P301, DOI 10.1023/A:1016363605613
   Poplawski Marek, 2008, 2008 Conference on Human System Interactions, P405, DOI 10.1109/HSI.2008.4581473
   Rahman N, 2005, IEEE: 2005 INTERNATIONAL CONFERENCE ON EMERGING TECHNOLOGIES, PROCEEDINGS, P230, DOI 10.1109/ICET.2005.1558886
   Rao R.S., 2002, P IEEE INT C ROB AUT, V4, P3583
   Rofer Thomas, 2009, 2009 IEEE International Conference on Rehabilitation Robotics: Reaching Users & the Community (ICORR), P743, DOI 10.1109/ICORR.2009.5209506
   Simpson RC, 2002, IEEE T NEUR SYS REH, V10, P118, DOI 10.1109/TNSRE.2002.1031980
   Simpson RC, 2005, J REHABIL RES DEV, V42, P423, DOI 10.1682/JRRD.2004.08.0101
   Sinyukov D, 2014, INTEL SERV ROBOT, V7, P145, DOI 10.1007/s11370-014-0149-7
   TalebiFard P, 2014, IEEE INT C INT ROBOT, P3592, DOI 10.1109/IROS.2014.6943065
   Thongchai S, 2000, PROCEEDINGS OF THE 2000 IEEE INTERNATIONAL CONFERENCE ON CONTROL APPLICATIONS, P425, DOI 10.1109/CCA.2000.897461
   Tomari R, 2013, INT J ADV ROBOT SYST, V10, DOI 10.5772/55477
   Tyagi Vishal, 2013, 2013 IEEE Global Humanitarian Technology Conference: South Asia Satellite (GHTC-SAS), P175, DOI 10.1109/GHTC-SAS.2013.6629911
   Urdiales C, 2011, AUTON ROBOT, V30, P179, DOI 10.1007/s10514-010-9211-2
   Wang C, 2016, ROBOTICA, V34, P1880, DOI 10.1017/S0263574714002641
   Ying-Shieh Kung, 2010, 2010 8th IEEE International Conference on Industrial Informatics (INDIN 2010), P523, DOI 10.1109/INDIN.2010.5549687
   Zal F, 2013, 2013 INTERNATIONAL CONFERENCE ON ADVANCED ROBOTICS AND INTELLIGENT SYSTEMS (ARIS), P158, DOI 10.1109/ARIS.2013.6573552
   Zhang R, 2016, IEEE T NEUR SYS REH, V24, P128, DOI 10.1109/TNSRE.2015.2439298
NR 48
TC 2
Z9 2
U1 4
U2 17
PU SAGE PUBLICATIONS INC
PI THOUSAND OAKS
PA 2455 TELLER RD, THOUSAND OAKS, CA 91320 USA
SN 1729-8814
J9 INT J ADV ROBOT SYST
JI Int. J. Adv. Robot. Syst.
PD FEB 11
PY 2018
VL 15
IS 1
AR 1729881418755768
DI 10.1177/1729881418755768
PG 12
WC Robotics
SC Robotics
GA FV7WQ
UT WOS:000424796600001
OA DOAJ Gold
DA 2019-02-18
ER

PT J
AU Merad, M
   de Montalivet, E
   Touillet, A
   Martinet, N
   Roby-Brami, A
   Jarrasse, N
AF Merad, Manelle
   de Montalivet, Etienne
   Touillet, Amelie
   Martinet, Noel
   Roby-Brami, Agnes
   Jarrasse, Nathanael
TI Can We Achieve Intuitive Prosthetic Elbow Control Based on Healthy Upper
   Limb Motor Strategies?
SO FRONTIERS IN NEUROROBOTICS
LA English
DT Article
DE upper limb prosthetics; transhumeral amputation; prosthetic elbow
   control; inter-joint coordination; compensatory strategies
ID ARTIFICIAL NEURAL-NETWORKS; REACHING TASKS; ARM; MOVEMENTS; SYNERGIES;
   DESIGN
AB Most transhumeral amputees report that their prosthetic device lacks functionality, citing the control strategy as a major limitation. Indeed, they are required to control several degrees of freedom with muscle groups primarily used for elbow actuation. As a result, most of them choose to have a one-degree-of-freedom myoelectric hand for grasping objects, a myoelectric wrist for pronation/supination, and a body-powered elbow. Unlike healthy upper limb movements, the prosthetic elbow joint angle, adjusted prior to the motion, is not involved in the overall upper limb movements, causing the rest of the body to compensate for the lack of mobility of the prosthesis. A promising solution to improve upper limb prosthesis control exploits the residual limb mobility: like in healthy movements, shoulder and prosthetic elbow motions are coupled using inter-joint coordination models. The present study aims to test this approach. A transhumeral amputated individual used a prosthesis with a residual limb motion-driven elbow to point at targets. The prosthetic elbow motion was derived from IMU-based shoulder measurements and a generic model of inter-joint coordinations built from healthy individuals data. For comparison, the participant also performed the task while the prosthetic elbow was implemented with his own myoelectric control strategy. The results show that although the transhumeral amputated participant achieved the pointing task with a better precision when the elbow was myoelectrically-controlled, he had to develop large compensatory trunk movements. Automatic elbow control reduced trunk displacements, and enabled a more natural body behavior with synchronous shoulder and elbow motions. However, due to socket impairments, the residual limb amplitudes were not as large as those of healthy shoulder movements. Therefore, this work also investigates if a control strategy whereby prosthetic joints are automatized according to healthy individuals' coordination models can lead to an intuitive and natural prosthetic control.
C1 [Merad, Manelle; de Montalivet, Etienne; Roby-Brami, Agnes; Jarrasse, Nathanael] Sorbonne Univ, UPMC Univ Paris 06, Inst Syst Intelligents & Robot, Agathe Grp, Paris, France.
   [Merad, Manelle; de Montalivet, Etienne; Roby-Brami, Agnes; Jarrasse, Nathanael] CNRS, UMR 7222, Paris, France.
   [Merad, Manelle; de Montalivet, Etienne; Roby-Brami, Agnes; Jarrasse, Nathanael] INSERM, U1150, Paris, France.
   [Touillet, Amelie; Martinet, Noel] UGECAM Nord Est, Inst Reg Med Phys & Readaptat, Ctr Louis Pierquin, Nancy, France.
RP Jarrasse, N (reprint author), Sorbonne Univ, UPMC Univ Paris 06, Inst Syst Intelligents & Robot, Agathe Grp, Paris, France.; Jarrasse, N (reprint author), CNRS, UMR 7222, Paris, France.; Jarrasse, N (reprint author), INSERM, U1150, Paris, France.
EM jarrasse@isir.upmc.fr
RI Roby-Brami, Agnes/K-5759-2017
OI Roby-Brami, Agnes/0000-0002-6196-7229
FU Sorbonne Universite (project PROCOSY) as part of the Idex SUPER; ANR
   (project PhantoMovControl) [ANR-15-CE19-0008-02]; Lahex SMART - French
   state funds [ANR-11-LABX-65, ANR-11-IDEX-0004-02]
FX The study was financially supported by Sorbonne Universite (project
   PROCOSY) as part of the Idex SUPER, by the ANR (project PhantoMovControl
   ANR-15-CE19-0008-02) and the Lahex SMART (ANR-11-LABX-65) supported by
   French state funds managed by the ANR within the Investissements
   d'Avenir programme under reference ANR-11-IDEX-0004-02.
CR Abboudi R L, 1999, IEEE Trans Rehabil Eng, V7, P121, DOI 10.1109/86.769401
   Akhlaghi N, 2016, IEEE T BIO-MED ENG, V63, P1687, DOI 10.1109/TBME.2015.2498124
   Akhtar A, 2012, IEEE ENG MED BIO, P4160, DOI 10.1109/EMBC.2012.6346883
   Alshammary NA, 2016, IEEE INT CONF ROBOT, P3723, DOI 10.1109/ICRA.2016.7487559
   Atkins D. J., 1996, J PROSTHET ORTHOT, V8, P2
   Barton JE, 2014, J REHABIL RES DEV, V51, P711, DOI 10.1682/JRRD.2013.05.0120
   Belter JT, 2013, J REHABIL RES DEV, V50, P599, DOI 10.1682/JRRD.2011.10.0188
   Bernstein N., 1967, COORDINATION REGULAT
   Biddiss E, 2007, AM J PHYS MED REHAB, V86, P977, DOI 10.1097/PHM.0b013e3181587f6c
   Bockemuhl T, 2010, HUM MOVEMENT SCI, V29, P73, DOI 10.1016/j.humov.2009.03.003
   BOTTOMLEY A H, 1965, J Bone Joint Surg Br, V47, P411
   Castellini C, 2014, FRONT NEUROROBOTICS, V8, P1, DOI 10.3389/fnbot.2014.00022
   Cho E, 2016, FRONT BIOENG BIOTECH, V4, DOI 10.3389/fbioe.2016.00018
   Day S., 2002, IMPORTANT FACTORS SU
   de Groot JH, 2011, CLIN BIOMECH, V26, P713, DOI 10.1016/j.clinbiomech.2011.03.001
   Deijs M, 2016, J NEUROENG REHABIL, V13, DOI 10.1186/s12984-016-0130-0
   Farokhzadi M., 2017, J BIOMED PHYS ENG, V7, P1, DOI 10.22086/jbpe.v0i0.524
   Gable C., 1997, Annales de Readaptation et de Medecine Physique, V40, P95, DOI 10.1016/S0168-6054(97)83377-6
   GIBBONS DT, 1987, IEEE T BIO-MED ENG, V34, P493, DOI 10.1109/TBME.1987.325978
   Gonzalez DS, 2013, FRONT NEUROROBOTICS, V7, DOI 10.3389/fnbot.2013.00017
   Hussaini A, 2017, PROSTHET ORTHOT INT, V41, P286, DOI 10.1177/0309364616660248
   Iftime SD, 2005, IEEE T NEUR SYS REH, V13, P482, DOI 10.1109/TNSRE.2005.858458
   Kaliki RR, 2008, P IEEE, V96, P1217, DOI 10.1109/JPROC.2008.922591
   LACQUANITI F, 1982, J NEUROSCI, V2, P399, DOI 10.1523/JNEUROSCI.02-04-00399.1982
   Latash ML, 1999, HUM MOVEMENT SCI, V18, P3, DOI 10.1016/S0167-9457(98)00029-3
   Lipschutz RD, 2011, J REHABIL RES DEV, V48, P661, DOI 10.1682/JRRD.2010.04.0072
   Madgwick S. O. H., 2010, EFFICIENT ORIENTATIO
   Merad M., 2016, P INT C BIOM ROB BIO, P829
   Merad M, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P5677, DOI 10.1109/IROS.2016.7759835
   Metzger AJ, 2012, ARCH PHYS MED REHAB, V93, P2029, DOI 10.1016/j.apmr.2012.03.011
   Micera S, 2005, CLIN BIOMECH, V20, P939, DOI 10.1016/j.clinbiotech.2005.06.004
   Mijovic B, 2008, BRAZ J MED BIOL RES, V41, P389, DOI 10.1590/S0100-879X2008005000019
   Miller L. A., 2009, JPO J PROSTHETICS OR, V21, pP83
   Montagnani F, 2015, IEEE ENG MED BIO, P2462, DOI 10.1109/EMBC.2015.7318892
   Ostlie K, 2011, ARCH PHYS MED REHAB, V92, P1967, DOI 10.1016/j.apmr.2011.06.026
   Roby-Brami A, 2000, BRAIN RES, V869, P121, DOI 10.1016/S0006-8993(00)02378-7
   Silva J, 2003, ELECTRON LETT, V39, P1496, DOI 10.1049/el:20031003
   Stulp F, 2015, NEURAL NETWORKS, V69, P60, DOI 10.1016/j.neunet.2015.05.005
   Wright F., 2006, J PROSTHET ORTHOT, V18, P46, DOI [DOI 10.1097/00008526-200604000-00006, 10.1097/00008526-200604000-00006]
   WRIGHT TW, 1995, J HAND SURG-AM, V20A, P619, DOI 10.1016/S0363-5023(05)80278-3
NR 40
TC 1
Z9 1
U1 5
U2 11
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA PO BOX 110, EPFL INNOVATION PARK, BUILDING I, LAUSANNE, 1015,
   SWITZERLAND
SN 1662-5218
J9 FRONT NEUROROBOTICS
JI Front. Neurorobotics
PD FEB 2
PY 2018
VL 12
AR 1
DI 10.3389/fnbot.2018.00001
PG 11
WC Computer Science, Artificial Intelligence; Robotics; Neurosciences
SC Computer Science; Robotics; Neurosciences & Neurology
GA FU6ZT
UT WOS:000424002300001
PM 29456499
OA DOAJ Gold, Green Published
DA 2019-02-18
ER

PT J
AU Gombolay, MC
   Wilcox, RJ
   Shah, JA
AF Gombolay, Matthew C.
   Wilcox, Ronald J.
   Shah, Julie A.
TI Fast Scheduling of Robot Teams Performing Tasks With Temporospatial
   Constraints
SO IEEE TRANSACTIONS ON ROBOTICS
LA English
DT Article
DE Human-robot teaming; scheduling
ID SIMULATED ANNEALING ALGORITHM; MIXED-INTEGER; BENDERS DECOMPOSITION;
   RESOURCE-ALLOCATION; PROGRAMMING-MODEL; TIME WINDOWS; HEURISTICS;
   ASSIGNMENT; PATH
AB The application of robotics to traditionally manual manufacturing processes requires careful coordination between human and robotic agents in order to support safe and efficient coordinated work. Tasks must be allocated to agents and sequenced according to temporal and spatial constraints. Also, systems must be capable of responding on-the-fly to disturbances and people working in close physical proximity to robots. In this paper, we present a centralized algorithm, named "Tercio," that handles tightly intercoupled temporal and spatial constraints. Our key innovation is a fast, satisficing multi-agent task sequencer inspired by real-time processor scheduling techniques and adapted to leverage a hierarchical problem structure. We use this sequencer in conjunction with a mixed-integer linear program solver and empirically demonstrate the ability to generate near-optimal schedules for real-world problems an order of magnitude larger than those reported in prior art. Finally, we demonstrate the use of our algorithm in a multirobot hardware testbed.
C1 [Gombolay, Matthew C.; Shah, Julie A.] MIT, 77 Massachusetts Ave, Cambridge, MA 02139 USA.
   [Gombolay, Matthew C.] Georgia Inst Technol, Atlanta, GA 30332 USA.
   [Wilcox, Ronald J.] Oliver Wyman, New York, NY USA.
RP Gombolay, MC (reprint author), Georgia Inst Technol, Atlanta, GA 30332 USA.
EM gombolay@csail.mit.edu; Ronald.Wilcox@oliverwyman.com;
   julie_a_shah@csail.mit.edu
FU Boeing Research and Technology; National Science Foundation Graduate
   Research Fellowship Program [2388357]
FX This work was supported in part by Boeing Research and Technology and in
   part by the National Science Foundation Graduate Research Fellowship
   Program under Grant 2388357.
CR Ahmed A, 2005, 2005 International Conference on Integration of Knowledge Intensive Multi-Agent Systems, P311
   Baptiste P., 2000, Constraints, V5, P119, DOI 10.1023/A:1009822502231
   Beard RW, 2002, IEEE T ROBOTIC AUTOM, V18, P911, DOI 10.1109/TRA.2002.805653
   Benders JF, 2005, COMPUT MANAG SCI, V2, P3, DOI 10.1007/s10287-004-0020-y
   Bertsekas D. P., 1990, COMPUTAT OPTIM APPL, V1, P7
   BRUCKER P, 2001, SCHEDULING ALGORITHM
   Campbell AM, 2004, TRANSPORT SCI, V38, P369, DOI 10.1287/trsc.1030.0046
   Castanon DA, 2003, 42ND IEEE CONFERENCE ON DECISION AND CONTROL, VOLS 1-6, PROCEEDINGS, P13
   Castro E, 2012, J SCHEDULING, V15, P333, DOI 10.1007/s10951-011-0239-8
   Cesta A, 2002, J HEURISTICS, V8, P109, DOI 10.1023/A:1013617802515
   CGombolay M., 2013, ROBOTICS SCI SYSTEMS, P4956
   Chen F, 2014, IEEE T AUTOM SCI ENG, V11, P1065, DOI 10.1109/TASE.2013.2274099
   Chen JQ, 2009, EUR J OPER RES, V193, P23, DOI 10.1016/j.ejor.2007.10.040
   Chien S., 2000, Proceedings of the Fourth International Conference on Autonomous Agents, P100, DOI 10.1145/336595.337057
   Choi HL, 2009, IEEE T ROBOT, V25, P912, DOI 10.1109/TRO.2009.2022423
   Cordeau J.-F., 2001, TRANSPORT SCI, V35, P357
   Curtis J., 2003, P AIAA GUID NAV CONT
   Dai M, 2013, ROBOT CIM-INT MANUF, V29, P418, DOI 10.1016/j.rcim.2013.04.001
   Davis L., 1985, P INT C GEN ALG THEI, P136
   DECHTER R, 1991, ARTIF INTELL, V49, P61, DOI 10.1016/0004-3702(91)90006-6
   Devi UC, 2003, 15TH EUROMICRO CONFERENCE ON REAL-TIME SYSTEMS, PROCEEDINGS, P23, DOI 10.1109/EMRTS.2003.1212723
   Drexl A, 2000, EUR J OPER RES, V125, P59, DOI 10.1016/S0377-2217(99)00205-2
   Erdem E., 2012, P 17 IEEE ETFA, P1
   Erdem E, 2012, INTEL SERV ROBOT, V5, P275, DOI 10.1007/s11370-012-0119-x
   Erdem E, 2013, THEOR PRACT LOG PROG, V13, P831, DOI 10.1017/S1471068413000525
   FALKENAUER E, 1991, 1991 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS 1-3, P824, DOI 10.1109/ROBOT.1991.131689
   FANG HL, 1993, PROCEEDINGS OF THE FIFTH INTERNATIONAL CONFERENCE ON GENETIC ALGORITHMS, P375
   Fernandez-Viagas V, 2014, COMPUT OPER RES, V45, P60, DOI 10.1016/j.cor.2013.12.012
   FLOYD RW, 1962, COMMUN ACM, V5, P345, DOI 10.1145/367766.368168
   Gendreau M, 1998, OPER RES, V46, P330, DOI 10.1287/opre.46.3.330
   Geoffrion A. M., 1972, Journal of Optimization Theory and Applications, V10, P237, DOI 10.1007/BF00934810
   Gini M, 2015, P AAAI C ART INT, P2110
   Godinho M, 2014, FLEX SERV MANUF J, V26, P408, DOI 10.1007/s10696-012-9143-6
   Gombolay M. C., 2012, P AIAA INF AER, P1
   Gombolay MC, 2014, J AEROSP INFORM SYST, V11, P821, DOI 10.2514/1.I010202
   Gurobi Optimization Inc, 2016, GUROBI OPTIMIZER REF
   Harbour MG, 2003, RTSS 2003: 24TH IEEE INTERNATIONAL REAL-TIME SYSTEMS SYMPOSIUM, PROCEEDINGS, P200, DOI 10.1109/REAL.2003.1253267
   Harjunkoski I, 2002, COMPUT CHEM ENG, V26, P1533, DOI 10.1016/S0098-1354(02)00100-X
   Hooker J., 2000, LOGIC BASED METHODS
   Jain V, 2001, INFORMS J COMPUT, V13, P258, DOI 10.1287/ijoc.13.4.258.9733
   Johnson S. M., 1954, NAV RES LOG, V1, P61, DOI [DOI 10.1002/NAV.3800010110, 10.1002/(ISSN)1931-9193]
   Jones EG, 2011, AUTON ROBOT, V30, P41, DOI 10.1007/s10514-010-9202-3
   Korsah G. A., 2011, THESIS
   Korsah GA, 2013, INT J ROBOT RES, V32, P1495, DOI 10.1177/0278364913496484
   Kushleyev A, 2013, AUTON ROBOT, V35, P287, DOI 10.1007/s10514-013-9349-9
   Laborie P, 2003, ARTIF INTELL, V143, P151, DOI 10.1016/S0004-3702(02)00362-4
   Lakshmanan Karthik, 2010, Proceedings of the 16th IEEE Real-Time and Embedded Technology and Applications Symposium (RTAS 2010), P3, DOI 10.1109/RTAS.2010.38
   Lakshmanan K., 2010, P 1 INT REAL TIM SCH, P12
   Lemaire T, 2004, IEEE INT CONF ROBOT, P3622, DOI 10.1109/ROBOT.2004.1308816
   LENSTRA JK, 1978, OPER RES, V26, P22, DOI 10.1287/opre.26.1.22
   Li HT, 2009, J SCHEDULING, V12, P281, DOI 10.1007/s10951-008-0079-3
   Liu C, 2010, IEEE INT CONF EMBED, P13, DOI 10.1109/RTCSA.2010.14
   Liu L., 2013, P IEEE CUST INT CIRC, P1, DOI DOI 10.1109/FG.2013.6553765
   Martin R. K., 1999, LARGE SCALE LINEAR I
   McIntire M., 2016, INT C AUT AG MULT SY, P1078
   McLain TW, 2005, J GUID CONTROL DYNAM, V28, P150, DOI 10.2514/1.5791
   Mercier A, 2005, COMPUT OPER RES, V32, P1451, DOI 10.1016/j.cor.2003.11.013
   Mousavi SM, 2013, J MANUF SYST, V32, P335, DOI 10.1016/j.jmsy.2012.12.002
   Muscettola N., 1998, 6 INT C PRINC KNOWL, P444
   OSMAN IH, 1989, OMEGA-INT J MANAGE S, V17, P551, DOI 10.1016/0305-0483(89)90059-5
   PATTERSON JH, 1984, MANAGE SCI, V30, P854, DOI 10.1287/mnsc.30.7.854
   PINTO JM, 1995, IND ENG CHEM RES, V34, P3037, DOI 10.1021/ie00048a015
   Plaku Erion, 2012, Advances in Autonomous Robotics. Joint Proceedings of the 13th Annual TAROS Conference and the 15th Annual FIRA RoboWorld Congress, P331, DOI 10.1007/978-3-642-32527-4_30
   Planken L, 2012, J ARTIF INTELL RES, V43, P353, DOI 10.1613/jair.3509
   Ponda S, 2010, P AMER CONTR CONF, P3998
   Rajkumar R. R., 1991, TECH REP
   Rekik M, 2004, ANN OPER RES, V128, P111, DOI 10.1023/B:ANOR.0000019101.29692.2c
   Ren HZ, 2009, 2009 IEEE INTERNATIONAL CONFERENCE ON AUTOMATION AND LOGISTICS ( ICAL 2009), VOLS 1-3, P890, DOI 10.1109/ICAL.2009.5262795
   Ridouard F., 2006, P 25 IEEE INT REAL T, P47
   Sariel S., 2005, P AAAI 05 WORKSH INT, P27
   Shima T, 2005, P AMER CONTR CONF, P4107
   Smith DE, 2000, KNOWL ENG REV, V15, P47, DOI 10.1017/S0269888900001089
   SOLOMON MM, 1987, OPER RES, V35, P254, DOI 10.1287/opre.35.2.254
   SOTSKOV YN, 1995, DISCRETE APPL MATH, V59, P237, DOI 10.1016/0166-218X(93)E0169-Y
   Sung C, 2013, IEEE INT CONF ROBOT, P2999, DOI 10.1109/ICRA.2013.6630993
   SYCARA KP, 1991, IEEE EXPERT, V6, P29, DOI 10.1109/64.73815
   Tan W, 2004, J INTELL MANUF, V15, P593, DOI 10.1023/B:JIMS.0000037710.80847.b6
   Topcuoglu H, 1999, PROC HETER COMP WORK, P3, DOI 10.1109/HCW.1999.765092
   Tsamardinos I, 2003, ARTIF INTELL, V151, P43, DOI 10.1016/S0004-3702(03)00113-9
   Tsamardinos I, 1998, FIFTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-98) AND TENTH CONFERENCE ON INNOVATIVE APPLICATIONS OF ARTIFICAL INTELLIGENCE (IAAI-98) - PROCEEDINGS, P254
   VANLAARHOVEN PJM, 1992, OPER RES, V40, P113, DOI 10.1287/opre.40.1.113
   Vilim P, 2005, CONSTRAINTS, V10, P403, DOI 10.1007/s10601-005-2814-0
   Wang L, 2002, INT J ADV MANUF TECH, V20, P72, DOI 10.1007/s001700200126
   Wilcox R., 2012, ROBOTICS SCI SYSTEMS, P441
   Zavlanos MM, 2008, IEEE DECIS CONTR P, P1212, DOI 10.1109/CDC.2008.4739098
   Zhang F., 1997, IEEE Transactions on Evolutionary Computation, V1, P278, DOI 10.1109/4235.687888
   Zhang FX, 2009, IEEE T COMPUT, V58, P1250, DOI 10.1109/TC.2009.58
   Zhang LP, 2015, EUR J OPER RES, V244, P434, DOI 10.1016/j.ejor.2015.01.032
   Zhao H., 2007, P 3 INT C AUT AUT SY, P22
NR 89
TC 1
Z9 1
U1 1
U2 8
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1552-3098
EI 1941-0468
J9 IEEE T ROBOT
JI IEEE Trans. Robot.
PD FEB
PY 2018
VL 34
IS 1
BP 220
EP 239
DI 10.1109/TRO.2018.2795034
PG 20
WC Robotics
SC Robotics
GA FV6NP
UT WOS:000424698400016
DA 2019-02-18
ER

PT J
AU Kermavnar, T
   Power, V
   de Eyto, A
   O'Sullivan, LW
AF Kermavnar, Tjasa
   Power, Valerie
   de Eyto, Adam
   O'Sullivan, Leonard W.
TI Computerized Cuff Pressure Algometry as Guidance for Circumferential
   Tissue Compression for Wearable Soft Robotic Applications: A Systematic
   Review
SO SOFT ROBOTICS
LA English
DT Review
DE cuff pressure algometry; tissue compression; discomfort; exoskeleton;
   pressure
ID INTERFACE PRESSURE; TEMPORAL SUMMATION; SPATIAL SUMMATION; PAIN; DEEP;
   MUSCLE; HYPERSENSITIVITY; BIOMECHANICS; DEFORMATION; RELIABILITY
AB In this article, we review the literature on quantitative sensory testing of deep somatic pain by means of computerized cuff pressure algometry (CPA) in search of pressure-related safety guidelines for wearable soft exoskeleton and robotics design. Most pressure-related safety thresholds to date are based on interface pressures and skin perfusion, although clinical research suggests the deep somatic tissues to be the most sensitive to excessive loading. With CPA, pain is induced in deeper layers of soft tissue at the limbs. The results indicate that circumferential compression leads to discomfort at approximate to 16-34kPa, becomes painful at approximate to 20-27kPa, and can become unbearable even below 40kPa.
C1 [O'Sullivan, Leonard W.] Univ Limerick, Sch Design, Limerick V94 T9PX, Ireland.
   [O'Sullivan, Leonard W.] Univ Limerick, Hlth Res Inst, Limerick V94 T9PX, Ireland.
RP O'Sullivan, LW (reprint author), Univ Limerick, Sch Design, Limerick V94 T9PX, Ireland.; O'Sullivan, LW (reprint author), Univ Limerick, Hlth Res Inst, Limerick V94 T9PX, Ireland.
EM leonard.osullivan@ul.ie
OI Power, Valerie/0000-0002-1518-459X; O'Sullivan,
   Leonard/0000-0002-0255-1979
FU European Union's Horizon 2020 framework programme for research and
   innovation [688175]
FX This research was completed as part of the XoSoft project, which has
   received funding from the European Union's Horizon 2020 framework
   programme for research and innovation under grant agreement number
   688175.
CR Agam L, 2007, J Wound Care, V16, P336
   Anderson RJ, 2013, EUR J PAIN, V17, P67, DOI 10.1002/j.1532-2149.2012.00190.x
   Asbeck AT, 2014, IEEE ROBOT AUTOM MAG, V21, P22, DOI 10.1109/MRA.2014.2360283
   BADER D L, 1990, Journal of Rehabilitation Research and Development, V27, P141, DOI 10.1682/JRRD.1990.04.0141
   Black Joyce, 2007, Urol Nurs, V27, P144
   Bouten CV, 2003, ARCH PHYS MED REHAB, V84, P616, DOI 10.1053/apmr.2003.50038
   Chan A.P., 2002, INT J CLOTH SCI TECH, V14, P100
   CRENSHAW AG, 1988, ACTA ORTHOP SCAND, V59, P447, DOI 10.3109/17453678809149401
   De Rossi SMM, 2011, SENSORS-BASEL, V11, P207, DOI 10.3390/s110100207
   Defloor T, 1999, J CLIN NURS, V8, P206, DOI 10.1046/j.1365-2702.1999.00254.x
   Defrin R, 2003, PAIN, V106, P471, DOI 10.1016/j.pain.2003.09.010
   Estebe JP, 2000, ANAESTHESIA, V55, P21, DOI 10.1046/j.1365-2044.2000.01128.x
   Gefen A, 2005, J BIOMECH ENG-T ASME, V127, P512, DOI 10.1115/1.1894386
   Graven-Nielsen T, 2008, FUNDAMENTALS MUSCULO, P347
   Graven-Nielsen T, 2015, PAIN, V156, P2193, DOI 10.1097/j.pain.0000000000000294
   Greenspan JD, 1997, SOMATOSENS MOT RES, V14, P107, DOI 10.1080/08990229771105
   Izumi M, 2014, PAIN, V155, P792, DOI 10.1016/j.pain.2014.01.008
   Jespersen A, 2007, PAIN, V131, P57, DOI 10.1016/j.pain.2006.12.012
   John GW, 2007, P ANN INT IEEE EMBS, P2122, DOI 10.1109/IEMBS.2007.4352741
   Khanian BM, 2016, PAIN MED, V17, P915, DOI 10.1093/pm/pnv063
   Latremoliere A, 2009, J PAIN, V10, P895, DOI 10.1016/j.jpain.2009.06.012
   Lemming D, 2017, PAIN MED, V18, P1573, DOI 10.1093/pm/pnw309
   Linder-Ganz E, 2009, J BIOMECH ENG-T ASME, V131, DOI 10.1115/1.3005195
   Mak AFT, 2001, J REHABIL RES DEV, V38, P161
   Mak AFT, 2010, ANNU REV BIOMED ENG, V12, P29, DOI 10.1146/annurev-bioeng-070909-105223
   Makhsous M, 2012, HUM FACTORS, V54, P1066, DOI 10.1177/0018720812457681
   Manafi-Khanian B, 2015, EUR J PAIN, V19, P1456, DOI 10.1002/ejp.677
   Manafi-Khanian B, 2016, MED BIOL ENG COMPUT, V54, P315, DOI 10.1007/s11517-015-1291-x
   MOORE MR, 1987, J HAND SURG-AM, V12A, P1006, DOI 10.1016/S0363-5023(87)80098-9
   Olsen JK, 2017, PAIN PRACT, V17, P708, DOI 10.1111/papr.12514
   Oomens CWJ, 2010, J TISSUE VIABILITY, V19, P35, DOI 10.1016/j.jtv.2009.11.002
   Polianskis R, 2002, PAIN, V100, P19, DOI 10.1016/S0304-3959(02)00162-8
   Polianskis R, 2002, J PAIN, V3, P28, DOI 10.1054/jpai.2002.27140
   Polianskis R, 2001, EUR J PAIN, V5, P267, DOI 10.1053/eujp.2001.0245
   Pons JL., 2008, WEARABLE ROBOTS BIOM, P154
   RAL German Institute for Quality Assurance and Labelling, 2008, REQ COMPR BEH COMPR, P13
   Reenalda J, 2009, ASSIST TECHNOL, V21, P76, DOI 10.1080/10400430903050437
   SANGEORZAN BJ, 1989, J ORTHOPAED RES, V7, P423, DOI 10.1002/jor.1100070315
   Shen WQ, 1997, INT J IND ERGONOM, V20, P441, DOI 10.1016/S0169-8141(96)00068-6
   Staud Roland, 2013, Int J Clin Rheumtol, V8, P639
   Stekelenburg A, 2008, ARCH PHYS MED REHAB, V89, P1410, DOI 10.1016/j.apmr.2008.01.012
   Swain I D, 2002, J Tissue Viability, V12, P132
   Tamez-Duque J, 2015, SENSORS-BASEL, V15, P4550, DOI 10.3390/s150204550
   Vaegter HB, 2017, EUR J PAIN, V21, P73, DOI 10.1002/ejp.901
   Vaegter HB, 2015, EUR J PAIN, V19, P973, DOI 10.1002/ejp.623
NR 45
TC 1
Z9 1
U1 8
U2 20
PU MARY ANN LIEBERT, INC
PI NEW ROCHELLE
PA 140 HUGUENOT STREET, 3RD FL, NEW ROCHELLE, NY 10801 USA
SN 2169-5172
EI 2169-5180
J9 SOFT ROBOT
JI Soft Robot.
PD FEB
PY 2018
VL 5
IS 1
BP 1
EP 16
DI 10.1089/soro.2017.0046
PG 16
WC Robotics
SC Robotics
GA FV2HU
UT WOS:000424386300001
PM 29412078
DA 2019-02-18
ER

PT J
AU Salvini, P
AF Salvini, Pericle
TI Urban robotics: Towards responsible innovations for our cities
SO ROBOTICS AND AUTONOMOUS SYSTEMS
LA English
DT Article
ID ENVIRONMENTS; NAVIGATION; VEHICLES; CHALLENGES; SYSTEMS
C1 [Salvini, Pericle] Scuola Super St Anna Pisa, BioRobot Inst, Pisa, Italy.
RP Salvini, P (reprint author), Scuola Super St Anna Pisa, BioRobot Inst, Pisa, Italy.
EM p.salvini@sssup.it
RI Salvini, Paola/G-1670-2018
OI Salvini, Paola/0000-0001-9207-7256
CR Andrist S, 2013, ACMIEEE INT CONF HUM, P341, DOI 10.1109/HRI.2013.6483608
   [Anonymous], ROBOTICS 2020 MULTI
   [Anonymous], 2016, INS REP I ENG TECHN
   [Anonymous], 2017, DEFINITION ROBOT ENG
   Baker M., 2016, IEEE PERVASIVE COMPU, V15
   Bertolini A., 2016, INT J SOC ROBOT
   Bloomfield Robin E., 2015, IEEE SECUR PRIVACY, V13
   Broggi, 2015, IEEE T INTELL TRANSP, V16
   Campbell M, 2010, PHILOS T R SOC A, V368, P4649, DOI 10.1098/rsta.2010.0110
   Capi G, 2014, ADV ROBOTICS, V28, P1043, DOI 10.1080/01691864.2014.903202
   Chand Aneesh N., 2012, 2012 IEEE ASME INT C
   Chen Tongtong, 2015, 2015 IEEE INT VEH S
   Choia H. R., 2002, MECHATRONICS, V12
   CityMobil project, ADV ROAD TRANSP URB
   Coeckelbergh M., 2013, HUMAN BEING RISK
   DustBot project, FP6045299 DUSTBOT PR
   Effler S. W., 2002, J URBAN TECH, V9
   ENAC, 2013, REM PIL AER VEH REG
   ETSC, 2016, PRIOR SAF POT AUT DR
   Ferrer, 2013, 2013 IEEE RSJ INT C
   Ferri G., 2011, IEEE INT C ROB AUT I
   Ford M, 2015, RISE ROBOTS TECHNOLO
   Forster F., HRI 11 P 6 INT C HUM
   Fritz G, 2005, IEEE INT CONF ROBOT, P131
   Gao C., 2010, FIELD SERV ROB RES 7
   Gless Sabine, 2016, SELF DRIVING CARS CR
   Goller M., 12 INT C CLIMB WALK
   Greenblatt N. A., 2016, IEEE SPECTRUM
   Hagita N., 2016, HUMAN ROBOT HARMONIO
   Haug B. T., 1998, MODELING SIMULATION
   Hayashi Kotaro, 2012, IEEE T AUTON MENT DE, V4
   Hengstler M, 2016, TECHNOL FORECAST SOC, V105, P105, DOI 10.1016/j.techfore.2015.12.014
   Huesemann Michael H., 2011, TECHNO FIX WHY TECHN, P464
   Hydronet project, FP7212790 HYDR PROJ
   Jacob S., 2015, MACHINES LOVING GRAC
   Jiang JG, 2014, IND ROBOT, V41, P429, DOI 10.1108/IR-01-2014-0303
   Jones Raya, 2016, PERSONHOOD SOCIAL RO
   Kahn PH, 2009, CURR DIR PSYCHOL SCI, V18, P37, DOI 10.1111/j.1467-8721.2009.01602.x
   Kaplan J, 2015, HUMANS NEED NOT APPL
   Keynes J. M., 1930, ESSAYS PERSUASION, P358
   Koops Bert-Jaap, 2015, RESPONSIBLE INNOVATI, P4
   Kummerle R, 2015, J FIELD ROBOT, V32, P565, DOI 10.1002/rob.21534
   La Cecla F., 2017, AGAINST URBANISM
   Li J., 2016, 2016010164 SAE
   Li XH, 2016, IEEE-ASME T MECH, V21, P740, DOI 10.1109/TMECH.2015.2493980
   Liu YG, 2013, J INTELL ROBOT SYST, V72, P147, DOI 10.1007/s10846-013-9822-x
   Tur JMM, 2009, ROBOT AUTON SYST, V57, P922, DOI 10.1016/j.robot.2009.06.003
   Morales Y, 2009, J FIELD ROBOT, V26, P609, DOI 10.1002/rob.20301
   Munoz F. M., 2010, OPEN URBAN STUD J, P3
   Murphy, 2004, RESCUE ROBOTICS HOME
   Myeong W. C., 2015, 12 INT C UB ROB AMB
   Owen Richard, RESPONSIBLE RES INNO
   Panos Antsaklis, 1998, P 1998 IEEE ISIC ISA
   Patrick Lin, 2015, WHY ETHICS MATTERS A
   Pfifer Rolf, 2006, BODY SHAPES WAY WE T
   Pratt J. E., 2010, BOOK SERIES P SPIE I, V7692
   Qian J, 2007, ROBOTICA, V25, P351, DOI 10.1017/S0263574706003146
   Reina G, 2015, SENSORS-BASEL, V15, P14661, DOI 10.3390/s150614661
   Richardson S., 1987, P 2 INT OCC ERG S ZA
   Robot I, 2004, 20 CENTURY FOX
   Salvini P., 2011, IEEE ROBOT AUTOM MAG, V18
   Salvini P., 2010, P 19 IEEE INT S ROB
   Salvini P, 2012, INT J TECHNOETHICS, V3, P9, DOI 10.4018/jte.2012040102
   Salvini P, 2010, INT J SOC ROBOT, V2, P451, DOI 10.1007/s12369-010-0079-2
   Sam Jacob, MACHINES LOVING GRAC
   Sanfeliu A., 2010, ADV ROBOT J, V24
   Sanfeliu A, 2008, ROBOT AUTON SYST, V56, P793, DOI 10.1016/j.robot.2008.06.007
   Satake Satoru, 2016, 2016 11 ACM IEEE INT
   Schneier B., 2016, LITTLE BLACK BOOK BI
   Sheriff KD, 2015, DEFINING AUTONOMY CO, DOI 10. 2139/ssrn. 2735945
   Sholtz J., 2003, HAW INT C SYST SCI H
   Smith A., 2014, US VIEWS TECHNOLOGY
   Soloiu V., 2016, 2016010161 SAE
   Special Eurobarometer 427 'Autonomous Systems', 2015, COND TNS OP SOC REQ
   The Royal Academy of Engineering, 2009, AUT SYST SOC LEG ETH
   Trulls E, 2011, J FIELD ROBOT, V28, P329, DOI 10.1002/rob.20386
   Turkle S., 2012, ALONE TOGETHER WHY W
   Turkle S, 2007, INTERACT STUD, V8, P501
   Uhlemann E, 2016, IEEE VEH TECHNOL MAG, V11, P25, DOI 10.1109/MVT.2015.2508322
   United Nations, GOAL 11 MAK CIT INCL
   Urmson C, 2008, IEEE INTELL SYST, V23, P66, DOI 10.1109/MIS.2008.34
   URUS Project, IST045062 URUS PROJ
   Utility Infrastructures and Condition Monitoring for Sewer Network, ROB INSP CLEAR SEW N
   Valentina Gatteschi, 2015, COMP SOFTW APPL C CO, V2
   Vicente K, 2004, HUMAN FACTOR REVOLUT
   von Schomberg R, 2011, RESPONSIBLE RES INNO
   Von Schomberg Rene, 2014, EUROSCIENTIST I 1029
   Wei Yuanlong, 2013, IEEE ASME INT C ADV
   Weiss, 2015, J BEHAV ROBOT, V6
   Weng Y.-H., 2007, ICAIL 07
   Wilheim J, 1996, INT SOC SCI J, V48, P9
   Yokomizo Y., 1987, OCCUPATIONAL HLTH SA, P309
   Yokozuka Masashi, 2012, 2012 IEEE RSJ INT C
NR 93
TC 0
Z9 0
U1 3
U2 3
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0921-8890
EI 1872-793X
J9 ROBOT AUTON SYST
JI Robot. Auton. Syst.
PD FEB
PY 2018
VL 100
BP 278
EP 286
DI 10.1016/j.robot.2017.03.007
PG 9
WC Automation & Control Systems; Computer Science, Artificial Intelligence;
   Robotics
SC Automation & Control Systems; Computer Science; Robotics
GA FU1WE
UT WOS:000423639400022
DA 2019-02-18
ER

PT J
AU Yu, T
   Zhang, ZW
   Zhao, WB
   Fan, TR
   Wang, JL
AF Yu, Tao
   Zhang, Zhao-Wen
   Zhao, Wen-Bin
   Fan, Tong-Rang
   Wang, Jilong
TI A CONTROL POLICY OF INFORMATION FLOW BEHAVIOUR MODEL BASED ON NODE
   HETEROGENEITY
SO INTERNATIONAL JOURNAL OF ROBOTICS & AUTOMATION
LA English
DT Article
DE Information flow; complex network; heterogeneity; behaviour; control
   policy
ID SOCIAL NETWORKS; CENTRALITY
AB The development and improvement of Internet technology has made network information richer and more attractive. Users can access networks more easily and enjoy greater network services. While the Internet provides rich and convenient service, Internet networks also provide greater conditions now for the breeding and spreading of harmful information. The user is subject to information dissemination on the network, and the user's behaviour in information flow has a tremendous impact on information dissemination. In this paper, based on the heterogeneity of the nodes in a network, an information flow model is established, wherein the factors influencing a node's information flow behaviour are researched and categorized as factors internal and external to the node. The internal factor entails the autonomy of a node, which contains the degree of interest and the subjective judgment of the node. The external factors comprise the network structure, the location of the node, and the relationships among the nodes. Considering the issue of the spread of harmful information, a complex network model is built based on the information flow behaviour of the nodes, and a control policy to address harmful information is established.
C1 [Yu, Tao; Wang, Jilong] Tsinghua Univ, Inst Network Sci & Cyberspace, Beijing, Peoples R China.
   [Zhang, Zhao-Wen; Zhao, Wen-Bin; Fan, Tong-Rang] Shijiazhuang Tiedao Univ, Sch Informat Sci & Technol, Shijiazhuang, Hebei, Peoples R China.
RP Fan, TR (reprint author), Shijiazhuang Tiedao Univ, Sch Informat Sci & Technol, Shijiazhuang, Hebei, Peoples R China.
EM yu_tao@mail.tsinghua.edu.cn; 1289356001@qq.com; zhaowb.email@qq.com;
   fantr2009@126.com; wjl@cernet.edu.cn
FU National Natural Science Foundation of China [61373160]; Standardization
   Processing and Application System Development of Science and
   Technology's Big Data Project [17210113D]; Science and Technology
   Department of Hebei Province
FX This research was financially supported by the National Natural Science
   Foundation of China (Grant No. 61373160), and the Standardization
   Processing and Application System Development of Science and
   Technology's Big Data Project (Grant No. 17210113D) of the Science and
   Technology Department of Hebei Province.
CR Aydin MA, 2009, COMPUT ELECTR ENG, V35, P517, DOI 10.1016/j.compeleceng.2008.12.005
   Briscoe Gerard, 2009, 2009 3rd IEEE International Conference on Digital Ecosystems and Technologies (DEST), P103, DOI 10.1109/DEST.2009.5276725
   Chun-Nan Lin, 2011, Information Technology Journal, V10, P146
   Crowston K., 2006, ACTA PHYS SINICA, V6, P118
   Cui P., 2014, SCI REPORTS, V4
   FREEMAN LC, 1977, SOCIOMETRY, V40, P35, DOI 10.2307/3033543
   Gruhl D., 2004, P 13 INT C WORLD WID, P491, DOI DOI 10.1145/988672.988739
   Huang JM, 2014, SCI REP-UK, V4, DOI 10.1038/srep05334
   Kanovsky I, 2013, 2013 ASE/IEEE INTERNATIONAL CONFERENCE ON SOCIAL COMPUTING (SOCIALCOM), P971, DOI 10.1109/SocialCom.2013.154
   Li Q, 2010, INFORM SCIENCES, V180, P4929, DOI 10.1016/j.ins.2010.08.044
   Liginlal D, 2010, LECT NOTES BUS INF P, V52, P166
   Lu DY, 2010, LECT NOTES COMPUT SC, V6335, P74
   [路兰 Lu Lan], 2014, [复杂系统与复杂性科学, Complex Systems and Complexity Science], V11, P44
   Negoescu RA, 2010, IEEE T MULTIMEDIA, V12, P399, DOI 10.1109/TMM.2010.2050649
   Pon RK, 2011, INFORM PROCESS MANAG, V47, P97, DOI 10.1016/j.ipm.2010.03.001
   Poulin R, 2000, SOC NETWORKS, V22, P187, DOI 10.1016/S0378-8733(00)00020-4
   SABIDUSSI G, 1966, PSYCHOMETRIKA, V31, P581, DOI 10.1007/BF02289527
   Shu PP, 2014, 2014 IEEE 17TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL SCIENCE AND ENGINEERING (CSE), P554, DOI 10.1109/CSE.2014.126
   Staab S, 2005, IEEE INTELL SYST, V20, P80, DOI 10.1109/MIS.2005.16
   Waters J., 2010, P 15 INT COMM CONTR, P117
   Wenbin Zhao, 2012, Journal of Software, V7, P2606, DOI 10.4304/jsw.7.11.2606-2613
   Yan S, 2013, PHYSICA A, V392, P3846, DOI 10.1016/j.physa.2013.04.018
   Yang Jian-mei, 2013, Journal of South China University of Technology (Natural Science Edition), V41, P136, DOI 10.3969/j.issn.1000-565X.2013.12.023
   Zhang J, 2011, CHAOS, V21, DOI 10.1063/1.3553644
   Zhang Y, 2015, DISCRETE DYN NAT SOC, DOI 10.1155/2015/649814
   Zhang Z. J., 2011, P 54 ANN IEEE GLOB T
   Zhijie H., 2010, J COMPUTER RES DEV, V47, P128
   Zhu ZQ, 2014, J STAT PHYS, V154, P1569, DOI 10.1007/s10955-014-0924-z
   Zhuo-Ming R., 2013, ACTA PHYS SINICA, V62, P1
NR 29
TC 0
Z9 0
U1 1
U2 1
PU ACTA PRESS
PI CALGARY
PA 2509 DIEPPE AVE SW, BLDG B6, STE 101, CALGARY, AB T3E 7J9, CANADA
SN 0826-8185
EI 1925-7090
J9 INT J ROBOT AUTOM
JI Int. J. Robot. Autom.
PY 2018
VL 33
IS 5
BP 518
EP 526
DI 10.2316/Journal.206.2018.5.206-0069
PG 9
WC Automation & Control Systems; Robotics
SC Automation & Control Systems; Robotics
GA HE7FS
UT WOS:000453596100010
DA 2019-02-18
ER

PT J
AU Peng, Y
   Xu, T
   Hou, L
   Fan, CJ
   Zhou, W
AF Peng, Yong
   Xu, Tuo
   Hou, Lin
   Fan, Chaojie
   Zhou, Wei
TI An Investigation of Dynamic Responses and Head Injuries of Standing
   Subway Passengers during Collisions
SO APPLIED BIONICS AND BIOMECHANICS
LA English
DT Article
ID ACCIDENT RECONSTRUCTION; GROUND IMPACT; VEHICLE; DESIGN
AB With the development of the subway and the pressing demand of environmentally friendly transportation, more and more people travel by subway. In recent decades, the issues about passenger passive safety on the train have received extensive attention. In this research, the head injury of a standing passenger in the subway is investigated. Three MADYMO models of the different standing passenger postures, defined as baseline scenarios, are numerically set up. HIC15 values of passengers with different postures are gained by systematic parametric studies. The injury numerical simulation results of various scenarios with different friction coefficients, collision acceleration, standing angle, horizontal handrail height, and ring handrail height are analyzed. Results show that the horizontal handrail provides better protection in the three different standing passenger postures. Different friction coefficients and the standing angle have great impact on the head injuries of passengers in three different scenarios. The handrail height also has some effects on head injury of passengers with different standing postures, so it is necessary to be considered when designing the interior layout of the subway. This study may provide guidance for the safety design of the subway and some advices for standing subway passengers.
C1 [Peng, Yong; Xu, Tuo; Hou, Lin; Fan, Chaojie; Zhou, Wei] Cent S Univ, Key Lab Traff Safety Track, Minist Educ, Sch Traff & Transportat Engn, Changsha 410075, Hunan, Peoples R China.
   [Peng, Yong] Cent S Univ, State Key Lab High Performance Complex Mfg, Changsha 410006, Hunan, Peoples R China.
   [Xu, Tuo; Hou, Lin] Cent S Univ, Joint Int Res Lab Key Technol Rail Traff Safety, Changsha 410075, Hunan, Peoples R China.
   [Fan, Chaojie; Zhou, Wei] Cent S Univ, Natl & Local Joint Engn Res Ctr Safety Technol Ra, Changsha 410075, Hunan, Peoples R China.
RP Hou, L; Zhou, W (reprint author), Cent S Univ, Key Lab Traff Safety Track, Minist Educ, Sch Traff & Transportat Engn, Changsha 410075, Hunan, Peoples R China.; Hou, L (reprint author), Cent S Univ, Joint Int Res Lab Key Technol Rail Traff Safety, Changsha 410075, Hunan, Peoples R China.; Zhou, W (reprint author), Cent S Univ, Natl & Local Joint Engn Res Ctr Safety Technol Ra, Changsha 410075, Hunan, Peoples R China.
EM houlin@csu.edu.cn; zhou_wei000@126.com
OI PENG, Yong/0000-0003-0101-0342; Hou, Lin/0000-0002-5577-0649
FU National Natural Science Foundation of China [51405517, U1334208];
   Natural Science Foundation of Hunan Province [2015JJ3155]; China
   Postdoctoral Science Foundation [2015M570691]; National Key Research and
   Development Program of China [2016YFB1200505]; Fundamental Research
   Funds for the Central Universities of Central South University
   [2018zzts165]
FX The work was supported by the National Natural Science Foundation of
   China (51405517, U1334208), the Natural Science Foundation of Hunan
   Province (2015JJ3155), the China Postdoctoral Science Foundation
   (2015M570691), the National Key Research and Development Program of
   China (2016YFB1200505), and the Fundamental Research Funds for the
   Central Universities of Central South University (2018zzts165).
CR Association of Train Operation Companies, 2002, ATOC VEH STAND AV ST
   Automotive TNO, 2001, MAN MADYMO HUM BOD M
   Chen JG, 2013, INT CONF MEAS, P570, DOI 10.1109/ICMTMA.2013.142
   Crocetta G, 2015, ACCIDENT ANAL PREV, V79, P56, DOI 10.1016/j.aap.2015.03.009
   Edirisinghe PAS, 2014, J FORENSIC LEG MED, V27, P9, DOI 10.1016/j.jflm.2014.07.002
   General Administration of Sport, 2011, 2010 NAT FITN MON RE
   Greengard S, 2009, COMMUN ACM, V52, P18, DOI 10.1145/1610252.1610261
   Huang SN, 2010, ACCIDENT ANAL PREV, V42, P1136, DOI 10.1016/j.aap.2009.12.028
   Kirkpatrick SW, 2001, INT J CRASHWORTHINES, V6, P95, DOI 10.1533/cras.2001.0165
   Kullgren A., 2002, P INT IRC C MUN GERM
   Lu G, 2002, P I MECH ENG F-J RAI, V216, P31, DOI 10.1243/0954409021531665
   McHenry B. G., 2004, HEAD INJURY CRITERIA
   Nakai Kazuma, 2012, Quarterly Report of RTRI, V53, P235
   Olivares G., 2008, 0021 FTA
   Olivares G., 2007, 20 INT TECHN C ENH S, P1
   Olivares G., 2009, 2009 IEEE C EV COMP, P1
   Omino Koji, 2008, Quarterly Report of RTRI, V49, P47, DOI 10.2219/rtriqr.49.47
   Omino K., 2002, Q REPORT RTRI, V43, P77
   Omino K., 1998, RTRI REPORT, V12, P11
   Omino K., 1997, JAPANESE J ERGONOMIC, V33, P271
   Palacio A, 2009, ACCIDENT ANAL PREV, V41, P1, DOI 10.1016/j.aap.2008.08.016
   Peng Y, 2018, FUTURE GENER COMP SY, V86, P1251, DOI 10.1016/j.future.2017.07.065
   Peng Y, 2017, P I MECH ENG F-J RAI, V231, P902, DOI 10.1177/0954409716647418
   Peng Y, 2014, INT J CRASHWORTHINES, V19, P105, DOI 10.1080/13588265.2013.805290
   Peng Y, 2012, SAFETY SCI, V50, P1749, DOI 10.1016/j.ssci.2012.03.005
   Peng Y, 2012, INT J CRASHWORTHINES, V17, P415, DOI 10.1080/13588265.2012.661659
   Sahoo D, 2015, MED BIOL ENG COMPUT, V53, P869, DOI 10.1007/s11517-015-1295-6
   Severson K. J., 2006, ASME C P, P75
   Shackelford Stacy, 2011, Am J Disaster Med, V6, P127
   Simms CK, 2006, INT J CRASHWORTHINES, V11, P345, DOI 10.1533/ijcr.2005.0109
   Simons JW, 1999, INT J CRASHWORTHINES, V4, P121
   Tass B. V., 2010, MADYMO REFERENCE MAN
   Tian GD, 2018, RENEW SUST ENERG REV, V81, P682, DOI 10.1016/j.rser.2017.08.050
   Tyrell DC, 1995, ASME AMD, V210, P539
   Wang WB, 2011, APPL MECH MATER, V79, P227, DOI 10.4028/www.scientific.net/AMM.79.227
   Xie SC, 2013, TRAFFIC INJ PREV, V14, P816, DOI 10.1080/15389588.2013.768341
   Xie SC, 2013, VEHICLE SYST DYN, V51, P1803, DOI 10.1080/00423114.2013.834368
   Xu J, 2016, ACCIDENT ANAL PREV, V87, P102, DOI 10.1016/j.aap.2015.10.022
   Yang JK, 2011, COMPUTATIONAL BIOMECHANICS FOR MEDICINE: SOFT TISSUES AND THE MUSCULOSKELETAL SYSTEM, P5, DOI 10.1007/978-1-4419-9619-0_2
   Yang JK, 2008, CHIN J MECH ENG-EN, V21, P81, DOI 10.3901/CJME.2008.04.081
   Yao JF, 2008, SAFETY SCI, V46, P1103, DOI 10.1016/j.ssci.2007.06.021
   Yin S, 2017, ACCIDENT ANAL PREV, V106, P285, DOI 10.1016/j.aap.2017.06.005
   Zeng Z. M., 2003, ELECT LOCOMOTIVES MA, V4
   Zhao JB, 2007, J BIOMECH, V40, P3187, DOI 10.1016/j.jbiomech.2007.04.002
NR 44
TC 0
Z9 0
U1 6
U2 6
PU HINDAWI LTD
PI LONDON
PA ADAM HOUSE, 3RD FLR, 1 FITZROY SQ, LONDON, W1T 5HF, ENGLAND
SN 1176-2322
EI 1754-2103
J9 APPL BIONICS BIOMECH
JI Appl. Bionics Biomech.
PY 2018
AR 1096056
DI 10.1155/2018/1096056
PG 13
WC Engineering, Biomedical; Robotics
SC Engineering; Robotics
GA GT9TU
UT WOS:000444889700001
PM 30245740
OA DOAJ Gold, Green Published
DA 2019-02-18
ER

PT J
AU Wang, F
   Yu, C
   Li, GB
   Han, Y
   Wang, BY
   Yang, JK
   Lan, DD
AF Wang, Fang
   Yu, Chao
   Li, Guibing
   Han, Yong
   Wang, Bingyu
   Yang, Jikuang
   Lan, Diandian
TI A Study on Influence of Minivan Front-End Design and Impact Velocity on
   Pedestrian Thorax Kinematics and Injury Risk
SO APPLIED BIONICS AND BIOMECHANICS
LA English
DT Article
ID ACCIDENTS; COLLISIONS; MULTIBODY; VEHICLES; SHAPE; CARS
AB Thoracic injuries occur frequently in minivan-to-pedestrian impact accidents and can cause substantial fatalities. The present research work investigates the human thoracic responses and injury risks in minivan-to-pedestrian impacts, when changing the minivan front-end design and the impact velocity, by using computational biomechanics model. We employed three typical types of minivan model of different front-end designs that are quite popular in Chinese market and considered four impact velocities (20, 30, 40, and 50 km/h). The contact time of car to thorax region (CTCTR), thorax impact velocity, chest deformation, and thoracic injury risks were extracted for the investigation. The results indicate that the predicted pedestrian kinematics, injury responses, and thoracic injury risks are strongly affected by the variation of the minivan front-end design and impact velocity. The pedestrian thoracic injury risks increase with the increasing vehicle impact velocity. It is also revealed that the application of the extra front bumper is beneficial for reducing the thoracic injury risk, and a relatively flatter minivan front-end design gives rise to a higher thoracic injury risk. This study is expected to be served as theoretical references for pedestrian protection design of minivans.
C1 [Wang, Fang; Yu, Chao; Han, Yong; Wang, Bingyu; Lan, Diandian] Xiamen Univ Technol, Sch Mech & Automot Engn, Xiamen, Peoples R China.
   [Wang, Fang; Yu, Chao; Han, Yong; Wang, Bingyu; Lan, Diandian] Fujian Collaborat Innovat Ctr R&D Coach & Special, Xiamen, Peoples R China.
   [Li, Guibing] Hunan Univ Sci & Technol, Sch Mech Engn, Xiangtan, Peoples R China.
   [Yang, Jikuang] Hunan Univ, State Key Lab Adv Design & Mfg Vehicle Body, Res Ctr Vehicle & Traff Safety VTS, Changsha, Hunan, Peoples R China.
   [Yang, Jikuang] Chalmers Univ Technol, Dept Appl Mech, Gothenburg, Sweden.
RP Wang, BY (reprint author), Xiamen Univ Technol, Sch Mech & Automot Engn, Xiamen, Peoples R China.; Wang, BY (reprint author), Fujian Collaborat Innovat Ctr R&D Coach & Special, Xiamen, Peoples R China.
EM 2016000075@xmut.edu.cn
RI Yang, Jikuang/Y-2391-2018
OI Yang, Jikuang/0000-0003-4737-511X
FU National Natural Science Foundation of China [51605407]; Fujian
   Provincial Department of Science and Technology [2017J01652]; Fujian
   Provincial Department of Education [JAT160365]; State Administration of
   Foreign Experts Affairs China [GDT20173600566]
FX The authors would like to gratefully acknowledge the support of National
   Natural Science Foundation of China (Grant no. 51605407), Fujian
   Provincial Department of Science and Technology (Grant no. 2017J01652),
   Fujian Provincial Department of Education (Grant no. JAT160365), and
   State Administration of Foreign Experts Affairs China (Grant no.
   GDT20173600566).
CR Cai Z., 2009, FINITE ELEMENT ANAL
   Chidester A. B., 2001, INT TECHN C ENH SAF, P12
   Desapriya E, 2010, TRAFFIC INJ PREV, V11, P48, DOI 10.1080/15389580903390623
   Eppinger R. H., 1984, 840885 SAE
   Fahlstedt M, 2016, TRAFFIC INJ PREV, V17, P320, DOI 10.1080/15389588.2015.1067803
   Fildes B., 2004, IRCOBI C, P167
   Forman Jason L, 2015, Stapp Car Crash J, V59, P401
   Guo C., 2006, ZHEJIANG J PREVENTIV, V18, P59
   Guo W., 2012, STUDY INFLUENCES B B
   Han Y., 2011, STUDY DYNAMIC RESPON
   Han Y, 2012, TRAFFIC INJ PREV, V13, P507, DOI 10.1080/15389588.2012.661111
   Han Y, 2012, INT J CRASHWORTHINES, V17, P141, DOI 10.1080/13588265.2011.632243
   Han Y, 2011, CHIN J MECH ENG-EN, V24, P1045, DOI 10.3901/CJME.2011.06.1045
   Huang J., 2018, APPL BIONICS BIOMECH, V2018
   Isenberg R. A., 1998, INT TECHN C ENH SAF, P1212
   Jingwen Hu, 2015, International Journal of Vehicle Safety, V8, P22, DOI 10.1504/IJVS.2015.066272
   Kuppa S., 2003, STAPP CAR CRASH J, V47, P189
   Li G., 2014, IRCOBI C BERL GERM
   Li G., 2012, 5 INT C ESAR EXP S A
   Li GB, 2018, ACCIDENT ANAL PREV, V115, P143, DOI 10.1016/j.aap.2018.03.014
   Li GB, 2017, ACCIDENT ANAL PREV, V101, P11, DOI 10.1016/j.aap.2017.01.012
   Li K., 2015, IN DEPTH INVESTIGATI
   Li K, 2015, MED SCI MONITOR, V21, P727, DOI 10.12659/MSM.893622
   [李莉 Li Li], 2005, [汽车工程, Automotive Engineering], V27, P44
   Liu WJ, 2015, CHIN J TRAUMATOL, V18, P74, DOI 10.1016/j.cjtee.2015.03.003
   LSTC, 2007, LS DYNA KEYW US MAN
   Maki T, 2003, ACCIDENT ANAL PREV, V35, P927, DOI 10.1016/S0001-4575(02)00101-X
   Martin Jean-Louis, 2011, Ann Adv Automot Med, V55, P137
   Mizuno K., 2000, SAE TECHNICAL PAPER, P232
   Mizuno Y., 2005, INT TECHN C ENH SAF, P15
   Naci H, 2009, INJURY PREV, V15, P55, DOI 10.1136/ip.2008.018721
   Roudsari Bahman S, 2005, Traffic Inj Prev, V6, P185
   Simms CK, 2006, P I MECH ENG D-J AUT, V220, P1085, DOI 10.1243/09544070JAUT0319
   Talantikite Y. B., 1998, INT TECHN C ENH SAF, P1542
   Tanno K, 2000, Leg Med (Tokyo), V2, P68, DOI 10.1016/S1344-6223(00)80026-7
   Tencer AF, 2005, ACCIDENT ANAL PREV, V37, P287, DOI 10.1016/j.aap.2004.09.005
   Teresinski G, 2001, FORENSIC SCI INT, V124, P74, DOI 10.1016/S0379-0738(01)00569-2
   Wang BF, 2019, IEEE T POWER ELECTR, V34, P1914, DOI [10.1109/TPEL.2018.2832243, 10.1080/00207454.2018.1512985]
   Wang F., 2010, 6 WORLD C BIOM WCB 2
   Wang F, 2017, J MECH MED BIOL, V17, DOI 10.1142/S0219519417501135
   Wang F, 2016, COMPUT METHOD BIOMEC, V19, P527, DOI 10.1080/10255842.2015.1043905
   [许伟 Xu Wei], 2008, [汽车工程, Automotive Engineering], V30, P151
   Yang J., 2007, INT TECHN C ENH SAF
   [杨济匡 Yang Jikuang], 2005, [湖南大学学报. 自然科学版, Journal of Hunan University.Natural Sciences], V32, P6
   Yao JF, 2008, SAFETY SCI, V46, P1103, DOI 10.1016/j.ssci.2007.06.021
   Zhang Y., 2006, J CHANGSHA COMMUNICA, V22, P58
   Zhao H, 2010, INT J CRASHWORTHINES, V15, P313, DOI 10.1080/13588260903335290
NR 47
TC 0
Z9 0
U1 2
U2 2
PU HINDAWI LTD
PI LONDON
PA ADAM HOUSE, 3RD FLR, 1 FITZROY SQ, LONDON, W1T 5HF, ENGLAND
SN 1176-2322
EI 1754-2103
J9 APPL BIONICS BIOMECH
JI Appl. Bionics Biomech.
PY 2018
AR 7350159
DI 10.1155/2018/7350159
PG 8
WC Engineering, Biomedical; Robotics
SC Engineering; Robotics
GA GT9UF
UT WOS:000444891000001
PM 30250503
OA DOAJ Gold, Green Published
DA 2019-02-18
ER

PT J
AU Melnyk, A
   Pitti, A
AF Melnyk, Artem
   Pitti, Alexandre
TI Synergistic control of a multi-segments vertebral column robot based on
   tensegrity for postural balance
SO ADVANCED ROBOTICS
LA English
DT Article
DE Motor synergies; central pattern generators; tensegrity; vertebral
   column; postural balance; phase synchronization; soft robotics; feedback
   resonance; biological robotics
ID PATTERN GENERATION; LOCOMOTION; COORDINATION; MODEL; ORGANIZATION;
   PRINCIPLES; DYNAMICS; FEEDBACK; SPINE
AB We present a neuronal architecture to control a compliant robotic model of the human vertebral column for postural balance. The robotic structure is designed using the principle of tensegrity that ensures to be lightweight, auto-replicative with multi-degrees of freedom, flexible and also robust to perturbations. We model the central pattern generators of the spinal cords with a network of nonlinear Kuramoto oscillators coupled internally and externally to the structure and error-driven by a proportional derivative (PD) controller using an accelerometer for feedback. This coupling between the two controllers is original and we show it serves to generate controlled rhythmical patterns. We observe for certain coupling parameters some intervals of synchronization and of resonance of the neural units to the tensile structure to permit smooth control and balance. We show that the top-down PD control of the oscillators flexibly absorbs external shocks proportionally to the perturbation and converges to steady state behaviors. We discuss then about our neural architecture to model motor synergies for compliance control and also about tensegrity structures for soft robotics. The 3D printed model is provided as well as a movie at the address https://sites.google.com/site/embodiedai/current-research/tensegrityrobots.
C1 [Melnyk, Artem] Univ Cote Azur, Hephaistos Project, INRIA, Nice, France.
   [Pitti, Alexandre] Univ Cergy Pontoise, Univ Paris Seine, CNRS, Lab ETIS,UMR,ENSEA, Cergy Pontoise, France.
RP Pitti, A (reprint author), Univ Cergy Pontoise, Univ Paris Seine, CNRS, Lab ETIS,ENSEA,UMR 8051, Cergy Pontoise, France.
EM alexandre.pitti@u-cergy.fr
OI MELNYK, Artem/0000-0003-3991-2720
FU chaire d'Excellence CNRS-UCP; project Labex MME-DII [ANR11-LBX-0023-01];
   EQUIPEX-ROBOTEX (CNRS)
FX This research project was partially funded by chaire d'Excellence
   CNRS-UCP, the project Labex MME-DII (ANR11-LBX-0023-01) and
   EQUIPEX-ROBOTEX (CNRS).
CR Alexander RM, 2005, SCIENCE, V308, P58, DOI 10.1126/science.1111110
   Allen JL, 2016, SPR SER COMPUT NEURO, P197, DOI 10.1007/978-1-4939-3267-2_7
   Amrollah Elmira, 2010, Front Neurorobot, V4, P113, DOI 10.3389/fnbot.2010.00113
   [Anonymous], 2016, TINKERCAD
   Bardy BG, 2007, J MOTOR BEHAV, V39, P326, DOI 10.3200/JMBR.39.4.326-336
   Bardy BG, 1999, J EXP PSYCHOL HUMAN, V25, P1284, DOI 10.1037//0096-1523.25.5.1284
   Bardy BG, 2002, J EXP PSYCHOL HUMAN, V28, P499, DOI 10.1037//0096-1523.28.3.499
   Bernstein N., 1967, COORDINATION REGULAT
   Berthoz A., 2000, BRAINS SENSE MOVEMEN
   Bizzi E, 2008, BRAIN RES REV, V57, P125, DOI 10.1016/j.brainresrev.2007.08.004
   BIZZI E, 1995, TRENDS NEUROSCI, V18, P442, DOI 10.1016/0166-2236(95)94494-P
   Bizzi E, 1999, CURR OPIN NEUROBIOL, V9, P659, DOI 10.1016/S0959-4388(99)00042-2
   Bliss T, 2013, IEEE T CONTR SYST T, V21, P666, DOI 10.1109/TCST.2012.2189400
   Bonnet V, 2011, J BIOMECH, V44, P2123, DOI 10.1016/j.jbiomech.2011.05.027
   Calabrese RL, 1995, CURR OPIN NEUROBIOL, V5, P816, DOI 10.1016/0959-4388(95)80111-1
   Caluwaerts K, 2014, J R SOC INTERFACE, V11, DOI 10.1098/rsif.2014.0520
   Der R, 2005, P INT C COMP INT MOD, P252
   Falotico E, 2017, AUTON ROBOT, V41, P349, DOI 10.1007/s10514-016-9583-z
   Flemons T., 2012, BONES TENSEGRITY
   Fradkov A, 1999, PHYSICA D, V128, P159, DOI 10.1016/S0167-2789(98)00322-4
   FRADKOV AL, 1999, AUTOMAT REM CONTR, V60, P3
   Frumar A, 2009, J INT ASS SHELL SPAT, V161, P99
   Fujita K, 2017, P EDINBURGH MATH SOC, P1
   Fuller R.B, 1975, SYNERGETICS EXPLORAT
   Geyer H, 2010, IEEE T NEUR SYS REH, V18, P263, DOI 10.1109/TNSRE.2010.2047592
   Hauser H, 2012, BIOL CYBERN, V106, P595, DOI 10.1007/s00422-012-0516-4
   Hauser H, 2011, BIOL CYBERN, V105, P355, DOI 10.1007/s00422-012-0471-0
   Hoinville T, 2011, ADAPT BEHAV, V19, P187, DOI 10.1177/1059712311403631
   Iida F, LECT NOTES COMPUTER, V3139, P119
   Ijspeert A, 2003, LEARNING ATTRACTOR L
   Ijspeert AJ, 2008, NEURAL NETWORKS, V21, P642, DOI 10.1016/j.neunet.2008.03.014
   Ikemoto S, 2012, ARTIF LIFE ROBOT, V17, P63, DOI 10.1007/s10015-012-0017-5
   Ingber DE, 2014, REP PROG PHYS, V77, DOI 10.1088/0034-4885/77/4/046603
   Kelso J. A. S, 1995, DYNAMIC PATTERNS SEL
   Kelso JS, 1995, WHAT IS LIFE NEXT 50, P137
   Laumond JP, 2015, INT S ROB RES ISRR S
   Levin SM, 2002, J MECH MED BIOL, V2, P375, DOI 10.1142/S0219519402000472
   Ly O, 2011, INT C ROB SYST SAN F, P1
   Marder E, 1996, PHYSIOL REV, V76, P687
   McEvoy M, 2007, SCIENCE, V318, P1088, DOI [10.1126/science.1145803, DOI 10.1126/SCIENCE.1145803]
   Melnyk A, 2016, 2016 IEEE 36TH INTERNATIONAL CONFERENCE ON ELECTRONICS AND NANOTECHNOLOGY (ELNANO), P163, DOI 10.1109/ELNANO.2016.7493040
   Nakajima K, 2013, FRONT COMPUT NEUROSC, V7, DOI 10.3389/fncom.2013.00091
   Nakanishi J., 2004, 2004 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) (IEEE Cat. No.04CH37566), P919
   Nassour J, 2014, BIOL CYBERN, V108, P291, DOI 10.1007/s00422-014-0592-8
   Paul C, 2006, IEEE T ROBOT, V22, P944, DOI 10.1109/TRO.2006.878980
   Pfeifer R, LECT NOTES COMPUTER, V5436, P66
   Pfeifer R, 2012, REVOLUTION INTELLIGE
   Pfeifer R, 1999, BODY SHAPES WAY WE T
   Pfeifer R, 2007, SCIENCE, V318, P1088, DOI 10.1126/science.1145803
   Pitti A, 2005, RECENT ADV ARTIFICIA, V3, P199, DOI [10.1142/9789812701497_0015, DOI 10.1142/9789812701497_0015]
   Pitti A, 2006, INTELLIGENT AUTONOMOUS SYSTEMS 9, P558
   Pitti Alexandre, 2009, Front Neurorobot, V3, P2, DOI 10.3389/neuro.12.002.2009
   Pitti A, 2010, AUTON ROBOT, V28, P317, DOI 10.1007/s10514-009-9176-1
   Snelson K., 1965, U.S. Patent, Patent No. [3169611, 3,169,611]
   Strogatz S. H., 2003, SYNC EMERGING SCI SP
   TAGA G, 1995, BIOL CYBERN, V73, P97, DOI 10.1007/s004220050166
   Tietz BR, 2013, IEEE ASME INT C ADV, P261, DOI 10.1109/AIM.2013.6584102
   Ting LH, 2007, PROG BRAIN RES, V165, P299, DOI 10.1016/S0079-6123(06)65019-X
   Todorov E, 2004, NAT NEUROSCI, V7, P907, DOI 10.1038/nn1309
   Turvey MT, 2014, J MOTOR BEHAV, V46, P143, DOI 10.1080/00222895.2013.798252
   Wei XH, 2015, ADV ROBOTICS, V29, P973, DOI 10.1080/01691864.2015.1015442
   Zhao Q, 2014, ADV ROBOTICS, V28, P367, DOI 10.1080/01691864.2013.867287
NR 62
TC 0
Z9 0
U1 8
U2 8
PU TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND
SN 0169-1864
EI 1568-5535
J9 ADV ROBOTICS
JI Adv. Robot.
PY 2018
VL 32
IS 15
SI SI
BP 850
EP 864
DI 10.1080/01691864.2018.1483209
PG 15
WC Robotics
SC Robotics
GA GS6VI
UT WOS:000443837500006
DA 2019-02-18
ER

PT J
AU Beckerle, P
   Bianchi, M
   Castellini, C
   Salvietti, G
AF Beckerle, Philipp
   Bianchi, Matteo
   Castellini, Claudio
   Salvietti, Gionata
TI Mechatronic designs for a robotic hand to explore human body experience
   and sensory-motor skills: a Delphi study
SO ADVANCED ROBOTICS
LA English
DT Article
DE Robotic hand design; human body experience; sensory-motor skills; expert
   study; assistive robotics
ID RUBBER HAND; OWNERSHIP; SYNERGIES; ILLUSION; CONSENSUS; PROTOTYPE;
   SOFTHAND; SCHEMA; MOTION
AB To bridge the gap between users' expectations and technological solutions, a better understanding of human body experience and sensory-motor skills is mandatory. This could pave the way towards a novel generation of robotic hands, which can be successfully employed in everyday life e.g. in prosthetics and assistive robotics. Available robotic hands are still far from matching the requirements of the corresponding experimental and real-world applications, e.g. fast motions might be achieved at the expense of accuracy. Knowledge of the users' sensory-motor skills can guide technical developments, e.g. prosthetic design processes. This paper presents design solutions developed in a Delphi study. Explorative questionnaires are prepared to acquire and elaborate expert opinions to improve the design of previously developed robotic anthropomorphic hands. By gathering and fusing expert opinions, novel robotic hand and wrist concepts specifically optimized regarding body experience and sensory-motor skill research are developed. In three rounds, experts with experience in robotic hand design and/or control analyze, develop, and rank solutions for mechanisms, actuators, and control , which result in overall design concepts. The technical concepts and implications resulting from the study are discussed considering psychological and biomechanical aspects.
C1 [Beckerle, Philipp] Tech Univ Darmstadt, Inst Mechatron Syst Mech Engn, Darmstadt, Germany.
   [Bianchi, Matteo] Univ Pisa, Res Ctr Enrico Piaggio, Pisa, Italy.
   [Bianchi, Matteo] Univ Pisa, Dept Informat Engn, Pisa, Italy.
   [Castellini, Claudio] DLR German Aerosp Ctr, Inst Robot & Mech, Oberpfaffenhofen, Germany.
   [Salvietti, Gionata] Univ Siena, Dept Informat Engn & Math, Siena, Italy.
   [Salvietti, Gionata] Ist Italiano Tecnol, Dept Adv Robot, Genoa, Italy.
RP Beckerle, P (reprint author), Tech Univ Darmstadt, Inst Mechatron Syst Mech Engn, Darmstadt, Germany.
EM beckerle@ims.tu-darmstadt.de
OI Beckerle, Philipp/0000-0001-5703-6029; SALVIETTI,
   GIONATA/0000-0001-9170-4051
FU Deutsche Forschungsgemeinschaft (DFG) project 'Users' Body Experience
   and Human-Machine Interfaces in (Assistive) Robotics' [BE 5729/3];
   Deutsche Forschungsgemeinschaft (DFG) project 'TACT-HAND: Improving
   control of prosthetic hands using tactile sensors and realistic machine
   learning' [CA 1389/1]; European Union's Horizon 2020 Research and
   Innovation Programme [688857]
FX This work was supported by the Deutsche Forschungsgemeinschaft (DFG)
   projects 'Users' Body Experience and Human-Machine Interfaces in
   (Assistive) Robotics' [number BE 5729/3] and 'TACT-HAND: Improving
   control of prosthetic hands using tactile sensors and realistic machine
   learning' [number CA 1389/1]. This research has received funding from
   the European Union's Horizon 2020 Research and Innovation Programme
   [grant agreement number 688857] (SoftPro). The content of this
   publication is the sole responsibility of the authors. The European
   Commission or its services cannot be held responsible for any use that
   may be made of the information it contains.
CR Arieta A. H., 2006, Applied Bionics and Biomechanics, V3, P101, DOI 10.1533/abbi.2005.0060
   Beckerle P, 2016, IEEE INT S ROB HUM I
   Beckerle P, 2017, FRONT NEUROROBOTICS, V11, DOI 10.3389/fnbot.2017.00024
   Botvinick M, 1998, NATURE, V391, P756, DOI 10.1038/35784
   Brown CY, 2007, IEEE RSJ INT C INT R
   Caspar EA, 2015, BEHAV RES METHODS, V47, P744, DOI 10.3758/s13428-014-0498-3
   Catalano MG, 2014, INT J ROBOT RES, V33, P768, DOI 10.1177/0278364913518998
   Cerulo I, 2017, ROBOT AUTON SYST, V89, P75, DOI 10.1016/j.robot.2016.12.004
   Choi W, 2016, BIOMED RES INT, V2016
   Christ O., 2012, BIOMED TECH, V57, P1098, DOI DOI 10.1515/BMT-2012-4306
   Christ O, 2014, NEUROSCI BIOBEHAV R, V44, P33, DOI 10.1016/j.neubiorev.2014.02.013
   Ciocarlie MT, 2009, INT J ROBOT RES, V28, P851, DOI 10.1177/0278364909105606
   Dalley SA, 2009, IEEE-ASME T MECH, V14, P699, DOI 10.1109/TMECH.2009.2033113
   Della Santina C, 2017, IEEE ROBOT AUTOM MAG, V24, P48, DOI 10.1109/MRA.2016.2636366
   Diamond IR, 2014, J CLIN EPIDEMIOL, V67, P401, DOI 10.1016/j.jclinepi.2013.12.002
   Ficuciello F, 2011, IEEE RSJ INT C INT R
   Gabiccini M, 2013, IEEE RSJ INT C INT R
   Gallagher S, 1995, J MIND BEHAV, V16, P369
   Gioioso G, 2013, IEEE T ROBOT, V29, P825, DOI 10.1109/TRO.2013.2252251
   Godfrey SB, 2017, BIOSYST BIOROBOT, V15, P469, DOI 10.1007/978-3-319-46669-9_78
   Hara M, 2016, IEEE T HUM-MACH SYST, V46, P78, DOI 10.1109/THMS.2015.2487499
   Holey EA, 2007, BMC MED RES METHODOL, V7, DOI 10.1186/1471-2288-7-52
   Kalckert A, 2014, CONSCIOUS COGN, V26, P117, DOI 10.1016/j.concog.2014.02.003
   Kim YJ, 2014, IEEE INT C ROB AUT
   Liarokapis M, 2013, DIRECTIONS METHODS M
   Ma K, 2015, CONSCIOUS COGN, V36, P75, DOI 10.1016/j.concog.2015.06.003
   Maister L, 2013, COGNITION, V128, P170, DOI 10.1016/j.cognition.2013.04.002
   Mayer A, 2008, PROSTHET ORTHOT INT, V32, P363, DOI 10.1080/03093640802024971
   Micera S, 2006, P IEEE, V94, P1752, DOI 10.1109/JPROC.2006.881294
   Padilla MA, 2010, LECT NOTES COMPUT SC, V6192, P194, DOI 10.1007/978-3-642-14075-4_28
   Pahl G., 2007, ENG DESIGN SYSTEMATI
   Riek LD, 2009, ACM IEEE INT C HUM R
   Romano D, 2015, NEUROPSYCHOLOGIA, V70, P414, DOI 10.1016/j.neuropsychologia.2014.10.033
   Salvietti G, 2013, IEEE RSJ INT C INT R
   Santello M, 1998, J NEUROSCI, V18, P10105
   Santello M, 2016, PHYS LIFE REV, V17, P1, DOI 10.1016/j.plrev.2016.02.001
   Santello M, 2013, FRONT COMPUT NEUROSC, V7, DOI 10.3389/fncom.2013.00023
   Schaffalitzky E, 2012, DISABIL REHABIL, V34, P2085, DOI 10.3109/09638288.2012.671885
   Sturman DJ., 1992, THESIS
   Tsakiris M, 2010, EXP BRAIN RES, V204, P343, DOI 10.1007/s00221-009-2039-3
   van der Linde H, 2005, J REHABIL RES DEV, V42, P693, DOI 10.1682/JRRD.2003.11.0172
   von der Gracht HA, 2012, TECHNOL FORECAST SOC, V79, P1525, DOI 10.1016/j.techfore.2012.04.013
NR 42
TC 1
Z9 1
U1 1
U2 1
PU TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND
SN 0169-1864
EI 1568-5535
J9 ADV ROBOTICS
JI Adv. Robot.
PY 2018
VL 32
IS 12
BP 670
EP 680
DI 10.1080/01691864.2018.1489737
PG 11
WC Robotics
SC Robotics
GA GM4MW
UT WOS:000438095900004
DA 2019-02-18
ER

PT J
AU Oberhofer, K
   Wettenschwiler, PD
   Singh, N
   Ferguson, SJ
   Annaheim, S
   Rossi, RM
   Lorenzetti, S
AF Oberhofer, Katja
   Wettenschwiler, Patrick D.
   Singh, Navrag
   Ferguson, Stephen J.
   Annaheim, Simon
   Rossi, Rene M.
   Lorenzetti, Silvio
TI The Influence of Backpack Weight and Hip Belt Tension on Movement and
   Loading in the Pelvis and Lower Limbs during Walking
SO APPLIED BIONICS AND BIOMECHANICS
LA English
DT Article
ID CARRIAGE; KINEMATICS; GAIT; PAIN; ADOLESCENTS; SQUATS; TRUNK
AB The introduction of hip belts to backpacks has caused a shift of loading from the spine to the hips with reported improvements in musculoskeletal comfort. Yet the effects of different hip belt tensions on gait biomechanics remain largely unknown. The goal of this study was to assess the influence of backpack weight and hip belt tension on gait biomechanics. Data from optical motion capture and ground reaction forces (GRF) during walking were acquired in nine healthy male subjects (age 28.0 +/- 3.9 years). Six configurations of a commercial backpack were analyzed, that is, 15 kg, 20 kg, and 25 kg loading with 30 N and 120 N hip belt tension. Joint ranges of motion (ROM), peak GRF, and joint moments during gait were analyzed for significant differences by repeated measures of ANOVA with Bonferroni post hoc comparison. Increased loading led to a significant reduction of knee flexion-extension ROM as well as pelvis rotational ROM. No statistically significant effect of hip belt tension magnitudes on gait dynamics was found at any backpack weight, yet there was a trend of increased pelvis ROM in the transverse plane with higher hip belt tension at 25 kg loading. Further research is needed to elucidate the optimum hip belt tension magnitudes for different loading weights to reduce the risks of injury especially with higher loading.
C1 [Oberhofer, Katja; Singh, Navrag; Ferguson, Stephen J.; Lorenzetti, Silvio] Swiss Fed Inst Technol, D HEST, Inst Biomech, Leopold Ruzicka Weg 4, CH-8093 Zurich, Switzerland.
   [Wettenschwiler, Patrick D.; Annaheim, Simon; Rossi, Rene M.] Empa, Lab Biomimet Membranes & Text, Lerchenfeldstr 5, CH-9014 St Gallen, Switzerland.
   [Lorenzetti, Silvio] Swiss Fed Inst Sport Magglingen SFISM, Alpenstr 16, CH-2532 Magglingen, Switzerland.
RP Lorenzetti, S (reprint author), Swiss Fed Inst Technol, D HEST, Inst Biomech, Leopold Ruzicka Weg 4, CH-8093 Zurich, Switzerland.; Lorenzetti, S (reprint author), Swiss Fed Inst Sport Magglingen SFISM, Alpenstr 16, CH-2532 Magglingen, Switzerland.
EM slorenzetti@ethz.ch
RI Lorenzetti, Silvio/B-1188-2009; Singh, Navrag/F-5305-2012
OI Lorenzetti, Silvio/0000-0002-8339-8960; Singh,
   Navrag/0000-0001-8074-041X; Rossi, Rene/0000-0003-0946-682X
CR Attwells RL, 2006, ERGONOMICS, V49, P1527, DOI 10.1080/00140130600757237
   Birrell SA, 2009, MIL MED, V174, P177, DOI 10.7205/MILMED-D-58-7308
   Birrell SA, 2010, APPL ERGON, V41, P585, DOI 10.1016/j.apergo.2009.12.004
   Birrell SA, 2009, ERGONOMICS, V52, P1298, DOI 10.1080/00140130903003115
   Bryant JT, 2001, VALIDATION OBJECTIVE
   Cavallo Carla Maria, 2003, Work, V20, P137
   Chow DHK, 2005, ERGONOMICS, V48, P642, DOI 10.1080/00140130500070921
   Connolly Barbara H, 2008, Pediatr Phys Ther, V20, P347, DOI 10.1097/PEP.0b013e31818a0f8f
   Knapik JJ, 2004, MIL MED, V169, P45, DOI 10.7205/MILMED.169.1.45
   Korovessis P, 2004, J SPINAL DISORD TECH, V17, P33, DOI 10.1097/00024720-200402000-00008
   LaFiandra M, 2004, MED SCI SPORT EXER, V36, P460, DOI 10.1249/01.MSS.0000117113.77904.46
   Liew B, 2016, J APPL BIOMECH, V32, P614, DOI 10.1123/jab.2015-0339
   List R, 2013, J STRENGTH COND RES, V27, P1529, DOI 10.1519/JSC.0b013e3182736034
   Majumdar D, 2010, ERGONOMICS, V53, P782, DOI 10.1080/00140131003672015
   Martin J., 2001, MILITARY LOAD CARRIA
   Schellenberg F, 2013, BMC SPORTS SCI MED R, V5, DOI 10.1186/2052-1847-5-27
   Schutz P, 2014, J APPL BIOMECH, V30, P373, DOI 10.1123/jab.2013-0175
   Sharpe SR, 2008, J BIOMECH, V41, P968, DOI 10.1016/j.jbiomech.2007.12.018
   Sheir-Neiss GI, 2003, SPINE, V28, P922, DOI 10.1097/00007632-200305010-00015
   Singh T, 2009, J BIOMECH, V42, P736, DOI 10.1016/j.jbiomech.2009.01.035
   Skaggs DL, 2006, J PEDIATR ORTHOPED, V26, P358, DOI 10.1097/01.bpo.0000217723.14631.6e
   Stevenson JM, 2004, ERGONOMICS, V47, P1160, DOI 10.1080/00140130410001699119
   Wettenschwiler PD, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0142004
NR 23
TC 0
Z9 0
U1 1
U2 2
PU HINDAWI LTD
PI LONDON
PA ADAM HOUSE, 3RD FLR, 1 FITZROY SQ, LONDON, W1T 5HF, ENGLAND
SN 1176-2322
EI 1754-2103
J9 APPL BIONICS BIOMECH
JI Appl. Bionics Biomech.
PY 2018
AR 4671956
DI 10.1155/2018/4671956
PG 7
WC Engineering, Biomedical; Robotics
SC Engineering; Robotics
GA GJ9ZI
UT WOS:000435764600001
PM 29977333
OA DOAJ Gold, Green Published
DA 2019-02-18
ER

PT J
AU Ma, C
   Li, J
   Wang, DY
AF Ma, Chen
   Li, Jin
   Wang, Dongyang
TI OPTIMAL EVALUATION INDEX SYSTEM AND BENEFIT EVALUATION MODEL FOR
   AGRICULTURAL INFORMATIZATION IN BEIJING
SO INTERNATIONAL JOURNAL OF ROBOTICS & AUTOMATION
LA English
DT Article
DE Agricultural informatization; evaluation index system; benefit
   evaluation model; urban-rural income gap; Beijing city
ID CHINA; URBANIZATION; PROVINCE; QUALITY; POLICY
AB The level of informatization is an important indicator of a country or region's level of economic development, and many domestic and foreign scholars have studied this topic. Informatization is seen as a developing social phenomenon, with both national and regional characteristics, therefore the foreign standard systems are not entirely suitable for the development of an information society in China. This paper establishes new indexes and designs an optimal evaluation index system according to the characteristics of informatization. The optimal index system is more suitable for the current development of informatization in China. Using this index system, we measure the informatization level in Beijing from 2003 to 2012. Using the Cobb-Douglass model, we construct an information benefit evaluation model to verify the positive effect of informatization on economic development in Beijing. To further study the relationship between the informatization evaluation index and the urban-rural income gap, we conduct a regression between the information evaluation index and the urban-rural income gap. It provides a quantitative scientific basis for the study of the impact of information technology on economic and social development plans, enabling improved government decision-making.
C1 [Ma, Chen; Li, Jin] Beijing Res Ctr Informat Technol Agr, Beijing 100097, Peoples R China.
   [Ma, Chen; Wang, Dongyang] Chinese Acad Agr Sci, Inst Agr Econ & Dev, Beijing 100081, Peoples R China.
   [Wang, Dongyang] Minist Agr, Inst Food & Nutr Dev, Beijing 100081, Peoples R China.
RP Ma, C (reprint author), Beijing Res Ctr Informat Technol Agr, Beijing 100097, Peoples R China.; Ma, C (reprint author), Chinese Acad Agr Sci, Inst Agr Econ & Dev, Beijing 100081, Peoples R China.
EM mac@nercita.org.cn; lij@nercita.org.cn; wangdongyang@caas.cn
FU Beijing Social Science Fund [14JGB053]; Beijing Academy of Agriculture
   and Forestry Sciences Innovation Ability Construction Project
   [KJCX20160501]; Beijing Natural Science Foundation [9162006]; Beijing
   Municipal Science and Technology Commission Science and Technology
   Innovation Center Construction Strategy Research and Expert Consultation
   Project [Z161100003116001]
FX This research was financially supported by the Beijing Social Science
   Fund (14JGB053), Beijing Academy of Agriculture and Forestry Sciences
   Innovation Ability Construction Project (KJCX20160501), Beijing Natural
   Science Foundation (9162006), and Beijing Municipal Science and
   Technology Commission Science and Technology Innovation Center
   Construction Strategy Research and Expert Consultation Project
   (Z161100003116001).
CR Ahmad Z., 2015, Journal of Northeast Agricultural University (English Edition), V22, P87, DOI 10.1016/S1006-8104(15)30037-4
   Allam A, 2015, SCI TOTAL ENVIRON, V536, P79, DOI 10.1016/j.scitotenv.2015.07.029
   [Anonymous], 16 NAT CPC C
   China Science and Technology Development Research Center, 1987, INF MISS HIST
   Chunhui C., 2003, STAT DECISION, V32, P10
   Gu C, 2012, FRONT ARCHIT RES, V1, P101, DOI 10.1016/j.foar.2012.02.013
   Jia WS, 2011, PROCEDIA ENVIRON SCI, V10, P2247, DOI 10.1016/j.proenv.2011.09.352
   Li YC, 2014, HABITAT INT, V42, P76, DOI 10.1016/j.habitatint.2013.10.009
   Liu C, 2012, GOV INFORM Q, V29, P85, DOI 10.1016/j.giq.2011.06.002
   Liu YL, 2013, ENVIRON MODELL SOFTW, V40, P226, DOI 10.1016/j.envsoft.2012.09.013
   Machlup F, 1962, PRODUCTION DISTRIBUT
   Machlup F., 1987, INFORM EC
   Nugroho A P, 2013, IFAC P, V46, P181
   Rahmanipour F, 2014, ECOL INDIC, V40, P19, DOI 10.1016/j.ecolind.2013.12.003
   Shihong L., 2008, RES THEORY METHOD IN
   Su CW, 2015, HABITAT INT, V48, P79, DOI 10.1016/j.habitatint.2015.03.002
   Ting C, 2013, TELECOMMUN POLICY, V37, P626, DOI 10.1016/j.telpol.2012.03.007
   Wang XH, 2014, ENERG POLICY, V67, P508, DOI 10.1016/j.enpol.2013.12.060
   Xia J, 2008, TELECOMMUN POLICY, V32, P686, DOI 10.1016/j.telpol.2008.07.006
   Xihe W., 2008, RES LIB SCI, V10, P12
   Xu SW, 2015, J INTEGR AGR, V14, P1889, DOI 10.1016/S2095-3119(15)61149-2
   Xu Y, 2012, J INTEGR AGR, V11, P839, DOI 10.1016/S2095-3119(12)60074-4
NR 22
TC 0
Z9 0
U1 7
U2 7
PU ACTA PRESS
PI CALGARY
PA 2509 DIEPPE AVE SW, BLDG B6, STE 101, CALGARY, AB T3E 7J9, CANADA
SN 0826-8185
EI 1925-7090
J9 INT J ROBOT AUTOM
JI Int. J. Robot. Autom.
PY 2018
VL 33
IS 1
BP 89
EP 96
DI 10.2316/Journal.206.2018.1.206-5433
PG 8
WC Automation & Control Systems; Robotics
SC Automation & Control Systems; Robotics
GA GF2XI
UT WOS:000431804100010
DA 2019-02-18
ER

PT J
AU Shang, S
   Zheng, YT
   Shen, M
   Yang, XF
   Xu, J
AF Shang, Shi
   Zheng, Yanting
   Shen, Ming
   Yang, Xianfeng
   Xu, Jun
TI Numerical Investigation on Head and Brain Injuries Caused by Windshield
   Impact on Riders Using Electric Self-Balancing Scooters
SO APPLIED BIONICS AND BIOMECHANICS
LA English
DT Article
ID PEDESTRIAN ACCIDENTS; LAMINATED GLASS; VEHICLE SPEED; KINEMATICS;
   RECONSTRUCTIONS; SIMULATIONS; COLLISIONS; MECHANISM; VELOCITY; SUBJECT
AB To investigate head-brain injuries caused by windshield impact on riders using electric self-balancing scooters (ESS). Numerical vehicle ESS crash scenarios are constructed by combining the finite element (FE) vehicle model and multibody scooter/rider models. Impact kinematic postures of the head-windshield contact under various impact conditions are captured. Then, the processes during head-windshield contact are reconstructed using validated FE head/laminated windshield models to assess the severity of brain injury caused by the head-windshield contact. Governing factors, such as vehicle speed, ESS speed, and the initial orientation of ESS rider, have nontrivial influences over the severity of a rider's brain injuries. Results also show positive correlations between vehicle speed and head-windshield impact speeds (linear and angular). Meanwhile, the time of head-windshield contact happens earlier when the vehicle speed is faster. According to the intensive study, windshield-head contact speed (linear and angular), impact location on the windshield, and head collision area are found to be direct factors on ESS riders' brain injuries during an impact. The von Mises stress and shear stress rise when relative contact speed of head-windshield increases. Brain injury indices vary widely when the head impacting the windshield from center to the edge or impacting with different areas.
C1 [Shang, Shi; Zheng, Yanting; Xu, Jun] Beihang Univ, AVRC, Beijing 100191, Peoples R China.
   [Shang, Shi; Xu, Jun] Beihang Univ, Sch Transportat Sci & Engn, Dept Automot Engn, Beijing 100191, Peoples R China.
   [Zheng, Yanting] Beihang Univ, Sch Transportat Sci & Engn, Dept Transportat, Beijing 100191, Peoples R China.
   [Shen, Ming] Wayne State Univ, Bioengn Ctr, Detroit, MI 48201 USA.
   [Yang, Xianfeng] Beihang Univ, Inst Solid Mech, Beijing 100191, Peoples R China.
RP Xu, J (reprint author), Beihang Univ, AVRC, Beijing 100191, Peoples R China.; Xu, J (reprint author), Beihang Univ, Sch Transportat Sci & Engn, Dept Automot Engn, Beijing 100191, Peoples R China.
EM junxu@buaa.edu.cn
RI Xu, Jun/B-2260-2016
OI Xu, Jun/0000-0002-8619-8737
FU "The Recruitment Program of Global Experts" awardee from Beihang
   University [YWF-16-RSC-011]; Beijing Municipal Science & Technology
   Commission [Z161100001416006]
FX This work is financially supported by start-up funds of "The Recruitment
   Program of Global Experts" awardee from Beihang University
   (YWF-16-RSC-011) and Beijing Municipal Science & Technology Commission
   (Grant no. Z161100001416006).
CR Alvarez V. S., 2016, 2016 IRCOBI C P INT, P813
   Boniface K, 2011, ANN EMERG MED, V57, P370, DOI 10.1016/j.annemergmed.2010.06.551
   Drew LB, 2004, NEUROCRIT CARE, V1, P385, DOI 10.1385/NCC:1:3:385
   El Sayed T, 2008, COMPUT METHOD APPL M, V197, P4692, DOI 10.1016/j.cma.2008.06.006
   Elliott JR, 2012, ACCIDENT ANAL PREV, V45, P342, DOI 10.1016/j.aap.2011.07.022
   Fahlstedt M, 2016, TRAFFIC INJ PREV, V17, P320, DOI 10.1080/15389588.2015.1067803
   Fahlstedt M, 2015, J BIOMECH, V48, P1331, DOI 10.1016/j.jbiomech.2015.02.057
   Han Y, 2012, TRAFFIC INJ PREV, V13, P507, DOI 10.1080/15389588.2012.661111
   Heinrichs BE, 2004, ACCIDENT ANAL PREV, V36, P829, DOI 10.1016/j.aap.2003.08.002
   Kerrigan J, 2012, INT J CRASHWORTHINES, V17, P243, DOI 10.1080/13588265.2011.648517
   Kimpara Hideyuki, 2006, Stapp Car Crash J, V50, P509
   Liu BH, 2016, INT J IMPACT ENG, V90, P26, DOI 10.1016/j.ijimpeng.2015.11.010
   Marzougui D, 2012, EXTENDED VALIDATION
   McLean A., 1996, P INT TECHN C ENH SA, P1408
   Mizuno K, 2014, ACCIDENT ANAL PREV, V73, P359, DOI 10.1016/j.aap.2014.09.018
   Mordaka J., 2007, P IRCOBI C MAASTR NE, P83
   Mueller Becky, 2013, Stapp Car Crash J, V57, P185
   Mukherjee S., 2000, P 2000 INT IRCOBI C, P323
   Okamoto Yutaka, 2003, Traffic Inj Prev, V4, P74, DOI 10.1080/15389580309856
   Peng Y, 2014, INT J CRASHWORTHINES, V19, P105, DOI 10.1080/13588265.2013.805290
   Peng Y, 2013, INT J IMPACT ENG, V57, P27, DOI 10.1016/j.ijimpeng.2013.01.010
   Peng Y, 2012, SAFETY SCI, V50, P1749, DOI 10.1016/j.ssci.2012.03.005
   Pyttel T, 2011, INT J IMPACT ENG, V38, P252, DOI 10.1016/j.ijimpeng.2010.10.035
   Sahoo D, 2015, MED BIOL ENG COMPUT, V53, P869, DOI 10.1007/s11517-015-1295-6
   Shigeta K., 2009, P INT TECHN C ENH SA, P15
   Simms C, 2009, SOLID MECH APPL, V166, P1, DOI 10.1007/978-90-481-2743-6
   Simms CK, 2006, INT J CRASHWORTHINES, V11, P345, DOI 10.1533/ijcr.2005.0109
   Tass B., 2010, MADYMO MODEL MANUAL
   TNO Automotive, 2001, MAN MADYMO HUM BOD M
   Van Hoof J, 2003, STAPP CAR CRASH J, V47, P401
   Xu J, 2011, INT J AUTO TECH-KOR, V12, P687, DOI 10.1007/s12239-011-0080-2
   Xu J, 2016, ACCIDENT ANAL PREV, V89, P128, DOI 10.1016/j.aap.2016.01.013
   Xu J, 2016, ACCIDENT ANAL PREV, V87, P102, DOI 10.1016/j.aap.2015.10.022
   Xu J, 2011, ENG FAIL ANAL, V18, P1605, DOI 10.1016/j.engfailanal.2011.05.004
   Xu J, 2011, COMPOS PART B-ENG, V42, P302, DOI 10.1016/j.compositesb.2010.10.009
   Xu J, 2010, COMP MATER SCI, V48, P582, DOI 10.1016/j.commatsci.2010.02.026
   Yang J., 2005, P 19 INT TECHN C ENH
   Yao JF, 2008, SAFETY SCI, V46, P1103, DOI 10.1016/j.ssci.2007.06.021
   Yong Peng, 2012, 2012 Third International Conference on Digital Manufacturing and Automation (ICDMA), P541, DOI 10.1109/ICDMA.2012.128
   Yu GZ, 2017, COMPUT STRUCT, V193, P139, DOI 10.1016/j.compstruc.2017.08.011
   Zhang J., 2010, AUTOMOTIVE DESIGN CR
   Zhang XH, 2012, INT J PROT STRUCT, V3, P407, DOI 10.1260/2041-4196.3.4.407
   Zhao S, 2006, INT J CRASHWORTHINES, V11, P105, DOI 10.1533/ijcr.2005.0386
NR 43
TC 0
Z9 0
U1 4
U2 7
PU HINDAWI LTD
PI LONDON
PA ADAM HOUSE, 3RD FLR, 1 FITZROY SQ, LONDON, W1T 5HF, ENGLAND
SN 1176-2322
EI 1754-2103
J9 APPL BIONICS BIOMECH
JI Appl. Bionics Biomech.
PY 2018
AR 5738090
DI 10.1155/2018/5738090
PG 15
WC Engineering, Biomedical; Robotics
SC Engineering; Robotics
GA GC3OK
UT WOS:000429693200001
PM 29770161
OA DOAJ Gold, Green Published
DA 2019-02-18
ER

PT J
AU Rutkowska-Kucharska, A
   Kowal, M
   Winiarski, S
AF Rutkowska-Kucharska, Alicja
   Kowal, Mateusz
   Winiarski, Slawomir
TI Relationship between Asymmetry of Gait and Muscle Torque in Patients
   after Unilateral Transfemoral Amputation
SO APPLIED BIONICS AND BIOMECHANICS
LA English
DT Article
ID LOWER-LIMB AMPUTATION; TRANS-TIBIAL AMPUTEES; GROUND REACTION FORCE;
   ISOKINETIC STRENGTH; PROSTHETIC KNEES; WALKING SPEED; LEVEL WALKING; HIP
   STRENGTH; ADJUSTMENTS; PATTERNS
AB Many studies have shown that unilateral transfemoral amputation involves asymmetric gait. Transfemoral amputation leads to muscle atrophy in a tight stump resulting in asymmetry in muscle torque between the amputated and intact limb. This research is aimed at verifying if a relationship between torque values of hip joint flexors and extensors and gait asymmetry in patients with TFA exists. Fourteen adult subjects with unilateral TFA took part in the experiment. Gait symmetry was evaluated based on the ground reaction force (GRF). Measurements of muscle torque of hip flexors and extensors were taken with a Biodex System. All measurements were taken under isokinetic (60 degrees/s and 120 degrees/s) and isometric conditions. The symmetry index of vertical GRF components was from 7.5 to 11.5%, and anterio-posterior GRF from 6.2 to 9.3%. The symmetry index for muscle torque was from 24.3 to 44% for flexors, from 39 to 50.5% for extensors, and from 28.6 to 50% in the flexor/extensor ratio. Gait asymmetry correlated with muscle torque in hip joint extensors. Therapy which enhances muscle torque may be an effective form of patient therapy. The patient needs to undergo evaluation of their muscle strength and have the therapy programme adjusted to their level of muscle torque deficit.
C1 [Rutkowska-Kucharska, Alicja; Winiarski, Slawomir] Univ Sch Phys Educ Wroclaw, Dept Biomech, Wroclaw, Poland.
   [Kowal, Mateusz] Wroclaw Med Univ, Dept Physiotherapy, Fac Hlth Sci, Wroclaw, Poland.
RP Rutkowska-Kucharska, A (reprint author), Univ Sch Phys Educ Wroclaw, Dept Biomech, Wroclaw, Poland.
EM alicja.rutkowska-kucharska@awf.wroc.pl
OI Winiarski, Slawomir/0000-0001-6109-7510; Rutkowska-Kucharska,
   Alicja/0000-0001-7196-2985
CR Bae TS, 2007, CLIN BIOMECH, V22, P557, DOI 10.1016/j.clinbiomech.2006.12.009
   Burger H, 1996, CLIN BIOMECH, V11, P35, DOI 10.1016/0268-0033(95)00032-1
   BURKE MJ, 1978, ANN RHEUM DIS, V37, P252, DOI 10.1136/ard.37.3.252
   Burkett B, 2003, PROSTHET ORTHOT INT, V27, P36
   CHAO EY, 1983, J BIOMECH, V16, P219, DOI 10.1016/0021-9290(83)90129-X
   Cigali BS, 2004, BIOL SPORT, V21, P241
   Croisier JL, 2001, ISOKINET EXERC SCI, V9, P163, DOI 10.3233/IES-2001-0080
   de Castro M. P., 2014, PM&R, V6
   Devan H, 2015, J REHABIL RES DEV, V52, P1, DOI 10.1682/JRRD.2014.05.0135
   Maraes VRFD, 2014, REV BRAS MED ESPORTE, V20, P336, DOI 10.1590/1517-86922014200501806
   Gailey R, 2008, J REHABIL RES DEV, V45, P15, DOI 10.1682/JRRD.2006.11.0147
   Hafner BJ, 2015, J REHABIL RES DEV, V52, P677, DOI 10.1682/JRRD.2014.09.0210
   Harbo T, 2012, EUR J APPL PHYSIOL, V112, P267, DOI 10.1007/s00421-011-1975-3
   Kaufman KR, 2012, CLIN BIOMECH, V27, P460, DOI 10.1016/j.clinbiomech.2011.11.011
   KLINGENSTIERNA U, 1990, SCAND J REHABIL MED, V22, P39
   Kowal M., 2014, BIOMEDICAL HUMAN KIN, V6
   Kulkarni J, 1998, CLIN REHABIL, V12, P348, DOI 10.1191/026921598672367610
   Lim YP, 2013, GAIT POSTURE, V38, P253, DOI 10.1016/j.gaitpost.2012.11.020
   Michaud SB, 2000, J REHABIL RES DEV, V37, P1
   Moirenfeld I, 2000, PROSTHET ORTHOT INT, V24, P221, DOI 10.1080/03093640008726551
   Morgenroth DC, 2012, PM&R, V4, pS20, DOI 10.1016/j.pmrj.2012.01.003
   Nadler SF, 2001, AM J PHYS MED REHAB, V80, P572, DOI 10.1097/00002060-200108000-00005
   Nadollek Heidi, 2002, Physiother Res Int, V7, P203, DOI 10.1002/pri.260
   Nederhand MJ, 2012, CLIN BIOMECH, V27, P40, DOI 10.1016/j.clinbiomech.2011.07.008
   Nolan L, 2003, GAIT POSTURE, V17, P142, DOI 10.1016/S0966-6362(02)00066-8
   Nolan L, 2012, J REHABIL MED, V44, P241, DOI 10.2340/16501977-0921
   Nolan L, 2009, PROSTHET ORTHOT INT, V33, P230, DOI 10.1080/03093640903082118
   Pedzich W, 2012, ACTA BIOENG BIOMECH, V14, P107, DOI 10.5277/abb120412
   RADIN EL, 1973, J BIOMECH, V6, P51, DOI 10.1016/0021-9290(73)90037-7
   RENSTROM P, 1983, SCAND J REHABIL MED, P163
   ROBINSON RO, 1987, J MANIP PHYSIOL THER, V10, P172
   Roerdink M, 2012, GAIT POSTURE, V35, P446, DOI 10.1016/j.gaitpost.2011.11.005
   RYSER DK, 1988, ARCH PHYS MED REHAB, V69, P840
   Schaarschmidt M, 2012, HUM MOVEMENT SCI, V31, P907, DOI 10.1016/j.humov.2011.09.004
   Villa C, 2015, CLIN BIOMECH, V30, P623, DOI 10.1016/j.clinbiomech.2015.03.022
   Vrieling AH, 2009, CLIN REHABIL, V23, P659, DOI 10.1177/0269215509102947
   White R, 1999, CLIN BIOMECH, V14, P185, DOI 10.1016/S0268-0033(99)80003-5
   Winiarski S, 2017, ACTA BIOENG BIOMECH, V19, P107, DOI 10.5277/ABB-00671-2016-04
   Winiarski S, 2009, ACTA BIOENG BIOMECH, V11, P53
NR 39
TC 0
Z9 0
U1 1
U2 3
PU HINDAWI LTD
PI LONDON
PA ADAM HOUSE, 3RD FLR, 1 FITZROY SQ, LONDON, W1T 5HF, ENGLAND
SN 1176-2322
EI 1754-2103
J9 APPL BIONICS BIOMECH
JI Appl. Bionics Biomech.
PY 2018
AR 5190816
DI 10.1155/2018/5190816
PG 9
WC Engineering, Biomedical; Robotics
SC Engineering; Robotics
GA GB3LY
UT WOS:000428960700001
PM 29755583
OA DOAJ Gold, Green Published
DA 2019-02-18
ER

PT J
AU Lara-Barrios, CM
   Blanco-Ortega, A
   Guzman-Valdivia, CH
   Valles, KDB
AF Lara-Barrios, Carlos M.
   Blanco-Ortega, Andres
   Guzman-Valdivia, Cesar H.
   Bustamante Valles, Karla D.
TI Literature review and current trends on transfemoral powered prosthetics
SO ADVANCED ROBOTICS
LA English
DT Article
DE Active prosthetics; biomechanics; series elastic actuator (SEA); gait
   analysis; electromyography
ID KNEE PROSTHESIS; AMPUTEES; LEVEL
AB Transfemoral amputation is a common amputation procedure for the human lower limbs. Passive, semi-active, and active prosthetic devices are usually prescribed to amputees in order to restore their quality of life (QOL) according to their abilities. From an engineering perspective, prosthetic and normal gait analysis, actuator technology, and biologic prosthetic control strategies are some of the current objects of study on active lower limb prosthetic design which aimed to reduce potential biomechanical disorders such as gait asymmetry or elevated metabolic cost due to the use of passive prosthetic devices. The main goal of active prosthetic design is to deliver prosthetic assistance at biological levels. This paper reviews the latest developments of semi-active and active prosthetics for transfemoral amputees; as well as the common design considerations and efficiency assessments performed on active transfemoral prosthetics under development in recent years.
C1 [Lara-Barrios, Carlos M.; Blanco-Ortega, Andres] Tecnol Nacl Mexico, Dept Mech Engn, Ctr Nacl Inestigac & Desarrollo Tecnol, Cuernavaca, Morelos, Mexico.
   [Guzman-Valdivia, Cesar H.] Univ Politecn Zacatecas, Dept Mechatron Engn, Robot, Fresnillo, Mexico.
   [Bustamante Valles, Karla D.] Ctr Invest Bioingn AC, Chihuahua, Mexico.
RP Lara-Barrios, CM (reprint author), Tecnol Nacl Mexico, Dept Mech Engn, Ctr Nacl Inestigac & Desarrollo Tecnol, Cuernavaca, Morelos, Mexico.
EM carlos.lara@cenidet.edu.mx
FU Consejo Nacional de Ciencia y Tecnologia (CONACYT) in Mexico
FX This work was supported by Consejo Nacional de Ciencia y Tecnologia
   (CONACYT) in Mexico.
CR Alimusaj M, 2009, GAIT POSTURE, V30, P356, DOI 10.1016/j.gaitpost.2009.06.009
   Alves GC, 2015, INT J BIOMED ENG TEC, V17, P72, DOI 10.1504/IJBET.2015.066969
   Ambrozic L, 2014, IEEE ROBOT AUTOM MAG, V21, P82, DOI 10.1109/MRA.2014.2360278
   Andriacchi TP, 1980, J BONE JOINT SURG AM, V62, P749, DOI 10.2106/00004623-198062050-00008
   Argunsah Bayram H, 2014, CLIN BIOMECH, V29, P1193, DOI 10.1016/j.clinbiomech.2014.09.004
   Arnout M, 2012, P IEEE RAS-EMBS INT, P550, DOI 10.1109/BioRob.2012.6290833
   Au S, 2008, NEURAL NETWORKS, V21, P654, DOI 10.1016/j.neunet.2008.03.006
   Bae TS, 2009, J MED ENG TECHNOL, V33, P130, DOI 10.1080/03091900701404043
   Bedard S, 2008, ACTUATED LEG PROSTHE, P1
   Buckley JG, 1997, ARCH PHYS MED REHAB, V78, P330, DOI 10.1016/S0003-9993(97)90044-7
   Carlson JD, 2001, P SOC PHOTO-OPT INS, V4332, P308, DOI 10.1117/12.429670
   Chin T, 2006, PROSTHET ORTHOT INT, V30, P73, DOI 10.1080/03093640500533414
   Cluff T, 2011, GAIT POSTURE, V33, P423, DOI 10.1016/j.gaitpost.2010.12.016
   Crea S, 2012, IEEE ENG MED BIO, P5018, DOI 10.1109/EMBC.2012.6347120
   Datta D, 1998, PROSTHET ORTHOT INT, V22, P129
   De Rossi SMM, 2012, P IEEE RAS-EMBS INT, P361, DOI 10.1109/BioRob.2012.6290278
   De Roy K, 2008, CASE STUDY INTELLIGE, P295
   Deffenbaugh BW, 2004, ELECT CONTROLLED PRO, P1
   Della Croce U, 2007, J BIOMECH, V40, P702, DOI 10.1016/j.jbiomech.2006.01.020
   Drevelle X, 2014, COMPUT METHOD BIOMEC, V17, P80, DOI 10.1080/10255842.2014.931146
   Dumas R, 2009, GAIT POSTURE, V30, P560, DOI 10.1016/j.gaitpost.2009.07.126
   Eberly VJ, 2014, PROSTHET ORTHOT INT, V38, P447, DOI 10.1177/0309364613506912
   El-Sayed AM, 2014, SCI WORLD J, DOI 10.1155/2014/297431
   Eslamy M., 2013, IEEE INT C REH ROB, P1
   Esquenazi A, 2011, PHYS MED REHABILITAT, P99
   Everarts C, 2012, IEEE INT C INT ROBOT, P323, DOI 10.1109/IROS.2012.6385789
   Farrell MT, 2011, IEEE ENG MED BIO, P6041, DOI 10.1109/IEMBS.2011.6091493
   Fey NP, 2014, IEEE J TRANSL ENG HE, V2
   Fite K, 2007, INT C REHAB ROBOT, P902, DOI 10.1109/ICORR.2007.4428531
   Flynn L, 2015, INT C REHAB ROBOT, P410, DOI 10.1109/ICORR.2015.7281234
   Frossard L, 2011, PROSTHET ORTHOT INT, V35, P140, DOI 10.1177/0309364611409002
   Geeroms J, 2013, IEEE 13 INT C REH RO, P1
   Ha KH, 2010, IEEE ENG MED BIO, P3515, DOI 10.1109/IEMBS.2010.5627736
   Hafner BJ, 2015, J REHABIL RES DEV, V52, P677, DOI 10.1682/JRRD.2014.09.0210
   Hargrove LJ, 2013, N ENGL J MED, V369, P1237, DOI 10.1056/NEJMoa1300126
   Hefferman GM, 2015, PROSTHET ORTHOT INT, V39, P166, DOI 10.1177/0309364613516484
   Heitzmann D, 2012, GAIT POSTURE, V36, pS72, DOI 10.1016/j.gaitpost.2011.10.303
   Herr H, 2003, IND ROBOT INT J, V30, P42, DOI 10.1108/01439910310457706
   Herr HM, 2007, SPEED ADAPTIVE PATIE, P1
   HILL DECLAN, 2013, REH ROB ICORR 2013 I
   Hobara H, 2011, PROSTHET ORTHOT INT, V35, P467, DOI 10.1177/0309364611425564
   Hoover Carl D, 2011, IEEE Int Conf Rehabil Robot, V2011, P5975480, DOI 10.1109/ICORR.2011.5975480
   Hoover CD, 2012, J MED DEVICE, V6, DOI 10.1115/1.4005784
   Huang H, 2011, IEEE T BIO-MED ENG, V58, P2867, DOI 10.1109/TBME.2011.2161671
   KOGANEZAWA K, 1987, PROSTHET ORTHOT INT, V11, P139
   Laferrier JZ, 2010, PHYS MED REH CLIN N, V21, P87, DOI 10.1016/j.pmr.2009.08.003
   Lambrecht BGA, 2009, IEEE INT CONF ROBOT, P4097
   Lawson B. E., 2011, IEEE INT C REH ROB Z, P1
   Lawson BE, 2014, CONTROL METHODOLOGIE
   Lawson BE, 2012, IEEE ENG MED BIO, P4164, DOI 10.1109/EMBC.2012.6346884
   Lawson BE, 2010, IEEE ENG MED BIO, P511, DOI 10.1109/IEMBS.2010.5626021
   Lawson BE, 2011, IEEE T BIO-MED ENG, V58, P2617, DOI 10.1109/TBME.2011.2160173
   Ledoux ED, 2015, IEEE ENG MED BIO, P5307, DOI 10.1109/EMBC.2015.7319589
   Liu M, 2014, J INTELL ROBOT SYST, V76, P461, DOI 10.1007/s10846-013-9979-3
   LYONS K, 1983, PHYS THER, V63, P1597, DOI 10.1093/ptj/63.10.1597
   Martinez-Villalpando EC, 2009, J REHABIL RES DEV, V46, P361, DOI 10.1682/JRRD.2008.09.0131
   Martinez-Villalpando EC, 2012, DESIGN AND EVALUATIO
   Martinez-Villalpando EC, 2011, IEEE ENG MED BIO, P8519, DOI 10.1109/IEMBS.2011.6092102
   Martinez-Villalpando EC, 2008, P IEEE RAS-EMBS INT, P529, DOI 10.1109/BIOROB.2008.4762919
   McFadyen BJ, 1988, J BIOMECH, V21, P733, DOI 10.1016/0021-9290(88)90282-5
   Peng J, 2016, J BIOMECH, V49, P528, DOI 10.1016/j.jbiomech.2015.12.041
   Pfeifer S, 2015, IEEE ASME T MECHATRO, V20, P1384, DOI 10.1109/TMECH.2014.2337514
   Pfeifer S, 2010, FINDING BEST PREDICT, P39
   Pfeifer S. M., 2014, THESIS
   Pfeifer S, 2012, P IEEE RAS-EMBS INT, P1807, DOI 10.1109/BioRob.2012.6290745
   Pillai M. V., 2011, 2011 IEEE International Conference on Robotics and Automation (ICRA 2011), P5293, DOI 10.1109/ICRA.2011.5980178
   Pinitlertsakun J., 2011, Proceedings of the 2011 Biomedical Engineering International Conference (BMEiCON) - Conference postponed to 2012, P120, DOI 10.1109/BMEiCon.2012.6172033
   Pinitlertsakun J, 2013, 6 BIOM ENG INT C AMP, P1
   PRATT GA, 1995, IROS '95 - 1995 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS: HUMAN ROBOT INTERACTION AND COOPERATIVE ROBOTS, PROCEEDINGS, VOL 1, P399, DOI 10.1109/IROS.1995.525827
   Pratt J, 2002, IND ROBOT INT J, V29, P234, DOI 10.1108/01439910210425522
   Protopapadaki A, 2007, CLIN BIOMECH, V22, P203, DOI [10.1016/j.clinbiomech.2006.09.010, DOI 10.1016/J.CLINBI0MECH.2006.09.010]
   Rouse E. J., 2013, IEEE INT C REH ROB 2, P1, DOI DOI 10.1109/IC0RR.2013.6650383
   Russell Esposito E, 2016, PROSTHET ORTHOT INT, V40, P311, DOI 10.1177/0309364614564021
   Sagawa Y, 2011, GAIT POSTURE, V33, P511, DOI 10.1016/j.gaitpost.2011.02.003
   Schmalz T, 2007, GAIT POSTURE, V25, P267, DOI 10.1016/j.gaitpost.2006.04.008
   Schuy J, 2014, 2014 IEEE Healthcare Innovation Conference (HIC), P91, DOI 10.1109/HIC.2014.7038882
   Stacoff A, 2005, GAIT POSTURE, V21, P24, DOI 10.1016/j.gaitpost.2003.11.003
   Sup F. C., 2006, ASME INT MECH ENG C, V2006, P1419
   Sup F, 2007, IEEE INT CONF ROBOT, P4134, DOI 10.1109/ROBOT.2007.364114
   Sup Frank, 2009, IEEE Int Conf Rehabil Robot, V2009, P638, DOI 10.1109/ICORR.2009.5209625
   Sup F, 2009, IEEE-ASME T MECH, V14, P667, DOI 10.1109/TMECH.2009.2032688
   Tucker MR, 2010, IEEE ASME INT C ADV
   Varol HA, 2010, IEEE T BIOMED ENG, V57, P542, DOI 10.1109/TBME.2009.2034734
   Varol Huseyin Atakan, 2009, IEEE Int Conf Rehabil Robot, V5209582, P645, DOI 10.1109/ICORR.2009.5209582
   Varol HA, 2008, P IEEE RAS-EMBS INT, P66, DOI 10.1109/BIOROB.2008.4762860
   Wang J, 2013, IEEE INT C REH ROB, V2013, P1
   Waters R, 1976, J BONE JT SURG, V58, P42, DOI 10.2106/00004623-197658010-00007
   Wentink EC, 2014, GAIT POSTURE, V39, P391, DOI 10.1016/j.gaitpost.2013.08.008
   Wolf EJ, 2012, J REHABIL RES DEV, V49, P831, DOI 10.1682/JRRD.2010.12.0234
   Wolf EJ, 2013, GAIT POSTURE, V38, P397, DOI 10.1016/j.gaitpost.2013.01.007
   Yokogushi K, 2004, J REHABIL RES DEV, V41, P675, DOI 10.1682/JRRD.2003.05.0076
NR 91
TC 0
Z9 0
U1 1
U2 9
PU TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND
SN 0169-1864
EI 1568-5535
J9 ADV ROBOTICS
JI Adv. Robot.
PY 2018
VL 32
IS 2
BP 51
EP 62
DI 10.1080/01691864.2017.1402704
PG 12
WC Robotics
SC Robotics
GA FU1NH
UT WOS:000423616200001
DA 2019-02-18
ER

PT J
AU Tan, ZH
   Thomsen, NB
   Duan, XD
   Vlachos, E
   Shepstone, SE
   Rasmussen, MH
   Hojvang, JL
AF Tan, Zheng-Hua
   Thomsen, Nicolai Baek
   Duan, Xiaodong
   Vlachos, Evgenios
   Shepstone, Sven Ewan
   Rasmussen, Morten Hojfeldt
   Hojvang, Jesper Lisby
TI iSocioBot: A Multimodal Interactive Social Robot
SO INTERNATIONAL JOURNAL OF SOCIAL ROBOTICS
LA English
DT Article; Proceedings Paper
CT 9th International Conference on Social Robotics (ICSR)
CY NOV 22-24, 2017
CL Tsukuba, JAPAN
DE Social robot; Human robot interaction; Speech processing; Image
   processing
ID ANTHROPOMORPHISM; CHILDREN; PEOPLE
AB We present one way of constructing a social robot, such that it is able to interact with humans using multiple modalities. The robotic system is able to direct attention towards the dominant speaker using sound source localization and face detection, it is capable of identifying persons using face recognition and speaker identification and the system is able to communicate and engage in a dialog with humans by using speech recognition, speech synthesis and different facial expressions. The software is built upon the open-source robot operating system framework and our software is made publicly available. Furthermore, the electrical parts (sensors, laptop, base platform, etc.) are standard components, thus allowing for replicating the system. The design of the robot is unique and we justify why this design is suitable for our robot and the intended use. By making software, hardware and design accessible to everyone, we make research in social robotics available to a broader audience. To evaluate the properties and the appearance of the robot we invited users to interact with it in pairs (active interaction partner/observer) and collected their responses via an extended version of the Godspeed Questionnaire. Results suggest an overall positive impression of the robot and interaction experience, as well as significant differences in responses based on type of interaction and gender.
C1 [Tan, Zheng-Hua; Thomsen, Nicolai Baek; Duan, Xiaodong; Vlachos, Evgenios; Rasmussen, Morten Hojfeldt] Aalborg Univ, Dept Elect Syst, Fredrik Bajers Vej 7B, DK-9220 Aalborg, Denmark.
   [Shepstone, Sven Ewan] Bang & Olufsen AS, Peter Bangs Vej 15, DK-7600 Struer, Denmark.
   [Hojvang, Jesper Lisby] MV Nordic, Lucernemarken 17, DK-5260 Odense, Denmark.
RP Tan, ZH (reprint author), Aalborg Univ, Dept Elect Syst, Fredrik Bajers Vej 7B, DK-9220 Aalborg, Denmark.
EM zt@es.aau.dk
OI Vlachos, Evgenios/0000-0001-8235-0423
FU Danish Council for Independent Research \ Technology and Production
   Sciences [1335-00162]
FX This work is supported by the Danish Council for Independent Research
   vertical bar Technology and Production Sciences under Grant Number.
   1335-00162 (iSocioBot).
CR Baddoura R, 2013, INT J SOC ROBOT, V5, P529, DOI 10.1007/s12369-013-0207-x
   Bartneck C, 2009, INT J SOC ROBOT, V1, P71, DOI 10.1007/s12369-008-0001-3
   Boersma P., 1993, P I PHONETIC SCI, V17, P97, DOI DOI 10.1371/JOURNAL.PONE.0069107
   Brahnam S., 2014, LOCAL BINARY PATTERN, V506, P1
   Breazeal C, 2004, IEEE T SYST MAN CY C, V34, P181, DOI 10.1109/TSMCC.2004.826268
   Broekens Joost, 2009, Gerontechnology, V8, P94
   Chang WL, 2015, ACMIEEE INT CONF HUM, P343, DOI 10.1145/2696454.2696472
   Cialdini RB, 1993, INFLUENCE PSYCHOL PE
   Cooney Martin D., 2011, 2011 11th IEEE-RAS International Conference on Humanoid Robots (Humanoids 2011), P112, DOI 10.1109/Humanoids.2011.6100847
   Dehak N, 2011, IEEE T AUDIO SPEECH, V19, P788, DOI 10.1109/TASL.2010.2064307
   DiBiase J. H., 2000, THESIS
   Duan XD, 2015, IEEE IMAGE PROC, P2905, DOI 10.1109/ICIP.2015.7351334
   EKMAN P, 1992, COGNITION EMOTION, V6, P169, DOI 10.1080/02699939208411068
   Eyssel F, 2012, BRIT J SOC PSYCHOL, V51, P724, DOI 10.1111/j.2044-8309.2011.02082.x
   Feil-Seifer D, 2005, INT C REHAB ROBOT, P465
   Fortenberry B, 2004, P INT C DEV LEARN IC
   Francois D, 2009, INTERACT STUD, V10, P324, DOI 10.1075/is.10.3.04fra
   Garofolo J., 1993, TIMIT ACOUSTIC PHONE
   Gass Robert H., 2015, PERSUASION SOCIAL IN
   Haring KS, 2015, 2015 24TH IEEE INTERNATIONAL SYMPOSIUM ON ROBOT AND HUMAN INTERACTIVE COMMUNICATION (RO-MAN), P821, DOI 10.1109/ROMAN.2015.7333613
   Hashimoto T, 2006, SICE ICASE INT JOINT, P5423, DOI DOI 10.1109/SICE.2006.315537
   Ho CC, 2010, COMPUT HUM BEHAV, V26, P1508, DOI 10.1016/j.chb.2010.05.015
   Ho Seok Ahn, 2012, Social Robotics. 4th International Conference (ICSR 2012). Proceedings, P219, DOI 10.1007/978-3-642-34103-8_22
   Jochum E, 2016, INT J SOC ROBOT, P1
   Kanda T, 2004, P IEEE, V92, P1839, DOI 10.1109/JPROC.2004.835359
   Kenny P, 2005, IEEE T SPEECH AUDI P, V13, P345, DOI 10.1109/TSA.2004.840940
   Kim ES, 2013, J AUTISM DEV DISORD, V43, P1038, DOI 10.1007/s10803-012-1645-2
   Kober J, 2012, ADAPT LEARN OPTIM, V12, P579
   Larcher A, 2013, ANN C INT SPEECH COM, P1
   Manohar V, 2014, IEEE T HUM-MACH SYST, V44, P362, DOI 10.1109/THMS.2014.2309662
   Mazzei D, 2012, P IEEE RAS-EMBS INT, P195
   Metta G., 2008, P 8 WORKSH PERF METR, P50, DOI DOI 10.1145/1774674.1774683
   Michalowski MP, 2006, 9TH IEEE INTERNATIONAL WORKSHOP ON ADVANCED MOTION CONTROL, VOLS 1 AND 2, PROCEEDINGS, P762, DOI 10.1109/AMC.2006.1631755
   Ojansivu V, 2008, LECT NOTES COMPUT SC, V5099, P236, DOI 10.1007/978-3-540-69905-7_27
   Okuno HG, 2002, LECT NOTES ARTIF INT, V2358, P725
   Okuno HG, 2001, IROS 2001: PROCEEDINGS OF THE 2001 IEEE/RJS INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-4, P1402, DOI 10.1109/IROS.2001.977177
   Pereira FG, 2013, J CONTROL AUTOM ELEC, V24, P187, DOI 10.1007/s40313-013-0040-3
   Pietikainen M, 2011, COMPUT IMAGING VIS, V40, P1
   Reich-Stiebert N, 2015, INT J SOC ROBOT, V7, P875, DOI 10.1007/s12369-015-0308-9
   Robinson H, 2014, INT J SOC ROBOT, V6, P575, DOI 10.1007/s12369-014-0242-2
   Salichs MA, 2006, 2006 IEEE CONFERENCE ON ROBOTICS, AUTOMATION AND MECHATRONICS, VOLS 1 AND 2, P862
   Siegel M, 2009, 2009 IEEE-RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, P2563, DOI 10.1109/IROS.2009.5354116
   Stiefelhagen R., 2004, 2004 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) (IEEE Cat. No.04CH37566), P2422
   Stiefelhagen R, 2007, IEEE T ROBOT, V23, P840, DOI 10.1109/TRO.2007.907484
   Stiefelhagen Rainer, 2002, CHI 02 HUM FACT COMP, P858, DOI [DOI 10.1145/506443.506634., 10.1145/506443.506634]
   Tahir Y, 2014, ACMIEEE INT CONF HUM, P300, DOI 10.1145/2559636.2559831
   Tan ZH, 2015, MECH MACH SCI, V33, P113, DOI 10.1007/978-3-319-18126-4_11
   Tan ZH, 2010, IEEE J-STSP, V4, P798, DOI 10.1109/JSTSP.2010.2057192
   Thomsen NB, 2015, 3 AAU WORKSH ROB AAL
   Thomsen NB, 2014, MULTIMODAL ANAL ENAB, P25
   Viola P, 2001, INT J COMPUTER VISIO
   Vlachos Evgenios, 2012, Social Robotics. 4th International Conference (ICSR 2012). Proceedings, P56, DOI 10.1007/978-3-642-34103-8_6
   Vlachos E, 2016, LNAI, V9549
   Vlachos E, 2015, 2015 24TH IEEE INTERNATIONAL SYMPOSIUM ON ROBOT AND HUMAN INTERACTIVE COMMUNICATION (RO-MAN), P746, DOI 10.1109/ROMAN.2015.7333676
NR 54
TC 0
Z9 0
U1 2
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1875-4791
EI 1875-4805
J9 INT J SOC ROBOT
JI Int. J. Soc. Robot.
PD JAN
PY 2018
VL 10
IS 1
BP 5
EP 19
DI 10.1007/s12369-017-0426-7
PG 15
WC Robotics
SC Robotics
GA FT4VI
UT WOS:000423152900002
DA 2019-02-18
ER

PT J
AU Hirano, T
   Shiomi, M
   Iio, T
   Kimoto, M
   Tanev, I
   Shimohara, K
   Hagita, N
AF Hirano, Takahiro
   Shiomi, Masahiro
   Iio, Takamasa
   Kimoto, Mitsuhiko
   Tanev, Ivan
   Shimohara, Katsunori
   Hagita, Norihiro
TI How Do Communication Cues Change Impressions of Human-Robot Touch
   Interaction?
SO INTERNATIONAL JOURNAL OF SOCIAL ROBOTICS
LA English
DT Article; Proceedings Paper
CT 9th International Conference on Social Robotics (ICSR)
CY NOV 22-24, 2017
CL Tsukuba, JAPAN
DE Human-robot interaction; Haptic interaction; Touch; Communication cue
ID INTERPERSONAL TOUCH; SUPPORT; REQUEST; STRESS; AGENTS
AB Communication cues, e.g., gaze behaviors and touch styles, are essential factors in the close interaction of people with social robots. Even though the communication cues are broadly investigated in human-robot interaction, it remain unknown how they change human impressions of social robots in haptic interaction situations. For better understanding of communication cues in human-robot touch interaction, we conducted an experiment with 28 participants who interacted with a robot with gaze behaviors and touch styles. We prepared two gaze behaviors and three touch styles based on past research works. Our experimental results showed that participants preferred a gaze behavior more that only looks at their faces during a touch than a gaze behavior that looks at their faces, hands and returns to their face. They also preferred a touch style in which they touched the robot more than touch styles where a robot touches them.
C1 [Hirano, Takahiro; Shiomi, Masahiro; Iio, Takamasa; Kimoto, Mitsuhiko; Hagita, Norihiro] ATR, Intelligent Robot & Commun Labs, 2-2-2 Hikaridai, Keihanna Sci City, Kyoto, Japan.
   [Hirano, Takahiro; Kimoto, Mitsuhiko; Tanev, Ivan; Shimohara, Katsunori] Doshisha Univ, 1-3 Tatara Miyakodani, Kyotanabe, Kyoto, Japan.
   [Iio, Takamasa] Osaka Univ, 1-3 Machikaneyama, Toyonaka, Osaka, Japan.
RP Shiomi, M (reprint author), ATR, Intelligent Robot & Commun Labs, 2-2-2 Hikaridai, Keihanna Sci City, Kyoto, Japan.
EM m-shiomi@atr.jp
OI Kimoto, Mitsuhiko/0000-0001-8441-8815
FU JSPS KAKENHI Grant [JP15H05322, JP 16K12505, JP 15K16075]
FX This research work was supported by JSPS KAKENHI Grant Numbers
   JP15H05322, JP 16K12505, and JP 15K16075.
CR Bainbridge WA, 2008, 2008 17TH IEEE INTERNATIONAL SYMPOSIUM ON ROBOT AND HUMAN INTERACTIVE COMMUNICATION, VOLS 1 AND 2, P701, DOI 10.1109/ROMAN.2008.4600749
   Breazeal C., 2005, 2005 IEEE/RSJ International Conference on Intelligent Robots and Systems, P708
   BURGOON JK, 1984, HUM COMMUN RES, V10, P351, DOI 10.1111/j.1468-2958.1984.tb00023.x
   Chen TL, 2014, INT J SOC ROBOT, V6, P141, DOI 10.1007/s12369-013-0215-x
   Cohen S, 2015, PSYCHOL SCI, V26, P135, DOI 10.1177/0956797614559284
   Cooney M, 2014, INT J SOC ROBOT, V6, P173, DOI 10.1007/s12369-013-0212-0
   Cramer H, 2009, WORKSH REIGN CATZ DO
   Cramer H, 2009, COMPUT ANIMAT VIRT W, V20, P437, DOI 10.1002/cav.317
   Essick GK, 1999, NEUROREPORT, V10, P2083, DOI 10.1097/00001756-199907130-00017
   Field T, 2010, DEV REV, V30, P367, DOI 10.1016/j.dr.2011.01.001
   FISHER JD, 1976, SOCIOMETRY, V39, P416, DOI 10.2307/3033506
   Fukuda H, 2012, ACMIEEE INT CONF HUM, P131
   Gallace A, 2010, NEUROSCI BIOBEHAV R, V34, P246, DOI 10.1016/j.neubiorev.2008.10.004
   Gharbi M, 2015, 2015 24TH IEEE INTERNATIONAL SYMPOSIUM ON ROBOT AND HUMAN INTERACTIVE COMMUNICATION (RO-MAN), P319, DOI 10.1109/ROMAN.2015.7333626
   Grewen KM, 2003, BEHAV MED, V29, P123, DOI 10.1080/08964280309596065
   Gueguen N., 2007, International Journal of Hospitality Management, V26, P1019, DOI 10.1016/j.ijhm.2006.12.004
   Gueguen N, 2002, PERCEPT MOTOR SKILL, V95, P355, DOI 10.2466/PMS.95.6.355-360
   Gueguen N., 2005, INT J HOSP MANAG, V24, P295, DOI DOI 10.1016/J.IJHM.2004.06.004
   Hayashi K, 2012, ROBOTICS: SCIENCE AND SYSTEMS VII, P121
   Hirano T., 2016, P 4 INT C HUM AG INT, P201
   Hornik J., 1992, MARKET LETT, V3, P49, DOI DOI 10.1007/BF00994080
   Jakubiak BK, 2016, J EXP SOC PSYCHOL, V65, P59, DOI 10.1016/j.jesp.2016.04.001
   Komatsubara T., 2014, P 2 INT C HUM AG INT, P83
   Kuno Y, 2007, CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1 AND 2, P1191
   Lee JK, 2008, 2008 17TH IEEE INTERNATIONAL SYMPOSIUM ON ROBOT AND HUMAN INTERACTIVE COMMUNICATION, VOLS 1 AND 2, P166, DOI 10.1109/ROMAN.2008.4600661
   Li J., 2016, 66 ANN C INT COMM AS
   Li J, 2015, INT J HUM-COMPUT ST, V77, P23, DOI 10.1016/j.ijhcs.2015.01.001
   Light KC, 2005, BIOL PSYCHOL, V69, P5, DOI 10.1016/j.biopsycho.2004.11.002
   MAJOR B, 1982, J NONVERBAL BEHAV, V6, P148, DOI 10.1007/BF00987064
   Martin BAS, 2012, J CONSUM RES, V39, P174, DOI 10.1086/662038
   Mutlu B., 2009, 2009 4th ACM/IEEE International Conference on Human-Robot Interaction (HRI), P61
   Nie JQ, 2012, ACMIEEE INT CONF HUM, P201
   Park E, 2014, ROBOTICA, V32, P133, DOI 10.1017/S026357471300074X
   Powers A., 2007, 2007 2nd Annual Conference on Human-Robot Interaction (HRI), P145
   Salter T., 2007, 2007 2nd Annual Conference on Human-Robot Interaction (HRI), P105
   Satake S, 2013, IEEE T ROBOT, V29, P508, DOI 10.1109/TRO.2012.2226387
   Shi C, 2013, ROBOTICS SCI SYSTEMS, P24
   Shi C, 2015, INT J SOC ROBOT, V7, P889, DOI 10.1007/s12369-015-0285-z
   Shinozawa K, 2005, INT J HUM-COMPUT ST, V62, P267, DOI 10.1016/j.ijhcs.2004.11.003
   Shiomi M, 2017, INT J SOC ROBOT, V9, P5, DOI 10.1007/s12369-016-0339-x
   Shiomi M, 2013, INTERACT STUD, V14, P317, DOI 10.1075/is.14.3.01shi
   Smith DE, 1982, BASIC APPL SOC PSYCH, V3, P35, DOI 10.1207/s15324834basp0301_3
   Yamazaki R, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.00537
   Yu R, 2015, JMIR RES PROTOC, V4, DOI 10.2196/resprot.4189
NR 44
TC 1
Z9 1
U1 4
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1875-4791
EI 1875-4805
J9 INT J SOC ROBOT
JI Int. J. Soc. Robot.
PD JAN
PY 2018
VL 10
IS 1
BP 21
EP 31
DI 10.1007/s12369-017-0425-8
PG 11
WC Robotics
SC Robotics
GA FT4VI
UT WOS:000423152900003
DA 2019-02-18
ER

PT J
AU Kim, M
   Kwon, T
   Kim, K
AF Kim, Mingyu
   Kwon, Taesoo
   Kim, Kwanguk
TI Can Human-Robot Interaction Promote the Same Depth of Social Information
   Processing as Human-Human Interaction?
SO INTERNATIONAL JOURNAL OF SOCIAL ROBOTICS
LA English
DT Article; Proceedings Paper
CT 9th International Conference on Social Robotics (ICSR)
CY NOV 22-24, 2017
CL Tsukuba, JAPAN
DE Humanoid robot; Human-human interaction; Human-robot interaction; Social
   cognition; Joint attention
ID JOINT ATTENTION; COGNITION; CHILDREN; AUTISM; PERSONALITY; EXPRESSION;
   GENDER; TASK
AB Recent studies on human-robot interactions have suggested that humanoid robots have considerable potential in social cognition research. However, the authors are not aware of any studies regarding social information processing from human-robot interactions. To address this issue, we considered two types of social interaction tasks (initiating and responding joint attention tasks) and two types of interaction partners (robot and human partners). Distinguishing between these types of joint attention (JA) is important, because they are thought to reflect unique but common constellations of processes in human social cognition and social learning. Thirty-seven participants were recruited (Study 1:20 participants, Study 2:17 participants) for the current study, and they conducted a picture recognition social information processing task with either robot or human partners. The results of Study 1 suggested that participants who interacted with a humanoid robot achieved a better recognition memory performance in the initiating JA condition than in the responding JA condition. The results of Study 2 suggested that the human-human and human-robot interactions resulted in no quantifiable differences in recognition memory. We discuss the implications of our results for the utility of humanoid robots in social cognition studies and future research questions on human-robot interactions.
C1 [Kim, Mingyu; Kim, Kwanguk] Hanyang Univ, Dept Comp Sci, Human Comp Interact Lab, 222 Wangsimni Ro, Seoul 133791, South Korea.
   [Kwon, Taesoo] Hanyang Univ, Dept Comp Sci, Comp Graph & Animat Lab, 222 Wangsimni Ro, Seoul 133791, South Korea.
RP Kim, K (reprint author), Hanyang Univ, Dept Comp Sci, Human Comp Interact Lab, 222 Wangsimni Ro, Seoul 133791, South Korea.
EM kenny@hanyang.ac.kr
FU National Research Foundation of Korea (NRF) grant - Korea government
   (MSIP) [NRF-2014R1A1A1005390, NRF-2016R1E1A2020733]
FX This work was supported by the National Research Foundation of Korea
   (NRF) grant funded by the Korea government (MSIP) (NRF-2014R1A1A1005390
   and NRF-2016R1E1A2020733).
CR Anzalone SM, 2014, RES AUTISM SPECT DIS, V8, P814, DOI 10.1016/j.rasd.2014.03.002
   BALDWIN MW, 1995, J SOC PERS RELAT, V12, P547, DOI 10.1177/0265407595124008
   BANDURA A, 1977, PSYCHOL REV, V84, P191, DOI 10.1037//0033-295X.84.2.191
   Baron-Cohen S., 1997, MINDBLINDNESS ESSAY
   Bisio A, 2014, PLOS ONE, V9, P1
   Bluethmann W, 2003, AUTON ROBOT, V14, P179, DOI 10.1023/A:1022231703061
   Brooks R, 2002, DEV PSYCHOL, V38, P958, DOI 10.1037//0012-1649.38.6.958
   Burns JK, 2006, PROG NEURO-PSYCHOPH, V30, P797, DOI 10.1016/j.pnpbp.2006.01.006
   Chaminade T, 2013, FRONT NEUROROBOTICS, V7, DOI 10.3389/fnbot.2013.00012
   Chaminade T, 2009, J PHYSIOL-PARIS, V103, P286, DOI 10.1016/j.jphysparis.2009.08.011
   Dautenhahn K, 2003, ROBOTICA, V21, P443, DOI 10.1017/S0263574703004922
   Duquette A, 2008, AUTON ROBOT, V24, P147, DOI 10.1007/s10514-007-9056-5
   EAGLY AH, 1983, AM PSYCHOL, V38, P971
   Fasola J, 2012, P IEEE, V100, P2512, DOI 10.1109/JPROC.2012.2200539
   Fiske ST, 2013, SOCIAL COGNITION BRA
   HADAR U, 1985, J NONVERBAL BEHAV, V9, P214, DOI 10.1007/BF00986881
   Hall E. T., 1966, HIDDEN DIMENSION
   Horan WP, 2008, AM J PSYCHIATR REHAB, V11, P205, DOI 10.1080/15487760801963652
   Imai M, 2003, IEEE T IND ELECTRON, V50, P636, DOI 10.1109/TIE.2003.814769
   Johansson M, 2013, LECT NOTES ARTIF INT, V8239, P351, DOI 10.1007/978-3-319-02675-6_35
   Kaliouby RE, 2005, MING READING MACHINE
   Kasari C, 2008, J CONSULT CLIN PSYCH, V76, P125, DOI 10.1037/0022-006X.76.1.125
   Kim K, 2012, FRONT HUM NEUROSCI, V6, DOI 10.3389/fnhum.2012.00172
   Larsen RJ, 1996, PERS INDIV DIFFER, V21, P907, DOI 10.1016/S0191-8869(96)00148-1
   Lewis M, 2012, SOCIAL COGNITION ACQ
   Liu Y, 2013, 2013 IEEE 6TH INTERNATIONAL CONFERENCE ON ADVANCED INFOCOMM TECHNOLOGY (ICAIT), P9, DOI 10.1109/ICAIT.2013.6621472
   Marti P., 2006, P INT C BIOROB, P483, DOI 10.1109/BIOROB.2006.1639135
   Mundy P, 2000, DEV PSYCHOBIOL, V36, P325, DOI 10.1002/(SICI)1098-2302(200005)36:4<325::AID-DEV7>3.0.CO;2-F
   Mundy P, 2007, CURR DIR PSYCHOL SCI, V16, P269, DOI 10.1111/j.1467-8721.2007.00518.x
   Mundy P, 2009, AUTISM RES, V2, P2, DOI 10.1002/aur.61
   Pierno AC, 2008, NEUROPSYCHOLOGIA, V46, P448, DOI 10.1016/j.neuropsychologia.2007.08.020
   PREMACK D, 1978, BEHAV BRAIN SCI, V1, P515, DOI 10.1017/S0140525X00076512
   Redcay E, 2010, NEUROIMAGE, V50, P1639, DOI 10.1016/j.neuroimage.2010.01.052
   Ricks DJ, 2010, IEEE INT CONF ROBOT, P4354, DOI 10.1109/ROBOT.2010.5509327
   Robins B., 2005, Universal Access in the Information Society, V4, P105, DOI 10.1007/s10209-005-0116-3
   Scassellati B, 2007, SPRINGER TRAC ADV RO, V28, P552
   Schilbach L, 2010, J COGNITIVE NEUROSCI, V22, P2702, DOI 10.1162/jocn.2009.21401
   Schulz KP, 2007, ARCH CLIN NEUROPSYCH, V22, P151, DOI 10.1016/j.acn.2006.12.001
   Seibert J. M., 1982, INFANT MENT HEALTH J, V3, P244, DOI DOI 10.1002/1097-0355(198224)3:4<244::AID-IMHJ2280030406>3.0.CO;2-R
   Sheslow D, 2003, WIDE RANGE ASSESSMEN
   Siegel M, 2009, 2009 IEEE-RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, P2563, DOI 10.1109/IROS.2009.5354116
   Skantze G, 2014, SPEECH COMMUN, V65, P50, DOI 10.1016/j.specom.2014.05.005
   Stanislaw H, 1999, BEHAV RES METH INS C, V31, P137, DOI 10.3758/BF03207704
   Tapus A, 2007, IEEE ROBOT AUTOM MAG, V14, P35, DOI 10.1109/MRA.2007.339605
   Tay B, 2014, COMPUT HUM BEHAV, V38, P75, DOI 10.1016/j.chb.2014.05.014
   Tomasello M, 2005, MONOGR SOC RES CHILD, V70, P1
   Tomasello M, 2005, BEHAV BRAIN SCI, V28, P675, DOI 10.1017/S0140525X05000129
   Torta E, 2015, INT J SOC ROBOT, V7, P89, DOI 10.1007/s12369-014-0271-x
   Vygotsky L. S., 1978, READINGS DEV CHILDRE, P34
   Wallbott HG, 1998, EUR J SOC PSYCHOL, V28, P879, DOI 10.1002/(SICI)1099-0992(1998110)28:6<879::AID-EJSP901>3.0.CO;2-W
   Warren ZE, 2015, J AUTISM DEV DISORD, V45, P3726, DOI 10.1007/s10803-013-1918-4
   WATSON D, 1969, J CONSULT CLIN PSYCH, V33, P448, DOI 10.1037/h0027806
   Won AS, 2016, CYBERPSYCH BEH SOC N, V19, P380, DOI 10.1089/cyber.2015.0326
NR 53
TC 2
Z9 2
U1 4
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1875-4791
EI 1875-4805
J9 INT J SOC ROBOT
JI Int. J. Soc. Robot.
PD JAN
PY 2018
VL 10
IS 1
BP 33
EP 42
DI 10.1007/s12369-017-0428-5
PG 10
WC Robotics
SC Robotics
GA FT4VI
UT WOS:000423152900004
DA 2019-02-18
ER

PT J
AU Taheri, A
   Meghdari, A
   Alemi, M
   Pouretemad, H
AF Taheri, Alireza
   Meghdari, Ali
   Alemi, Minoo
   Pouretemad, Hamidreza
TI Human-Robot Interaction in Autism Treatment: A Case Study on Three Pairs
   of Autistic Children as Twins, Siblings, and Classmates
SO INTERNATIONAL JOURNAL OF SOCIAL ROBOTICS
LA English
DT Article; Proceedings Paper
CT 9th International Conference on Social Robotics (ICSR)
CY NOV 22-24, 2017
CL Tsukuba, JAPAN
DE Autism spectrum disorders; Human-Robot interaction; Joint attention;
   Imitation; Humanoid robot; Social skills
ID JOINT ATTENTION SKILLS; SPECTRUM DISORDERS; YOUNG-CHILDREN; IMITATION
   SKILLS; SOCIAL-SKILLS; INTERVENTION; DEFICITS; THERAPY; TRAITS; IMPACT
AB In this paper, three pairs of children with autism include a pair of twins, two siblings, and two classmates were enrolled in a 12-session robot-assisted group-games program. As many environmental factors were for the most part the same for the siblings as well as genetic factors for the twins, we were able to observe/compare the effect of the designed games on the participants individually and in paired-groups. The results indicated that all participants' autism severity decreased after the course of the program. Improvement in social skills, social participation/avoidance, and detrimental social behaviors were also observed in the participants with high-functioning autism with close to being large Cohen's d effect sizes. Moreover, based on the video coders' observations the joint attention, gaze scores toward the robot, and verbal communications of the paired-groups increased significantly over the treatment time (p < 0.05). However, in general, the designed program effect on the subjects' behavior seems to be different for participants from different points on the autism spectrum; and even the high-functioning subjects showed different potential behavioral progress.
C1 [Taheri, Alireza; Meghdari, Ali; Alemi, Minoo] Sharif Univ Technol, CEDRA, Social & Cognit Robot Lab, Tehran, Iran.
   [Alemi, Minoo] Islamic Azad Univ, Fac Humanities, West Tehran Branch, Tehran, Iran.
   [Pouretemad, Hamidreza] Shahid Beheshti Univ, ICBS, Tehran, Iran.
   [Taheri, Alireza; Pouretemad, Hamidreza] CTAD, Tehran, Iran.
RP Meghdari, A (reprint author), Sharif Univ Technol, CEDRA, Social & Cognit Robot Lab, Tehran, Iran.
EM taheri@mech.sharif.edu; meghdari@sharif.edu; alemi@sharif.edu;
   h-pouretemad@sbu.ac.ir
FU "Cognitive Sciences and Technology Council" (CSTC) of Iran
FX This study was funded by the "Cognitive Sciences and Technology Council"
   (CSTC) of Iran.
CR Ahmadi S. J., 2012, J RES COGNITIVE BEHA, V1, P87
   Alemi M, 2015, INT J SOC ROBOT, V7, P523, DOI 10.1007/s12369-015-0286-y
   Alemi M, 2016, INT J SOC ROBOT, V8, P743, DOI 10.1007/s12369-015-0294-y
   [Anonymous], 2010, MIN 17 STAT SOFTW CO
   Ashburner J, 2008, AM J OCCUP THER, V62, P564, DOI 10.5014/ajot.62.5.564
   Baron-Cohen S, 2001, PRISME, V34, P74
   Bellini S, 2008, CHILD ADOL PSYCH CL, V17, P857, DOI 10.1016/j.chc.2008.06.008
   BOCCANFUSO L, 2016, ACMIEEE INT CONF HUM, P19
   BURACK JA, 1992, J CHILD PSYCHOL PSYC, V33, P607, DOI 10.1111/j.1469-7610.1992.tb00894.x
   Carpenter M, 2002, J AUTISM DEV DISORD, V32, P91, DOI 10.1023/A:1014836521114
   Cohen J., 1988, STAT POWER ANAL BEHA
   Constantino JN, 2003, ARCH GEN PSYCHIAT, V60, P524, DOI 10.1001/archpsyc.60.5.524
   de Graaf MMA, 2016, INT J SOC ROBOT, V8, P589, DOI 10.1007/s12369-016-0368-5
   Duquette A, 2008, AUTON ROBOT, V24, P147, DOI 10.1007/s10514-007-9056-5
   Feil-Seifer D, 2009, EXPT ROBOTICS STAR, DOI [10.1007/978-3-642-00196-3_24, DOI 10.1007/978-3-642-00196-3_24]
   FOLSTEIN S, 1977, J CHILD PSYCHOL PSYC, V18, P297, DOI 10.1111/j.1469-7610.1977.tb00443.x
   Gilliam JE, 1995, GILLIAM AUTISM RATIN
   Hilton JC, 2007, J AUTISM DEV DISORD, V37, P1197, DOI 10.1007/s10803-006-0258-z
   Ho A, 2005, J AUTISM DEV DISORD, V35, P129, DOI 10.1007/s10803-004-1040-8
   Huskens B, 2015, J AUTISM DEV DISORD, V45, P3746, DOI 10.1007/s10803-014-2326-0
   Ingersoll B, 2008, INFANT YOUNG CHILD, V21, P107, DOI 10.1097/01.IYC.0000314482.24087.14
   Ingersoll B, 2007, RES DEV DISABIL, V28, P163, DOI 10.1016/j.ridd.2006.02.004
   Ingersoll B, 2006, J AUTISM DEV DISORD, V36, P487, DOI 10.1007/s10803-006-0089-y
   Ingersoll B, 2013, AJIDD-AM J INTELLECT, V118, P247, DOI 10.1352/1944-7558-188.4.247
   Kajopoulos J, 2015, LECT NOTES ARTIF INT, V9388, P296, DOI 10.1007/978-3-319-25554-5_30
   Kazdin A. E., 2011, SINGLE CASE RES DESI
   KEAN JM, 1975, NEW ZEAL MED J, V81, P204
   Khosla R., 2015, PACIS, P12
   Kim Sojung, 2015, BEHAV DEV B, V20, P253, DOI DOI 10.1037/H0101314
   Kozima H, 2005, 2005 IEEE International Workshop on Robot and Human Interactive Communication (RO-MAN), P341
   Kozima H, 2007, PROG BRAIN RES, V164, P385, DOI 10.1016/S0079-6123(07)64021-7
   Liu CC, 2008, IEEE T ROBOT, V24, P883, DOI 10.1109/TRO.2008.2001362
   Mavadati SM, 2014, IEEE-RAS INT C HUMAN, P1128, DOI 10.1109/HUMANOIDS.2014.7041510
   Mazefsky CA, 2008, RES AUTISM SPECT DIS, V2, P320, DOI 10.1016/j.rasd.2007.08.002
   Mitchell SR, 2009, AM J PSYCHIAT, V166, P917, DOI 10.1176/appi.ajp.2009.08101538
   Mundy P., 2003, EARLY SOCIAL COMMUNI
   Ozonoff S, 2011, PEDIATRICS, V128, pE488, DOI 10.1542/peds.2010-2825
   Pioggia G., 2006, P 6 INT C EP ROB MOD
   Pouretemad H., 2011, DIAGNOSIS TREATMENT
   Riff D., 2014, ANAL MEDIA MESSAGES
   RIMLAND B, 2000, AUTISM TREATMENT EVA
   Robins B., 2005, Universal Access in the Information Society, V4, P105, DOI 10.1007/s10209-005-0116-3
   Robins B, 2004, INTERACT STUD, V5, P161, DOI 10.1075/is.5.2.02rob
   Salvador M, 2015, IEEE INT C ROB AUT S
   Scassellati B, 2012, ANNU REV BIOMED ENG, V14, P275, DOI 10.1146/annurev-bioeng-071811-150036
   STEFFENBURG S, 1989, J CHILD PSYCHOL PSYC, V30, P405, DOI 10.1111/j.1469-7610.1989.tb00254.x
   Taheri AR, 2014, 2014 SECOND RSI/ISM INTERNATIONAL CONFERENCE ON ROBOTICS AND MECHATRONICS (ICROM), P760, DOI 10.1109/ICRoM.2014.6990995
   Taheri A, 2016, LECT NOTES ARTIF INT, V9979, P541, DOI 10.1007/978-3-319-47437-3_53
   Taheri A, 2015, LECT NOTES ARTIF INT, V9388, P623, DOI 10.1007/978-3-319-25554-5_62
   Tapus A, 2012, INTERACT STUD, V13, P315, DOI 10.1075/is.13.3.01tap
   Uzgiris I, 1999, IMITATION INFANCY, P186
   Warren ZE, 2015, J AUTISM DEV DISORD, V45, P3726, DOI 10.1007/s10803-013-1918-4
   Werry I, 2001, LECT NOTES ARTIF INT, V2117, P57
   Whalen C, 2003, J CHILD PSYCHOL PSYC, V44, P456, DOI 10.1111/1469-7610.00135
   Wong CCY, 2014, MOL PSYCHIATR, V19, P495, DOI 10.1038/mp.2013.41
NR 55
TC 2
Z9 2
U1 3
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1875-4791
EI 1875-4805
J9 INT J SOC ROBOT
JI Int. J. Soc. Robot.
PD JAN
PY 2018
VL 10
IS 1
BP 93
EP 113
DI 10.1007/s12369-017-0433-8
PG 21
WC Robotics
SC Robotics
GA FT4VI
UT WOS:000423152900007
DA 2019-02-18
ER

PT J
AU Jercic, P
   Wen, W
   Hagelback, J
   Sundstedt, V
AF Jercic, Petar
   Wen, Wei
   Hagelback, Johan
   Sundstedt, Veronica
TI The Effect of Emotions and Social Behavior on Performance in a
   Collaborative Serious Game Between Humans and Autonomous Robots
SO INTERNATIONAL JOURNAL OF SOCIAL ROBOTICS
LA English
DT Article; Proceedings Paper
CT 9th International Conference on Social Robotics (ICSR)
CY NOV 22-24, 2017
CL Tsukuba, JAPAN
DE Autonomous robots; Serious games; Collaborative play; Social
   interaction; Robot-assisted play; Emotions
AB The aim of this paper is to investigate performance in a collaborative human-robot interaction on a shared serious game task. Furthermore, the effect of elicited emotions and perceived social behavior categories on players' performance will be investigated. The participants collaboratively played a turn-taking version of the Tower of Hanoi serious game, together with the human and robot collaborators. The elicited emotions were analyzed in regards to the arousal and valence variables, computed from the Geneva Emotion Wheel questionnaire. Moreover, the perceived social behavior categories were obtained from analyzing and grouping replies to the Interactive Experiences and Trust and Respect questionnaires. It was found that the results did not show a statistically significant difference in participants' performance between the human or robot collaborators. Moreover, all of the collaborators elicited similar emotions, where the human collaborator was perceived as more credible and socially present than the robot one. It is suggested that using robot collaborators might be as efficient as using human ones, in the context of serious game collaborative tasks.
C1 [Jercic, Petar; Sundstedt, Veronica] Blekinge Inst Technol, Dept Creat Technol, S-37179 Karlskrona, Sweden.
   [Wen, Wei] Blekinge Inst Technol, Dept Technol & Aesthet, S-37179 Karlskrona, Sweden.
   [Hagelback, Johan] Linnaeus Univ, Dept Comp Sci, S-35195 Vaxjo, Sweden.
RP Jercic, P (reprint author), Blekinge Inst Technol, Dept Creat Technol, S-37179 Karlskrona, Sweden.
EM petar.jercic@bth.se; wei.wen@bth.se; johan.hagelback@lnu.se;
   veronica.sundstedt@bth.se
OI Wen, Wei/0000-0003-3887-5972; Hagelback, Johan/0000-0002-8591-1035
FU PsyIntEC EU Project through the European Clearing House for Open
   Robotics Development (ECHORD) [FP7-ICT-231143]
FX This work was funded by the PsyIntEC EU Project (FP7-ICT-231143) through
   the European Clearing House for Open Robotics Development (ECHORD).
CR Adamowicz M, 2011, EUR CONF POW ELECTR
   Bechara A, 2005, GAME ECON BEHAV, V52, P336, DOI 10.1016/j.geb.2004.06.010
   Bengtsson B., 1999, P 32 HAW INT C SYST, P1
   Breazeal C, 2002, DESIGNING SOCIABLE R
   BROOKS AG, 2004, COMPUTERS ENTERTAINM, V2, P10
   Burgoon JK, 2002, J COMMUN, V52, P657, DOI 10.1111/j.1460-2466.2002.tb02567.x
   Burgoon JK, 2000, COMPUT HUM BEHAV, V16, P553, DOI 10.1016/S0747-5632(00)00029-7
   Butler JT, 2001, AUTON ROBOT, V10, P185, DOI 10.1023/A:1008986004181
   Castellano G, 2012, PROCEEDINGS OF 2012 ASE/IEEE INTERNATIONAL CONFERENCE ON PRIVACY, SECURITY, RISK AND TRUST AND 2012 ASE/IEEE INTERNATIONAL CONFERENCE ON SOCIAL COMPUTING (SOCIALCOM/PASSAT 2012), P421, DOI 10.1109/SocialCom-PASSAT.2012.51
   Chen J, 2007, COMMUN ACM, V50, P31, DOI 10.1145/1232743.1232769
   Cooney M, 2015, ACM T INTERACT INTEL, V4, DOI 10.1145/2685395
   Corti K., 2006, INFORM PIXELLEARNING, V34, P1
   Crown Copyright, 2003, INTR HLTH SAF
   Csikszentmihalyi M., 2008, HARPER PERENNIAL MOD
   Dautenhahn K, 2007, INT J ADV ROBOT SYST, V4, P15, DOI DOI 10.5772/5702
   Dick Philip K, 1968, DO ANDROIDS DREAM EL
   Fenton-O'Creevy M, 2011, J ORGAN BEHAV, V32, P1044, DOI 10.1002/job.720
   Fiore SM, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00859
   Fong T, 2003, ROBOT AUTON SYST, V42, P143, DOI 10.1016/S0921-8890(02)00372-X
   Goetz J., 2003, P 12 IEEE WORKSH ROB
   Goetz J, 2002, CHI 02 HUM FACT COMP, P578
   Goodrich Michael A, 2007, Foundations and Trends in Human-Computer Interaction, V1, P203, DOI 10.1561/1100000005
   Gross J. J., 1998, REV GEN PSYCHOL, V2, P271, DOI DOI 10.1037/1089-2680.2.3.271
   Gross J. J, 2009, HDB EMOTION REGULATI
   Hagelback J, 2014, SPRINGER TRAC ADV RO, V94, P283, DOI 10.1007/978-3-319-02934-4_14
   Heerink M., 2008, J PHYS AGENTS, V2, P33
   Hinds PJ, 2004, HUM-COMPUT INTERACT, V19, P151, DOI 10.1207/s15327051hci1901&2_7
   Hocine N, 2013, SERIOUS GAMES FOR HEALTHCARE: APPLICATIONS AND IMPLICATIONS, P107, DOI 10.4018/978-1-4666-1903-6.ch006
   Ijsselsteijn W, 2000, TECHNICAL REPORT
   Jung Y, 2004, P 7 INT WORKSH PRES, P80, DOI DOI 10.1145/1349822.1349866
   Kanda Takayuki, 2007, 16th IEEE International Conference on Robot and Human Interactive Communication, P665
   KARWOWSKI W, 1991, ERGONOMICS, V34, P531, DOI 10.1080/00140139108967335
   Kidd C, 2003, THESIS
   Kidd C. D., 2004, 2004 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) (IEEE Cat. No.04CH37566), P3559
   Koay KL, 2005, 2005 IEEE INTERNATIONAL WORKSHOP ON ROBOT AND HUMAN INTERACTIVE COMMUNICATION (RO-MAN), P359
   Koda T, 1996, RO-MAN '96 - 5TH IEEE INTERNATIONAL WORKSHOP ON ROBOT AND HUMAN COMMUNICATION, PROCEEDINGS, P189, DOI 10.1109/ROMAN.1996.568812
   Licklider J.C.R., 1960, Institute of Radio Engineers Transactions on Human Factors in Electronics, VHFE-1, P4, DOI 10.1109/THFE2.1960.4503259
   Likert R., 1932, ARCH PSYCHOL, V22, P136
   Loewenstein G, 2000, AM ECON REV, V90, P426, DOI 10.1257/aer.90.2.426
   Loewenstein G, 1996, ORGAN BEHAV HUM DEC, V65, P272, DOI 10.1006/obhd.1996.0028
   Lombard Matthew, 2000, PRESENCE 2000
   Lucas E, 1893, RECREATIONS MATH
   Moravec Hans, 1998, ROBOT MERE MACHINE T
   Norman D. A., 2003, EMOTIONAL DESIGN WHY
   Pereira Andre, 2012, Advances in Computer Entertainment. Proceedings 9th International Conference, ACE 2012, P101, DOI 10.1007/978-3-642-34292-9_8
   Pfeifer R, 2014, TRENDS COGN SCI, V18, P404, DOI 10.1016/j.tics.2014.04.004
   Pfeifer R, 2012, COMMUN ACM, V55, P76, DOI 10.1145/2366316.2366335
   Picard RW, 2001, IEEE T PATTERN ANAL, V23, P1175, DOI 10.1109/34.954607
   Powers A., 2007, 2007 2nd Annual Conference on Human-Robot Interaction (HRI), P145
   Reeves B, 2003, C HUM FACT COMP SYST
   Reeves B., 1996, PEOPLE TREAT COMPUTE
   Rehnmark F, 2005, COMPUTER, V38, P28, DOI 10.1109/MC.2005.32
   Ros R, 2014, ROBOT AUTON SYST, V62, P707, DOI 10.1016/j.robot.2014.03.005
   Rubin R. B., 2010, COMMUNICATION RES ME
   RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714
   Sanghvi J, 2011, ACMIEEE INT CONF HUM, P305, DOI 10.1145/1957656.1957781
   SCHAEFFER J, 1997, ONE JUMP AHEAD CHALL
   Scherer KR, 2005, SOC SCI INFORM, V44, P695, DOI 10.1177/0539018405058216
   Scholl BJ, 2000, TRENDS COGN SCI, V4, P299, DOI 10.1016/S1364-6613(00)01506-0
   Sidner Candace L., 2004, P 9 INT C INT US INT, P78, DOI DOI 10.1145/964442.964458
   Sidner CL, 2005, ARTIF INTELL, V166, P140, DOI 10.1016/j.artint.2005.03.005
   Sisbot EA, 2005, IEEE-RAS INT C HUMAN, P181
   Susi T., 2007, TECHNICAL REPORT
   Syrdal D. S, 2006, 15 IEEE INT S ROB HU, P183, DOI DOI 10.1109/ROMAN.2006.314415
   Dang THH, 2013, LECT NOTES ARTIF INT, V8239, P160, DOI 10.1007/978-3-319-02675-6_16
   Thrun S, 1999, ICRA '99: IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS 1-4, PROCEEDINGS, P1999, DOI 10.1109/ROBOT.1999.770401
   Tira-Thompson EJ, 2004, INT C COGN MOD PITTS
   Van der Hoek M, 2007, P 2 ACM IEEE INT C H, P217, DOI [10.1145/1228716.1228746, DOI 10.1145/1228716.1228746]
   Wainer J, 2014, INT J SOC ROBOT, V6, P45, DOI 10.1007/s12369-013-0195-x
   Walters ML, 2005, 2005 IEEE International Workshop on Robot and Human Interactive Communication (RO-MAN), P347
   Walters ML, 2005, P ART INT SIM BEH AI
   Xin M, 2007, HUMAN ROBOT INTERACT, P522
   Xin M, 2006, LECT NOTES COMPUT SC, V4282, P249
   YAMATO J, 2003, NTT TECH REV, V1, P37
   Zoghbi S, 2010, P WORKSH MULT HUM RO
NR 75
TC 0
Z9 0
U1 1
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1875-4791
EI 1875-4805
J9 INT J SOC ROBOT
JI Int. J. Soc. Robot.
PD JAN
PY 2018
VL 10
IS 1
BP 115
EP 129
DI 10.1007/s12369-017-0437-4
PG 15
WC Robotics
SC Robotics
GA FT4VI
UT WOS:000423152900008
OA Other Gold, Green Published
DA 2019-02-18
ER

PT J
AU Seo, SH
   Griffin, K
   Young, JE
   Bunt, A
   Prentice, S
   Loureiro-Rodriguez, V
AF Seo, Stela H.
   Griffin, Keelin
   Young, James E.
   Bunt, Andrea
   Prentice, Susan
   Loureiro-Rodriguez, Veronica
TI Investigating People's Rapport Building and Hindering Behaviors When
   Working with a Collaborative Robot
SO INTERNATIONAL JOURNAL OF SOCIAL ROBOTICS
LA English
DT Article; Proceedings Paper
CT 9th International Conference on Social Robotics (ICSR)
CY NOV 22-24, 2017
CL Tsukuba, JAPAN
DE Human-robot interaction; Social robotics; Industrial team-work robots;
   Rapport
ID GENDER; DESIGN
AB Modern industrial robots are increasingly moving toward collaborating with people on complex tasks as team members, and away from working in isolated cages that are separated from people. Collaborative robots are programmed to use social communication techniques with people, enabling human team members to use their existing inter-personal skills to work with robots, such as speech, gestures, or gaze. Research is increasingly investigating how robots can use higher-level social structures such as team dynamics or conflict resolution. One particularly important aspect of human-human teamwork is rapport building: these are everyday social interactions between people that help to develop professional relationships by establishing trust, confidence, and collegiality, but which are formally peripheral to a task at hand. In this paper, we report on our investigations of how and if people apply similar rapport-building behaviors to robot collaborators. First, we synthesized existing human-human rapport knowledge into an initial human-robot interaction framework; this framework includes verbal and non-verbal behaviors, both for rapport building and rapport hindering, that people can be expected to exhibit. We developed a novel mock industrial task scenario that emphasizes ecological validity, and creates a range of social interactions necessary for investigating rapport. Finally, we report on a qualitative study that investigates how people use rapport hindering or building behaviors in our industrial scenario, which reflects how people may interact with robots in industrial settings.
C1 [Seo, Stela H.; Young, James E.; Bunt, Andrea] Univ Manitoba, Dept Comp Sci, Winnipeg, MB, Canada.
   [Griffin, Keelin; Prentice, Susan] Univ Manitoba, Dept Sociol, Winnipeg, MB, Canada.
   [Loureiro-Rodriguez, Veronica] Univ Manitoba, Dept Linguist, Winnipeg, MB, Canada.
RP Seo, SH (reprint author), Univ Manitoba, Dept Comp Sci, Winnipeg, MB, Canada.
EM stela.seo@cs.umanitoba.ca; umgrif37@myumanitoba.ca;
   young@cs.umanitoba.ca; bunt@cs.umanitoba.ca;
   Susan.Prentice@umanitoba.ca; V.Loureiro-rodriguez@umanitoba.ca
CR Adel A, 2011, J PRAGMATICS, V43, P2932, DOI 10.1016/j.pragma.2011.05.007
   Argyle M, 1990, PSYCHOL INQ, V1, P297, DOI DOI 10.1207/S15327965PLI0104_3
   Basow SA, 2003, SEX ROLES, V48, P183, DOI 10.1023/A:1022411623948
   Bernieri FJ, 1996, J PERS SOC PSYCHOL, V71, P110, DOI 10.1037/0022-3514.71.1.110
   Bickmore T. W., 2005, ACM Transactions on Computer-Human Interaction, V12, P293, DOI 10.1145/1067860.1067867
   Bohus D, 2010, INT C MULT INT WORKS, P1
   Bronstein I, 2012, J CONFLICT RESOLUT, V56, P1089, DOI 10.1177/0022002712448913
   Cakmak M, 2012, ACMIEEE INT CONF HUM, P17
   Chao C, 2012, J HUM-ROBOT INTERACT, V1, P4, DOI 10.5898/JHRI.1.1.Chao
   Driskell T, 2013, GROUP DYN-THEOR RES, V17, P1, DOI 10.1037/a0029686
   Eagly AH, 2009, AM PSYCHOL, V64, P644, DOI 10.1037/0003-066X.64.8.644
   Eyssel F, 2012, J APPL SOC PSYCHOL, V42, P2213, DOI 10.1111/j.1559-1816.2012.00937.x
   Gratch J, 2007, LECT NOTES ARTIF INT, V4722, P125
   Gratch J, 2006, LECT NOTES ARTIF INT, V4133, P14
   Gremler DD, 2008, J RETAILING, V84, P308, DOI 10.1016/j.jretai.2008.07.001
   Haddadi A, 2013, IEEE INT CONF ROBOT, P2146, DOI 10.1109/ICRA.2013.6630865
   Haferd T, 2013, WANT WORK YOU FUTURE
   Hawkins KP, 2014, IEEE INT CONF ROBOT, P2215, DOI 10.1109/ICRA.2014.6907165
   HAYASHI K, 2007, P ACM IEEE INT C HUM, P137
   Hoffman G., 2004, P AIAA 1 INT SYST TE, DOI [10.2514/6.2004-6434, DOI 10.2514/6.2004-6434]
   Huang CM, 2013, P ROB SCI SYST BERL, V2013, P26
   Jung MF, 2015, ACMIEEE INT CONF HUM, P229, DOI 10.1145/2696454.2696460
   Kanda T., 2009, 2009 4th ACM/IEEE International Conference on Human-Robot Interaction (HRI), P173
   Kato Y, 2015, ACMIEEE INT CONF HUM, P35, DOI 10.1145/2696454.2696463
   Kay R., 2006, Journal of Educational Computing Research, V34, P187, DOI 10.2190/9BLQ-883Y-XQMA-FCAH
   Lee MK, 2012, ACMIEEE INT CONF HUM, P319
   Lixing Huang, 2011, Intelligent Virtual Agents. Proceedings 11th International Conference, IVA 2011, P68, DOI 10.1007/978-3-642-23974-8_8
   Melder WA, 2007, P INT WORKSH HUM CTR, P31, DOI DOI 10.1145/1290128.1290134
   Moon A, 2013, J HUM-ROBOT INTERACT, V2, P18, DOI 10.5898/JHRI.2.3.Moon
   Morris MG, 2005, IEEE T ENG MANAGE, V52, P69, DOI 10.1109/TEM.2004.839967
   Morrison RL, 2009, SEX ROLES, V60, P1, DOI 10.1007/s11199-008-9513-4
   Mulac A, 2001, HUM COMMUN RES, V27, P121, DOI 10.1093/hcr/27.1.121
   Mutlu B, 2009, P 4 ACM IEEE INT C H, P61, DOI [10. 1145/1514095. 1514109, DOI 10.1145/1514095.1514109]
   Niculescu A., 2011, Proceedings of the 2011 International Conference on User Science and Engineering (i-USEr 2011), P18, DOI 10.1109/iUSEr.2011.6150529
   Niculescu A, 2013, INT J SOC ROBOT, V5, P171, DOI 10.1007/s12369-012-0171-x
   Nomura T, 2014, P ACM IEEE INT C HUM, P383
   Nomura T, 2013, ACMIEEE INT CONF HUM, P201, DOI 10.1109/HRI.2013.6483571
   Rea DJ, 2015, P INT C SOC ROB ICSR
   Reysen S, 2005, SOC BEHAV PERSONAL, V33, P201, DOI 10.2224/sbp.2005.33.2.201
   Sakamoto D., 2006, 1st Annual Conference on Human-Robot Interaction, P355
   Seo SH, 2015, P ACM INT C HUM AG I
   Seo SH, 2015, ACMIEEE INT CONF HUM, P125, DOI 10.1145/2696454.2696471
   Shah J, 2011, ACMIEEE INT CONF HUM, P29, DOI 10.1145/1957656.1957668
   Shibata T, 2012, INT J SOC ROBOT, V4, P53, DOI 10.1007/s12369-011-0111-1
   Short E, 2010, ACMIEEE INT CONF HUM, P219, DOI 10.1109/HRI.2010.5453193
   Strabala K, 2013, J HUM-ROBOT INTERACT, V2, P112, DOI 10.5898/JHRI.2.1.Strabala
   Sung JY, 2007, LECT NOTES COMPUT SC, V4717, P145
   Tickle-Degnen L, 1990, PSYCHOL INQ, V1, P285, DOI DOI 10.1207/S15327965PLI0104_
   Venkatesh V, 2003, MIS QUART, V27, P425
   Wang Y, 2014, EUROPEAN SOC SOCIALL, P49
   Young JE, 2011, INT J SOC ROBOT, V3, P53, DOI 10.1007/s12369-010-0081-8
NR 51
TC 1
Z9 1
U1 3
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1875-4791
EI 1875-4805
J9 INT J SOC ROBOT
JI Int. J. Soc. Robot.
PD JAN
PY 2018
VL 10
IS 1
BP 147
EP 161
DI 10.1007/s12369-017-0441-8
PG 15
WC Robotics
SC Robotics
GA FT4VI
UT WOS:000423152900010
DA 2019-02-18
ER

PT J
AU Dziergwa, M
   Kaczmarek, M
   Kaczmarek, P
   Kedzierski, J
   Wadas-Szydlowska, K
AF Dziergwa, Michal
   Kaczmarek, Mirela
   Kaczmarek, Pawel
   Kedzierski, Jan
   Wadas-Szydlowska, Karolina
TI Long-Term Cohabitation with a Social Robot: A Case Study of the
   Influence of Human Attachment Patterns
SO INTERNATIONAL JOURNAL OF SOCIAL ROBOTICS
LA English
DT Article; Proceedings Paper
CT 9th International Conference on Social Robotics (ICSR)
CY NOV 22-24, 2017
CL Tsukuba, JAPAN
DE Social robot; Robot control; Emotions; Long-term study; HRI; Attachment
   theory
ID DESIGN
AB This paper presents the methodology, setup and results of a study involving long-term cohabitation with a fully autonomous social robot. During the experiment, three people with different attachment styles (as defined by John Bowlby) spent ten days each with an EMYS type robot, which was installed in their own apartments. It was hypothesized that the attachment patterns represented by the test subjects influence the interaction. In order to provide engaging and non-schematic actions suitable for the experiment requirements, the existing robot control system was modified, which allowed EMYS to become an effective home assistant. Experiment data was gathered using the robot's state logging utility (during the cohabitation period) and in-depth interviews (after the study). Based on the analyzed data, it was concluded that the satisfaction stemming from prolonged cohabitation and the assessment of robot's operation depend on the user's attachment style. Results lead to first robot's behavior personalization guidelines for different user's attachment patterns. The study confirmed readiness of a EMYS robot for satisfying, autonomous, and long-term cohabitation with users.
C1 [Dziergwa, Michal; Kaczmarek, Mirela; Kaczmarek, Pawel; Kedzierski, Jan] Wroclaw Univ Sci & Technol, Wybrzeze Wyspianskiego 27, PL-50370 Wroclaw, Poland.
   [Wadas-Szydlowska, Karolina] SWPS Univ Social Sci & Humanities, Ul Aleksandra Ostrowskiego 30b, PL-53238 Wroclaw, Poland.
RP Dziergwa, M (reprint author), Wroclaw Univ Sci & Technol, Wybrzeze Wyspianskiego 27, PL-50370 Wroclaw, Poland.
EM michal.dziergwa@pwr.edu.pl
FU National Science Centre of Poland [2012/05/N/ST7/01098]
FX This research was supported by Grant No. 2012/05/N/ST7/01098 awarded by
   the National Science Centre of Poland.
CR Becker C, 2007, WHY EMOTIONS SHOULD, P49
   Becker-Asano C., 2008, THESIS
   Bowlby J., 1969, ATTACHMENT LOSS ATTA
   Bowlby J., 1972, ATTACHMENT LOSS SEPA
   Bowlby J., 1980, ATTACHMENT LOSS LOSS
   Bradley M. M., 1999, TECHNICAL REPORT
   Breazeal C, 2005, 2005 IEEE/RSJ International Conference on Intelligent Robots and Systems, Vols 1-4, P383, DOI 10.1109/IROS.2005.1545011
   COLLINS NL, 1990, J PERS SOC PSYCHOL, V58, P644, DOI 10.1037/0022-3514.58.4.644
   Dziergwa M, 2013, LECT NOTES ARTIF INT, V8239, P170, DOI 10.1007/978-3-319-02675-6_17
   EMYS, 2015, US GUID
   EMYS FLASH, 2015, ON DOC
   Esuli A., 2006, P 5 INT C LANG RES E, V6, P417, DOI DOI 10.1155/2015/715730
   Eysenck H. J, 1975, MANUAL EYSENCK PERSO
   Fellbaum C., 1998, WORDNET ELECT LEXICA
   Ferrari Ester, 2009, RO-MAN 2009 - The 18th IEEE International Symposium on Robot and Human Interactive Communication, P108, DOI 10.1109/ROMAN.2009.5326251
   FLASH, 2015, SOC ROB
   Fridin M, 2011, ARCHITECTURAL DESIGN
   Gat E., 1998, ARTIFICIAL INTELLIGE
   Gostai, 2015, URB
   Han J, 2008, J INF PROCESS SYST, V4, P159, DOI 10.3745/JIPS.2008.4.4.159
   Hiolle Antoine, 2009, RO-MAN 2009 - The 18th IEEE International Symposium on Robot and Human Interactive Communication, P251, DOI 10.1109/ROMAN.2009.5326216
   Hiolle A, 2012, ACM T INTERACT INTEL, V2
   Iacovides Joanna, 2011, International Journal of Virtual and Personal Learning Environments, V2, P1, DOI 10.4018/jvple.2011040101
   Janssen Joris B., 2011, Social Robotics. Proceedings Third International Conference (ICSR 2011), P153, DOI 10.1007/978-3-642-25504-5_16
   Kaplan F, 2001, P 2 IEEE RAS INT C H, P99
   Kedzierski J, 2014, THESIS
   Kedzierski J, 2015, INT J HUM ROBOT, V12, DOI 10.1142/S0219843615500073
   Kedzierski J, 2013, INT J SOC ROBOT, V5, P237, DOI 10.1007/s12369-013-0183-1
   Keefer LA, 2012, J EXP SOC PSYCHOL, V48, P912, DOI 10.1016/j.jesp.2012.02.007
   KELLEY JF, 1984, ACM T OFF INF SYST, V2, P26, DOI 10.1145/357417.357420
   Keren G, 2012, IEEE INT C INT ROBOT, P1084, DOI 10.1109/IROS.2012.6385645
   MAULSBY D, 1993, HUMAN FACTORS IN COMPUTING SYSTEMS, P277
   Mehrabian A., 1974, APPROACH ENV PSYCHOL
   Norris JI, 2012, PERS INDIV DIFFER, V53, P666, DOI 10.1016/j.paid.2012.05.009
   Okita Sandra Y, 2009, RO-MAN 2009 - The 18th IEEE International Symposium on Robot and Human Interactive Communication, P1125, DOI 10.1109/ROMAN.2009.5326135
   Ribeiro T, 2012, ACMIEEE INT CONF HUM, P383
   Richardson K, 2015, ANTHR ROBOTS AI ANNI
   Robins B, 2004, DESIGNING A MORE INCLUSIVE WORLD, P225
   Saerbeck M, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1613
   Tanaka F, 2012, J HUM-ROBOT INTERACT, V1, P78, DOI 10.5898/JHRI.1.1.Tanaka
   W3C, 2015, SPEECH REC GRAMM SPE
   Wainer J, 2010, 2010 10th IEEE-RAS International Conference on Humanoid Robots (Humanoids 2010), P631, DOI 10.1109/ICHR.2010.5686346
   Warriner AB, 2013, BEHAV RES METHODS, V45, P1191, DOI 10.3758/s13428-012-0314-x
NR 43
TC 0
Z9 0
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1875-4791
EI 1875-4805
J9 INT J SOC ROBOT
JI Int. J. Soc. Robot.
PD JAN
PY 2018
VL 10
IS 1
BP 163
EP 176
DI 10.1007/s12369-017-0439-2
PG 14
WC Robotics
SC Robotics
GA FT4VI
UT WOS:000423152900011
OA Other Gold
DA 2019-02-18
ER

PT J
AU Di Nuovo, A
   Broz, F
   Wang, N
   Belpaeme, T
   Cangelosi, A
   Jones, R
   Esposito, R
   Cavallo, F
   Dario, P
AF Di Nuovo, Alessandro
   Broz, Frank
   Wang, Ning
   Belpaeme, Tony
   Cangelosi, Angelo
   Jones, Ray
   Esposito, Raffaele
   Cavallo, Filippo
   Dario, Paolo
TI The multi-modal interface of Robot-Era multi-robot services tailored for
   the elderly
SO INTELLIGENT SERVICE ROBOTICS
LA English
DT Article
DE Socially assistive robotics; Human-robot interaction; User-centred
   design; Multi-modal user interface; Elderly care
AB Socially assistive robotic platforms are now a realistic option for the long-term care of ageing populations. Elderly users may benefit from many services provided by robots operating in different environments, such as providing assistance inside apartments, serving in shared facilities of buildings or guiding people outdoors. In this paper, we present the experience gained within the EU FP7 ROBOT-ERA project towards the objective of implementing easy-to-use and acceptable service robotic system for the elderly. In particular, we detail the user-centred design and the experimental evaluation in realistic environments of a web-based multi-modal user interface tailored for elderly users of near future multi-robot services. Experimental results demonstrate positive evaluation of usability and willingness to use by elderly users, especially those less experienced with technological devices who could benefit more from the adoption of robotic services. Further analyses showed how multi-modal modes of interaction support more flexible and natural elderly-robot interaction, make clear the benefits for the users and, therefore, increase its acceptability. Finally, we provide insights and lessons learned from the extensive experimentation, which, to the best of our knowledge, is one of the largest experimentation of a multi-robot multi-service system so far.
C1 [Di Nuovo, Alessandro] Sheffield Hallam Univ, Sheffield Robot, Dept Comp, Sheffield, S Yorkshire, England.
   [Di Nuovo, Alessandro] Univ Enna Kore, Fac Engn & Architecture, Enna, Italy.
   [Broz, Frank] Heriot Watt Univ, Sch Math & Comp Sci, Edinburgh, Midlothian, Scotland.
   [Wang, Ning; Belpaeme, Tony; Cangelosi, Angelo] Plymouth Univ, Sch Comp Elect & Math, Plymouth, Devon, England.
   [Belpaeme, Tony] Univ Ghent, IMEC, IDLab, Ghent, Belgium.
   [Jones, Ray] Plymouth Univ, Sch Nursing & Midwifery, Plymouth, Devon, England.
   [Esposito, Raffaele; Cavallo, Filippo; Dario, Paolo] SSSA, BioRobot Inst, Pisa, Italy.
RP Di Nuovo, A (reprint author), Sheffield Hallam Univ, Sheffield Robot, Dept Comp, Sheffield, S Yorkshire, England.; Di Nuovo, A (reprint author), Univ Enna Kore, Fac Engn & Architecture, Enna, Italy.
EM a.dinuovo@shu.ac.uk; f.broz@hw.ac.uk; ning.wang@plymouth.ac.uk;
   tony.belpaeme@plymouth.ac.uk; a.cangelosi@plymouth.ac.uk;
   ray.jones@plymouth.ac.uk; r.esposito@sssup.it; f.cavallo@sssup.it;
   paolo.dario@sssup.it
OI Broz, Frank/0000-0002-9624-0599; Cavallo, Filippo/0000-0001-7432-5033;
   Cangelosi, Angelo/0000-0002-4709-2243; Di Nuovo,
   Alessandro/0000-0003-2677-2650
FU European Union Seventh Framework Programme [288899]
FX The research leading to these results has received funding from the
   European Union Seventh Framework Programme (FP7/2007-2013) under grant
   agreement no288899.
CR Amirat Y, 2016, ROBOT AUTON SYST, V75, P1, DOI 10.1016/j.robot.2015.11.002
   Bangor A, 2008, INT J HUM-COMPUT INT, V24, P574, DOI 10.1080/10447310802205776
   Bohus D, 2009, COMPUT SPEECH LANG, V23, P332, DOI 10.1016/j.csl.2008.10.001
   Bonaccorsi M, 2015, AMBIENT ASSISTED LIVING: ITALIAN FORUM 2014, P465, DOI 10.1007/978-3-319-18374-9_43
   Broekens Joost, 2009, Gerontechnology, V8, P94
   Brooke J, 1996, USABILITY EVALUATION, V189, P4, DOI DOI 10.1002/HBM.20701
   Broz Frank, 2015, Paladyn, Journal of Behavioral Robotics, V6, P111, DOI 10.1515/pjbr-2015-0007
   Broz F, 2012, WORKSH ROB FEEDB HUM, P1
   Casiddu N., 2013, FORITAAL
   Cavallo F, 2014, COGN COMPUT, V6, P954, DOI 10.1007/s12559-014-9290-z
   Cavallo F, 2013, IEEE INT CONF ROBOT, P4310, DOI 10.1109/ICRA.2013.6631187
   Coeckelbergh M, 2016, SCI ENG ETHICS, V22, P47, DOI 10.1007/s11948-015-9649-x
   Conti D, 2017, INT J SOC ROBOT, V9, P51, DOI 10.1007/s12369-016-0359-6
   de Graaf MMA, 2013, ROBOT AUTON SYST, V61, P1476, DOI 10.1016/j.robot.2013.07.007
   Di Nuovo A, 2016, LECT NOTES ARTIF INT, V9716, P87, DOI 10.1007/978-3-319-40379-3_9
   Di Nuovo A, 2016, INT J SOC ROBOT, V8, P353, DOI 10.1007/s12369-016-0350-2
   Di Nuovo A, 2014, IEEE SYS MAN CYBERN, P2186, DOI 10.1109/SMC.2014.6974248
   Di Rocco M., 2014, 2014 AAAI SPRING S S
   Dumas B, 2009, LECT NOTES COMPUT SC, V5440, P3, DOI 10.1007/978-3-642-00437-7_1
   Einhorn E, 2012, IEEE INT C INT ROBOT, P2591, DOI 10.1109/IROS.2012.6385959
   Eurobarometer S, 2012, PUBL ATT ROB
   Ezer Neta, 2009, Proc Hum Factors Ergon Soc Annu Meet, V53, P136
   Feil-Seifer D, 2005, INT C REHAB ROBOT, P465
   Ferri G, 2010, P IEEE INT C ROB AUT
   Glende S, 2012, 1 REPORT STRUCTURES
   Hawthorn D, 2007, BEHAV INFORM TECHNOL, V26, P333, DOI 10.1080/01449290601176930
   Heerink M, 2010, INT J SOC ROBOT, V2, P361, DOI 10.1007/s12369-010-0068-5
   Heerink M, 2011, ACMIEEE INT CONF HUM, P147, DOI 10.1145/1957656.1957704
   Hertzog C, 1996, RES DESIGN STUDIES A
   Jian C., 2013, COMMUN COMPUT PHYS, V357, P385
   Kleinberger T, 2007, LECT NOTES COMPUT SC, V4555, P103
   Kline P, 2000, HDB PSYCHOL TESTING
   Kristoffersson A, 2013, ADV HUM-COMPUT INTER, DOI 10.1155/2013/902316
   Loureiro B, 2011, INF SYST TECHN CISTI, P1
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Marcellini F., 2013, EXPT PROTOCOL 1 CYCL
   Mayer P, 2012, 3RD IEEE INTERNATIONAL CONFERENCE ON COGNITIVE INFOCOMMUNICATIONS (COGINFOCOM 2012), P401
   Melenhorst AS, 2006, PSYCHOL AGING, V21, P190, DOI 10.1037/0882-7974.21.1.190
   Moon A, 2012, INT J SOC ROBOT, V4, P77, DOI 10.1007/s12369-011-0120-0
   Ofcom, 2014, TECHNICAL REPORT
   Panek P., 2012, ADV TECHNOLOGIES SOC, P77
   Plowman T, 2010, GLOBAL AGING EXPERIE
   Quigley M., 2009, ICRA WORKSH OP SOURC
   Renaud K, 2007, BEHAV INFORM TECHNOL, V26, P309, DOI 10.1080/01449290601173770
   Rousseau GK, 1998, COMPUT HUM BEHAV, V14, P417, DOI 10.1016/S0747-5632(98)00014-4
   Saffiotti A, 2008, 2008 IEEE/RSJ INTERNATIONAL CONFERENCE ON ROBOTS AND INTELLIGENT SYSTEMS, VOLS 1-3, CONFERENCE PROCEEDINGS, P2329, DOI 10.1109/IROS.2008.4650962
   Smarr Cory-Ann, 2012, Proc Hum Factors Ergon Soc Annu Meet, V56, P153
   Tapus A, 2007, IEEE ROBOT AUTOM MAG, V14, P35, DOI 10.1109/MRA.2007.339605
   Torun M, 2012, LECT NOTES COMPUT SC, V7382, P689, DOI 10.1007/978-3-642-31522-0_103
   VanDenBroek G, 2010, AMB INTELL SMART ENV, V6, P1
   Venkatesh V, 2003, MIS QUART, V27, P425
   Wang N, 2016, SMART INNOV SYST TEC, V48, P275, DOI 10.1007/978-3-319-28109-4_28
   Werner F., 2012, AMBIENT ASSISTED LIV, P177, DOI [DOI 10.1007/978-3-642-27491-6_13, 10.1007/978-3-642-27491-6_13]
NR 53
TC 3
Z9 3
U1 2
U2 10
PU SPRINGER HEIDELBERG
PI HEIDELBERG
PA TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY
SN 1861-2776
EI 1861-2784
J9 INTEL SERV ROBOT
JI Intell. Serv. Robot.
PD JAN
PY 2018
VL 11
IS 1
BP 109
EP 126
DI 10.1007/s11370-017-0237-6
PG 18
WC Robotics
SC Robotics
GA FS8KC
UT WOS:000422658900008
OA Other Gold
DA 2019-02-18
ER

PT J
AU Shah, D
   Denicia, E
   Pimentel, T
   Bruno, B
   Mastrogiovanni, F
AF Shah, Divya
   Denicia, Ernesto
   Pimentel, Tiago
   Bruno, Barbara
   Mastrogiovanni, Fulvio
TI Detection of bimanual gestures everywhere: Why it matters, what we need
   and what is missing
SO ROBOTICS AND AUTONOMOUS SYSTEMS
LA English
DT Article
DE Human activity recognition; Gesture recognition; Wearable sensors;
   Inertial sensors
ID TRIAXIAL ACCELEROMETER; COORDINATION; MOVEMENTS; SYSTEM
AB Bimanual gestures are of the utmost importance for the study of motor coordination in humans and in everyday activities. A reliable detection of bimanual gestures in unconstrained environments is fundamental for their clinical study and to assess common activities of daily living. This paper investigates techniques for a reliable, unconstrained detection and classification of bimanual gestures. The work assumes the availability of inertial data originating from the two hands/arms, builds upon a previously developed technique for gesture modeling based on Gaussian Mixture Modeling (GMM) and Gaussian Mixture Regression (GMR), and compares different modeling and classification techniques, which are based on a number of assumptions inspired by literature about how bimanual gestures are represented and modeled in the brain. Experiments show results related to 5 everyday bimanual activities, which have been selected on the basis of three main parameters: (not) constraining the two hands by a physical tool, (not) requiring a specific sequence of single-hand gestures, being recursive (or not). In the best performing combination of modeling approach and classification technique, we achieve overall accuracy, precision, recall and F1-score above 80%. (c) 2017 Elsevier B.V. All rights reserved.
C1 [Shah, Divya; Denicia, Ernesto; Pimentel, Tiago; Bruno, Barbara; Mastrogiovanni, Fulvio] Univ Genoa, Dept Informat Bioengn Robot & Syst Engn, Via Opera Pia 13, I-16145 Genoa, Italy.
RP Bruno, B (reprint author), Univ Genoa, Dept Informat Bioengn Robot & Syst Engn, Via Opera Pia 13, I-16145 Genoa, Italy.
EM barbara.bruno@unige.it
OI Shah, Divya/0000-0002-1246-5556; Bruno, Barbara/0000-0003-0953-7173
CR ANTONSSON EK, 1985, J BIOMECH, V18, P39, DOI 10.1016/0021-9290(85)90043-0
   Baltes PB, 1997, PSYCHOL AGING, V12, P12, DOI 10.1037/0882-7974.12.1.12
   Bernstein N., 1967, COORDINATION REGULAT
   Bonnet S, 2007, IEEE T BIO-MED ENG, V54, P1353, DOI 10.1109/TBME.2007.890742
   Bruno B., 2014, P 15 INT C INF PROC
   Bruno B, 2013, P 2013 IEEE INT C RO
   Bruno B., 2012, P 8 IEEE INT C AUT S
   Bulling A, 2014, ACM COMPUT SURV, V46, DOI 10.1145/2499621
   Byblow WD, 2000, EXP BRAIN RES, V131, P366, DOI 10.1007/s002219900271
   Calinon S, 2010, IEEE ROBOT AUTOM MAG, V17, P44, DOI 10.1109/MRA.2010.936947
   Cho Y., 2008, P 2 INT WORKSH SYST
   Choudhury T, 2008, IEEE PERVAS COMPUT, V7, P32, DOI 10.1109/MPRV.2008.39
   Chul H., 2009, P 2009 INT JOINT C I
   Coronado E., 2017, P 2017 IEEE INT C RO
   Darvish K., 2017, ARXIV170702591
   Dietrich M., 2014, P 2014 ACM INT JOINT
   Gao S., 2016, SOCIAL MEDIA GOOD BA
   HAKEN H, 1985, BIOL CYBERN, V51, P347, DOI 10.1007/BF00336922
   Heuer H, 1998, EXP BRAIN RES, V118, P381, DOI 10.1007/s002210050292
   Karantonis DM, 2006, IEEE T INF TECHNOL B, V10, P156, DOI 10.1109/TITB.2005.856864
   Kelso J. A. S., 1984, AM J PHYSIOL-REG I, V15, P1000, DOI DOI 10.1152/AJPREGU.1984.246.6.R1000
   Kodama K., 2012, PLOS ONE, V10
   Krassnig G., 2010, P 2010 INT C PERV CO
   Lara OD, 2013, IEEE COMMUN SURV TUT, V15, P1192, DOI 10.1109/SURV.2012.110112.00192
   Lee MW, 2011, PERS UBIQUIT COMPUT, V15, P887, DOI 10.1007/s00779-011-0403-3
   Lester J., 2005, P 19 INT JOINT C ART
   Lund ME, 2015, INT BIOMECH, V2, P1, DOI [10.1080/23335432.2014.993706, DOI 10.1080/23335432.2014.993706]
   Mahalanobis PC, 1936, P NATL I SCI INDIA, V12, P49, DOI DOI 10.1145/1390156.1390302
   Mashita T., 2012, P IEEE WORKSH VIRT R
   Mathie MJ, 2004, MED BIOL ENG COMPUT, V42, P679, DOI 10.1007/BF02347551
   Mechsner F, 2001, NATURE, V414, P69, DOI 10.1038/35102060
   Minnen D., 2005, P 2005 IEEE INT C MU
   Olguin D., 2006, P 2006 IEEE INT S WE
   Rosenbaum DA, 2007, HUM MOVEMENT SCI, V26, P525, DOI 10.1016/j.humov.2007.04.001
   ROUSSEEUW PJ, 1987, J COMPUT APPL MATH, V20, P53, DOI 10.1016/0377-0427(87)90125-7
   Sakurada T, 2016, EUR J NEUROSCI, V43, P120, DOI 10.1111/ejn.13123
   Schack T, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00328
   Seon-Woo Lee, 2002, IEEE Pervasive Computing, V1, P24, DOI 10.1109/MPRV.2002.1037719
   Sharma A., 2008, P 2008 INT C MULT FU
   Sleimen-Malkoun R, 2014, FRONT AGING NEUROSCI, V6, DOI 10.3389/fnagi.2014.00140
   Swinnen SP, 2004, TRENDS COGN SCI, V8, P18, DOI 10.1016/j.tics.2003.10.017
   Villani V, 2017, IEEE ROBOT AUTOM LET, V2, P1640, DOI 10.1109/LRA.2017.2678541
   Wiles JL, 2012, GERONTOLOGIST, V52, P357, DOI 10.1093/geront/gnr098
   Zhang ML, 2014, IEEE T KNOWL DATA EN, V26, P1819, DOI 10.1109/TKDE.2013.39
   Zijlstra A, 2012, J NEUROENG REHABIL, V9, DOI 10.1186/1743-0003-9-75
NR 45
TC 0
Z9 0
U1 0
U2 2
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0921-8890
EI 1872-793X
J9 ROBOT AUTON SYST
JI Robot. Auton. Syst.
PD JAN
PY 2018
VL 99
BP 30
EP 49
DI 10.1016/j.robot.2017.09.016
PG 20
WC Automation & Control Systems; Computer Science, Artificial Intelligence;
   Robotics
SC Automation & Control Systems; Computer Science; Robotics
GA FR9TY
UT WOS:000419417200003
DA 2019-02-18
ER

PT J
AU Taniguchi, A
   Taniguchi, T
   Inamura, T
AF Taniguchi, Akira
   Taniguchi, Tadahiro
   Inamura, Tetsunari
TI Unsupervised spatial lexical acquisition by updating a language model
   with place clues
SO ROBOTICS AND AUTONOMOUS SYSTEMS
LA English
DT Article
DE Ambiguous speech recognition; Bayesian nonparametrics; Lexical
   acquisition; Place categorization; Spatial concept acquisition;
   Unsupervised word segmentation
ID LOCALIZATION; RATSLAM; SPEECH; ROBOT
AB This paper describes how to achieve highly accurate unsupervised spatial lexical acquisition from speech-recognition results including phoneme recognition errors. In most research into lexical acquisition, the robot has no pre-existing lexical knowledge. The robot acquires sequences of some phonemes as words from continuous speech signals. In a previous study, we proposed a nonparametric Bayesian spatial concept acquisition method (SpCoA) that integrates the robot's position and words obtained by unsupervised word segmentation from uncertain syllable recognition results. However, SpCoA has a very critical problem to be solved in lexical acquisition; the boundaries of word segmentation are incorrect in many cases because of many phoneme recognition errors. Therefore, we propose an unsupervised machine learning method (SpCoA++) for the robust lexical acquisition of novel words relating to places visited by the robot. The proposed SpCoA++ method performs an iterative estimation of learning spatial concepts and updating a language model using place information. SpCoA++ can select a candidate including many words that better represent places from multiple word-segmentation results by maximizing the mutual information between segmented words and spatial concepts. The experimental results demonstrate a significant improvement of the phoneme accuracy rate of learned words relating to place in the proposed method by word-segmentation results based on place information, in comparison to the conventional methods. We indicate that the proposed method enables the robot to acquire words from speech signals more accurately, and improves the estimation accuracy of the spatial concepts. (c) 2017 Elsevier B.V. All rights reserved.
C1 [Taniguchi, Akira; Taniguchi, Tadahiro] Ritsumeikan Univ, 1-1-1 Noji Higashi, Kusatsu, Shiga 5258577, Japan.
   [Inamura, Tetsunari] Grad Univ Adv Studies, Natl Inst Informat, Chiyoda Ku, 2-1-2 Hitotsubashi, Tokyo 1018430, Japan.
RP Taniguchi, A (reprint author), Ritsumeikan Univ, 1-1-1 Noji Higashi, Kusatsu, Shiga 5258577, Japan.
EM a.taniguchi@em.ci.ritsumei.ac.jp; taniguchi@em.ci.ritsumei.ac.jp;
   inamura@nii.ac.jp
FU JST CREST; Ministry of Education, Culture, Sports, Science, and
   Technology, Japan [16H06569]
FX This research was partially supported by JST CREST, and a Grant-in-Aid
   for Scientific Research on Innovative Areas (16H06569) funded by the
   Ministry of Education, Culture, Sports, Science, and Technology, Japan.
CR Ando Y, 2013, IEEE INT C INT ROBOT, P2272, DOI 10.1109/IROS.2013.6696674
   Araki T, 2012, IEEE INT C INT ROBOT, P1623, DOI 10.1109/IROS.2012.6385812
   Attamimi M, 2010, IEEE INT CONF ROBOT, P745, DOI 10.1109/ROBOT.2010.5509417
   Bastianelli E., 2013, P 16 INT C ADV ROB I
   Bastianelli E., 2016, P INT JOINT C ART IN, P2747
   Cummins M, 2008, INT J ROBOT RES, V27, P647, DOI 10.1177/0278364908090961
   Dellaert F, 1999, ICRA '99: IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS 1-4, PROCEEDINGS, P1322, DOI 10.1109/ROBOT.1999.772544
   Fox EB, 2011, ANN APPL STAT, V5, P1020, DOI 10.1214/10-AOAS395
   Gildea D., 1999, P 6 EUR C SPEECH COM
   Gillick L., 1989, ICASSP-89: 1989 International Conference on Acoustics, Speech and Signal Processing (IEEE Cat. No.89CH2673-2), P532, DOI 10.1109/ICASSP.1989.266481
   Goldwater S, 2009, COGNITION, V112, P21, DOI 10.1016/j.cognition.2009.03.008
   Hagiwara Y., 2016, P 13 IFAC IFIP IFORS
   Heath S, 2016, IEEE T COGN DEV SYST, V8, P3, DOI 10.1109/TAMD.2015.2442619
   Heath S, 2013, IEEE INT CONF ROBOT, P490, DOI 10.1109/ICRA.2013.6630619
   Heymann J., 2014, P INT C AC SPEECH SI
   Hornstein J, 2010, STUD COMPUT INTELL, V264, P467
   HUBERT L, 1985, J CLASSIF, V2, P193, DOI 10.1007/BF01908075
   Inamura T, 2010, Proceedings of the 2010 IEEE/SICE International Symposium on System Integration (SII 2010), P212, DOI 10.1109/SII.2010.5708327
   Ishibushi S, 2015, IEEE IND ELEC, P1369, DOI 10.1109/IECON.2015.7392291
   Iwahashi N, 2003, INFORM SCIENCES, V156, P109, DOI 10.1016/S0020-0255(03)00167-0
   Iwahashi N., 2009, P INT S SPEECH LANG, P532
   Iwahashi N, 2007, HUMAN ROBOT INTERACT, P95
   Kawahara T., 1998, P 5 INT C SPOK LANG
   Kitagawa G, 2014, ANN I STAT MATH, V66, P443, DOI 10.1007/s10463-014-0446-0
   Kostavelis I, 2015, ROBOT AUTON SYST, V66, P86, DOI 10.1016/j.robot.2014.12.006
   Krizhevsky A., 2012, ADV NEUR INFORM PROC, P1097, DOI DOI 10.1145/3065386
   Lee A., 2001, P EUR C SPEECH COMM
   Mikolov T, 2013, ARXIV13013781
   Milford M, 2007, ROBOT AUTON SYST, V55, P403, DOI 10.1016/j.robot.2006.12.006
   Milford MJ, 2004, IEEE INT CONF ROBOT, P403, DOI 10.1109/ROBOT.2004.1307183
   Mochihashi D., 2009, P JOINT C 47 ANN M A, P100
   Nakamura T, 2014, IEEE INT C INT ROBOT, P600, DOI 10.1109/IROS.2014.6942621
   Nakamura T, 2013, IEEE INT C INT ROBOT, P157, DOI 10.1109/IROS.2013.6696347
   Nakamura T, 2011, ADV ROBOTICS, V25, P2189, DOI 10.1163/016918611X595035
   Neubig G, 2012, IEICE T INF SYST, VE95D, P614, DOI 10.1587/transinf.E95.D.614
   Qu S., 2008, P C EMP METH NAT LAN, P244
   Qu SL, 2010, J ARTIF INTELL RES, V37, P247, DOI 10.1613/jair.2912
   Roy DK, 2002, COGNITIVE SCI, V26, P113, DOI 10.1016/S0364-0213(01)00061-1
   Schulz R, 2011, ADAPT BEHAV, V19, P409, DOI 10.1177/1059712311421437
   Schulz R, 2011, IEEE T AUTON MENT DE, V3, P163, DOI 10.1109/TAMD.2010.2103361
   SETHURAMAN J, 1994, STAT SINICA, V4, P639
   Spranger M, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1909
   Taguchi R., 2009, P INTERSPEECH2009, P2731
   Taguchi R., 2011, INTERSPEECH, P1325
   Taguchi R., 2012, HUMAN MACHINE INTERA, P69
   Taniguchi A., 2016, P 13 IFAC IFIP IFORS
   Taniguchi A, 2016, IEEE T COGN DEV SYST, V8, P285, DOI 10.1109/TCDS.2016.2565542
   Thrun S., 2005, PROBABILISTIC ROBOTI
   Walter M.R., 2013, P ROB SCI SYST RSS
   Welke K, 2013, IEEE-RAS INT C HUMAN, P484, DOI 10.1109/HUMANOIDS.2013.7030018
NR 50
TC 0
Z9 0
U1 1
U2 1
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0921-8890
EI 1872-793X
J9 ROBOT AUTON SYST
JI Robot. Auton. Syst.
PD JAN
PY 2018
VL 99
BP 166
EP 180
DI 10.1016/j.robot.2017.10.013
PG 15
WC Automation & Control Systems; Computer Science, Artificial Intelligence;
   Robotics
SC Automation & Control Systems; Computer Science; Robotics
GA FR9TY
UT WOS:000419417200013
DA 2019-02-18
ER

EF